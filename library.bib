Automatically generated by Mendeley Desktop 1.19.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Cesarini1997,
abstract = {Much attention has recently been paid to the recognition of graphical objects, such as company logos and trademarks. Recognizing these objects facilitates the recognition of document classes. Some promising results have been achieved by using autoassociator-based artificial neural networks (AANN) in the presence of homogeneously distributed noise. However, the performance drops significantly when dealing with spot-noisy logos, where strips or blobs produce a partial obstruction of the pictures. We propose a new approach for training AANNs especially conceived for dealing with spot noise. The basic idea is to introduce new metrics for assessing the reproduction error in AANNs. The proposed algorithm, referred to as spot-backpropagation (S-BP), is significantly more robust with respect to spot-noise than classical Euclidean norm-based backpropagation (BP). Our experimental results are based on a database of 88 real logos that are artificially corrupted by spot-noise},
author = {Cesarini, F. and Francesconi, E. and Gori, M. and Marinai, S. and Sheng, J.Q. and Soda, G},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition},
xxurl = {10.1109/ICDAR.1997.619836},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cesarini et al. - 1997 - A neural-based architecture for spot-noisy logo recognition.pdf:pdf},
isbn = {0-8186-7898-4},
keywords = {Auto-associator,Image defect models,Logo recognition,Neural networks,Sobel operator,Spot Backpropagation,Spot noise},
pages = {175--179},
title = {{A neural-based architecture for spot-noisy logo recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=619836{\%}5Cnhttp://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=619836},
volume = {1},
year = {1997}
}
@article{Cheng2018,
abstract = {To increase the flexibility and scalability of deep neural networks for image reconstruction, a framework is proposed based on bandpass filtering. For many applications, sensing measurements are performed indirectly. For example, in magnetic resonance imaging, data are sampled in the frequency domain. The introduction of bandpass filtering enables leveraging known imaging physics while ensuring that the final reconstruction is consistent with actual measurements to maintain reconstruction accuracy. We demonstrate this flexible architecture for reconstructing subsampled datasets of MRI scans. The resulting high subsampling rates increase the speed of MRI acquisitions and enable the visualization rapid hemodynamics.},
archivePrefix = {arXiv},
arxivId = {1805.03300},
author = {Cheng, Joseph Y. and Chen, Feiyu and Alley, Marcus T. and Pauly, John M. and Vasanawala, Shreyas S.},
eprint = {1805.03300},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng et al. - 2018 - Highly Scalable Image Reconstruction using Deep Neural Networks with Bandpass Filtering.pdf:pdf},
pages = {1--9},
title = {{Highly Scalable Image Reconstruction using Deep Neural Networks with Bandpass Filtering}},
url = {http://arxiv.org/abs/1805.03300},
year = {2018}
}
@article{Norouzi2011,
abstract = {Abstract  In annual grasslands that experience a mediterranean-type climate, the synchrony between plant senescence and peak solar radiation over summer results in high litter sun exposure. We examined the decomposition of both shaded and sun-exposed litter over summer and inferred the effects of photodegradation from changes in mass loss and litter chemistry. The carry-over effects of summer litter exposure on wet season decomposition were also assessed, and the attenuation of photodegradation with litter layer thickness was used to estimate the proportion of grass litter lignin susceptible to photodegradation under different treatments of a factorial global change experiment. Over summer, mass loss from grass and forb litter exposed to ambient sunlight ranged from 8{\%} to 10{\%}, whereas lignin decreased in grass litter by approximately 20{\%}. After one year of decomposition, mass losses from grass leaves exposed to sunlight over summer were more than double the mass losses from summer-shaded leaves. When shade litter layer thickness was varied, mass losses over summer for all treatments were also approximately 8{\%}; however, lignin decreased significantly only in the low shade treatments (064 g m2 of shade litter). Aboveground production of annual grasses nearly quadrupled in response to the combined effects of N addition, elevated atmospheric CO2, increased precipitation and warming. The estimated proportion of grass litter lignin experiencing full photodegradation ranged from 100{\%} under ambient conditions to 3162{\%} in plots receiving the combined global change treatments. These results reveal an important role of sun exposure over summer in accelerating litter decomposition in these grasslands and provide evidence that future changes in the quantity of litter deposition may modulate the influence of photodegradation integrated across the litter layer.},
author = {Norouzi, Mohammad and Blei, Dm and Fleet, David},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Norouzi, Blei, Fleet - 2011 - Minimal Loss Hashing for Compact Binary Codes.pdf:pdf},
isbn = {978-1-4503-0619-5},
journal = {Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
pages = {353--360},
title = {{Minimal Loss Hashing for Compact Binary Codes}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/ICML2011Norouzi{\_}246.pdf},
year = {2011}
}
@article{Krishnan2013,
author = {Krishnan, Praveen and Jawahar, C.V.},
xxurl = {10.1109/ICDAR.2013.150},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krishnan, Jawahar - 2013 - Bringing Semantics in Word Image Retrieval.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {bag of,semantic indexing,word image retrieval},
month = {aug},
pages = {733--737},
publisher = {Ieee},
title = {{Bringing Semantics in Word Image Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628715},
year = {2013}
}
@article{Idika2013,
author = {Idika, Nwokedi and Phan, Harry and Varia, Mayank},
xxurl = {10.1109/ICDAR.2013.133},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Idika, Phan, Varia - 2013 - Achieving Linguistic Provenance via Plagiarism Detection.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-provenance,graphs,plagiarism detection},
month = {aug},
pages = {648--652},
publisher = {Ieee},
title = {{Achieving Linguistic Provenance via Plagiarism Detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628698},
year = {2013}
}
@article{Flow2002,
author = {Flow, Measuring Fluid and Spinners, Continuous and Bore, Full and Meters, Flow and Meters, Diverting Flow and Format, Log and Speed, Cable and Conventions, Sign and Principles, Fluid Flow and Tools, Radioactive Tracer and Logging, Oxygen Activation and Activation, Oxygen and Example, Log and Water, Schlumberger and Log, Flow and Principles, Operating and Oxygen, Stationary and Example, Activation and Oxygen, Stationary and Example, Activation},
file = {:home/mondal/Documents/MATHS/Alg{\_}Complete.pdf:pdf},
number = {July},
pages = {1--12},
title = {{Table of Contents Table of Contents ی ﺮ ﺘ ﮐ د ﻪ ﺒ ﺣ ﺎ ﺼ ﻣ ر د ﺎ ﻫ ز ﺎ ﯿ ﺘ ﻣ ا ﻪ ﺴ ﯾ ﺎ ﻘ ﻣ ) ؟ ﻢ ﻨ ﮐ پ ﺎ ﭼ ب ﺎ ﺘ ﮐ ﺪ ﯾ ﺎ ﺑ ا ﺮ ﭼ )}},
year = {2002}
}
@article{Thillou2004,
author = {Thillou, C},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thillou - 2004 - Degraded Character Recognition Read Wavelet based.pdf:pdf},
journal = {DEA Report},
title = {{Degraded Character Recognition : Read Wavelet based}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?xxurl=10.1.1.93.972{\&}rep=rep1{\&}type=pdf},
year = {2004}
}
@article{Schambach2013,
author = {Schambach, Marc-Peter and Rashid, Sheikh Faisal},
xxurl = {10.1109/ICDAR.2013.257},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schambach, Rashid - 2013 - Stabilize Sequence Learning with Recurrent Neural Networks by Forced Alignment.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1270--1274},
publisher = {Ieee},
title = {{Stabilize Sequence Learning with Recurrent Neural Networks by Forced Alignment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628818},
year = {2013}
}
@article{Mosa2015,
abstract = {{\textcopyright} 2005 - 2015 JATIT  {\&}  LLS. All rights reserved. The presence of a large number of broken characters in a digital document image represents the main problem in Optical Character Recognition (OCR) of historical documents. This problem still continues a challenge for recent OCR solutions. Broken character restoration from historical documents it is substantial because these documents contain important facts and leaving them leads to losing invaluable information. Gradient Vector Flow (GVF) snake has much more capture range than traditional snake therefore widely used in image segmentation. In this paper we used balloon with triangle steps to improve GVF snake to converge of deep concavity area and Restore broken characters using the improved GVF.},
author = {Mosa, Qusay O. and Nasrudin, Mohammad F.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mosa, Nasrudin - 2015 - Broken character restoration using gradient vector flow and balloon force algorithm.pdf:pdf},
issn = {18173195},
journal = {Journal of Theoretical and Applied Information Technology},
keywords = {Balloon force,Deep concavity,Divergence,GVF,Snake algorithm},
number = {3},
pages = {441--446},
title = {{Broken character restoration using gradient vector flow and balloon force algorithm}},
volume = {73},
year = {2015}
}
@inproceedings{Keogh2005a,
abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. Discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.},
author = {Keogh, Eamonn and Lin, Jessica and Fu, Ada},
booktitle = {Fifth IEEE International Conference on Data Mining (ICDM'05)},
xxurl = {10.1109/ICDM.2005.79},
isbn = {0-7695-2278-5},
issn = {15504786},
keywords = {Anomaly detection,Clustering,Time series data mining},
pages = {226--233},
publisher = {IEEE},
title = {{HOT SAX: Efficiently Finding the Most Unusual Time Series Subsequence}},
url = {http://ieeexplore.ieee.org/document/1565683/},
year = {2005}
}
@article{Leydier2007a,
author = {Leydier, Yann and Lebourgeois, Frank and Emptoz, Hubert},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydier, Lebourgeois, Emptoz - 2007 - Text search for medieval manuscript images.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {medieval manuscripts,word-spotting},
month = {dec},
number = {12},
pages = {3552--3567},
title = {{Text search for medieval manuscript images}},
volume = {40},
year = {2007}
}
@article{Romero2013,
author = {Romero, Veronica and Sanchez, Joan Andreu},
xxurl = {10.1109/ICDAR.2013.161},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Romero, Sanchez - 2013 - Category-Based Language Models for Handwriting Recognition of Marriage License Books.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {788--792},
publisher = {Ieee},
title = {{Category-Based Language Models for Handwriting Recognition of Marriage License Books}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628726},
year = {2013}
}
@article{Sriraghavendra,
author = {Sriraghavendra, R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sriraghavendra - Unknown - Fr ´ echet Distance based Approach for Searching Online Handwritten Documents.pdf:pdf},
journal = {Science},
title = {{Fr ´ echet Distance based Approach for Searching Online Handwritten Documents}}
}
@article{Neumann2002,
abstract = {A comparison is made of global and local methods for the shape analysis of logos in an image database. The qualities of the methods are judged by using the shape signatures to define a similarity metric on the logos. As representatives for the two classes of methods, we use the negative shape method which is based on local shape information and a wavelet-based method which makes use of global information. We apply both methods to images with different kinds of degradations and examine how a particular degradation highlights the strengths and shortcomings of each method. Finally, we use these results to develop a new adaptive weighting scheme which is based on the relative performances of the two methods. This scheme gives rise to a new method that is much more robust with respect to all degradations examined and works by automatically predicting if the negative shape or wavelet method is performing better. ?? 2002 Elsevier Science B.V. All rights reserved.},
author = {Neumann, Jan and Samet, Hanan and Soffer, Aya},
xxurl = {10.1016/S0167-8655(02)00105-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neumann, Samet, Soffer - 2002 - Integration of local and global shape analysis for logo classification.pdf:pdf},
isbn = {0167-8655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Image databases,Logos,Shape recognition,Shape representation,Symbol recognition},
number = {12},
pages = {1449--1457},
title = {{Integration of local and global shape analysis for logo classification}},
volume = {23},
year = {2002}
}
@article{Bresler2013,
author = {Bresler, Martin and Prua, Daniel and Hlavac, Vaclav},
xxurl = {10.1109/ICDAR.2013.246},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bresler, Prua, Hlavac - 2013 - Modeling Flowchart Structure Recognition as a Max-Sum Problem.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1215--1219},
publisher = {Ieee},
title = {{Modeling Flowchart Structure Recognition as a Max-Sum Problem}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628807},
year = {2013}
}
@article{Harris1988,
abstract = {Consistency of image edge filtering is of prime importance for 3D interpretation of image sequences using feature tracking algorithms. To cater for image regions containing texture and isolated features, a combined corner and edge detector based on the local auto-correlation function is utilised, and it is shown to perform with good consistency on natural imagery.},
author = {Harris, Chris and Stephens, Mike},
journal = {Proc 4th Alvey Vision Conference},
title = {{A combined edge and corner detector}},
year = {1988}
}
@article{Bouillon2013,
author = {Bouillon, Manuel and Li, Peiyu and Anquetil, Eric and Richard, Gregoire},
xxurl = {10.1109/ICDAR.2013.204},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouillon et al. - 2013 - Using Confusion Reject to Improve (User and) System (Cross) Learning of Gesture Commands.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {1},
pages = {1017--1021},
publisher = {Ieee},
title = {{Using Confusion Reject to Improve (User and) System (Cross) Learning of Gesture Commands}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628769},
year = {2013}
}
@article{Mack2007,
abstract = {OBJECTIVE Deep hypothermic circulatory arrest is a useful adjunct for treating complex aneurysms. Decreased cerebral metabolism and resultant ischemic tolerance create an environment suitable for devascularizing high-risk lesions. However, the advent of modern imaging modalities, innovative cerebral revascularization strategies, and the emergence of endovascular stenting and coiling limit the number of aneurysms requiring this surgical intervention. We present 66 patients with intracranial aneurysms who underwent surgical clipping under deep hypothermic arrest and attempt to identify patients well-suited for this procedure. METHODS This study was conducted during a 15-year period and examined patients with aneurysms of the anterior and posterior cerebral circulation. Demographics, aneurysm characteristics, and surgical factors were evaluated as predictors of functional outcome. RESULTS Patient age and the duration of cardiac arrest were independent predictors of early clinical outcome (P {\textless} 0.05). Our experience suggests that the ideal patient is younger than 60 years old and harbors few medical comorbidities. Individuals with large aneurysms of the anterior communicating artery, internal carotid artery bifurcation, posterior inferior cerebellar artery, midbasilar, or vertebral arteries and with an absence of thrombosis and calcium may be most likely to experience favorable outcomes. Circulatory arrest should not exceed 30 minutes. Postoperative computed tomographic scanning and timely anesthetic emergence allow for early detection of hemorrhage. Complete dissection of the aneurysm before bypass and avoiding extreme hypothermia yield a low incidence of life-threatening postoperative hematomas. CONCLUSION Hypothermic circulatory arrest is a useful technique for neuroprotection during the clipping of complex cerebral aneurysms. This procedure, however, has several associated risks. Patient factors, pathoanatomic characteristics, and surgical parameters may be used to guide patient selection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.7522v4},
author = {Mack, William J. and Ducruet, Andrew F. and Angevine, Peter D. and Komotar, Ricardo J. and Shrebnick, Debra B. and Edwards, Niloo M. and Smith, Craig R. and Heyer, Eric J. and Monyero, Linda and Connolly, E. Sander and Solomon, Robert A.},
xxurl = {10.1227/01.NEU.0000255452.20602.C9},
eprint = {arXiv:1412.7522v4},
isbn = {0148-396X},
issn = {0148396X},
journal = {Neurosurgery},
keywords = {Aneurysm,Circulatory arrest,Hypothermia},
pmid = {17460516},
title = {{Learning to protect communications with adversarial neual cryptography}},
year = {2007}
}
@article{Clark2002,
author = {Clark, Paul and Mirmehdi, Majid},
xxurl = {10.1007/s10032-001-0072-2},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition},
month = {jul},
number = {4},
pages = {243--257},
title = {{Recognising text in real scenes}},
url = {http://link.springer.com/10.1007/s10032-001-0072-2},
volume = {4},
year = {2002}
}
@article{Newell2014,
abstract = {We describe how oriented Basic Image Feature Columns (oBIF Columns) can be used for writer identification and how this texture-based scheme can be enhanced by encoding a writer's style as the deviation from the mean encoding for a population of writers. We hypothesise that this deviation, the Delta encoding, provides a more informative encoding than the texture-based encoding alone. The methods have been evaluated using the IAM dataset and by making entries to two top international competitions for assessing the state-of-the-art in writer identification. We demonstrate that the oBIF Column scheme on its own is sufficient to gain a performance level of 99{\%} when tested using 300 writers from the IAM dataset. However, on the more challenging competition datasets, significantly improved performance was obtained using the Delta encoding scheme, which achieved first place in both competitions. In our characterisation of the Delta encoding, we demonstrate that the method is making use of information contained in the correlation between the written style of different textual elements, which may not be used by other methods. {\textcopyright} 2013 Elsevier Ltd.},
author = {Newell, Andrew J. and Griffin, Lewis D.},
xxurl = {10.1016/j.patcog.2013.11.029},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newell, Griffin - 2014 - Writer identification using oriented Basic Image Features and the Delta encoding.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Delta encoding,Handwriting,Texture,Writer identification,oBIF Columns},
number = {6},
pages = {2255--2265},
title = {{Writer identification using oriented Basic Image Features and the Delta encoding}},
volume = {47},
year = {2014}
}
@article{Wei2009,
abstract = {A trademark image retrieval (TIR) system is proposed in this work to deal with the vast number of trademark images in the trademark registration system. The proposed approach commences with the extraction of edges using the Canny edge detector, performs a shape normalisation procedure, and then extracts the global and local features. The global features capture the gross essence of the shapes while the local features describe the interior details of the trademarks. A two-component feature matching strategy is used to measure the similarity between the query and database images. The performance of the proposed algorithm is compared against four other algorithms. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Wei, Chia Hung and Li, Yue and Chau, Wing Yin and Li, Chang Tsun},
xxurl = {10.1016/j.patcog.2008.08.019},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei et al. - 2009 - Trademark image retrieval using synthetic features for describing global shape and interior structure.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Content-based image retrieval,Feature extraction,Multimedia database,Trademark image retrieval,Zernike moments},
number = {3},
pages = {386--394},
title = {{Trademark image retrieval using synthetic features for describing global shape and interior structure}},
volume = {42},
year = {2009}
}
@article{Papandreou2013,
author = {Papandreou, a. and Gatos, B.},
xxurl = {10.1109/ICDAR.2013.52},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papandreou, Gatos - 2013 - A Coarse to Fine Skew Estimation Technique for Handwritten Words.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {225--229},
publisher = {Ieee},
title = {{A Coarse to Fine Skew Estimation Technique for Handwritten Words}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628617},
year = {2013}
}
@article{Gerig1992,
abstract = {In contrast to acquisition-based noise reduction methods a postprocess based on anisotropic diffusion is proposed. Extensions of this technique support 3-D and multiecho magnetic resonance imaging (MRI), incorporating higher spatial and spectral dimensions. The procedure overcomes the major drawbacks of conventional filter methods, namely the blurring of object boundaries and the suppression of fine structural details. The simplicity of the filter algorithm permits an efficient implementation, even on small workstations. The efficient noise reduction and sharpening of object boundaries are demonstrated by applying this image processing technique to 2-D and 3-D spin echo and gradient echo MR data. The potential advantages for MRI, diagnosis, and computerized analysis are discussed in detail.},
author = {Gerig, Guido and Kbler, Olaf and Kikinis, Ron and Jolesz, Ferenc A.},
xxurl = {10.1109/42.141646},
isbn = {0278-0062 (Print)$\backslash$r0278-0062 (Linking)},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
pmid = {18218376},
title = {{Nonlinear Anisotropic Filtering of MRI Data}},
year = {1992}
}
@inproceedings{Alahi2012,
abstract = {A large number of vision applications rely on match-ing keypoints across images. The last decade featured an arms-race towards faster and more robust keypoints and association algorithms: Scale Invariant Feature Trans-form (SIFT)[17], Speed-up Robust Feature (SURF)[4], and more recently Binary Robust Invariant Scalable Keypoints (BRISK)[16] to name a few. These days, the deployment of vision algorithms on smart phones and embedded de-vices with low memory and computation complexity has even upped the ante: the goal is to make descriptors faster to compute, more compact while remaining robust to scale, rotation and noise. To best address the current requirements, we propose a novel keypoint descriptor inspired by the human visual sys-tem and more precisely the retina, coined Fast Retina Key-point (FREAK). A cascade of binary strings is computed by efficiently comparing image intensities over a retinal sam-pling pattern. Our experiments show that FREAKs are in general faster to compute with lower memory load and also more robust than SIFT, SURF or BRISK. They are thus com-petitive alternatives to existing keypoints in particular for embedded applications.},
author = {Alahi, Alexandre and Ortiz, Raphael and Vandergheynst, Pierre},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
xxurl = {10.1109/CVPR.2012.6247715},
isbn = {9781467312264},
issn = {10636919},
pages = {510--517},
title = {{FREAK: Fast retina keypoint}},
year = {2012}
}
@article{Shafait2007,
abstract = {Dewarping of documents captured with hand-held cameras in an uncontrolled environment has triggered a lot of interest in the scientific community over the last few years and many approaches have been proposed. However, there has been no comparative evaluation of different dewarping techniques so far. In an attempt to fill this gap, we have organized a page dewarping contest along with CBDAR 2007. We have created a dataset of 102 documents captured with a hand-held camera and have made it freely available online. We have prepared text-line, text-zone, and ASCII text ground-truth for the documents in this dataset. Three groups participated in the contest with their methods. In this paper we present an overview of the approaches that the participants used, the evaluation measure, and the dataset used in the contest. We report the performance of all participating methods. The evaluation shows that none of the participating methods was statistically significantly better than any other participating method.},
author = {Shafait, Faisal and Breuel, Thomas},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shafait, Breuel - 2007 - Document Image Dewarping Contest.pdf:pdf},
journal = {2nd Int. Workshop on Camera-Based Document Analysis and Recognition (CBDAR-2007), September 22, Curitiba, Brazil.},
pages = {181--188},
title = {{Document Image Dewarping Contest}},
url = {http://www.dfki.de/web/forschung/publikationen/renameFileForDownload?filename=didcontest.pdf{\&}file{\_}id=uploads{\_}58},
year = {2007}
}
@article{Saabni2011,
abstract = {In this paper, we present a novel language-independent algorithm for extracting text-lines from handwrit-ten document images. Our algorithm is based on the seam carving approach for content aware image resizing. We adopted the signed distance transform to generate the energy map, where extreme points indicate the layout of text-lines. Dynamic programming is then used to compute the minimum energy left-to-right paths (seams), which pass along the “middle“ of the text-lines. Each path intersects a set of components, which determine the extracted text-line and estimate its hight. The estimated hight determines the text-line's region, which guides splitting touching components among consecutive lines. Unassigned components that fall within the region of a text-line are added to the components list of the line. The components between two consecutive lines are processed when the two lines are extracted and assigned to the closest text-line, based on the attributes of extracted lines, the sizes and positions of components. Our experimental results on Arabic, Chinese, and English historical documents show that our approach manage to separate multi-skew text blocks into lines at high success rates.},
author = {Saabni, Raid and El-Sana, Jihad},
xxurl = {10.1109/ICDAR.2011.119},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saabni, El-Sana - 2011 - Language-independent text lines extraction using seam carving.pdf:pdf},
isbn = {9780769545202},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {Dynamic programming,Handwriting,Line Extraction,Multilingual,Seam Carving,Signed Distance Transform},
pages = {563--568},
title = {{Language-independent text lines extraction using seam carving}},
year = {2011}
}
@article{Mondal2016,
abstract = {In this paper, a robust method is presented to perform word spotting in degraded handwritten and printed document images. A new sequence matching technique, called the Flexible Sequence Matching (FSM) algorithm, is introduced for this word spotting task. The FSM algorithm was specially designed to incorporate crucial characteristics of other sequence matching algorithms (especially Dynamic Time Warping (DTW), Subsequence DTW (SSDTW), Minimal Variance Matching (MVM) and Continuous Dynamic Programming (CDP)). Along with the characteristics of multiple matching (many-to-one and one-to-many), FSM is strongly capable of skipping existing outliers or noisy elements, regardless of their positions in the target signal. More precisely, in the domain of word spotting, FSM has the ability to retrieve complete words or words that contain only a part of the query. Furthermore, due to its adaptable skipping capability, FSM is less sensitive to local variation in the spelling of words and to local degradation effects within the word image. The multiple matching capability (many-to-one, one-to-many) of FSM helps it addressing the stretching effects of query and/or target images. Moreover, FSM is designed in such a way that with little modification, its architecture can be changed into the architecture of DTW, MVM, and SSDTW and to CDP-like techniques. To illustrate these possibilities for FSM applied to specific cases of word spotting, such as incorrect word segmentation and word-level local variations, we performed experiments on historical handwritten documents and also on historical printed document images. To demonstrate the capabilities of sub-sequence matching, of noise skipping, as well as the ability to work in a multilingual paradigm with local spelling variations, we have considered properly segmented lines of historical handwritten documents in different languages and improperly as well as properly segmented words in printed and handwritten historical documents. From the comparative experimental results shown in this paper, it can be clearly seen that FSM can be equivalent or better than most DTW-based word spotting techniques in the literature while providing at the same time more meaningful correspondences between elements.},
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean Yves and Pal, Umapada},
xxurl = {10.1016/j.patcog.2016.05.011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2016 - Flexible Sequence Matching technique An effective learning-free approach for word spotting.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Continuous Dynamic Programming (CDP),Dynamic Time Warping (DTW),Flexible Sequence Matching (FSM),George Washington dataset,Handwritten documents,Historical documents,Minimal Variance Matching (MVM),Printed documents,Subsequence DTW (SSDTW),Word spotting},
pages = {596--612},
publisher = {Elsevier},
title = {{Flexible Sequence Matching technique: An effective learning-free approach for word spotting}},
volume = {60},
year = {2016}
}
@article{Tian2015,
abstract = {Shape restoration for characters in video is challenging because natural scene characters usually suffer from low resolution, complex background and perspective distortion. In this paper, we propose histogram gradient division and reverse gradient orientation in a new way to select Text Pixel Candidates (TPC) for a given input character. We apply a ring radius transform on TPC in different directions, namely, horizontal, vertical, principal and secondary diagonals in a TPC image to obtain respective radius maps, where each pixel is assigned a value that is the radius to the nearest TPC. This helps in finding Medial Axis Points (MAP) by searching for the maximum radius values from their neighborhoods in a radius image. The union of all the medial axis points obtained from the respective directions at each location is considered as Candidate Medial Axis Points (CMAP) of the character. Then color difference and k-means clustering are proposed to eliminate false CMAP, which outputs Potential Medial Axis Points (PMAP). We finally propose a novel way to restore the shape of the character from the PMAP. The method is tested on a video dataset and the benchmark ICDAR 2013 dataset to show its effectiveness for complex background and low resolution. Experimental results show that the proposed method is superior to the existing methods in terms of shape restoration error and recognition rate.},
author = {Tian, Shangxuan and Shivakumara, Palaiahnakote and Phan, Trung Quy and Lu, Tong and Tan, Chew Lim},
xxurl = {10.1016/j.neucom.2015.02.044},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - 2015 - Character shape restoration system through medial axis points in video.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Histogram gradient division,Medial axis points,Reverse gradient orientation,Ring radius transform,Shape restoration,Text pixel candidate},
pages = {183--198},
publisher = {Elsevier},
title = {{Character shape restoration system through medial axis points in video}},
url = {http://dx.xxurl.org/10.1016/j.neucom.2015.02.044},
volume = {161},
year = {2015}
}
@article{DiStefano2001,
author = {{Di Stefano}, Luigi and Mattoccia, Stefano},
xxurl = {10.1007/s00138-002-0070-5},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Di Stefano, Mattoccia - 2001 - Fast template matching using bounded partial correlation.pdf:pdf},
issn = {09328092},
journal = {Machine Vision and Applications},
keywords = {Normalised cross-correlation,PDE,Pattern matching,SEA,Template matching},
number = {4},
pages = {213--221},
title = {{Fast template matching using bounded partial correlation}},
volume = {13},
year = {2001}
}
@article{Huh2018,
author = {Huh, Minyoung and Liu, Andrew and Owens, Andrew and Efros, Alexei},
file = {:home/mondal/Downloads/5b3d98cc17c44a510f801fbc{\_}0.pdf:pdf},
journal = {European Conference on Computer Vision},
keywords = {exif,image splicing,self-supervised learning,visual forensics},
title = {{Fighting Fake News: Image Splice Detection}},
year = {2018}
}
@article{Nixon1989,
abstract = {What is environmental management? This question has many answers that could fill more than just this book. In this chapter, however, we want to give you an overview of a number of environmental management and assessment approaches. We start with showing a classification scheme that can help shed some light in the forest of buzzwords, as it may seem to be for some of you. We will outline the ISO 14000 environmental management standards, as well as some approaches that attempt to link economic and environmental assessments. As you will see, a lot depends on what you define as being ‘environmental impact' and how you measure it. In this chapter, we also give an illustrative overview of environmental metrics, including a metric that we developed ourselves: the Waste Index (WI).},
author = {Nixon, Ashley},
xxurl = {10.1007/BF02241838},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nixon - 1989 - Environmental impact assessment and management.pdf:pdf},
issn = {0251-1088},
journal = {The Environmentalist},
month = {dec},
number = {4},
pages = {308--309},
title = {{Environmental impact assessment and management}},
url = {http://link.springer.com/10.1007/BF02241838},
volume = {9},
year = {1989}
}
@article{Cohen2012,
abstract = {Broken or partially visible characters is common phenomenon in$\backslash$nhistorical documents. It stems from various factors, such as overlaid$\backslash$ntext or degradation. Restoring such characters is necessary for document$\backslash$nanalysis applications. This paper presents a new approach for restoring$\backslash$nunderlaying Hebrew broken characters that were partially occluded by$\backslash$nArabic text in a palimpsest. We apply text recognition on the fragments$\backslash$nof the Hebrew letters and select the k candidate letters that match best$\backslash$nthe fragments of the Hebrew letters. We then complete the broken Hebrew$\backslash$ncharacters using active contour with the k candidates as shape priors.$\backslash$nWe use a modified geodesic active contour, which we tailored to occluded$\backslash$ntext restoration. It is initialized on the fragments of the Hebrew text,$\backslash$nthen it under-goes an expansion phase and a contraction phase via the$\backslash$noccluding Arabic text to form the restored Hebrew character. We measure$\backslash$nthe distance between the completed character and its corresponding$\backslash$npriors and choose the shape with the minimal distance as the$\backslash$nreconstructed character. Experimental results are presented. On average$\backslash$n68{\%} of the characters were correctly reconstructed.},
author = {Cohen, Rafi and Kedem, Klara and Dinstein, Itshak and El-Sana, Jihad},
xxurl = {10.1109/ICFHR.2012.243},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen et al. - 2012 - Occluded character restoration using active contour with shape priors.pdf:pdf},
isbn = {9780769547749},
issn = {15505235},
journal = {Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR},
pages = {497--502},
title = {{Occluded character restoration using active contour with shape priors}},
year = {2012}
}
@article{Bai2008,
author = {Bai, Xiang and Yang, Xingwei and Latecki, Longin Jan},
xxurl = {10.1016/j.patcog.2007.12.016},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai, Yang, Latecki - 2008 - Detection and recognition of contour parts based on shape similarity.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {detection of contour parts,parts of visual form,shape similarity},
month = {jul},
number = {7},
pages = {2189--2199},
title = {{Detection and recognition of contour parts based on shape similarity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308000022},
volume = {41},
year = {2008}
}
@article{Fortuner2018,
author = {Fortuner, Brendan},
file = {:home/mondal/Documents/MATHS/L04{\_}linalg-dl{\_}slides.pdf:pdf},
number = {x},
pages = {1--7},
title = {{Linear algebra cheat sheet for deep learning}},
year = {2018}
}
@article{Halawani2010,
author = {Halawani, Sami M and Albidewi, Ibrahim A},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Halawani, Albidewi - 2010 - Logo Matching Technique Based on Principle Component Analysis.pdf:pdf},
keywords = {complex object matching,euclidean distance,feature extraction,principle component analysis},
number = {03},
pages = {1--5},
title = {{Logo Matching Technique Based on Principle Component Analysis}},
volume = {1},
year = {2010}
}
@inproceedings{Assent2012,
abstract = {With the increase of sensor and monitoring applications, data mining on streaming data is receiving increasing research attention. As data is continuously generated, mining algorithms need to be able to analyze the data in a one-pass fashion. In many applications the rate at which the data objects arrive varies greatly. This has led to anytime mining algorithms for classification or clustering. They successfully mine data until the a priori unknown point of interruption by the next data in the stream. In this work we investigate anytime outlier detection. Anytime outlier detection denotes the problem of determining within any period of time whether an object in a data stream is anomalous. The more time is available, the more reliable the decision should be. We introduce AnyOut, an algorithm capable of solving anytime outlier detection, and investigate different approaches to build up the underlying data structure. We propose a confidence measure for AnyOut that allows to improve the performance on constant data streams. We evaluate our method in thorough experiments and demonstrate its performance in comparison with established algorithms for outlier detection. {\textcopyright} 2012 Springer-Verlag.},
author = {Assent, Ira and Kranen, Philipp and Baldauf, Corinna and Seidl, Thomas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
xxurl = {10.1007/978-3-642-29038-1_18},
isbn = {9783642290374},
issn = {03029743},
title = {{AnyOut: Anytime outlier detection on streaming data}},
year = {2012}
}
@inproceedings{Shin,
author = {Shin, M.C. and Goldgof, D. and Bowyer, K.W.},
booktitle = {Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)},
xxurl = {10.1109/CVPR.1998.698608},
isbn = {0-8186-8497-6},
pages = {190--195},
publisher = {IEEE Comput. Soc},
title = {{An objective comparison methodology of edge detection algorithms using a structure from motion task}},
url = {http://ieeexplore.ieee.org/document/698608/}
}
@article{Ramirez-Ortegon2013,
author = {Ramirez-Ortegon, Marte a. and Margner, Volker and Rojas, Raul and Cuevas, Erik},
xxurl = {10.1109/ICDAR.2013.42},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramirez-Ortegon et al. - 2013 - An Objective Method to Evaluate Stroke-Width Measures for Binarized Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {175--179},
publisher = {Ieee},
title = {{An Objective Method to Evaluate Stroke-Width Measures for Binarized Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628607},
year = {2013}
}
@article{Shobha2014,
abstract = {— This paper proposes a novel binarization algorithm for converting the grayscale and color images into black and white images. The binarization is one of the very important process in all the researches pertaining to the field of the Document image processing and Pattern recognition. Since quality of binary image plays a critical role in the further processing of the document, especially in the area of researches belonging to the field of Optical character recognition the accuracy of the character recognition mainly depends upon the binarized image. It is very important to perform Binarization accurately and with lowest time complexity. This paper attempts to devise a simple and an efficient algorithm for binarization in order to improvise the outputs in the process of character recognition of various scripts with reduced time complexity. Keywords-Binarization, Degraded documents, Quadtrees, Character recognition, image subdivisions I. INTRODUCTION Binarization is an initial stage of the all the researches of document image processing. The binarization is mainly performed to reduce the amount of the data like intensity definitions of the image which is taken into consideration while processing the Image. Binarizing an image reduces the complexity of the image processing system in terms of time, space by upgrading the performance of the system. Binarizing an image represents converting the image into black and white i.e., intensity information will be reduced to only two values respectively '0' and '1'. This makes the processing very easier in the succeeding stages to consider the various components of performing manipulations particularly on foreground objects of the image. An efficient Binarization of an image also depends upon the quality of scanned image. The scanned image might be captured at different illumination conditions and at lower resolutions which may reflect some kind of adverse effects on the quality of document images. Binarization of such degraded images still degrades the image quality, and that might become useless to proceed into the further stages of character recognition or any image processing experimentation. Therefore it requires an efficient algorithm to perform Binarization accurately even on low quality degraded images. This paper attempts to propose a simple and efficient Binarization algorithm using quad trees which will be useful to convert the color or grayscale images into binary images. In the theory of the image processing and as well as in the literature there are various methods of performing the Binarization on the images. Some of the existing techniques of Binarization include Histogram-based methods, Clustering-based methods, Entropy-based methods, Object attribute-based methods, Spatial binarization methods, Locally adaptive methods [2] etc. The algorithms to binarize the image include Berson, Niblack, savoula, Eikvil and parker etc. The algorithms and the techniques which are dicussed in the literature are all suitable for satisifying certain kind of application requirements. The existing algorithms are all application dependent.},
author = {Shobha, N and Lecturer, Rani and Gopi, Arun},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shobha, Lecturer, Gopi - 2014 - A Quad Tree Based Binarization Approach to Improve quality of Degraded Document Images.pdf:pdf},
keywords = {- binarization,character recognition,degraded documents,image subdivisions,quadtrees},
number = {01},
title = {{A Quad Tree Based Binarization Approach to Improve quality of Degraded Document Images}},
volume = {3},
year = {2014}
}
@inproceedings{Bulacu2007,
author = {Bulacu, Marius and van Koert, Rutger and Schomaker, Lambert and van der Zant, Tijn},
booktitle = {Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)},
xxurl = {10.1109/ICDAR.2007.4378732},
isbn = {0-7695-2822-8},
issn = {1520-5363},
keywords = {Cultural differences,Global communication,Government,Image analysis,Image color analysis,Image processing,Image retrieval,Netherlands,Performance analysis,Search engines,Text analysis,archive searching,ascenders preservation,contour tracing,curvilinear separation paths,descenders preservation,document image processing,edge detection,handwritten character recognition,handwritten historical document digitization,handwritten historical document retrieval,history,image retrieval,information retrieval systems,layout analysis,text lines},
language = {English},
month = {sep},
pages = {357--361},
publisher = {IEEE},
title = {{Layout Analysis of Handwritten Historical Documents for Searching the Archive of the Cabinet of the Dutch Queen}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4378732},
volume = {1},
year = {2007}
}
@inproceedings{Mondal2014,
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean-yves and Pal, Umapada},
booktitle = {ICFHR},
xxurl = {10.1109/ICFHR.2014.43},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal, Ragot, Ramel - Unknown - Flexible Sequence Matching Technique Application to Word Spotting in Degraded Documents.pdf:pdf},
isbn = {978-1-4799-4334-0},
issn = {2167-6445},
keywords = {Algorithm design and analysis,CDP algorithm,Computer architecture,Continuous dynamic programming (CDP),DTW algorithm,Degraded historical document,Dynamic programming,Dynamic time warping (DTW),Elastic matching,FSM algorithm,Feature extraction,Handwritten documents,Image segmentation,MVM algorithm,Minimal variance matching (MVM),Pattern recognition,Robustness,Sequence alignment,Word spotting,application domain,cdp,continuous dynamic,degraded historical document,document image processing,dtw,dynamic time warping,elastic matching,feature extraction,flexible sequence matching algorithm,handwritten George Washington dataset,handwritten documents,historical typewritten document images,image matching,minimal variance matching,mvm,programming,query retrieval,query sequences,scale factor,sequence alignment,word processing,word segmentation process,word spotting},
language = {English},
month = {sep},
pages = {210--215},
publisher = {IEEE},
title = {{Flexible Sequence Matching Technique: Application to Word Spotting in Degraded Documents}},
year = {2014}
}
@article{Parker2013,
author = {Parker, Jon and Frieder, Ophir and Frieder, Gideon},
xxurl = {10.1109/ICDAR.2013.49},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parker, Frieder, Frieder - 2013 - Automatic Enhancement and Binarization of Degraded Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {document degradation,processing,readability enhancement},
month = {aug},
pages = {210--214},
publisher = {Ieee},
title = {{Automatic Enhancement and Binarization of Degraded Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628614},
year = {2013}
}
@article{Nikolaou2010,
author = {Nikolaou, Nikos and Makridis, Michael and Gatos, Basilis and Stamatopoulos, Nikolaos and Papamarkos, Nikos},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nikolaou et al. - 2010 - Segmentation of historical machine-printed documents using Adaptive Run Length Smoothing and skeleton segmentat.pdf:pdf},
journal = {Image and Vision Computing},
keywords = {text line segmentation},
month = {apr},
number = {4},
pages = {590--604},
publisher = {Elsevier B.V.},
title = {{Segmentation of historical machine-printed documents using Adaptive Run Length Smoothing and skeleton segmentation paths}},
volume = {28},
year = {2010}
}
@inproceedings{DBLP:conf/icdar/2015,
isbn = {978-1-4799-1805-8},
publisher = {{\{}IEEE{\}} Computer Society},
title = {{13th International Conference on Document Analysis and Recognition, {\{}ICDAR{\}} 2015, Nancy, France, August 23-26, 2015}},
url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7321714},
year = {2015}
}
@article{Guerin2013,
author = {Guerin, Clement and Rigaud, Christophe and Mercier, Antoine and Ammar-Boudjelal, Farid and Bertet, Karell and Bouju, Alain and Burie, Jean-Christophe and Louis, Georges and Ogier, Jean-Marc and Revel, Arnaud},
xxurl = {10.1109/ICDAR.2013.232},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guerin et al. - 2013 - eBDtheque A Representative Database of Comics.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {annotation,database,database in association with,ground truth,image,purpose,scientific comics collection,semantic,several renowned authors and,the first comic books,therefore,we decided to gather},
month = {aug},
pages = {1145--1149},
publisher = {Ieee},
title = {{eBDtheque: A Representative Database of Comics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628793},
year = {2013}
}
@article{Chen2014,
abstract = {This paper addresses the large-scale visual font recogni- tion (VFR) problem, which aims at automatic identification of the typeface, weight, and slope of the text in an image or photo without any knowledge of content. Although vi- sual font recognition has many practical applications, it has largely been neglected by the vision community. To address the VFR problem, we construct a large-scale dataset con- taining 2, 420 font classes, which easily exceeds the scale of most image categorization datasets in computer vision. As font recognition is inherently dynamic and open-ended, i.e., new classes and data for existing categories are constantly added to the database over time, we propose a scalable so- lution based on the nearest class mean classifier (NCM). The core algorithm is built on local feature embedding, lo- cal feature metric learning and max-margin template se- lection, which is naturally amenable to NCM and thus to such open-ended classification problems. The new algo- rithm can generalize to new classes and new data at lit- tle added cost. Extensive experiments demonstrate that our approach is very effective on our synthetic test images, and achieves promising results on real world test images.},
author = {Chen, Guang and Yang, Jianchao and Jin, Hailin and Brandt, Jonathan and Shechtman, Eli and Agarwala, Aseem and Han, Tony X.},
xxurl = {10.1109/CVPR.2014.460},
file = {:home/mondal/Downloads/CVPR14{\_}Font.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {character recognition,fine-grained recognition,font recognition,large-scale recognition},
pages = {3598--3605},
title = {{Large-scale visual font recognition}},
year = {2014}
}
@article{Blumenstein2002,
author = {Blumenstein, M and Cheng, CK and Liu, XY},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blumenstein, Cheng, Liu - 2002 - New preprocessing techniques for handwritten word recognition.pdf:pdf},
journal = {Proceedings of the Second IASTED {\ldots}},
keywords = {handwritten word recognition,preprocessing,skew detection,underline removal},
title = {{New preprocessing techniques for handwritten word recognition}},
year = {2002}
}
@article{Yan2005,
abstract = {Most commercial television channels use video logos, which can be$\backslash$nconsidered a form of visible watermark, as a declaration of intellectual$\backslash$nproperty ownership. They are also used as a symbol of authorization to$\backslash$nrebroadcast when original logos are used in conjunction with newer$\backslash$nlogos. An unfortunate side effect of such logos is the concomitant$\backslash$ndecrease in viewing pleasure. In this paper, we use the temporal$\backslash$ncorrelation of video frames to detect and remove video logos. In the$\backslash$nvideo-logo-detection part, as an initial step, the logo boundary box is$\backslash$nfirst located by using a distance threshold of video frames and is$\backslash$nfurther refined by employing a comparison of edge lengths. Second, our$\backslash$nproposed Bayesian classifier framework locates fragments of logos called$\backslash$nlogo-lets. In this framework, we systematically integrate the prior$\backslash$nknowledge about the location of the video logos and their intrinsic$\backslash$nlocal features to achieve a robust detection result. In our logo-removal$\backslash$npart, after the logo region is marked, a matching technique is used to$\backslash$nfind the best replacement patch for the marked region within that video$\backslash$nshot. This technique is found to be useful for small logos. Furthermore,$\backslash$nwe extend the image inpainting technique to videos. Unlike the use of 2D$\backslash$ngradients in the image inpainting technique, we inpaint the logo region$\backslash$nof video frames by using 3D gradients exploiting the temporal$\backslash$ncorrelations in video. The advantage of this algorithm is that the$\backslash$ninpainted regions are consistent with the surrounding texture and hence$\backslash$nthe result is perceptually pleasing. We present the results of our$\backslash$nimplementation and demonstrate the utility of our method for logo$\backslash$nremoval.},
author = {Yan, Wei Qi and Wang, Jun and Kankanhalli, Mohan S.},
xxurl = {10.1007/s00530-005-0167-6},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, Wang, Kankanhalli - 2005 - Automatic video logo detection and removal.pdf:pdf},
isbn = {0053000501},
issn = {09424962},
journal = {Multimedia Systems},
keywords = {Neural network,Video inpainting,Video logo detection,Video logo removal,Visual watermark attack},
number = {5},
pages = {379--391},
title = {{Automatic video logo detection and removal}},
volume = {10},
year = {2005}
}
@book{Durbin1998,
abstract = {Probablistic models are becoming increasingly important in analyzing the huge amount of data being produced by large-scale DNA- sequencing efforts such as the Human Genome Project. For example, hidden Markov models are used for analyzing biological sequences , ... $\backslash$n},
author = {Durbin, Richard and Sanger and {Eddy, A. Krogh}, G. Mitchison},
booktitle = {Cambridge University Press},
isbn = {9780521629713},
title = {{Biological sequence analysis, Probabilistic models of proteins and nucleic acids}},
year = {1998}
}
@article{Tian2013a,
author = {Tian, Shangxuan and Shivakumara, Palaiahnakote and Phan, Trung Quy and Tan, Chew Lim},
xxurl = {10.1109/ICDAR.2013.275},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - 2013 - Scene Character Reconstruction through Medial Axis.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1360--1364},
publisher = {Ieee},
title = {{Scene Character Reconstruction through Medial Axis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628836},
year = {2013}
}
@misc{GeorgeWashingtonPapers,
author = {{George Washington Papers}},
booktitle = {The Library of Congress},
title = {{No Title}}
}
@article{Howe2013b,
abstract = {Document analysis systems often begin with bina- rization as a first processing stage. Although numerous techniques for binarization have been proposed, the results produced can vary in quality and often prove sensitive to the settings of one or more control parameters. This paper examines a promising ap- proach to binarization based upon simple principles, and shows that its success depends most significantly upon the values of two key parameters. It further de- scribes an automatic technique for setting these pa- rameters in a manner that tunes them to the individ- ual image, yielding a final binarization algorithm that can cut total error by one-third with respect to the baseline version. The results of this method advance the state of the art on recent benchmarks.},
author = {Howe, Nicholas R.},
xxurl = {10.1007/s10032-012-0192-x},
issn = {14332833},
journal = {International Journal on Document Analysis and Recognition},
title = {{Document binarization with automatic parameter tuning}},
year = {2013}
}
@article{Shang2014,
abstract = {{\textcopyright} 2014 Shang et al.; licensee Springer. This paper describes a method to distinguish documents produced by laser printers, inkjet printers, and electrostatic copiers, three commonly used document creation devices. The proposed approach can distinguish between documents produced by these sources based on features extracted from the characters in the documents. Hence, it can also be used to detect tampered documents produced by a mixture of these sources. We analyze the characteristics associated with laser/inkjet printers and electrostatic copiers and determine the signatures created by the different physical and technical processes involved in each type of printing. Based on the analysis of these signatures, we computed the features of noise energy, contour roughness, and average gradient. To the best of our knowledge, this is the first work to distinguish documents produced by laser printer, inkjet printer, and copier based on features extracted from individual characters in the documents. Experimental results show that this method has an average accuracy of 90{\%} and works with JPEG compression.},
author = {Shang, Shize and Memon, Nasir and Kong, Xiangwei},
xxurl = {10.1186/1687-6180-2014-140},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shang, Memon, Kong - 2014 - Detecting documents forged by printing and copying.pdf:pdf},
issn = {16876180},
journal = {Eurasip Journal on Advances in Signal Processing},
keywords = {Average gradient,Contour roughness,Device type identification,Noise energy,Tampering detection},
number = {1},
pages = {1--13},
title = {{Detecting documents forged by printing and copying}},
volume = {2014},
year = {2014}
}
@article{Pratikakis2017,
abstract = {H-DIBCO 2010 is the International Document Image Binarization Contest which is dedicated to handwritten document images organized in conjunction with ICFHR 2010 conference. The general objective of the contest is to identify current advances in handwritten document image binarization using meaningful evaluation performance measures. This paper reports on the contest details including the evaluation measures used as well as the performance of the 17 submitted methods along with a short description of each method.},
author = {Pratikakis, Ioannis and Zagoris, Konstantinos and Barlas, George and Gatos, Basilis},
xxurl = {10.1109/ICFHR.2016.0118},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratikakis et al. - 2017 - ICFHR 2016 handwritten document image binarization contest (H-DIBCO 2016).pdf:pdf},
isbn = {9781509009817},
issn = {21676453},
journal = {ICFHR},
keywords = {Binarization,Handwritten document image,Performance evaluation},
pages = {619--623},
title = {{ICFHR 2016 handwritten document image binarization contest (H-DIBCO 2016)}},
volume = {0},
year = {2017}
}
@article{Ratan2004,
abstract = {It has long been known that Dynamic Time Warping (DTW) is superior to Euclidean distance for classification and clustering of time series. However, until lately, most research has utilized Euclidean distance because it is more efficiently calculated. A recently introduced technique that greatly mitigates DTWs demanding CPU time has sparked a flurry of research activity. However, the technique and its many extensions still only allow DTW to be applied to moderately large datasets. In addition, almost all of the research on DTW has focused exclusively on speeding up its calculation; there has been little work done on improving its accuracy. In this work, we target the accuracy aspect of DTW performance and introduce a new framework that learns arbitrary constraints on the warping path of the DTW calculation. Apart from improving the accuracy of classification, our technique as a side effect speeds up DTW by a wide margin as well. We show the utility of our approach on datasets from diverse domains and demonstrate significant gains in accuracy and efficiency.$\backslash$n},
author = {Ratanamahatana, Chotirat Ann CA and Keogh, Eamonn"},
xxurl = {10.1.1.215.1648},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratanamahatana, Keogh - 2004 - Making time-series classification more accurate using learned constraints.pdf:pdf},
journal = {Proceedings of SIAM},
keywords = {(review),dynamic time warping,time series},
pages = {11--22},
title = {{Making time-series classification more accurate using learned constraints}},
year = {2004}
}
@inproceedings{Keogh2002,
abstract = {The problem of finding a specified pattern in a time series database (i.e. query by content) has received much attention and is now a relatively mature field. In contrast, the important problem of enumerating all surprising or interesting patterns has received far less attention. This problem requires a meaningful definition of "surprise" , and an efficient search technique. All previous attempts at finding surprising patterns in time series use a very limited notion of surprise, and/or do not scale to massive datasets. To overcome these limitations we introduce a novel technique that defines a pattern surprising if the frequency of its occurrence differs substantially from that expected by chance, given some previously seen data. This notion has the advantage of not requiring an explicit definition of surprise,which may be impossible to elicit from a domain expert.Instead the user simply gives the algorithm a collection of previously observed normal data. Our algorithm uses a suffix tree to efficiently encode the frequency of all ob-served patterns and allows a Markov model to predict the expected frequency of previously unobserved pat-terns. Once the suffix tree has been constructed, a measure of surprise for all the patterns in a new database can be determined in time and space linear in the size of the database. We demonstrate the utility of our approach with an extensive experimental evaluation.},
address = {New York, New York, USA},
author = {Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill 'Yuan-chi'},
booktitle = {Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '02},
xxurl = {10.1145/775107.775128},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keogh, Lonardi, Chiu - 2002 - Finding surprising patterns in a time series database in linear time and space.pdf:pdf},
isbn = {158113567X},
keywords = {4,57tghp8hx,8,8fbdtg8,8ff,98,a,bd,bd8f,bfedtgc,btv,c,c1,c³,d,e,fc,fce4,f²,gv,h hc s,hgv,j8fed8,j8fed8fbfedtgc,p,p{\textordfeminine}y,q,qrar9c,qµ,r,r3,s,t,v1ed,w,x,y,z e,ze53bd8,{\textordfeminine}f,²h},
pages = {550},
publisher = {ACM Press},
title = {{Finding surprising patterns in a time series database in linear time and space}},
url = {http://portal.acm.org/citation.cfm?xxurld=775047.775128},
year = {2002}
}
@inproceedings{Fayyad1998,
abstract = {Iterative refinement clustering algorithms (e.g. K-Means, EM) converge to one of numerous local minima. It is known that they are especially sensitive to initial conditions. We present a procedure for computing a refined starting condition from a given initial one that is based on an efficient technique for estimating the modes of a distribution. The refined initial starting condition leads to convergence to the application of “better” this method local minima. The procedure is applicable to a wide class of clustering algorithms for both discrete and continuous data. We demonstrate to the Expectation Maximization (EM) clustering algorithm and show that refined initial points indeed lead to improved solutions. Refinement run time is considerably lower than the time required to cluster the full database. The method is scalable and can be coupled with a scalable clustering algorithm to address the large-scale clustering in data mining.},
author = {Fayyad, Usama and Reina, Cory and Bradley, P. S.},
booktitle = {KDD '98},
title = {{Initialization of Iterative Refinement Clustering Algorithms}},
year = {1998}
}
@article{Dietrich2004,
abstract = {Automated classification of cricket songs from Thailand and Ecuador is the topic of this study. For this, the locations of pulses are determined and different features in the time and the frequency domain are extracted automatically from the time series. For the categorization of the sound patterns these features are combined through data fusion, temporal fusion and decision fusion. Local features and global features are distinguished. For the classification a fuzzy-k-nearest-neighbour classifier was used. Classification results for a data set containing songs of 28 different species are presented.},
author = {Dietrich, Christian and Palm, G{\"{u}}nther and Riede, Klaus and Schwenker, Friedhelm},
xxurl = {10.1016/j.patcog.2004.04.004},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietrich et al. - 2004 - Classification of bioacoustic time series based on the combination of global and local decisions.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Bioacoustics,Classifier fusion,Global feature,Local feature,Multiple classifier system,Temporal classification},
month = {dec},
number = {12},
pages = {2293--2305},
title = {{Classification of bioacoustic time series based on the combination of global and local decisions}},
url = {http://www.sciencedirect.com/science/article/pii/S003132030400161X},
volume = {37},
year = {2004}
}
@inproceedings{ZhuYZKK18,
author = {{Yan Zhu, Chin-Chia Michael Yeh}, Zachary Zimmerman Kaveh Kamgar and Keogh, Eamonn},
booktitle = {Proceedings of the International Conference on Data Mining (ICDM)},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - Unknown - Matrix Profile XI SCRIMP Motif Discovery at Interactive Speeds.pdf:pdf},
title = {{Matrix Proﬁle XI: SCRIMP++: Time Series Motif Discovery at Interactive Speed}},
year = {2018}
}
@inproceedings{Pavon2012,
address = {Berlin, Heidelberg},
author = {Zalewski, W. and Silva, F. and Lee, H. D. and Maletzke, A. and Wu, F. C.},
booktitle = {IBERAMIA},
xxurl = {10.1007/978-3-642-34654-5},
editor = {Pav{\'{o}}n, Juan and Duque-M{\'{e}}ndez, N{\'{e}}stor D. and Fuentes-Fern{\'{a}}ndez, Rub{\'{e}}n},
isbn = {978-3-642-34653-8},
pages = {91--100},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Time series discretization based on the approximation of the local slope information}},
volume = {7637},
year = {2012}
}
@article{Piastra2013,
abstract = {Competitive Hebbian Learning (CHL) (Martinetz, 1993) is a simple and elegant method for estimating the topology of a manifold from point samples. The method has been adopted in a number of self-organizing networks described in the literature and has given rise to related studies in the fields of geometry and computational topology. Recent results from these fields have shown that a faithful reconstruction can be obtained using the CHL method only for curves and surfaces.Within these limitations, these findings constitute a basis for defining a CHL-based, growing self-organizing network that produces a faithful reconstruction of an input manifold. The SOAM (Self-Organizing Adaptive Map) algorithm adapts its local structure autonomously in such a way that it can match the features of the manifold being learned. The adaptation process is driven by the defects arising when the network structure is inadequate, which cause a growth in the density of units. Regions of the network undergo a phase transition and change their behavior whenever a simple, local condition of topological regularity is met. The phase transition is eventually completed across the entire structure and the adaptation process terminates. In specific conditions, the structure thus obtained is homeomorphic to the input manifold. During the adaptation process, the network also has the capability to focus on the acquisition of input point samples in critical regions, with a substantial increase in efficiency.The behavior of the network has been assessed experimentally with typical data sets for surface reconstruction, including suboptimal conditions, e.g. with undersampling and noise. ?? 2012 Elsevier Ltd.},
author = {Piastra, Marco},
xxurl = {10.1016/j.neunet.2012.07.007},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Piastra - 2013 - Self-organizing adaptive map Autonomous learning of curves and surfaces from point samples.pdf:pdf},
isbn = {1879-2782 (Electronic)$\backslash$r0893-6080 (Linking)},
issn = {08936080},
journal = {Neural Networks},
keywords = {Cellular automata,Growing self-organizing networks,Learning and adaptive systems,Manifold learning},
pages = {96--112},
pmid = {22963998},
publisher = {Elsevier Ltd},
title = {{Self-organizing adaptive map: Autonomous learning of curves and surfaces from point samples}},
url = {http://dx.xxurl.org/10.1016/j.neunet.2012.07.007},
volume = {41},
year = {2013}
}
@article{Phan2009,
abstract = {In this paper, we present an extension of the Colour Edge Co-occurence Histogram (CECH) object detection scheme for detecting logos and trademarks in unconstrained colour images. We introduce more accurate information to the CECH by virtue of incorporating colour edge detection using vector order statistics, producing a more accurate representation of edges in images, as compared to the simple colour difference edge classification which is done in the CECH. Our proposed method is thus reliant on edge gradient information, and so we call it the Colour Edge Gradient Co-occurrence Histogram (CEGCH). We also illustrate a colour quantization scheme based in the Hue-Saturation-Value (HSV) colour space, illustrating that it is more suitable for logo and trademark detection in comparison to the colour quantization scheme used with the CECH. Results illustrate that the CEGCH detects logos and trademarks with greater accuracy in comparison to the CECH},
author = {Phan, Raymond and Androutsos, Dimitrios},
xxurl = {10.1109/CCECE.2009.5090125},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phan, Androutsos - 2009 - Colour logo and trademark retrieval and tracking in unconstrained image sequences using colour edge gradient c.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phan, Androutsos - 2009 - Colour logo and trademark retrieval and tracking in unconstrained image sequences using colour edge gradien(2).pdf:pdf},
isbn = {9781424435081},
issn = {08407789},
journal = {Canadian Conference on Electrical and Computer Engineering},
keywords = {Colour Edge Gradient Co-occurrence Histogram (CEGC,Colour edge detection,HSV quantization,Logo and trademark retrieval and tracking},
number = {June 2017},
pages = {225--228},
title = {{Colour logo and trademark retrieval and tracking in unconstrained image sequences using colour edge gradient co-occurrence histograms}},
year = {2009}
}
@article{Masseti1997,
abstract = {This paper presents a new adaptive approach for the binarization and enhancement of degraded documents. The proposed method does not require any parameter tuning by the user and can deal with degradations which occur due to shadows, non-uniform illumination, low contrast, large signal-dependent noise, smear and strain. We follow several distinct steps: a pre-processing procedure using a low-pass Wiener filter, a rough estimation of foreground regions, a background surface calculation by interpolating neighboring background intensities, a thresholding by combining the calculated background surface with the original image while incorporating image up-sampling and finally a post-processing step in order to improve the quality of text regions and preserve stroke connectivity. After extensive experiments, our method demonstrated superior performance against four (4) well-known techniques on numerous degraded document images. {\textcopyright} 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Gatos, Basilis},
xxurl = {10.1016/j.patcog.2005.09.010},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos - 2005 - Adaptive degraded document image binarization.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {International Journal of Osteoarchaeology},
keywords = {B. Gatos,I. Pratikakis,S.J. Perantonis},
number = {4},
pages = {354--363},
pmid = {84262800005},
title = {{Adaptive degraded document image binarization}},
volume = {7},
year = {2005}
}
@article{Alaei2014a,
author = {Alaei, Alireza and Roy, Partha Pratim},
xxurl = {10.1109/ICFHR.2014.44},
isbn = {9781479943340},
issn = {21676453},
journal = {Proceedings of International Conference on Frontiers in Handwriting Recognition, ICFHR},
keywords = {English and Kannada Handwritten Documents,Histogram Symbolic Representation,Similarity Measure,Writer Identification/Verification},
number = {November},
pages = {216--221},
title = {{A New Method for Writer Identification Based on Histogram Symbolic Representation}},
volume = {2014-Decem},
year = {2014}
}
@article{Boumaiza2012,
author = {Boumaiza, Ameni and Tabbone, Salvatore},
xxurl = {10.1109/DAS.2012.83},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boumaiza, Tabbone - 2012 - Symbol recognition using a Galois lattice of frequent graphical patterns.pdf:pdf},
isbn = {9780769546612},
journal = {Proceedings - 10th IAPR International Workshop on Document Analysis Systems, DAS 2012},
keywords = {Bag of words,Descriptor,Frequent attributes,Galois Lattice,Graphical symbol,Symbol recognition},
pages = {165--169},
title = {{Symbol recognition using a Galois lattice of frequent graphical patterns}},
year = {2012}
}
@article{Xiong2018,
abstract = {This paper presents a support vector machine (SVM) based method for degraded historical document image binarization. Given a degraded historical document image, the proposed method first segments the image into w × w regions and implements a local contrast enhancement in each image block. We then use a SVM to select an optimal global threshold for binarization of each image block. Finally, the entire image is further binarized by a locally adaptive thresholding method. The proposed method has been evaluated over the recent Document Image Binarization Competition (DIBCO) datasets. The experimental results show that our proposed method outperforms other state-of-the-art techniques in terms of F-measure, NRM, DRD, and MPM.},
author = {Xiong, Wei and Xu, Jingjing and Xiong, Zijie and Wang, Juan and Liu, Min},
xxurl = {10.1016/j.ijleo.2018.02.072},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiong et al. - 2018 - Degraded historical document image binarization using local features and support vector machine (SVM).pdf:pdf},
issn = {00304026},
journal = {Optik},
keywords = {Document image binarization,SVM,Segmentation,Support vector machine,Thresholding},
number = {May},
pages = {218--223},
publisher = {Elsevier GmbH.},
title = {{Degraded historical document image binarization using local features and support vector machine (SVM)}},
url = {https://xxurl.org/10.1016/j.ijleo.2018.02.072},
volume = {164},
year = {2018}
}
@article{Zhang2013c,
author = {Zhang, Xin and Sun, Fuchun},
xxurl = {10.1109/ICDAR.2013.113},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Sun - 2013 - Multiple Geometry Transform Estimation from Single Camera-Captured Text Image.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {538--542},
publisher = {Ieee},
title = {{Multiple Geometry Transform Estimation from Single Camera-Captured Text Image}},
year = {2013}
}
@article{Eddy1996,
author = {Eddy, S R and Moore, Andrew W},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moore - Unknown - Hidden Markov Models.pdf:pdf},
journal = {Current opinion in structural biology},
pages = {1--41},
title = {{Hidden markov models}},
url = {http://www.sciencedirect.com/science/article/pii/S0959440X9680056X},
year = {1996}
}
@article{Ghosh2015a,
author = {Ghosh, Suman K and Valveny, Ernest},
xxurl = {10.1007/978-3-319-19390-8_73},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosh, Valveny - 2015 - A sliding window framework for word spotting based on word attributes.pdf:pdf},
isbn = {9783319193892},
issn = {16113349},
journal = {Iberian Conference on Pattern Recognition and Image Analysis},
keywords = {sliding window,word attributes,word spotting},
pages = {652--661},
title = {{A sliding window framework for word spotting based on word attributes}},
year = {2015}
}
@article{Lu2008e,
abstract = {This paper reports a document retrieval technique that retrieves machine-printed Latin-based document images through word shape coding. Adopting the idea of image annotation, a word shape coding scheme is proposed, which converts each word image into a word shape code by using a few shape features. The text contents of imaged documents are thus captured by a document vector constructed with the converted word shape code and word frequency information. Similarities between different document images are then gauged based on the constructed document vectors. We divide the retrieval process into two stages. Based on the observation that documents of the same language share a large number of high-frequency language-specific stop words, the first stage retrieves documents with the same underlying language as that of the query document. The second stage then re-ranks the documents retrieved in the first stage based on the topic similarity. Experiments show that document images of different languages and topics can be retrieved properly by using the proposed word shape coding scheme.},
author = {Lu, Shijian and Tan, Chew Lim},
xxurl = {10.1016/j.patcog.2007.10.017},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Tan - 2008 - Retrieval of machine-printed Latin documents through Word Shape Coding.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Document image analysis,Language identification,Multilingual document retrieval,Word shape coding},
month = {may},
number = {5},
pages = {1816--1826},
title = {{Retrieval of machine-printed Latin documents through Word Shape Coding}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320307004669},
volume = {41},
year = {2008}
}
@inproceedings{DonaldJ.Berndt1994,
author = {{Donald J. Berndt}, James Clifford},
pages = {359 -- 370},
title = {{Using Dynamic Time Warping to Find Patterns in Time Series.}},
year = {1994}
}
@article{Lew20061,
abstract = {Extending beyond the boundaries of science, art, and culture, content-based multimedia information retrieval provides new paradigms and methods for searching through the myriad variety of media all over the world. This survey reviews 100+ recent articles on content-based multimedia information retrieval and discusses their role in current research directions which include browsing and search paradigms, user studies, affective computing, learning, semantic queries, new features and media types, high performance indexing, and evaluation techniques. Based on the current state of the art, we discuss the major challenges for the future.},
author = {Lew, M.S. and Sebe, N. and Djeraba, Chabane and Jain, Ramesh},
xxurl = {10.1145/1126004.1126005},
isbn = {1551-6857},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)},
keywords = {Multimedia information retrieval,audio retrieval,human-computer interaction,image databases,image search,multimedia indexing,video retrieval},
number = {1},
pages = {1--19},
title = {{Content-based multimedia information retrieval: State of the art and challenges}},
url = {http://portal.acm.org/citation.cfm?id=1126005},
volume = {2},
year = {2006}
}
@article{Chaudhuri1998,
abstract = {A complete Optical Character Recognition (OCR) system for printed Bangla, the fourth most popular script in the world, is presented. This is the first OCR system among all script forms used in the Indian sub-continent. The problem is difficult because (i) there are about 300 basic, modified and compound character shapes in the script, (ii) the characters in a word are topologically connected and (iii) Bangla is an inflectional language. In our system the document image captured by Flat-bed scanner is subject to skew correction, text graphics separation, line segmentation, zone detection, word and character segmentation using some conventional and some newly developed techniques. From zonal information and shape characteristics, the basic, modified and compound characters are separated for the convenience of classification. The basic and modified characters which are about 75 in number and which occupy about 96{\%} of the text corpus, are recognized by a structural-feature-based tree classifier. The compound characters are recognized by a tree classifier followed by template-matching approach. The feature detection is simple and robust where preprocessing like thinning and pruning are avoided. The character unigram statistics is used to make the tree classifier efficient. Several heuristics are also used to speed up the template matching approach. A dictionary-based error-correction scheme has been used where separate dictionaries are compiled for root word and suffixes that contain morpho-syntactic informations as well. For single font clear documents 95.50{\%} word level (which is equivalent to 99.10{\%} character level) recognition accuracy has been obtained. Extension of the work to Devnagari, the third most popular script in the world, is also discussed.},
author = {Chaudhuri, B.B and Pal, U},
xxurl = {10.1016/S0031-3203(97)00078-2},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
number = {5},
pages = {531--549},
title = {{A complete printed Bangla OCR system}},
volume = {31},
year = {1998}
}
@article{Feng2013,
author = {Feng, Bo-Yuan and Ren, Mingwu and Zhang, Xu-Yao and Suen, Ching Y.},
xxurl = {10.1109/ICDAR.2013.143},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feng et al. - 2013 - Extraction of Serial Numbers on Bank Notes.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {combination,image binarization},
month = {aug},
pages = {698--702},
publisher = {Ieee},
title = {{Extraction of Serial Numbers on Bank Notes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628708},
year = {2013}
}
@article{Terada2013,
author = {Terada, Yugo and Huang, Rong and Feng, Yaokai and Uchida, Seiichi},
xxurl = {10.1109/ICDAR.2013.101},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Terada et al. - 2013 - On the Possibility of Structure Learning-Based Scene Character Detector.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {472--476},
publisher = {Ieee},
title = {{On the Possibility of Structure Learning-Based Scene Character Detector}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628666},
year = {2013}
}
@article{Marinai2011,
author = {Marinai, Simone},
xxurl = {10.1007/s10032-010-0146-0},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
month = {jan},
number = {2},
pages = {117--129},
title = {{Text retrieval from early printed books}},
volume = {14},
year = {2011}
}
@article{DelaTorre2012b,
annote = {From Duplicate 1 ( 

Generalized time warping for multi-modal alignment of human motion

- De la Torre, F )

},
author = {{De la Torre}, F.},
xxurl = {10.1109/CVPR.2012.6247812},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De la Torre - 2012 - Generalized time warping for multi-modal alignment of human motion.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = {jun},
pages = {1282--1289},
publisher = {Ieee},
title = {{Generalized time warping for multi-modal alignment of human motion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247812},
year = {2012}
}
@article{Baluja2017,
abstract = {Steganography is the practice of concealing a secret message within another, ordinary, message. Commonly, steganography is used to unobtrusively hide a small message within the noisy regions of a larger image. In this study, we attempt to place a full size color image within another image of the same size. Deep neural networks are simultaneously trained to create the hiding and revealing processes and are designed to specifically work as a pair. The system is trained on images drawn randomly from the ImageNet database, and works well on natural images from a wide variety of sources. Beyond demonstrating the successful application of deep learning to hiding images, we carefully examine how the result is achieved and explore extensions. Unlike many popular steganographic methods that encode the secret message within the least significant bits of the carrier image, our approach compresses and distributes the secret image's representation across all of the available bits.},
author = {Baluja, Shumeet},
file = {:home/mondal/Downloads/6802-hiding-images-in-plain-sight-deep-steganography.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {2070--2080},
title = {{Hiding images in plain sight: Deep steganography}},
volume = {2017-Decem},
year = {2017}
}
@article{Sankaran2013,
author = {Sankaran, Naveen and Neelappa, Aman and Jawahar, C.V.},
xxurl = {10.1109/ICDAR.2013.139},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sankaran, Neelappa, Jawahar - 2013 - Devanagari Text Recognition A Transcription Based Formulation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {678--682},
publisher = {Ieee},
title = {{Devanagari Text Recognition: A Transcription Based Formulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628704},
year = {2013}
}
@article{Zhou2013b,
author = {Zhou, Xiang-Dong and Tian, Feng and Liu, Cheng-Lin and Wang, Hong-An},
xxurl = {10.1109/ICDAR.2013.191},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2013 - Minimum Risk Training for Handwritten ChineseJapanese Text Recognition Using Semi-Markov Conditional Random Fields.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {940--944},
publisher = {Ieee},
title = {{Minimum Risk Training for Handwritten Chinese/Japanese Text Recognition Using Semi-Markov Conditional Random Fields}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628756},
year = {2013}
}
@article{Mansimov2015,
abstract = {Motivated by the recent progress in generative models, we introduce a model that generates images from natural language descriptions. The proposed model iteratively draws patches on a canvas, while attending to the relevant words in the description. After training on Microsoft COCO, we compare our model with several baseline generative models on image generation and retrieval tasks. We demonstrate that our model produces higher quality samples than other approaches and generates images with novel scene compositions corresponding to previously unseen captions in the dataset.},
archivePrefix = {arXiv},
arxivId = {1511.02793},
author = {Mansimov, Elman and Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
xxurl = {10.1088/0004-6256/150/6/203},
eprint = {1511.02793},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mansimov et al. - 2015 - Generating Images from Captions with Attention.pdf:pdf},
isbn = {9781467369640},
issn = {1538-3881},
pages = {1--12},
title = {{Generating Images from Captions with Attention}},
url = {http://arxiv.org/abs/1511.02793},
year = {2015}
}
@article{Pham2011,
abstract = {This paper presents a new approach for logo detection exploiting contour based features. At first stage, pre-processing, contour detection and line segmentation are done. These processes result in set of Outer Contour Strings (OCSs) describing each graphics and text parts of the documents. Then, the logo detection problem is defined as a region scoring problem. Two types of features, coarse and finer ones, are computed from each OCS. Coarse features catch graphical and domain information about OCSs, such as logo positions and aspect ratios. Finer features characterize the contour regions using a gradient based representation. Using these features, we employ regression fitting to score how likely an OCS takes part of a logo region. A final step of correction helps with the wrong segmentation cases. We present experiments done on the Tobacco-800 dataset, and compare our results with the literature. We obtain interesting results compared to the best systems.},
author = {Pham, The Anh and Delalandre, Mathieu and Barrat, Sabine},
xxurl = {10.1109/ICDAR.2011.150},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pham, Delalandre, Barrat - 2011 - A contour-based method for logo detection.pdf:pdf},
isbn = {9780769545202},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {contour detection,imp-logo-paper,logo detection,regression fitting},
mendeley-tags = {imp-logo-paper},
pages = {718--722},
title = {{A contour-based method for logo detection}},
year = {2011}
}
@article{Jaderberg2016,
abstract = {In this work we present an end-to-end system for text spotting -- localising and recognising text in natural scene images -- and text based image retrieval. This system is based on a region proposal mechanism for detection and deep convolutional neural networks for recognition. Our pipeline uses a novel combination of complementary proposal generation techniques to ensure high recall, and a fast subsequent filtering stage for improving precision. For the recognition and ranking of proposals, we train very large convolutional neural networks to perform word recognition on the whole proposal region at the same time, departing from the character classifier based systems of the past. These networks are trained solely on data produced by a synthetic text generation engine, requiring no human labelled data. Analysing the stages of our pipeline, we show state-of-the-art performance throughout. We perform rigorous experiments across a number of standard end-to-end text spotting benchmarks and text-based image retrieval datasets, showing a large improvement over all previous methods. Finally, we demonstrate a real-world application of our text spotting system to allow thousands of hours of news footage to be instantly searchable via a text query.},
archivePrefix = {arXiv},
arxivId = {1412.1842},
author = {Jaderberg, Max and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
xxurl = {10.1007/s11263-015-0823-z},
eprint = {1412.1842},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaderberg et al. - 2016 - Reading Text in the Wild with Convolutional Neural Networks.pdf:pdf},
isbn = {0920-5691},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Convolutional neural networks,Deep learning,Synthetic data,Text detection,Text recognition,Text retrieval,Text spotting},
number = {1},
pages = {1--20},
publisher = {Springer US},
title = {{Reading Text in the Wild with Convolutional Neural Networks}},
volume = {116},
year = {2016}
}
@inproceedings{Zhang2003a,
author = {Zhang, Bin and Srihari, Sargur N. and Huang, Chen},
booktitle = {Electronic Imaging 2004},
xxurl = {10.1117/12.523968},
editor = {{Barney Smith}, Elisa H. and Hu, Jianying and Allan, James},
month = {dec},
pages = {45--53},
publisher = {International Society for Optics and Photonics},
title = {{{\textless}title{\textgreater}Word image retrieval using binary features{\textless}/title{\textgreater}}},
year = {2003}
}
@article{Sakoe1978b,
annote = {From Duplicate 2 ( 





















Word spotting for historical documents





















- Rath, Tony M; Manmatha, R )







},
author = {Sakoe, H. and Chiba, S.},
xxurl = {10.1109/TASSP.1978.1163055},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sakoe, Chiba - 1978 - Dynamic programming algorithm optimization for spoken word recognition.pdf:pdf},
issn = {0096-3518},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
month = {feb},
number = {1},
pages = {43--49},
title = {{Dynamic programming algorithm optimization for spoken word recognition}},
volume = {26},
year = {1978}
}
@inproceedings{Ratanamahatana2005,
abstract = {The Dynamic Time Warping (DTW) distance measure is a technique that has long been known in speech recognition community. It allows a non-linear mapping of one signal to another by minimizing the distance between the two. A decade ago, DTW was introduced into Data Mining community as a utility for various tasks for time series problems including classification, clustering, and anomaly detection. The technique has flourished, particularly in the last three years, and has been applied to a variety of problems in various disciplines. In spite of DTW's great success, there are still several persistent “myths” about it. These myths have caused confusion and led to much wasted research effort. In this work, we will dispel these myths with the most comprehensive set of time series experiments ever conducted.},
author = {Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
booktitle = {Proceedings of SIAM International Conference on Data Mining (SDM'05)},
keywords = {data mining,dynamic time warping,experimentation},
pages = {506--510},
title = {{Three myths about dynamic time warping data mining}},
year = {2005}
}
@article{Westphal2018,
author = {Westphal, Florian and Lavesson, Niklas and Grahn, Hakan},
xxurl = {10.1109/DAS.2018.71},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Westphal, Lavesson, Grahn - 2018 - Document image binarization using recurrent neural networks.pdf:pdf},
isbn = {9781538633465},
journal = {DAS 2018},
keywords = {Grid LSTM,historical documents,image binarization,recurrent neural networks},
pages = {263--268},
publisher = {IEEE},
title = {{Document Image Binarization Using Recurrent Neural Networks}},
year = {2018}
}
@article{Kumaret.al.2015,
abstract = {Copy move forgery detection in digital images has become a very popular research topic in the area of image forensics. Due to the availability of sophisticated image editing tools and ever increasing hardware capabilities, it has become an easy task to manipulate the digital images. Passive forgery detection techniques are more relevant as they can be applied without the prior information about the image in question. Block based techniques are used to detect copy move forgery, but have limitations of large time complexity and sensitivity against affine operations like rotation and scaling. Keypoint based approaches are used to detect forgery in large images where the possibility of significant post processing operations like rotation and scaling is more. A hybrid approach is proposed using different methods for keypoint detection and description. Speeded Up Robust Features (SURF) are used to detect the keypoints in the image and Binary Robust Invariant Scalable Keypoints (BRISK) features are used to describe features at these keypoints. The proposed method has performed better than the existing forgery detection method using SURF significantly in terms of detection speed and is invariant to post processing operations like rotation and scaling. The proposed method is also invariant to other commonly applied post processing operations like adding Gaussian noise and JPEG compression.},
author = {Kumar, et. al., Sunil},
xxurl = {10.12785/ijcds/040203},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, et. al. - 2015 - A Fast Keypoint Based Hybrid Method for Copy Move Forgery Detection.pdf:pdf},
issn = {2210-142X},
journal = {International Journal of Computing and Digital Systems},
keywords = {blind forgery detection,brisk,hybrid technique,keypoint detection,surf},
number = {2},
pages = {91--99},
title = {{A Fast Keypoint Based Hybrid Method for Copy Move Forgery Detection}},
url = {https://journal.journals.uob.edu.bh//Article/ArticleFile/2141},
volume = {4},
year = {2015}
}
@article{Basics,
author = {Basics, Git},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Basics - Unknown - Git Cheat Sheet Additional Options.pdf:pdf},
pages = {1--2},
title = {{Git Cheat Sheet Additional Options +}}
}
@article{Maguluri2013,
author = {Maguluri, Hima Bindu and Tian, Qiongjie and Li, Baoxin},
xxurl = {10.1109/ICASSP.2013.6637990},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maguluri, Tian, Li - 2013 - Detecting text in floor maps using Histogram of Oriented Gradients.pdf:pdf},
isbn = {9781479903566},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Histogram of Oriented Gradients,Support Vector Machine,Text Detection},
number = {October 2013},
pages = {1932--1936},
title = {{Detecting text in floor maps using Histogram of Oriented Gradients}},
year = {2013}
}
@inproceedings{Rakthanmanon2013a,
abstract = {Most time series data mining algorithms use similarity search as a core subroutine, and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms, including classification, clustering, motif discovery, anomaly detection, and so on. The difficulty of scaling a search to large datasets explains to a great extent why most academic work on time series data mining has plateaued at considering a few millions of time series objects, while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine massive time series for the first time. We demonstrate the following unintuitive fact: in large datasets we can exactly search under Dynamic Time Warping (DTW) much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. In particular, the largest dataset we consider is larger than the combined size of all of the time series datasets considered in all data mining papers ever published. We explain how our ideas allow us to solve higher-level time series data mining problems such as motif discovery and clustering at scales that would otherwise be untenable. Moreover, we show how our ideas allow us to efficiently support the uniform scaling distance measure, a measure whose utility seems to be underappreciated, but which we demonstrate here. In addition to mining massive datasets with up to one trillion data points, we will show that our ideas also have implications for real-time monitoring of data streams, allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible. {\textcopyright} 2013 ACM.},
author = {Rakthanmanon, Thanawin and Campana, Bilson and Mueen, Abdullah and Batista, Gustavo and Westover, Brandon and Zhu, Qiang and Zakaria, Jesin and Keogh, Eamonn},
booktitle = {ACM Transactions on Knowledge Discovery from Data},
xxurl = {10.1145/2500489},
issn = {15564681},
keywords = {Lower bounds,Similarity search,Time series},
title = {{Addressing big data time series: Mining trillions of time series subsequences under dynamic time warping}},
year = {2013}
}
@article{Fischer2010,
author = {Fischer, Andreas and Keller, Andreas and Frinken, Volkmar and Bunke, Horst},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer et al. - 2010 - HMM-based Word Spotting in Handwritten Documents Using Subword Models.pdf:pdf},
isbn = {978-1-4244-7542-1},
journal = {ICPR},
keywords = {-handwriting recognition,hidden markov models},
month = {aug},
pages = {3416--3419},
publisher = {Ieee},
title = {{HMM-based Word Spotting in Handwritten Documents Using Subword Models}},
year = {2010}
}
@article{Zhu2013b,
author = {Zhu, Siyu and Zanibbi, Richard},
xxurl = {10.1109/ICDAR.2013.130},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Zanibbi - 2013 - Label Detection and Recognition for USPTO Images Using Convolutional K-Means Feature Quantization and Ada-Boost.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {633--637},
publisher = {Ieee},
title = {{Label Detection and Recognition for USPTO Images Using Convolutional K-Means Feature Quantization and Ada-Boost}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628695},
year = {2013}
}
@article{Stamatopoulos2008,
author = {Stamatopoulos, N. and Gatos, B. and Pratikakis, I. and Perantonis, S. J.},
xxurl = {10.1109/DAS.2008.40},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamatopoulos et al. - 2008 - A two-step dewarping of camera document images.pdf:pdf},
isbn = {9780769533377},
journal = {DAS 2008 - Proceedings of the 8th IAPR International Workshop on Document Analysis Systems},
pages = {209--216},
title = {{A two-step dewarping of camera document images}},
year = {2008}
}
@article{Bayraktar2017,
abstract = {The purpose of this study is to provide a detailed performance comparison of feature detector/descriptor methods, particularly when their various combinations are used for image-matching. The localization experiments of a mobile robot in an indoor environment are presented as a case study. In these experiments, 3090 query images and 127 dataset images were used. This study includes five methods for feature detectors (features from accelerated segment test (FAST), oriented FAST and rotated binary robust independent elementary features (BRIEF) (ORB), speeded-up robust features (SURF), scale invariant feature transform (SIFT), and binary robust invariant scalable keypoints (BRISK)) and five other methods for feature descriptors (BRIEF, BRISK, SIFT, SURF, and ORB). These methods were used in 23 different combinations and it was possible to obtain meaningful and consistent comparison results using the performance criteria defined in this study. All of these methods were used independently and separately from each other as either feature detector or descriptor. The performance analysis shows the discriminative power of various combinations of detector and descriptor methods. The analysis is completed using five parameters: (i) accuracy, (ii) time, (iii) angle difference between keypoints, (iv) number of correct matches, and (v) distance between correctly matched keypoints. In a range of 60{\{}$\backslash$deg{\}}, covering five rotational pose points for our system, the FAST-SURF combination had the lowest distance and angle difference values and the highest number of matched keypoints. SIFT-SURF was the most accurate combination with a 98.41{\%} correct classification rate. The fastest algorithm was ORB-BRIEF, with a total running time of 21,303.30 s to match 560 images captured during motion with 127 dataset images.},
archivePrefix = {arXiv},
arxivId = {1710.06232},
author = {Bayraktar, Ertuǧrul and Boyraz, Pinar},
xxurl = {10.3906/elk-1602-225},
eprint = {1710.06232},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bayraktar, Boyraz - 2017 - Analysis of feature detector and descriptor combinations with a localization experiment for various performan.pdf:pdf},
issn = {13036203},
journal = {Turkish Journal of Electrical Engineering and Computer Sciences},
keywords = {Feature detectors and descriptors,Localization,Object matching,Performance evaluation,Performance metrics},
number = {3},
pages = {2444--2454},
title = {{Analysis of feature detector and descriptor combinations with a localization experiment for various performance metrics}},
volume = {25},
year = {2017}
}
@article{Sam2012,
author = {Sam, Kam-tong and Tian, Xiao-lin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sam, Tian - 2012 - Vehicle Logo Recognition Using Modest AdaBoost and Radial Tchebichef Moments.pdf:pdf},
keywords = {modest adaboost,radial tchebichef moments,vehicle logo recognition},
pages = {91--95},
title = {{Vehicle Logo Recognition Using Modest AdaBoost and Radial Tchebichef Moments}},
volume = {25},
year = {2012}
}
@article{Iwamura2013,
author = {Iwamura, Masakazu and Tsukada, Masaki and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.276},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iwamura, Tsukada, Kise - 2013 - Automatic Labeling for Scene Text Database.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1365--1369},
publisher = {Ieee},
title = {{Automatic Labeling for Scene Text Database}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628837},
year = {2013}
}
@article{Junaidi2013,
author = {Junaidi, Akmal and Grzeszick, Rene and Fink, Gernot a. and Vajda, Szilard},
xxurl = {10.1109/ICDAR.2013.136},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Junaidi et al. - 2013 - Statistical Modeling of the Relation between Characters and Diacritics in Lampung Script.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-lampung script,diacritic-character relation},
month = {aug},
pages = {663--667},
publisher = {Ieee},
title = {{Statistical Modeling of the Relation between Characters and Diacritics in Lampung Script}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628701},
year = {2013}
}
@inproceedings{Vlachost2005,
abstract = {We present data representations, distance measures and organizational structures for fast and efficient retrieval of similar shapes in image databases. Using the Hough Transform we extract shape signatures that correspond to important features of an image. The new shape descriptor is robust against line discontinuities and takes into consideration not only the shape boundaries, but also the content inside the object perimeter. The object signatures are eventually projected into a space the renders them invariant to translation, scaling and rotation. In order to provide support for real-time query-by-content, we also introduce an index structure that hierarchically organizes compressed versions of the extracted object signatures. In this manner we can achieve a significant performance boost for multimedia retrieval. Our experiments suggest that by exploiting the proposed framework, similarity search in a database of 100,000 images would require under 1 sec, using an off-the-shelf personal computer. {\textcopyright} 2005 ACM.},
author = {Vlachost, Michail and Vagena, Zografoula and Yu, Philip S. and Athitsos, Vassilis},
booktitle = {International Conference on Information and Knowledge Management, Proceedings},
xxurl = {10.1145/1099554.1099580},
isbn = {1595931406},
keywords = {Hough Transform,Image Signature,Metric Tree},
title = {{Rotation invariant indexing of shapes and line drawings}},
year = {2005}
}
@article{Durand2016,
abstract = {In this paper, we introduce a novel framework for WEakly supervised Learning of Deep cOnvolutional neural Networks (WELDON). Our method is dedicated to automatically selecting relevant image regions from weak annotations, e.g. global image labels, and encompasses the following contributions. Firstly, WELDON leverages recent improvements on the Multiple Instance Learning paradigm, i.e. negative evidence scoring and top instance selection. Secondly, the deep CNN is trained to optimize Average Precision, and fine-tuned on the target dataset with efficient computations due to convolutional feature sharing. A thorough experimental validation shows that WELDON outperforms state-of-the-art results on six different datasets.},
author = {Durand, Thibaut and Thome, Nicolas and Cord, Matthieu},
xxurl = {10.1109/CVPR.2016.513},
file = {:home/mondal/Downloads/Durand{\_}WELDON{\_}Weakly{\_}Supervised{\_}CVPR{\_}2016{\_}paper.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {4743--4752},
title = {{WELDON: Weakly supervised learning of deep convolutional neural networks}},
volume = {2016-Decem},
year = {2016}
}
@article{Wang2013e,
author = {Wang, Xiaoqing and Liang, Xiaohui and Sun, Linjia and Liu, Min},
xxurl = {10.1109/ICDAR.2013.234},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2013 - Triangular Mesh Based Stroke Segmentation for Chinese Calligraphy.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1155--1159},
publisher = {Ieee},
title = {{Triangular Mesh Based Stroke Segmentation for Chinese Calligraphy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628795},
year = {2013}
}
@article{Alpaydn2012,
abstract = {The goal of machine learning is to program computers to use example data or past experience to solve a given problem. Many successful applications of machine learning exist already, including systems that analyze past sales data to predict customer behavior, optimize robot behavior so that a task can be completed using minimum resources, and extract knowledge from bioinformatics data. Introduction to Machine Learning is a comprehensive textbook on the subject, covering a broad array of topics not usually included in introductory machine learning texts. Subjects include supervised learning; Bayesian decision theory; parametric, semi-parametric, and nonparametric methods; multivariate analysis; hidden Markov models; reinforcement learning; kernel machines; graphical models; Bayesian estimation; and statistical testing. Machine learning is rapidly becoming a skill that computer science students must master before graduation. The third edition of Introduction to Machine Learning reflects this shift, with added support for beginners, including selected solutions for exercises and additional example data sets (with code available online). Other substantial changes include discussions of outlier detection; ranking algorithms for perceptrons and support vector machines; matrix decomposition and spectral methods; distance estimation; new kernel algorithms; deep learning in multilayered perceptrons; and the nonparametric approach to Bayesian methods. All learning algorithms are explained so that students can easily move from the equations in the book to a computer program. The book can be used by both advanced undergraduates and graduate students. It will also be of interest to professionals who are concerned with the application of machine learning methods.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Alpaydın, Ethem},
xxurl = {10.1007/s13398-014-0173-7.2},
eprint = {9809069v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alpaydın - 2012 - Introduction to machine learning.pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
journal = {The MIT Press},
number = {2},
pages = {81--87},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
title = {{Introduction to machine learning}},
volume = {XXXIII},
year = {2012}
}
@article{Ciresan2012,
abstract = {Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1202.2745v1},
author = {Cireşan, Dan and Meier, Ueli and Schmidhuber, Juergen},
xxurl = {10.1109/CVPR.2012.6248110},
eprint = {arXiv:1202.2745v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cireşan, Meier, Schmidhuber - 2012 - Multi-column Deep Neural Networks for Image Classification.pdf:pdf},
isbn = {978-1-4673-1228-8},
issn = {1063-6919},
journal = {International Conference of Pattern Recognition},
number = {February},
pages = {3642--3649},
pmid = {18225950},
title = {{Multi-column Deep Neural Networks for Image Classification}},
year = {2012}
}
@inproceedings{Fischer2010a,
abstract = {Automatic transcription of historical documents is vital for the creation of digital libraries. In this paper we propose graph similarity features as a novel descriptor for handwriting recognition in historical documents based on Hidden Markov Models. Using a structural graph-based representation of text images, a sequence of graph similarity features is extracted by means of dissimilarity embedding with respect to a set of character prototypes. On the medieval Parzival data set it is demonstrated that the proposed structural descriptor significantly outperforms two well-known statistical reference descriptors for single word recognition.},
author = {Fischer, Andreas and Riesen, Kaspar and Bunke, Horst},
booktitle = {ICFHR},
keywords = {HMM,Handwriting recognition,Hidden Markov models,character prototypes,digital libraries,dissimilarity embedding,document image processing,feature extraction,graph similarity features,graph theory,historical documents,image representation,medieval Parzival data set,novel descriptor,structural graph based representation,text analysis,text images},
language = {English},
month = {nov},
pages = {253--258},
publisher = {IEEE},
title = {{Graph Similarity Features for HMM-Based Handwriting Recognition in Historical Documents}},
year = {2010}
}
@article{Poznanski2016,
abstract = {Given an image of a handwritten word, a CNN is em-ployed to estimate its n-gram frequency profile, which is the set of n-grams contained in the word. Frequencies for un-igrams, bigrams and trigrams are estimated for the entire word and for parts of it. Canonical Correlation Analysis is then used to match the estimated profile to the true profiles of all words in a large dictionary. The CNN that is used employs several novelties such as the use of multiple fully connected branches. Applied to all commonly used hand-writing recognition benchmarks, our method outperforms, by a very large margin, all existing methods.},
author = {Poznanski, Arik and Wolf, Lior},
xxurl = {10.1109/CVPR.2016.253},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poznanski, Wolf - 2016 - CNN-N-Gram for HandwritingWord Recognition.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {10636919},
journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {2305--2314},
pmid = {12828330},
title = {{CNN-N-Gram for HandwritingWord Recognition}},
url = {http://ieeexplore.ieee.org/document/7780622/},
year = {2016}
}
@inproceedings{Vlachos2004,
abstract = {We present several methods for mining knowledge from the query logs of the MSN search engine. Using the query logs, we build a time series for each query word or phrase (e.g., 'Thanksgiving' or 'Christmas gifts') where the elements of the time series are the number of times that a query is issued on a day. All of the methods we describe use sequences of this form and can be applied to time series data generally. Our primary goal is the discovery of semantically similar queries and we do so by identifying queries with similar demand patterns. Utilizing the best Fourier coefficients and the energy of the omitted components, we improve upon the state-of-the-art in time-series similarity matching. The extracted sequence features are then organized in an efficient metric tree index structure. We also demonstrate how to efficiently and accurately discover the important periods in a time-series. Finally we propose a simple but effective method for identification of bursts (long or short-term). Using the burst information extracted from a sequence, we are able to efficiently perform 'query-by-burst' on the database of time-series. We conclude the presentation with the description of a tool that uses the described methods, and serves as an interactive exploratory data discovery tool for the MSN query database.},
author = {Vlachos, Michail and Meek, Chris and Vagena, Zografoula and Gunopulos, Dimitrios},
booktitle = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
xxurl = {10.1145/1007568.1007586},
issn = {07308078},
title = {{Identifying similarities, periodicities and bursts for online search queries}},
year = {2004}
}
@article{Indermuhle2011,
author = {Indermuhle, Emanuel and Frinken, Volkmar and Fischer, Andreas and Bunke, Horst},
xxurl = {10.1109/ICDAR.2011.24},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Indermuhle et al. - 2011 - Keyword Spotting in Online Handwritten Documents Containing Text and Non-text Using BLSTM Neural Networks.pdf:pdf},
isbn = {978-1-4577-1350-7},
journal = {2011 International Conference on Document Analysis and Recognition},
keywords = {documents containing text and,non-text,spotting in online handwritten,using blstm neural networks},
month = {sep},
pages = {73--77},
publisher = {Ieee},
title = {{Keyword Spotting in Online Handwritten Documents Containing Text and Non-text Using BLSTM Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065279},
year = {2011}
}
@article{Yeh2016a,
abstract = {Semantic image inpainting is a challenging task where large missing regions have to be filled based on the available visual data. Existing methods which extract information from only a single image generally produce unsatisfactory results due to the lack of high level context. In this paper, we propose a novel method for semantic image inpainting, which generates the missing content by conditioning on the available data. Given a trained generative model, we search for the closest encoding of the corrupted image in the latent image manifold using our context and prior losses. This encoding is then passed through the generative model to infer the missing content. In our method, inference is possible irrespective of how the missing content is structured, while the state-of-the-art learning based method requires specific information about the holes in the training phase. Experiments on three datasets show that our method successfully predicts information in large missing regions and achieves pixel-level photorealism, significantly outperforming the state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {1607.07539},
author = {Yeh, Raymond A. and Chen, Chen and Lim, Teck Yian and Schwing, Alexander G. and Hasegawa-Johnson, Mark and Do, Minh N.},
xxurl = {10.1109/CVPR.2017.728},
eprint = {1607.07539},
title = {{Semantic Image Inpainting with Deep Generative Models}},
url = {http://arxiv.org/abs/1607.07539},
year = {2016}
}
@article{Pouderoux2007,
author = {Pouderoux, Joachim and Spinello, Salvatore},
xxurl = {10.1109/ICDAR.2007.4377021},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pouderoux, Spinello - 2007 - Global contour lines reconstruction in topographic maps.pdf:pdf},
isbn = {0769528228},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
pages = {779--783},
title = {{Global contour lines reconstruction in topographic maps}},
volume = {2},
year = {2007}
}
@article{Kumar2013,
author = {Kumar, Vijay and Bansal, Amit and Tulsiyan, Goutam Hari and Mishra, Anand and Namboodiri, Anoop and Jawahar, C.V.},
xxurl = {10.1109/ICDAR.2013.146},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar et al. - 2013 - Sparse Document Image Coding for Restoration.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {dic-,document restoration,sparse representation},
month = {aug},
pages = {713--717},
publisher = {Ieee},
title = {{Sparse Document Image Coding for Restoration}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628711},
year = {2013}
}
@inproceedings{Fernandez-Mota2014,
author = {Fernandez-Mota, David and Riba, Pau and Fornes, Alicia and Llados, Josep},
booktitle = {14th International Conference on Frontiers in Handwriting Recognition},
xxurl = {10.1109/ICFHR.2014.86},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fernandez-Mota et al. - 2014 - On the Influence of Key Point Encoding for Handwritten Word Spotting.pdf:pdf},
isbn = {978-1-4799-4334-0},
keywords = {-local descriptors,documents,handwritten,historical document analysis,interest points,word spotting},
pages = {476--481},
title = {{On the Influence of Key Point Encoding for Handwritten Word Spotting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6981065},
year = {2014}
}
@article{Zhu2013a,
author = {Zhu, Bilan and Shivram, Arti and Setlur, Srirangaraj and Govindaraju, Venu and Nakagawa, Masaki},
xxurl = {10.1109/ICDAR.2013.77},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2013 - Online Handwritten Cursive Word Recognition Using Segmentation-Free MRF in Combination with P2DBMN-MQDF.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {beam search,mqdf,mrf,segmentation-free,trie lexicon,word recognition},
month = {aug},
pages = {349--353},
publisher = {Ieee},
title = {{Online Handwritten Cursive Word Recognition Using Segmentation-Free MRF in Combination with P2DBMN-MQDF}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628642},
year = {2013}
}
@article{Faloutsos1994,
author = {Faloutsos, Christos and Ranganathan, M. and Manolopoulos, Yannis},
xxurl = {10.1145/191843.191925},
isbn = {0-89791-639-5},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = {jun},
number = {2},
pages = {419--429},
publisher = {ACM},
title = {{Fast subsequence matching in time-series databases}},
url = {http://dl.acm.org/citation.cfm?id=191843.191925},
volume = {23},
year = {1994}
}
@article{Jawahar2004,
author = {Jawahar, C V and Meshesha, Million and Balasubramanian, A},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jawahar, Meshesha, Balasubramanian - 2004 - Searching in Document Images.pdf:pdf},
journal = {ICVGIP},
pages = {622--627},
title = {{Searching in Document Images.}},
year = {2004}
}
@article{Koknar-Tezel2010,
author = {K{\"{o}}knar-Tezel, Suzan and Latecki, Longin Jan},
xxurl = {10.1007/s10115-010-0310-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{o}}knar-Tezel, Latecki - 2010 - Improving SVM classification on imbalanced time series data sets with ghost points.pdf:pdf},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {imbalanced data sets,support vector machines,time series},
month = {jun},
number = {1},
pages = {1--23},
title = {{Improving SVM classification on imbalanced time series data sets with ghost points}},
url = {http://link.springer.com/10.1007/s10115-010-0310-3},
volume = {28},
year = {2010}
}
@article{Hu2013,
author = {Hu, Lei and Zanibbi, Richard},
xxurl = {10.1109/ICDAR.2013.239},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Zanibbi - 2013 - Segmenting Handwritten Math Symbols Using AdaBoost and Multi-scale Shape Context Features.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1180--1184},
publisher = {Ieee},
title = {{Segmenting Handwritten Math Symbols Using AdaBoost and Multi-scale Shape Context Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628800},
year = {2013}
}
@article{Krig2014,
abstract = {What is a good keypoint for a given application? Which ones are most useful? Which ones should be ignored? Tuning the detectors is not simple. Each detector has different parameters to tune for best results on a given image, and each image presents different challenges regarding lighting, contrast, and image pre-processing. Additionally, each detector is designed to be useful for a different class of interest points, and must be tuned accordingly to filter the results down to a useful set of good candidates for a specific feature descriptor. Each feature detector will work best with certain descriptors, see appendix A. So, the keypoints are further filtered to be useful for the chosen feature descriptor. In some cases, a keypoint is not suitable for producing a useful feature descriptor, even if the keypoint has a high score and high response. If the feature descriptor computed at the keypoint produces a descriptor score that is too weak, for example, the keypoint and corresponding descriptor should both be rejected. OpenCV provides several novel methods for working with detectors, enabling the user to try different detectors and descriptors in a common framework, and automatically adjust the parameters for tuning and culling as follows: • DynamicAdaptedFeatureDetector. This class will tune supported detectors using an adjusterAdapter() to only keep a limited number of features, and iterate the detector parameters several times and redetect features in an attempt to find the best parameters, keeping only the requested number of best features. Several OpenCV detectors have an adjusterAdapter() provided, some do not; the API allows for adjusters to be created. • AdjusterAdapter. This class implements the criteria for culling and keeping interest points. Criteria may include KNN nearest neighbor matching, detector response or strength, radius distance to nearest other detected points, number of keypoints within a local region, and other measures that can be included for culling keypoints for which a good descriptor cannot be computed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Krig, Scott},
xxurl = {10.1007/978-1-4302-5930-5},
eprint = {arXiv:1011.1669v3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krig - 2014 - Interest Point Detector and Feature Descriptor Survey.pdf:pdf},
isbn = {978-1-4302-5929-9},
issn = {1098-6596},
journal = {Computer Vision Metrics},
number = {1},
pages = {217--282},
pmid = {25246403},
title = {{Interest Point Detector and Feature Descriptor Survey}},
url = {http://link.springer.com/10.1007/978-1-4302-5930-5},
year = {2014}
}
@article{Yin2016,
abstract = {— The intelligent analysis of video data is currently in wide demand because a video is a major source of sensory data in our lives. Text is a prominent and direct source of information in video, while the recent surveys of text detection and recognition in imagery focus mainly on text extraction from scene images. Here, this paper presents a comprehensive survey of text detection, tracking, and recognition in video with three major contributions. First, a generic framework is proposed for video text extraction that uniformly describes detection, tracking, recognition, and their relations and interactions. Second, within this framework, a variety of methods, systems, and evaluation protocols of video text extraction are summarized, compared, and analyzed. Existing text tracking techniques, tracking-based detection and recognition techniques are specifically highlighted. Third, related applications, prominent challenges, and future directions for video text extraction (especially from scene videos and web videos) are also thoroughly discussed. Index Terms— Text tracking, tracking based text detection, tracking based text recognition, video text extraction, scene text.},
author = {Yin, Xu-Cheng and Zuo, Ze-Yu and Tian, Shu and Liu, Cheng-Lin},
xxurl = {10.1109/TIP.2016.2554321},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin et al. - 2016 - Text Detection, Tracking and Recognition in Video A Comprehensive Survey.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
number = {6},
pages = {2752--2773},
title = {{Text Detection, Tracking and Recognition in Video: A Comprehensive Survey}},
url = {http://ieeexplore.ieee.org/document/7452620/},
volume = {25},
year = {2016}
}
@article{Mesquita2015,
abstract = {Binarization of images of old documents is considered a challenging task due to the wide diversity of degradation effects that can be found. To deal with this, many algorithms whose performance depends on an appropriate choice of their parameters have been proposed. In this work, it is investigated the application of a racing procedure based on a statistical approach, named I/F-Race, to suggest the parameters for two binarization algorithms reasoned (i) on the perception of objects by distance (POD) and (ii) on the POD combined with a Laplacian energy-based technique. Our experiments show that both algorithms had their performance statistically improved outperforming other recent binarization techniques. The second proposal presented herein ranked first in H-DIBCO (Handwritten Document Image Binarization Contest) 2014.},
author = {Mesquita, Rafael G. and Silva, Ricardo M.A. A and Mello, Carlos A.B. B and Miranda, P??ricles B C P{\'{e}}ricles B.C.},
xxurl = {10.1016/j.eswa.2014.10.039},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mesquita et al. - 2015 - Parameter tuning for document image binarization using a racing algorithm.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mesquita et al. - 2015 - Parameter tuning for document image binarization using a racing algorithm(2).pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Document image binarization,Parameter tuning,Racing algorithms},
month = {apr},
number = {5},
pages = {2593--2603},
title = {{Parameter Tuning for Document Image Binarization Using a Racing Algorithm}},
volume = {42},
year = {2015}
}
@article{Zhu2018a,
abstract = {Since their introduction over a decade ago, time series motifs have become a fundamental tool for time series analytics, finding diverse uses in dozens of domains. In this work we introduce Time Series Chains, which are related to, but distinct from, time series motifs. Informally, time series chains are a temporally ordered set of subsequence patterns, such that each pattern is similar to the pattern that preceded it, but the first and last patterns are arbitrarily dissimilar. In the discrete space, this is similar to extracting the text chain “hit, hot, dot, dog” from a paragraph. The first and last words have nothing in common, yet they are connected by a chain of words with a small mutual difference. Time series chains can capture the evolution of systems, and help predict the future. As such, they potentially have implications for prognostics. In this work, we introduce a robust definition of time series chains, and a scalable algorithm that allows us to discover them in massive datasets.},
author = {Zhu, Yan and Imamura, Makoto and Nikovski, Daniel and Keogh, Eamonn},
xxurl = {10.1007/s10115-018-1224-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2018 - Matrix Profile VII Time Series Chains A New Primitive for Time Series Data Mining(2).pdf:pdf},
isbn = {9781538638347},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {Data Streams,Machine Learning: Data Mining,Machine Learning: Time-series,link analysis,motifs,prognostics,time series},
pages = {1--27},
title = {{Matrix Profile VII: Time Series Chains: A New Primitive for Time Series Data Mining}},
year = {2018}
}
@article{Wang2013d,
author = {Wang, Yanwei and Liu, Changsong and Ding, Xiaoqing},
xxurl = {10.1109/ICDAR.2013.211},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Liu, Ding - 2013 - Similar Pattern Discriminant Analysis for Improving Chinese Character Recognition Accuracy.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-similar pattern discriminant analysis,cascade mqdf,character discrimination,chinese character,similar},
month = {aug},
pages = {1056--1060},
publisher = {Ieee},
title = {{Similar Pattern Discriminant Analysis for Improving Chinese Character Recognition Accuracy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628776},
year = {2013}
}
@article{Bukhari2009a,
abstract = {Binarization is an important preprocessing step in several document image processing tasks. Nowadays hand-held camera devices are in widespread use, that allow fast and flexible document image capturing. But, they may produce degraded grayscale image, especially due to bad shading or nonuniform illumination. State-of-the-art binarization techniques, which are designed for scanned images, do not perform well on camera-captured documents. Further more, local adaptive binarization methods, like Niblack [1], Sauvola [2], etc, are sensitive to free parameter values, which are fixed for whole image. In this paper, we describe a novel binarization technique using ridges-guided local binarization method, in which appropriate free parameter value(s) is(are) selected for each pixel depending on the presence or absence of ridge(s) in the local neighborhood of a pixel. Our method gives a novel way of automatically selecting parameter values for local binarization method, this improves binarization results for both scanned and camera-captured document images relative to previous methods. Experimental results on a subset of CBDAR 2007 document image dewarping contest dataset show a decrease in OCR error rate using reported method with respect to other stat-of-the-art bianrization methods.},
author = {Bukhari, Syed Saqib and Shafait, Faisal and Breuel, Thomas},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bukhari, Shafait, Breuel - 2009 - Foreground-Background Regions Guided Binarization of Camera-Captured Document Images.pdf:pdf},
journal = {Proceedings of the Third International Workshop on Camera Based Document Analysis and Recognition. International Workshop on Camera-Based Document Analysis and Recognition (CBDAR-09), located at ICDAr 2009, June 25, Barcelona, Spain},
title = {{Foreground-Background Regions Guided Binarization of Camera-Captured Document Images}},
url = {http://www.dfki.de/web/forschung/publikationen/renameFileForDownload?filename=2009-IUPR-21Aug{\_}1654.pdf{\&}file{\_}id=uploads{\_}348},
year = {2009}
}
@article{Pevzner2000,
abstract = {Signal finding (pattern discovery in unaligned DNA sequences) is a fundamental problem in both computer science and molecular biology with important applications in locating regulatory sites and drug target identification. Despite many studies, this problem is far from being resolved: most signals in DNA sequences are so complicated that we don't yet have good models or reliable algorithms for their recognition. We complement existing statistical and machine learning approaches to this problem by a combinatorial approach that proved to be successful in identifying very subtle signals.},
author = {Pevzner, P A and Sze, S H},
issn = {1553-0833},
journal = {Proceedings. International Conference on Intelligent Systems for Molecular Biology},
pages = {269--78},
pmid = {10977088},
title = {{Combinatorial approaches to finding subtle signals in DNA sequences.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10977088},
volume = {8},
year = {2000}
}
@article{Mukherji2009,
author = {Mukherji, Prachi and Rege, Priti P},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mukherji, Rege - 2009 - Shape Feature and Fuzzy Logic Based Offline Devnagari Handwritten Optical Character Recognition.pdf:pdf},
keywords = {average compressed direction codes,devnagari script,fuzzy logic,ordered stroke matching,un-},
pages = {52--68},
title = {{Shape Feature and Fuzzy Logic Based Offline Devnagari Handwritten Optical Character Recognition}},
volume = {4},
year = {2009}
}
@article{Allison1987,
abstract = {Title of program: CXHULL Catalogue number: AATI Program obtainable from: CPC Program Library, Queen's University of Belfast, N. Ireland (see application form in this issue) Computer: VAX 8600; Installation: Lockheed Palo Alto Research Labs. Operating system: VMS Version 4.2 Programming language used: Fortran 77 High speed storage required: 8123 words No. of bits in a word: 32 No. of lines in combined program and test deck: 669. ?? 1987.},
author = {Allison, D. C S and Noga, M. T.},
xxurl = {10.1016/0010-4655(87)90055-5},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allison, Noga - 1987 - Computing the convex hull of a set of points.pdf:pdf},
issn = {00104655},
journal = {Computer Physics Communications},
keywords = {convex hull,polygon,sorting},
number = {3},
pages = {381--386},
title = {{Computing the convex hull of a set of points}},
volume = {43},
year = {1987}
}
@article{Yin2013a,
author = {Yin, Fei and Wang, Qiu-Feng and Zhang, Xu-Yao and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.218},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin et al. - 2013 - ICDAR 2013 Chinese Handwriting Recognition Competition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {but the participants are,casia-hwdb,chinese handwriting recognition competition,handwritten text recognition,isolated character recongition,offline,olhwdb database,online,training datasets were recommended},
month = {aug},
pages = {1464--1470},
publisher = {Ieee},
title = {{ICDAR 2013 Chinese Handwriting Recognition Competition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628856},
year = {2013}
}
@article{Zagoris2013,
author = {Zagoris, Konstantinos and Pratikakis, Ioannis},
xxurl = {10.1109/ICDAR.2013.277},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zagoris, Pratikakis - 2013 - Text Detection in Natural Images Using Bio-inspired Models.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1370--1374},
publisher = {Ieee},
title = {{Text Detection in Natural Images Using Bio-inspired Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628838},
year = {2013}
}
@article{AlKhateeb2011c,
author = {AlKhateeb, Jawad H. and Pauplin, Olivier and Ren, Jinchang and Jiang, Jianmin},
xxurl = {10.1016/j.knosys.2011.02.008},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/AlKhateeb et al. - 2011 - Performance of hidden Markov model and dynamic Bayesian network classifiers on handwritten Arabic word recogni.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {dbn,dynamic bayesian network,hidden markov model,hmm,off-line handwritten recognition},
month = {jul},
number = {5},
pages = {680--688},
publisher = {Elsevier B.V.},
title = {{Performance of hidden Markov model and dynamic Bayesian network classifiers on handwritten Arabic word recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950705111000359},
volume = {24},
year = {2011}
}
@article{Baronia2013,
author = {Baronia, Shrikant and Namboodiri, Anoop},
xxurl = {10.1109/ICDAR.2013.50},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baronia, Namboodiri - 2013 - Ink-Bleed Reduction Using Layer Separation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {215--219},
publisher = {Ieee},
title = {{Ink-Bleed Reduction Using Layer Separation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628615},
year = {2013}
}
@article{Coleman1979,
abstract = {This paper describes a procedure for segmenting imagery using digital methods and is based on a mathematical-pattern recognition model. The technique does not require training prototypes but operates in an "unsupervised" mode. The features most useful for the given image to be segmented are retained by the algorithm without human interaction, by rejecting those attributes which do not contribute to homogeneous clustering in N-dimensional vector space. The basic procedure is a K-means clustering algorithm which converges to a local minimum in the average squared intercluster distance for a specified number of clusters. The algorithm iterates on the number of clusters, evaluating the clustering based on a parameter of clustering quality. The parameter proposed is a product of between and within cluster scatter measures, which achieves a maximum value that is postulated to represent an intrinsic number of clusters in the data. At this value, feature rejection is implemented via a Bhattacharyya measure to make the image segments more homogeneous (thereby removing "noisy" features); and reclustering is performed. The resulting parameter of clustering fidelity is maximized with segmented imagery resulting in psychovisually pleasing and culturally logical image segments.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Coleman, Guy B. and Andrews, Harry C.},
xxurl = {10.1109/PROC.1979.11327},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {15582256},
journal = {Proceedings of the IEEE},
number = {5},
pages = {773--785},
pmid = {25246403},
title = {{Image Segmentation by Clustering}},
volume = {67},
year = {1979}
}
@article{El-Korashy2013,
author = {El-Korashy, Akram and Shafait, Faisal},
xxurl = {10.1109/ICDAR.2013.228},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/El-Korashy, Shafait - 2013 - Search Space Reduction for Holistic Ligature Recognition in Urdu Nastalique Script.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1125--1129},
publisher = {Ieee},
title = {{Search Space Reduction for Holistic Ligature Recognition in Urdu Nastalique Script}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628789},
year = {2013}
}
@article{Khoswanto2009,
author = {Khoswanto, T H and Pangaldus, R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khoswanto, Pangaldus - 2009 - Artificial Neural Network with Steepest DescentBackpropagation Training Algorithm forModeling Inverse Kine.pdf:pdf},
journal = {World Academy of Science, Engineering and Technology},
keywords = {artificial neural network,backpropagation,inverse,kinematics,manipulator,robot},
pages = {671--674},
title = {{Artificial Neural Network with Steepest DescentBackpropagation Training Algorithm forModeling Inverse Kinematics of Manipulator}},
volume = {60},
year = {2009}
}
@article{Li2014b,
author = {Li, Nan and Chen, Jinying and Cao, Huaigu and Zhang, Bing and Natarajan, Prem},
xxurl = {10.1109/ICFHR.2014.30},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2014 - Applications of Recurrent Neural Network Language Model in Offline Handwriting Recognition and Word Spotting.pdf:pdf},
isbn = {978-1-4799-4334-0},
journal = {2014 14th International Conference on Frontiers in Handwriting Recognition},
keywords = {- optical character recognition,2,3,due to its non-markovian,gram language models,information retrieval,keyword search,language model,nature,optical character recognition, keyword search, rec,recurrent neural networks,rnnlm,the n-,which is superior to},
pages = {134--139},
title = {{Applications of Recurrent Neural Network Language Model in Offline Handwriting Recognition and Word Spotting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6981009},
year = {2014}
}
@article{Khandelwal2009,
author = {Khandelwal, Abhishek and Choudhury, Pritha and Sarkar, Ram and Basu, Subhadip and Nasipuri, Mita and Das, Nibaran},
xxurl = {10.1007/978-3-642-11164-8_60},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khandelwal et al. - 2009 - Text line segmentation for unconstrained handwritten document images using neighborhood connected component a.pdf:pdf},
isbn = {3642111637},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Handwritten script,Neighborhood connected component analysis,Text line identification},
pages = {369--374},
title = {{Text line segmentation for unconstrained handwritten document images using neighborhood connected component analysis}},
volume = {5909 LNCS},
year = {2009}
}
@article{Zagoris2014,
author = {Zagoris, Konstantinos and Pratikakis, Ioannis and Gatos, Basilis},
xxurl = {10.1109/ICFHR.2014.10},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zagoris, Pratikakis, Gatos - 2014 - Segmentation-Based Historical Handwritten Word Spotting Using Document-Specific Local Features.pdf:pdf},
isbn = {978-1-4799-4334-0},
journal = {2014 14th International Conference on Frontiers in Handwriting Recognition},
keywords = {Word Spotting, Handwritten Documents, Local Featur,handwritten documents,local fea-,word spotting},
pages = {9--14},
title = {{Segmentation-Based Historical Handwritten Word Spotting Using Document-Specific Local Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6980989},
year = {2014}
}
@article{Gatos2010,
author = {Gatos, B. and Ntirogiannis, K. and Pratikakis, I.},
xxurl = {10.1007/s10032-010-0115-7},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos, Ntirogiannis, Pratikakis - 2010 - DIBCO 2009 document image binarization contest.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
keywords = {binarization,document image preprocessing,performance evaluation},
month = {may},
number = {1},
pages = {35--44},
title = {{DIBCO 2009: document image binarization contest}},
volume = {14},
year = {2010}
}
@inproceedings{Sudholt2015,
author = {Sudholt, Sebastian and Rothacker, Leonard and Fink, Gernot A},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sudholt, Rothacker, Fink - 2015 - Learning Local Image Descriptors for Word Spotting.pdf:pdf},
isbn = {9781479918058},
pages = {651--655},
title = {{Learning Local Image Descriptors for Word Spotting}},
year = {2015}
}
@article{Sarkar2010a,
author = {Sarkar, Aisharjya and Biswas, Arindam and Bhowmick, Partha and Bhattacharya, Bhargab B.},
xxurl = {10.1109/ICFHR.2010.76},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarkar et al. - 2010 - Word Segmentation and Baseline Detection in Handwritten Documents Using Isothetic Covers.pdf:pdf},
isbn = {978-1-4244-8353-2},
journal = {2010 12th International Conference on Frontiers in Handwriting Recognition},
month = {nov},
pages = {445--450},
publisher = {Ieee},
title = {{Word Segmentation and Baseline Detection in Handwritten Documents Using Isothetic Covers}},
year = {2010}
}
@article{Shekhar2013,
author = {Shekhar, Ravi and Jawahar, C.V.},
xxurl = {10.1109/ICDAR.2013.132},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shekhar, Jawahar - 2013 - Document Specific Sparse Coding for Word Retrieval.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {bag of,document image retrieval,sparse coding},
month = {aug},
pages = {643--647},
publisher = {Ieee},
title = {{Document Specific Sparse Coding for Word Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628697},
year = {2013}
}
@article{Hoang2010,
abstract = {In this paper, we present a novel graph-based method for extracting handwritten text lines in monochromatic Ara- bic document images. Our approach consists of two steps - Coarse text line estimation using primary components which define the line and assignment of diacritic components which are more difficult to associate with a given line. We first esti- mate local orientation at each primary component to build a sparse similarity graph. We then, use a shortest path algorithm to compute similarities between non-neighboring components. From this graph, we obtain coarse text lines using two estimates obtained from Affinity propagation and Breadth-first search. In the second step, we assign secondary components to each text line. The proposed method is very fast and robust to non-uniform skew and character size variations, normally present in handwritten text lines. We evaluate our method using a pixel-matching criteria, and report 96{\%} accuracy on a dataset of 125 Arabic document images. We also present a proximity analysis on datasets generated by artificially decreasing the spacings between text lines to demonstrate the robustness of our approach. Copyright 2010 ACM.},
author = {Hoang, Thai V. and Tabbone, Salvatore},
xxurl = {10.1145/1815330.1815349},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoang, Tabbone - 2010 - Text extraction from graphical document images using sparse representation.pdf:pdf},
isbn = {9781605587738},
journal = {Proceedings of the 8th IAPR International Workshop on Document Analysis Systems (DAS)},
keywords = {Arabic documents,Handwritten documents,Text line segmentation},
pages = {143--150},
pmid = {3354785},
title = {{Text extraction from graphical document images using sparse representation}},
volume = {2010},
year = {2010}
}
@article{Prasad2001,
author = {Prasad, B. G. and Gupta, S. K. and Biswas, K. K.},
isbn = {3-540-42120-3},
month = {may},
pages = {716--728},
publisher = {Springer-Verlag},
title = {{Color and Shape Index for Region-Based Image Retrieval}},
url = {http://dl.acm.org/citation.cfm?id=645651.665190},
year = {2001}
}
@article{Agrawal1993,
author = {Agrawal, Rakesh and Faloutsos, Christos and Swami, Arun N.},
isbn = {3-540-57301-1},
month = {oct},
pages = {69--84},
publisher = {Springer-Verlag},
title = {{Efficient Similarity Search In Sequence Databases}},
url = {http://dl.acm.org/citation.cfm?id=645415.652239},
year = {1993}
}
@article{Mondal2016a,
abstract = {In this paper, a robust method is presented to perform word spotting in degraded handwritten and printed document images. A new sequence matching technique, called the Flexible Sequence Matching (FSM) algorithm, is introduced for this word spotting task. The FSM algorithm was specially designed to incorporate crucial characteristics of other sequence matching algorithms (especially Dynamic Time Warping (DTW), Subsequence DTW (SSDTW), Minimal Variance Matching (MVM) and Continuous Dynamic Programming (CDP)). Along with the characteristics of multiple matching (many-to-one and one-to-many), FSM is strongly capable of skipping existing outliers or noisy elements, regardless of their positions in the target signal. More precisely, in the domain of word spotting, FSM has the ability to retrieve complete words or words that contain only a part of the query. Furthermore, due to its adaptable skipping capability, FSM is less sensitive to local variation in the spelling of words and to local degradation effects within the word image. The multiple matching capability (many-to-one, one-to-many) of FSM helps it addressing the stretching effects of query and/or target images. Moreover, FSM is designed in such a way that with little modification, its architecture can be changed into the architecture of DTW, MVM, and SSDTW and to CDP-like techniques. To illustrate these possibilities for FSM applied to specific cases of word spotting, such as incorrect word segmentation and word-level local variations, we performed experiments on historical handwritten documents and also on historical printed document images. To demonstrate the capabilities of sub-sequence matching, of noise skipping, as well as the ability to work in a multilingual paradigm with local spelling variations, we have considered properly segmented lines of historical handwritten documents in different languages and improperly as well as properly segmented words in printed and handwritten historical documents. From the comparative experimental results shown in this paper, it can be clearly seen that FSM can be equivalent or better than most DTW-based word spotting techniques in the literature while providing at the same time more meaningful correspondences between elements.},
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean Yves and Pal, Umapada},
xxurl = {10.1016/j.patcog.2016.05.011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2016 - Flexible Sequence Matching technique An effective learning-free approach for word spotting(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Continuous Dynamic Programming (CDP),Dynamic Time Warping (DTW),Flexible Sequence Matching (FSM),George Washington dataset,Handwritten documents,Historical documents,Minimal Variance Matching (MVM),Printed documents,Subsequence DTW (SSDTW),Word spotting},
pages = {596--612},
title = {{Flexible Sequence Matching technique: An effective learning-free approach for word spotting}},
volume = {60},
year = {2016}
}
@article{Lowe1999,
author = {Lowe, D.G.},
xxurl = {10.1109/ICCV.1999.790410},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowe - 1999 - Object recognition from local scale-invariant features.pdf:pdf},
isbn = {0-7695-0164-8},
journal = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
keywords = {3D projection,Computer science,Electrical capacitance tomography,Filters,Image recognition,Layout,Lighting,Neurons,Object recognition,Programmable logic arrays,Reactive power,blurred image gradients,candidate object matches,cluttered partially occluded images,computation time,computational geometry,feature extraction,image matching,inferior temporal cortex,least squares approximations,local geometric deformations,local image features,local scale-invariant features,low residual least squares solution,multiple orientation planes,nearest neighbor indexing method,primate vision,robust object recognition,staged filtering approach,unknown model parameters},
language = {English},
pages = {1150--1157 vol.2},
publisher = {Ieee},
title = {{Object recognition from local scale-invariant features}},
volume = {2},
year = {1999}
}
@article{Woalder2017,
author = {Woalder},
xxurl = {10.1016/j.physbeh.2017.03.040},
file = {:home/mondal/Downloads/nihms-818917.pdf:pdf},
isbn = {2163684814},
journal = {Physiology {\&} behavior},
keywords = {determination,protein crystallography,protein data bank,r -factor,resolution,restraints,structure,structure interpretation,structure quality,structure refinement,structure validation},
number = {1},
pages = {139--148},
title = {{乳鼠心肌提取 HHS Public Access}},
volume = {176},
year = {2017}
}
@article{Zirari2013,
author = {Zirari, F. and Ennaji, a. and Nicolas, S. and Mammass, D.},
xxurl = {10.1109/ICDAR.2013.154},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zirari et al. - 2013 - A Document Image Segmentation System Using Analysis of Connected Components.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {non-text,text},
month = {aug},
pages = {753--757},
publisher = {Ieee},
title = {{A Document Image Segmentation System Using Analysis of Connected Components}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628719},
year = {2013}
}
@article{Kulbacki2002a,
author = {Kulbacki, Marek and Kulbacki, Marek and Segen, Jakub and Segen, Jakub and Bak, Artur and Bak, Artur},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulbacki et al. - 2002 - Unsupervised Learning Motion Models Using Dynamic Time Warping.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulbacki et al. - 2002 - Unsupervised Learning Motion Models Using Dynamic Time Warping(2).pdf:pdf},
isbn = {3-7908-1509-8},
journal = {Systems Research},
keywords = {classi cation,computer animation,dynamic time warping,grouping,motion,motion capture,probabilistic motion models},
month = {jun},
number = {July 2015},
pages = {1--10},
publisher = {Physica-Verlag},
title = {{Unsupervised Learning Motion Models Using Dynamic Time Warping}},
year = {2002}
}
@article{Ahmed2012b,
abstract = {In this paper we propose a novel part-based method for the extraction of text touching graphic components. The Speeded Up Robust Features (SURF) are used to localize the text components and distinguish them from graphics. We introduce several post-processing steps to finally detect the text. We have tested our method on a publicly available data set of architectural floor plans and on real geographical maps. On floor plans we have located more than 95{\%}ofthe text components which were not identified as text beforehand because they were touching graphic components.},
author = {Ahmed, Sheraz and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/DAS.2012.39},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Liwicki, Dengel - 2012 - Extraction of text touching graphics using SURF.pdf:pdf},
isbn = {9780769546612},
journal = {Proceedings - 10th IAPR International Workshop on Document Analysis Systems, DAS 2012},
keywords = {SURF,Text extraction,Text/graphics segmentation},
number = {March},
pages = {349--353},
title = {{Extraction of text touching graphics using SURF}},
year = {2012}
}
@article{Krishnan2016,
author = {Krishnan, Reshmi and Anil, A R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krishnan, Anil - 2016 - A Survey On Image Matching Methods.pdf:pdf},
keywords = {dem,fsift,image matching,phase correlation,sift,surf},
number = {1},
pages = {58--61},
title = {{A Survey On Image Matching Methods}},
volume = {2},
year = {2016}
}
@article{Rigollet2015,
author = {Rigollet, Lecturer Philippe},
file = {:home/mondal/Documents/MATHS/MIT18{\_}657F15{\_}LecNote.pdf:pdf},
title = {{MIT18{\_}657F15{\_}LecNote}},
year = {2015}
}
@article{Almazan2013,
abstract = {We propose an approach to multi-writer word spotting, where the goal $\backslash$nis to find a query word in a dataset comprised of document images. We propose an $\backslash$nattributes-based approach that leads to a low-dimensional, fixed-length $\backslash$nrepresentation of the word images that is fast to compute and, especially, fast $\backslash$nto compare. This approach naturally leads to an unified representation of word $\backslash$nimages and strings, which seamlessly allows one to indistinctly perform $\backslash$nquery-by-example, where the query is an image, and query-by-string, where the $\backslash$nquery is a string. We also propose a calibration scheme to correct the $\backslash$nattributes scores based on Canonical Correlation Analysis that greatly improves $\backslash$nthe results on a challenging dataset. We test our approach on two public $\backslash$ndatasets showing state-of-the-art results.},
author = {Almazan, Jon and Gordo, Albert and Fornes, Alicia and Valveny, Ernest},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almazan et al. - 2013 - Handwritten Word Spotting with Corrected Attributes.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almazan et al. - 2013 - Handwritten Word Spotting with Corrected Attributes(2).pdf:pdf},
journal = {ICCV},
keywords = {ap-,as a consequence,at test time,attribu,be used as queries,because the methods deal,can,computing distances between words,document image processing,is usually very slow,known at training time,query processing,second,sequences of features,which need to be,with},
month = {dec},
pages = {1017--1024},
publisher = {Ieee},
title = {{Handwritten Word Spotting with Corrected Attributes}},
year = {2013}
}
@article{Of2011,
author = {Of, Ournal},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Of - 2011 - Robust Logo Recognition for Mobile Phone Applications.pdf:pdf},
keywords = {geometric and photo-,logo recognition and retrieval,metric transformations,mobile phone camera,phase and magnitude information,precision,zernike moments},
pages = {545--559},
title = {{Robust Logo Recognition for Mobile Phone Applications}},
volume = {559},
year = {2011}
}
@article{Chua,
author = {Chu, Selina and Narayanan, Shrikanth and Kuo, C Jay},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chu, Narayanan, Kuo - Unknown - Efficient Rotation Invariant Retrieval of Shapes using Dynamic Time Warping with Applications in Medical.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chu, Narayanan, Kuo - Unknown - Efficient Rotation Invariant Retrieval of Shapes using Dynamic Time Warping with Applications in Medi(2).pdf:pdf},
title = {{Efficient Rotation Invariant Retrieval of Shapes using Dynamic Time Warping with Applications in Medical Databases}}
}
@article{Gullo2009,
abstract = {Similarity search and detection is a central problem in time series data processing and management. Most approaches to this problem have been developed around the notion of dynamic time warping, whereas several dimensionality reduction techniques have been proposed to improve the efficiency of similarity searches. Due to the continuous increasing of sources of time series data and the cruciality of real-world applications that use such data, we believe there is a challenging demand for supporting similarity detection in time series in a both accurate and fast way. Our proposal is to define a concise yet feature-rich representation of time series, on which the dynamic time warping can be applied for effective and efficient similarity detection of time series. We present the Derivative time series Segment Approximation (DSA) representation model, which originally features derivative estimation, segmentation and segment approximation to provide both high sensitivity in capturing the main trends of time series and data compression. We extensively compare DSA with state-of-the-art similarity methods and dimensionality reduction techniques in clustering and classification frameworks. Experimental evidence from effectiveness and efficiency tests on various datasets shows that DSA is well-suited to support both accurate and fast similarity detection. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Gullo, Francesco and Ponti, Giovanni and Tagarelli, Andrea and Greco, Sergio},
xxurl = {10.1016/j.patcog.2009.03.030},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Classification,Clustering,Dimensionality reduction,Representation models,Similarity detection,Time series data},
pages = {2998--3014},
title = {{A time series representation model for accurate and fast similarity detection}},
volume = {42},
year = {2009}
}
@article{Xia2008,
abstract = {In this paper, a novel method for recognizing logos in natural images is presented. The difficulties lie in: (1) the logos in different images are highly variated in shape and location; (2) images will usually have several different kinds of logos; (3) the logo will be occluded by other objects, which traditional methods usually fail. Therefore, a learning-based logo recognition method is proposed to detect and classify the logos in natural image. First, the SIFT matching solution is applied in a set of training data to reliably detect the interest region in images and extract the discriminate features, which is used as the signature of each logo. Second, the approximate nearest neighbor searching strategy is build up by formulating the data into tree-based structure, for the purpose of efficient matching. Finally, to recognize the logos in test image, the corresponding SIFT features will be computed in the interest regions of test image and matched in the database which is achieved in the training stage. Promising results have been obtained in robustly classifying thousands of logos in the images captured by mobile phones, which the recognition accuracy is 95{\%}.},
author = {Xia, Liangfa and Qi, Feihu and Zhou, Qianhao},
xxurl = {10.1109/ICINFA.2008.4608292},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia, Qi, Zhou - 2008 - A learning-based logo recognition algorithm using SIFT and efficient correspondence matching.pdf:pdf},
isbn = {9781424421848},
journal = {Proceedings of the 2008 IEEE International Conference on Information and Automation, ICIA 2008},
keywords = {Logo recognition,Object matching,SIFT},
pages = {1767--1772},
title = {{A learning-based logo recognition algorithm using SIFT and efficient correspondence matching}},
year = {2008}
}
@misc{denoisingAE_2,
title = {{Denoising Autoencoders (dA) — DeepLearning 0.1 documentation}},
url = {http://deeplearning.net/tutorial/dA.html},
urldate = {2018-03-29}
}
@inproceedings{Dovgalecs2013,
author = {Dovgalecs, Vladislavs and Burnett, Alexandre and Tranouez, Pierrick and Nicolas, Stephane and Heutte, Laurent},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dovgalecs et al. - 2013 - Spot It! Finding Words and Patterns in Historical Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
issn = {1520-5363},
keywords = {BOVW representation,Clustering algorithms,Databases,DocExplore project,Feature extraction,George Washington handwritten document database,Hidden Markov models,LWP algorithm,Robustness,Training,Visualization,bag of visual words representation,document image analysis,document image processing,document understanding,filtering theory,historical documents,image retrieval,longest weighted profile algorithm,medieval manuscripts,pattern spotting,segmentation free,user made query,word spotting},
language = {English},
month = {aug},
pages = {1039--1043},
publisher = {IEEE},
title = {{Spot It! Finding Words and Patterns in Historical Documents}},
year = {2013}
}
@article{Chen2019,
abstract = {Font selection is one of the most important steps in a design workflow. Traditional methods rely on ordered lists which require significant domain knowledge and are often difficult to use even for trained professionals. In this paper, we address the problem of large-scale tag-based font retrieval which aims to bring semantics to the font selection process and enable people without expert knowledge to use fonts effectively. We collect a large-scale font tagging dataset of high-quality professional fonts. The dataset contains nearly 20,000 fonts, 2,000 tags, and hundreds of thousands of font-tag relations. We propose a novel generative feature learning algorithm that leverages the unique characteristics of fonts. The key idea is that font images are synthetic and can therefore be controlled by the learning algorithm. We design an integrated rendering and learning process so that the visual feature from one image can be used to reconstruct another image with different text. The resulting feature captures important font design details while is robust to nuisance factors such as text. We propose a novel attention mechanism to re-weight the visual feature for joint visual-text modeling. We combine the feature and the attention mechanism in a novel recognition-retrieval model. Experimental results show that our method significantly outperforms the state-of-the-art for the important problem of large-scale tag-based font retrieval.},
archivePrefix = {arXiv},
arxivId = {1909.02072},
author = {Chen, Tianlang and Wang, Zhaowen and Xu, Ning and Jin, Hailin and Luo, Jiebo},
eprint = {1909.02072},
file = {:home/mondal/Downloads/Chen{\_}Large-Scale{\_}Tag-Based{\_}Font{\_}Retrieval{\_}With{\_}Generative{\_}Feature{\_}Learning{\_}ICCV{\_}2019{\_}paper.pdf:pdf},
pages = {9116--9125},
title = {{Large-scale Tag-based Font Retrieval with Generative Feature Learning}},
url = {http://arxiv.org/abs/1909.02072},
year = {2019}
}
@article{Campos2015,
author = {Campos, Francisco M. and Correia, Lu{\'{i}}s and Calado, J. M. F.},
xxurl = {10.1007/s10846-013-0016-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campos, Correia, Calado - 2015 - Robot Visual Localization Through Local Feature Fusion An Evaluation of Multiple Classifiers Combinatio.pdf:pdf},
issn = {0921-0296},
journal = {Journal of Intelligent {\&} Robotic Systems},
month = {feb},
number = {2},
pages = {377--390},
publisher = {Springer Netherlands},
title = {{Robot Visual Localization Through Local Feature Fusion: An Evaluation of Multiple Classifiers Combination Approaches}},
url = {http://link.springer.com/10.1007/s10846-013-0016-3},
volume = {77},
year = {2015}
}
@article{Narang2013,
author = {Narang, Vipin and Roy, Sujoy and Murthy, O.V.R. and Hanmandlu, M.},
xxurl = {10.1109/ICDAR.2013.184},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Narang et al. - 2013 - Devanagari Character Recognition in Scene Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {000 most,10,and icdar03,camera-based character recognition,devanagari characters,frequently used english words,in training their framework,object,of 10,part-based model,recognition,they use a dictionary},
month = {aug},
pages = {902--906},
publisher = {Ieee},
title = {{Devanagari Character Recognition in Scene Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628749},
year = {2013}
}
@article{YALM18,
author = {Yagoubi, Djamel Edine and Akbarinia, Reza and Kolev, Boyan and Levchenko, Oleksandra and Masseglia, Florent and Valduriez, Patrick and Shasha, Dennis E},
xxurl = {10.1007/s10618-018-0580-z},
journal = {Data Mining and Knowledge Discovery (DMKD)},
number = {5},
pages = {1481--1507},
title = {{ParCorr: efficient parallel methods to identify similar time series pairs across sliding windows}},
url = {https://xxurl.org/10.1007/s10618-018-0580-z},
volume = {32},
year = {2018}
}
@article{Wei2013,
author = {Wei, Hao and Baechler, Micheal and Slimane, Fouad and Ingold, Rolf},
xxurl = {10.1109/ICDAR.2013.247},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei et al. - 2013 - Evaluation of SVM, MLP and GMM Classifiers for Layout Analysis of Historical Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1220--1224},
publisher = {Ieee},
title = {{Evaluation of SVM, MLP and GMM Classifiers for Layout Analysis of Historical Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628808},
year = {2013}
}
@article{Lemire2009,
abstract = {The dynamic time warping (DTW) is a popular similarity measure between time series. The DTW fails to satisfy the triangle inequality and its computation requires quadratic time. Hence, to find closest neighbors quickly, we use bounding techniques. We can avoid most DTW computations with an inexpensive lower bound (LB{\_}Keogh). We compare LB{\_}Keogh with a tighter lower bound (LB{\_}Improved). We find that LB{\_}Improved-based search is faster. As an example, our approach is 2-3 times faster over random-walk and shape time series. ?? 2008 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0811.3301},
author = {Lemire, Daniel},
xxurl = {10.1016/j.patcog.2008.11.030},
eprint = {0811.3301},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lemire - 2009 - Faster retrieval with a two-pass dynamic-time-warping lower bound.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Classification,Indexing,Time series,Very large databases},
number = {9},
pages = {2169--2180},
title = {{Faster retrieval with a two-pass dynamic-time-warping lower bound}},
volume = {42},
year = {2009}
}
@article{Makhzani2015a,
abstract = {In this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.},
archivePrefix = {arXiv},
arxivId = {1511.05644},
author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
eprint = {1511.05644},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makhzani et al. - 2015 - Adversarial Autoencoders.pdf:pdf},
month = {nov},
title = {{Adversarial Autoencoders}},
year = {2015}
}
@article{Jung2004,
abstract = {Text data present in images and video contain useful information for automatic annotation, indexing, and structuring of images. Extraction of this information involves detection, localization, tracking, extraction, enhancement, and recognition of the text from a given image. However, variations of text due to differences in size, style, orientation, and alignment, as well as low image contrast and complex background make the problem of automatic text extraction extremely challenging. While comprehensive surveys of related problems such as face detection, document analysis, and image {\&} video indexing can be found, the problem of text information extraction is not well surveyed. A large number of techniques have been proposed to address this problem, and the purpose of this paper is to classify and review these algorithms, discuss benchmark data and performance evaluation, and to point out promising directions for future research. {\textcopyright} 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Jung, Keechul and Kim, Kwang In and Jain, Anil K.},
xxurl = {10.1016/j.patcog.2003.10.012},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {OCR,Text detection,Text enhancement,Text information extraction,Text localization,Text tracking},
title = {{Text information extraction in images and video: A survey}},
year = {2004}
}
@article{Vats2017,
abstract = {Document image binarization is often a challenging task due to various forms of degradation. Although there exist several binarization techniques in literature, the binarized image is typically sensitive to control parameter settings of the employed technique. This paper presents an automatic document image binarization algorithm to segment the text from heavily degraded document images. The proposed technique uses a two band-pass filtering approach for background noise removal, and Bayesian optimization for automatic hyperparameter selection for optimal results. The effectiveness of the proposed binarization technique is empirically demonstrated on the Document Image Binarization Competition (DIBCO) and the Handwritten Document Image Binarization Competition (H-DIBCO) datasets.},
archivePrefix = {arXiv},
arxivId = {1709.01782},
author = {Vats, Ekta and Hast, Anders and Singh, Prashant},
xxurl = {10.1145/3151509.3151520},
eprint = {1709.01782},
isbn = {9781450353908},
pmid = {10121323},
title = {{Automatic Document Image Binarization using Bayesian Optimization}},
url = {http://arxiv.org/abs/1709.01782{\%}0Ahttp://dx.xxurl.org/10.1145/3151509.3151520},
year = {2017}
}
@article{Alaei2014,
author = {Alaei, Alireza and Delalandre, Mathieu},
xxurl = {10.1109/DAS.2014.79},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaei, Delalandre - 2014 - A Complete Logo Detection Recognition System for Document Images.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaei, Delalandre - 2014 - A complete logo detectionrecognition system for document images.pdf:pdf},
isbn = {9781479932436},
journal = {Proceedings - 11th IAPR International Workshop on Document Analysis Systems, DAS 2014},
keywords = {Logo detection,Logo recognition,Template matching,Under/over segmentation,and b,candidate from a database,document image,logo detection,logo recognition,over,recognizing the detected logo,segmentation,template matching,under},
number = {April},
pages = {324--328},
title = {{A complete logo detection/recognition system for document images}},
year = {2014}
}
@article{Perdoch2009,
abstract = {State of the art methods for image and object retrieval exploit both appearance (via visual words) and local geometry (spatial extent, relative pose). In large scale problems, memory becomes a limiting factor - local geometry is stored for each feature detected in each image and requires storage larger than the inverted file and term frequency and inverted document frequency weights together. We propose a novel method for learning discretized local geometry representation based on minimization of average reprojection error in the space of ellipses. The representation requires only 24 bits per feature without drop in performance. Additionally, we show that if the gravity vector assumption is used consistently from the feature description to spatial verification, it improves retrieval performance and decreases the memory footprint. The proposed method outperforms state of the art retrieval algorithms in a standard image retrieval benchmark.},
author = {Perd'och, Michal and Chum, Ondřej and Matas, Jiř{\'{i}}},
xxurl = {10.1109/CVPRW.2009.5206529},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perd'och, Chum, Matas - 2009 - E-cient representation of local geometry for large scale object retrieval.pdf:pdf},
isbn = {9781424439935},
issn = {1063-6919},
journal = {2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2009},
pages = {9--16},
title = {{E-cient representation of local geometry for large scale object retrieval}},
year = {2009}
}
@article{Alaei2016,
abstract = {With the advance of technology, business offices and organizations together with their clients create a massive amount of administrative documents every day. Administrative documents commonly contain some salient entities such as logos, stamps or seals as the means of their authentication and proprietorship. These salient entities provide quite discriminative information, which can effectively be used for different tasks of document image retrieval, classification and recognition in document-based applications. Thus, proper detection/recognition of these entities in document images increases the performance of such applications in terms of document retrieval, classification, and recognition. To present the state-of-the-art research on the retrieval of administrative document images, this paper deals with a survey of administrative document image retrieval in relation to seals and logos. All the available datasets, feature extraction and classification techniques for logo and seal detection/recognition are discussed systematically. The shortcomings of the present technologies on logo and seal based document processing are also highlighted. Avenues of the future works are further given for the benefit of readers. To the best of authors??? knowledge, there is no survey on administrative document image retrieval and hence the authors hope that this work will be helpful to the researchers of the document analysis community.},
author = {Alaei, Alireza and Roy, Partha Pratim and Pal, Umapada},
xxurl = {10.1016/j.cosrev.2016.09.002},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaei, Roy, Pal - 2016 - Logo and seal based administrative document image retrieval A survey.pdf:pdf},
issn = {15740137},
journal = {Computer Science Review},
keywords = {Administrative document image,Detection,Logo,Recognition,Retrieval,Seal},
pages = {47--63},
publisher = {Elsevier Inc.},
title = {{Logo and seal based administrative document image retrieval: A survey}},
url = {http://dx.xxurl.org/10.1016/j.cosrev.2016.09.002},
volume = {22},
year = {2016}
}
@article{Tian2013,
author = {Tian, Shangxuan and Lu, Shijian and Su, Bolan and Tan, Chew Lim},
xxurl = {10.1109/ICDAR.2013.186},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - 2013 - Scene Text Recognition Using Co-occurrence of Histogram of Oriented Gradients.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {912--916},
publisher = {Ieee},
title = {{Scene Text Recognition Using Co-occurrence of Histogram of Oriented Gradients}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628751},
year = {2013}
}
@article{Rusinol2015,
author = {Rusi{\~{n}}ol, Mar{\c{c}}al and Aldavert, David and Toledo, Ricardo and Llad{\'{o}}s, Josep},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusi{\~{n}}ol et al. - 2015 - Efficient segmentation-free keyword spotting in historical document collections.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Dense SIFT features,Historical documents,Keyword spotting,Latent semantic analysis,Product quantization,Segmentation-free,historical documents},
month = {feb},
number = {2},
pages = {545--555},
publisher = {Elsevier},
title = {{Efficient segmentation-free keyword spotting in historical document collections}},
volume = {48},
year = {2015}
}
@article{Mondal2018,
abstract = {In word spotting literature, many approaches have considered word images as temporal signals that could be matched by classical Dynamic Time Warping algorithm. Consequently, DTW has been widely used as a on the shelf tool. However there exists many other improved versions of DTW, along with other robust sequence matching techniques. Very few of them have been studied extensively in the context of word spotting whereas it has been well explored in other application domains such as speech processing, data mining etc. The motivation of this paper is to investigate such area in order to extract significant and useful information for users of such techniques. More precisely, this paper has presented a comparative study of classical Dynamic Time Warping (DTW) technique and many of its improved modifications, as well as other sequence matching techniques in the context of word spotting, considering both theoretical properties as well as experimental ones. The experimental study is performed on historical documents, both handwritten and printed, at word or line segmentation level and with a limited or extended set of queries. The comparative analysis is showing that classical DTW remains a good choice when there is no segmentation problems for word extraction. Its constrained version (e.g. Itakura Parallelogram) seems better on handwritten data, as well as Hilbert transform also shows promising performances on handwritten and printed datasets. In case of printed data and low level features (pixel's column based), the aggregation of features (e.g. Piecewise-DTW) seems also very important. Finally, when there are important word segmentation errors or when we are considering line segmentation level, Continuous Dynamic Programming (CDP) seems to be the best choice.},
author = {Mondal, Tanmoy and Ragot, Nicolas and yves Ramel, Jean and Pal, Umapada},
xxurl = {10.1016/j.patcog.2017.07.011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2018 - Comparative study of conventional time series matching techniques for word spotting.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Bentham dataset,Degraded historical documents,George Washington dataset,Hand-written documents,Japanese handwriting recognition,Word spotting},
pages = {47--64},
title = {{Comparative study of conventional time series matching techniques for word spotting}},
volume = {73},
year = {2018}
}
@article{Yankov2008a,
abstract = {The problem of finding unusual time series has recently attracted much attention, and several promising methods are now in the literature. However, virtually all proposed methods assume that the data reside in main memory. For many real-world problems this is not be the case. For example, in astronomy, multi-terabyte time series datasets are the norm. Most current algorithms faced with data which cannot fit in main memory resort to multiple scans of the disk/tape and are thus intractable. In this work we show how one particular definition of unusual time series, the time series discord, can be discovered with a disk aware algorithm. The proposed algorithm is exact and requires only two linear scans of the disk with a tiny buffer of main memory. Furthermore, it is very simple to implement. We use the algorithm to provide further evidence of the effectiveness of the discord definition in areas as diverse as astronomy, Web query mining, video surveillance, etc., and show the efficiency of our method on datasets which are many orders of magnitude larger than anything else attempted in the literature.},
author = {Yankov, Dragomir and Keogh, Eamonn and Rebbapragada, Umaa},
xxurl = {10.1007/s10115-008-0131-9},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Discords,Disk aware algorithms,Distance outliers,Time series},
title = {{Disk aware discord discovery: Finding unusual time series in terabyte sized datasets}},
year = {2008}
}
@article{Fink2005,
abstract = { Most successful systems for the recognition of unconstrained handwriting currently rely on expert-crafted feature sets that compute local geometric properties from text images. However, by applying appearance based analysis techniques appropriate features could be derived from training data automatically. Therefore, in this paper, several different methods for computing appearance-based feature representations are investigated and compared to the performance of a state-of-the-art writer-independent recognition system based on geometric features. In extensive experiments, promising results were obtained on a challenging recognition task.},
author = {Fink, G.a. Gernot A and Pl, Thomas and Plotz, T.},
xxurl = {10.1109/ICDAR.2005.172},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fink, Pl, Plotz - 2005 - On appearance-based feature extraction methods for writer-independent handwritten text recognition.pdf:pdf},
isbn = {0-7695-2420-6},
issn = {1520-5263},
journal = {Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
title = {{On appearance-based feature extraction methods for writer-independent handwritten text recognition}},
year = {2005}
}
@article{Katsouros2005,
author = {Katsouros, Vassilis and Papavassiliou, Vassilis},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Katsouros, Papavassiliou - 2005 - Segmentation of Handwritten Document Images into Text Lines.pdf:pdf},
isbn = {978-953-307-228-9},
title = {{Segmentation of Handwritten Document Images into Text Lines}},
year = {2005}
}
@article{MarcPeterDeisenroth2009,
abstract = {Mathmatics for economists},
author = {{Marc Peter Deisenroth}},
xxurl = {10.1007/b97511},
file = {:home/mondal/Documents/MATHS/Mathematics for machine learning.pdf:pdf},
isbn = {9783527406289},
journal = {Quantitative literacy: Why numeracy matters for schools},
number = {c},
pages = {533--540},
title = {{Mathematics for Machine Learning}},
url = {http://www.maa.org/external{\_}archive/QL/pgs75{\_}89.pdf},
year = {2009}
}
@article{Doucet2013,
author = {Doucet, Antoine and Kazai, Gabriella and Colutto, Sebastian and Muhlberger, Gunter},
xxurl = {10.1109/ICDAR.2013.290},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doucet et al. - 2013 - ICDAR 2013 Competition on Book Structure Extraction.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1438--1443},
publisher = {Ieee},
title = {{ICDAR 2013 Competition on Book Structure Extraction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628851},
year = {2013}
}
@article{Guru2001,
author = {Guru, D S and Nagabhushan, P},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guru, Nagabhushan - 2001 - Triangular spatial relationship a new approach for spatial knowledge representation.pdf:pdf},
keywords = {2d strings,9dlt matrix,principal,spatial relationship,symbolic image database system,triangular spatial relationships},
pages = {999--1006},
title = {{Triangular spatial relationship : a new approach for spatial knowledge representation}},
volume = {22},
year = {2001}
}
@article{Irshad2015,
abstract = {Digital pathology represents one of the major evolutions in modern medicine. Pathological examinations constitute the gold standard in many medical protocols, and also plays a critical and legal role in the diagnosis process. In conventional cancer diagnosis, pathologists analyse biopsies to make diagnostic and prognostic assessments, mainly based on cell morphology and architecture distribution. Recently, computerized methods have been rapidly evolving in the area of digital pathology, with growing applications related to nuclei detection, segmentation and classification. In cancer research, these approaches have played, and will continue to play a key (often bottleneck) role in minimizing human intervention, consolidating pertinent second opinions, and providing traceable clinical information. Pathological studies have been conducted for numerous cancer detection and grading applications, including brain, breast, cervix, lung and prostate cancer grading. Our study presents, discusses and extracts the major trends from an exhaustive overview of various nuclei detection, segmentation, feature computation and classification techniques used in histopathology imagery, specifically in hematoxylin-eosin (H and E) and immunohistochemical (IHC) staining protocols. This study also enables us to measure the challenges that remain, in order to reach robust analysis of whole slide images (WSI), essential high content imaging with diagnostic biomarkers and prognosis support in digital pathology.},
author = {Irshad, Humayun and Member, Student and Veillard, Antoine and Roux, Ludovic and Racoceanu, Daniel},
xxurl = {10.1109/RBME.2013.2295804},
file = {:home/mondal/Downloads/2014{\_}rmbe{\_}nucleisegmentation.pdf:pdf},
isbn = {1937-3333},
issn = {1937-3333},
keywords = {Cymbalta Duloxetine Hcl clinical pharmacology mech},
pages = {97--114},
pmid = {24802905},
title = {{Cymbalta (duloxetine HCl) drug information: Clinical pharmacology - Prescribing information at RxList}},
url = {http://www.rxlist.com/cymbalta-drug/clinical-pharmacology.htm},
volume = {7},
year = {2015}
}
@article{Jung2019,
author = {Jung, Hwejin and Lodhi, Bilal and Kang, Jaewoo},
xxurl = {10.1186/s42490-019-0026-8},
file = {:home/mondal/Downloads/Jung2019{\_}Article{\_}AnAutomaticNucleiSegmentationM.pdf:pdf},
issn = {2524-4426},
journal = {BMC Biomedical Engineering},
keywords = {convolutional neural network,deep learning,histopathology,image analysis,nuclei segmentation},
number = {1},
pages = {1--12},
publisher = {BMC Biomedical Engineering},
title = {{An automatic nuclei segmentation method based on deep convolutional neural networks for histopathology images}},
volume = {1},
year = {2019}
}
@article{Wang2012a,
abstract = {Traditional trademark image retrieval algorithm only using global feature easily makes mistaken retrieval, and scale invariant feature transform (SIFT) features have limited descriptive ability for image contour and high algorithm complexity. This paper proposes a trademark retrieval algorithm combining the image global features and local features. In this paper, we will firstly, extract Zernike moments of the retrieved image and sort them according to similarity. Candidate images are formed. Then, the SIFT features are used for matching the query image accurately with candidate images. Experimental results show that this method not only keeps high precision- recall of SIFT features and is superior than the method based on the single Zernike moments feature, but also improves effective retrieval speed compared to the single SIFT features. This method can be well applied to the trademark image retrieval system.},
author = {Wang, Zhenhai and Hong, Kicheon},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Hong - 2012 - A novel approach for trademark image retrieval by combining global features and local features.pdf:pdf},
issn = {15539105},
journal = {Journal of Computational Information Systems},
keywords = {cbir,content-based image retrieval,moments,scale invariant feature transform,sift,tir,trademark image retrieval,zernike},
number = {February},
pages = {1633--1640},
title = {{A novel approach for trademark image retrieval by combining global features and local features}},
url = {http://www.jofcis.com/publishedpapers/2012{\_}8{\_}4{\_}1633{\_}1640.pdf},
volume = {4},
year = {2012}
}
@article{Salvi2018,
abstract = {Background: Accurate nuclei detection and segmentation in histological images is essential for many clinical purposes. While manual annotations are time-consuming and operator-dependent, full automated segmentation remains a challenging task due to the high variability of cells intensity, size and morphology. Most of the proposed algorithms for the automated segmentation of nuclei were designed for specific organ or tissues. Results: The aim of this study was to develop and validate a fully multiscale method, named MANA (Multiscale Adaptive Nuclei Analysis), for nuclei segmentation in different tissues and magnifications. MANA was tested on a dataset of H{\&}E stained tissue images with more than 59,000 annotated nuclei, taken from six organs (colon, liver, bone, prostate, adrenal gland and thyroid) and three magnifications (10×, 20×, 40×). Automatic results were compared with manual segmentations and three open-source software designed for nuclei detection. For each organ, MANA obtained always an F1-score higher than 0.91, with an average F1 of 0.9305 ± 0.0161. The average computational time was about 20 s independently of the number of nuclei to be detected (anyway, higher than 1000), indicating the efficiency of the proposed technique. Conclusion: To the best of our knowledge, MANA is the first fully automated multi-scale and multi-tissue algorithm for nuclei detection. Overall, the robustness and versatility of MANA allowed to achieve, on different organs and magnifications, performances in line or better than those of state-of-art algorithms optimized for single tissues.},
author = {Salvi, Massimo and Molinari, Filippo},
xxurl = {10.1186/s12938-018-0518-0},
file = {:home/mondal/Downloads/12938{\_}2018{\_}Article{\_}518.pdf:pdf},
issn = {1475925X},
journal = {BioMedical Engineering Online},
keywords = {Adaptive thresholding,Cellular imaging,Computer-aided image analysis,Nuclei segmentation},
number = {1},
pages = {1--13},
publisher = {BioMed Central},
title = {{Multi-tissue and multi-scale approach for nuclei segmentation in H{\&}E stained images}},
url = {https://xxurl.org/10.1186/s12938-018-0518-0},
volume = {17},
year = {2018}
}
@article{Belussi2016b,
author = {Belussi, Luiz F F and Hirata, Nina S T},
xxurl = {10.1109/SIBGRAPI.2011.16},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belussi, Hirata - 2016 - Fast QR Code Detection in Arbitrarily Acquired Images Fast QR Code Detection in Arbitrarily Acquired Images.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belussi, Hirata - 2016 - Fast QR Code Detection in Arbitrarily Acquired Images Fast QR Code Detection in Arbitrarily Acquired Images(2).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belussi, Hirata - 2016 - Fast QR Code Detection in Arbitrarily Acquired Images Fast QR Code Detection in Arbitrarily Acquired Images(3).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belussi, Hirata - 2016 - Fast QR Code Detection in Arbitrarily Acquired Images Fast QR Code Detection in Arbitrarily Acquired Images(4).pdf:pdf},
isbn = {978-0-7695-4548-6},
keywords = {-qr code,2d barcode,cascade,haar-like features},
number = {September},
pages = {1--17},
title = {{Fast QR Code Detection in Arbitrarily Acquired Images Fast QR Code Detection in Arbitrarily Acquired Images}},
year = {2016}
}
@article{Eyben,
author = {Wollmer, M and Eyben, Florian and Keshet, Joseph and Graves, Alex and Rigoll, Gerhard},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wollmer et al. - 2009 - Robust Discriminative Keyword Spotting for Emotionally Colored Spontaneous Speech Using Bidirectional LSTM Netwo.pdf:pdf},
journal = {ICASSP},
keywords = {8,ar-,blstm,database,discriminative blstm keyword spotter,in the experimental section,of our,on the belfast sensitive,sal,spotting task,tificial listener,we evaluate the robustness,we show that applying},
pages = {3949 -- 3952},
title = {{Robust Discriminative Keyword Spotting for Emotionally Colored Spontaneous Speech Using Bidirectional LSTM Networks}},
year = {2009}
}
@article{Chandola2009,
abstract = {We present a comprehensive evaluation of a large number of semi-supervised anomaly detection techniques for time series data. Some of these are existing techniques and some are adaptations that have never been tried before. For example, we adapt the window based discord detection technique to solve this problem. We also investigate several techniques that detect anomalies in discrete sequences, by discretizing the time series data. We evaluate these techniques on a large variety of data sets obtained from a broad spectrum of application domains. The data sets have different char- acteristics in terms of the nature of normal time series and the nature of anomalous time series. We evaluate the tech- niques on di{\textregistered}erent metrics, such as accuracy in detecting the anomalous time series, sensitivity to parameters, and com- putational complexity, and provide useful insights regarding the e{\textregistered}ectiveness of di{\textregistered}erent techniques based on the exper- imental evaluation.},
author = {Chandola, Varun and Cheboli, Deepthi and Kumar, Vipin},
journal = {{\ldots} Department, University of Minnesota, Tech. Rep},
title = {{Detecting anomalies in a time series database}},
year = {2009}
}
@article{Friedman2002,
abstract = {We introduce a new shape descriptor, the shape context, for correspondence recovery and shape-based object recognition. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. Shape contexts greatly simplify recovery of correspondences between points of two given shapes. Moreover, the shape context leads to a robust score for measuring shape similarity, once shapes are aligned. The shape context descriptor is tolerant to all common shape deformations. As a key advantage no special landmarks or key-points are necessary. It is thus a generic method with applications in object recognition, image registration and point set matching. Using examples involving both handwritten digits and 3D objects, we illustrate its power for object recognition.},
author = {Friedman, Milton and History, Monetary},
xxurl = {10.1.1.27.8567},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedman, History - 2002 - Shape Context A new descriptor for shape matching and object recognition Serge.pdf:pdf},
isbn = {076950695X},
keywords = {coa ted pr opellant,combustio n,low tempera ture sensitivity,nitro amine pro pella,nt},
pages = {32--42},
title = {{Shape Context: A new descriptor for shape matching and object recognition Serge}},
year = {2002}
}
@article{Deryagin2013,
author = {Deryagin, Dmitry},
xxurl = {10.1109/ICDAR.2013.193},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deryagin - 2013 - Unified Performance Evaluation for OCR Zoning Calculating Page Segmentation's Score, That Includes Text Zones, Tables.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {953--957},
publisher = {Ieee},
title = {{Unified Performance Evaluation for OCR Zoning: Calculating Page Segmentation's Score, That Includes Text Zones, Tables and Non-text Objects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628758},
year = {2013}
}
@article{Tang2013,
author = {Tang, Peng and Hui, Siu Cheung and Fu, Chi-Wing},
xxurl = {10.1109/ICDAR.2013.79},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang, Hui, Fu - 2013 - A Progressive Structural Analysis Approach for Handwritten Chemical Formula Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {359--363},
publisher = {Ieee},
title = {{A Progressive Structural Analysis Approach for Handwritten Chemical Formula Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628644},
year = {2013}
}
@article{Li2013c,
author = {Li, Luyuan and Wang, Yongtao and Tang, Zhi and Lu, Xiaoqing and Gao, Liangcai},
xxurl = {10.1109/ICDAR.2013.241},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2013 - Unsupervised Speech Text Localization in Comic Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {bayesian classifier,font set,hypothesis test,text line generation,text localization},
month = {aug},
pages = {1190--1194},
publisher = {Ieee},
title = {{Unsupervised Speech Text Localization in Comic Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628802},
year = {2013}
}
@article{Kingma2013,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
xxurl = {10.1051/0004-6361/201527329},
eprint = {1312.6114},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Welling - 2013 - Auto-Encoding Variational Bayes.pdf:pdf},
isbn = {1312.6114v10},
issn = {1312.6114v10},
number = {Ml},
pages = {1--14},
pmid = {23459267},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2013}
}
@article{Rifai2011,
abstract = {Although the structure and composition of plant communities is known to influence the functioning of ecosystems, there is as yet no agreement as to how these should be described from a functional perspective. We tested the biomass ratio hypothesis, which postulates that ecosystem properties should depend on species traits and on species contribution to the total biomass of the community, in a successional sere following vineyard abandonment in the Mediterranean region of France. Ecosystem-specific net primary productivity, litter decomposition rate, and total soil carbon and nitrogen varied significantly with field age, and correlated with community-aggregated (i.e., weighed according to the relative abundance of species) functional leaf traits. The three easily measurable traits tested, specific leaf area, leaf dry matter content, and nitrogen concentration, provide a simple means to scale up from organ to ecosystem functioning in complex plant communities. We propose that they be called {\&}8220;functional markers,{\&}8221; and be used to assess the impacts of community changes on ecosystem properties induced, in particular, by global change drivers.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rifai, Salah and Muller, Xavier},
xxurl = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifai, Muller - 2011 - Contractive Auto-Encoders Explicit Invariance During Feature Extraction.pdf:pdf},
isbn = {978-1-4503-0619-5},
issn = {1467-9280},
journal = {Icml},
number = {1},
pages = {833--840},
pmid = {25052830},
title = {{Contractive Auto-Encoders : Explicit Invariance During Feature Extraction}},
volume = {85},
year = {2011}
}
@inproceedings{ZINK2017,
author = {Zhu, Yan and Imamura, Makoto and Nikovski, Daniel and Keogh, Eamonn J},
booktitle = {Proceedings of the International Conference on Data Mining (ICDM)},
pages = {695--704},
title = {{Matrix Profile {\{}VII:{\}} Time Series Chains: {\{}A{\}} New Primitive for Time Series Data Mining (Best Student Paper Award)}},
year = {2017}
}
@article{Sharma2013,
author = {Sharma, Nabin and Shivakumara, Palaiahnakote and Pal, Umapada and Blumenstein, Michael and Tan, Chew Lim},
xxurl = {10.1109/ICDAR.2013.90},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma et al. - 2013 - A New Method for Character Segmentation from Multi-oriented Video Words.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {mentation,multi-oriented document processing,piece-wise linear segmentation line,plsl,recognition,video character,video character seg-,video document analysis},
month = {aug},
pages = {413--417},
publisher = {Ieee},
title = {{A New Method for Character Segmentation from Multi-oriented Video Words}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628655},
year = {2013}
}
@inproceedings{Aldavert2013,
author = {Aldavert, David and Rusinol, Marcal and Toledo, Ricardo and Llados, Josep},
booktitle = {12th International Conference on Document Analysis and Recognition},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aldavert et al. - 2013 - Integrating Visual and Textual Cues for Query-by-String Word Spotting.pdf:pdf},
keywords = {Computational modeling,Computer vision,Hidden Markov models,Histograms,Pattern recognition,Vectors,Visualization,bag-of-visual-words,bag-of-visual-words scheme,document image processing,handwritten word spotting,historical document extraction,image representation,indexation structures,information retrieval,latent semantic analysis,query-by-string,query-by-string word spotting framework,statistical analysis,statistical representation,sub-vector space,textual cues,textual query,textual representation,visual cues,visual modality,visual representations,word images,word instances},
language = {English},
month = {aug},
pages = {511--515},
publisher = {IEEE},
title = {{Integrating Visual and Textual Cues for Query-by-String Word Spotting}},
year = {2013}
}
@article{Romero2013a,
author = {Romero, Veronica and Sanchez, Joan Andreu},
xxurl = {10.1109/ICDAR.2013.254},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Romero, Sanchez - 2013 - Human Evaluation of the Transcription Process of a Marriage License Book.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1255--1259},
publisher = {Ieee},
title = {{Human Evaluation of the Transcription Process of a Marriage License Book}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628815},
year = {2013}
}
@inproceedings{Torralba2008,
author = {Torralba, Antonio and Fergus, Rob and Weiss, Yair},
booktitle = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
xxurl = {10.1109/CVPR.2008.4587633},
isbn = {978-1-4244-2242-5},
issn = {1063-6919},
keywords = {Application software,Computer graphics,Gist descriptor,Handheld computers,Hardware,Image databases,Image recognition,Internet,Layout,Object recognition,Standards development,binary codes,compact binary code,image coding,image matching,image recognition,image retrieval,image search technique,large image database,learning (artificial intelligence),machine learning,object recognition,scene matching technique,search engines,very large databases,visual databases},
language = {English},
month = {jun},
pages = {1--8},
publisher = {IEEE},
title = {{Small codes and large image databases for recognition}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4587633},
year = {2008}
}
@article{Lopez1999,
author = {Lopez, A.M. and Lumbreras, F. and Serrat, J. and Villanueva, J.J.},
xxurl = {10.1109/34.761263},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {apr},
number = {4},
pages = {327--335},
title = {{Evaluation of methods for ridge and valley detection}},
url = {http://ieeexplore.ieee.org/document/761263/},
volume = {21},
year = {1999}
}
@article{Wang2013c,
annote = {From Duplicate 2 ( 





















A Comprehensive Representation Model for Handwriting Dedicated to Word Spotting





















- Wang, Peng; Eglin, Veronique; Garcia, Christophe; Largeron, Christine; McKenna, Antony )







},
author = {Wang, Peng and Eglin, Veronique and Garcia, Christophe and Largeron, Christine and McKenna, Antony},
xxurl = {10.1109/ICDAR.2013.97},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2013 - A Comprehensive Representation Model for Handwriting Dedicated to Word Spotting.pdf:pdf},
isbn = {978-0-7695-4999-6},
issn = {1520-5363},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {Context,DTW method,Handwriting recognition,Hidden Markov models,SC cost,SC descriptor,Shape,Skeleton,Text analysis,Writing,branch points,coarse-to-fine approach,coarse-to-fine description,comprehensive representation model,document image processing,dynamic time warping,feature extraction,gradient orientation feature,graph-based description,handwriting document images,handwriting representation models,high-curved points,image representation,interest points,loop difference,lower border projection feature,morphological handwriting information,orientation feature,projection profile feature,selective dominant features,shape context descriptor,similarity measure,starting-ending points,stroke analysis,stroke orientation feature,textural property,texture comparison,topological handwriting information,upper border projection feature,word segmentation-free method,word spotting},
language = {English},
month = {aug},
pages = {450--454},
publisher = {Ieee},
title = {{A Comprehensive Representation Model for Handwriting Dedicated to Word Spotting}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6628662 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628662},
year = {2013}
}
@article{Kokkinos,
author = {Kokkinos, Iasonas and Paris, Ecole Centrale and Group, Galen},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kokkinos, Paris, Group - Unknown - Introduction to Deep Learning Deep Belief Networks 1.pdf:pdf},
pages = {1--70},
title = {{Introduction to Deep Learning Deep Belief Networks 1}}
}
@article{Li2013d,
author = {Li, Jinpeng and Mouchere, Harold and Viard-Gaudin, Christian and Chen, Zhaoxin},
xxurl = {10.1109/ICDAR.2013.269},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2013 - A Multi-stroke Dynamic Time Warping Distance Based on A Optimization.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {1},
pages = {1330--1334},
publisher = {Ieee},
title = {{A Multi-stroke Dynamic Time Warping Distance Based on A* Optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628830},
volume = {269},
year = {2013}
}
@article{Gregor2015,
abstract = {This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.},
archivePrefix = {arXiv},
arxivId = {1502.04623},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
eprint = {1502.04623},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gregor et al. - 2015 - DRAW A Recurrent Neural Network For Image Generation.pdf:pdf},
title = {{DRAW: A Recurrent Neural Network For Image Generation}},
url = {http://arxiv.org/abs/1502.04623},
year = {2015}
}
@article{Gorecki2015a,
author = {G{\'{o}}recki, Tomasz and {\L}uczak, Maciej},
xxurl = {10.1016/j.eswa.2014.11.007},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}recki, {\L}uczak - 2015 - Multivariate time series classification with parametric derivative dynamic time warping.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {derivative dynamic time warping,dynamic time warping,multivariate time series},
number = {5},
pages = {2305--2312},
title = {{Multivariate time series classification with parametric derivative dynamic time warping}},
volume = {42},
year = {2015}
}
@inproceedings{Ueno2006,
abstract = {For many real world problems we must perform classification under widely varying amounts of computational resources. For example, if asked to classify an instance taken from a bursty stream, we may have from milliseconds to minutes to return a class prediction. For such problems an anytime algorithm may be especially useful. In this work we show how we can convert the ubiquitous nearest neighbor classifier into an anytime algorithm that can produce an instant classification, or if given the luxury of additional time, can utilize the extra time to increase classification accuracy. We demonstrate the utility of our approach with a comprehensive set of experiments on data from diverse domains. {\textcopyright} 2006 IEEE.},
author = {Ueno, Ken and Xi, Aopeng and Keogh, Eamonn and Lee, Dah Jye},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
xxurl = {10.1109/ICDM.2006.21},
isbn = {0769527019},
issn = {15504786},
title = {{Anytime classification using the nearest neighbor algorithm with applications to stream mining}},
year = {2006}
}
@article{Azadi2018,
abstract = {In this work, we focus on the challenge of taking partial observations of highly-stylized text and generalizing the observations to generate unobserved glyphs in the ornamented typeface. To generate a set of multi-content images following a consistent style from very few examples, we propose an end-to-end stacked conditional GAN model considering content along channels and style along network layers. Our proposed network transfers the style of given glyphs to the contents of unseen ones, capturing highly stylized fonts found in the real-world such as those on movie posters or infograph-ics. We seek to transfer both the typographic stylization (ex. serifs and ears) as well as the textual stylization (ex. color gradients and effects.) We base our experiments on our collected data set including 10,000 fonts with different styles and demonstrate effective generalization from a very small number of observed glyphs.},
archivePrefix = {arXiv},
arxivId = {arXiv:1611.07004},
author = {Azadi, Samaneh and Fisher, Matthew and Kim, Vladimir and Wang, Zhaowen and Shechtman, Eli and Darrell, Trevor},
eprint = {arXiv:1611.07004},
file = {:home/mondal/Downloads/Azadi{\_}Multi-Content{\_}GAN{\_}for{\_}CVPR{\_}2018{\_}paper.pdf:pdf},
journal = {Cvpr},
pages = {1--8},
title = {{Multi-Content GAN for Few-Shot Font Style Transfer}},
url = {https://github.com/azadis/{\%}0Ahttps://github.com/azadis/MC-GAN},
year = {2018}
}
@article{Zhang2003_abc,
abstract = {Existing word image retrieval algorithms suffer from either low retrieval precision or high computation complexity. We present an effective and efficient approach for word image matching by using gradient-based binary features. Experiments over a large database of handwritten word images show that the proposed approach consistently outperforms the existing best handwritten word image retrieval algorithm. Dynamic Time Warping (DTW) with profile-based shape features. Not only does the proposed approach have much higher retrieval accuracy, but also it is 893 times faster than DTW.},
author = {Zhang, Bin and Srihari, Sargur N. SN and Huang, Chen},
xxurl = {10.1117/12.523968},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Srihari, Huang - 2003 - Word image retrieval using binary features.pdf:pdf},
journal = {Document Recognition and Retrieval},
month = {dec},
pages = {45--53},
title = {{Word image retrieval using binary features}},
volume = {5296},
year = {2003}
}
@article{Nguyen2008,
abstract = {In this paper we present an adaptive method for graphic symbol$\backslash$nrepresentation based on shape contexts. The proposed descriptor is$\backslash$ninvariant under classical geometric transforms (rotation, scale) and$\backslash$nbased on interest points. To reduce the complexity of matching a symbol$\backslash$nto a large set of candidates we use the popular vector model for$\backslash$ninformation retrieval. In this way, on the set of shape descriptors we$\backslash$nbuild a visual vocabulary, where, each symbol is retrieved on visual$\backslash$nwords. Experimental results on complex and occluded symbols show that$\backslash$nthe approach is very promising.},
author = {Nguyen, T-O and Tabbone, S and Terrades, O Ramos},
xxurl = {10.1109/DAS.2008.58},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Tabbone, Terrades - 2008 - Symbol descriptor based on shape context and vector model of information retrieval.pdf:pdf},
isbn = {978-0-7695-3337-7},
journal = {Proceedings of the 8Th Iapr International Workshop on Document Analysis Systems},
pages = {191--197},
title = {{Symbol descriptor based on shape context and vector model of information retrieval}},
year = {2008}
}
@article{Pezeshk2010,
abstract = {Separation of the text and graphics layers in maps with dense and overlapping sets of features (e.g. topographic maps) is a challenging problem. Multi Angled Parallelism (MAP) provides an efficient tool to detect miscellaneous linear features using directional morphological operations and higher order feature representation. However, in its original formulation sides of characters, short lines, and parts of lines that pass through characters are often misclassified. This paper presents an improvement over MAP to automatically extract complete line networks with arbitrary orientation and curvature even when they pass through characters with minimal impact on the text content. The resulting text only image can then be processed for text grouping, reorientation, and recognition. The proposed algorithm does not rely on heuristics and can be easily adapted to work with maps of various scales and sources and other line drawing images by adjusting only a small number of parameters.},
author = {Pezeshk, Aria and Tutwiler, Richard L.},
xxurl = {10.1109/ICASSP.2010.5495342},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pezeshk, Tutwiler - 2010 - Improved multi angled parallelism for separation of text from intersecting linear features in scanned topogra.pdf:pdf},
isbn = {9781424442966},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Feature extraction,Mathematical morphology,Multi angled parallelism,Text extraction},
pages = {1078--1081},
title = {{Improved multi angled parallelism for separation of text from intersecting linear features in scanned topographic maps}},
year = {2010}
}
@article{Che2016,
abstract = {Although Generative Adversarial Networks achieve state-of-the-art results on a variety of generative tasks, they are regarded as highly unstable and prone to miss modes. We argue that these bad behaviors of GANs are due to the very particular functional shape of the trained discriminators in high dimensional spaces, which can easily make training stuck or push probability mass in the wrong direction, towards that of higher concentration than that of the data generating distribution. We introduce several ways of regularizing the objective, which can dramatically stabilize the training of GAN models. We also show that our regularizers can help the fair distribution of probability mass across the modes of the data generating distribution, during the early phases of training and thus providing a unified solution to the missing modes problem.},
archivePrefix = {arXiv},
arxivId = {1612.02136},
author = {Che, Tong and Li, Yanran and Jacob, Athul Paul and Bengio, Yoshua and Li, Wenjie},
eprint = {1612.02136},
pages = {1--13},
title = {{Mode Regularized Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1612.02136},
year = {2016}
}
@article{Gatos2010d,
author = {Gatos, B. and Stamatopoulos, N. and Louloudis, G.},
xxurl = {10.1007/s10032-010-0122-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos, Stamatopoulos, Louloudis - 2010 - ICDAR2009 handwriting segmentation contest.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
keywords = {document image,handwritten text line segmentation,handwritten word segmentation,processing evaluation},
month = {jun},
number = {1},
pages = {25--33},
title = {{ICDAR2009 handwriting segmentation contest}},
url = {http://link.springer.com/10.1007/s10032-010-0122-8},
volume = {14},
year = {2010}
}
@article{Martin-Albo2013,
author = {Martin-Albo, Daniel and Romero, Veronica and Vidal, Enrique},
xxurl = {10.1109/ICDAR.2013.259},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin-Albo, Romero, Vidal - 2013 - Interactive Off-Line Handwritten Text Transcription Using On-Line Handwritten Text as Feedback.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1280--1284},
publisher = {Ieee},
title = {{Interactive Off-Line Handwritten Text Transcription Using On-Line Handwritten Text as Feedback}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628820},
year = {2013}
}
@article{Rabeux2013b,
author = {Rabeux, Vincent and Journet, Nicholas and Vialard, Anne and Domenger, Jean-Philippe},
xxurl = {10.1109/ICDAR.2013.30},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabeux et al. - 2013 - Quality Evaluation of Ancient Digitized Documents for Binarization Prediction.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {113--117},
publisher = {Ieee},
title = {{Quality Evaluation of Ancient Digitized Documents for Binarization Prediction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628595},
year = {2013}
}
@inproceedings{DK2017,
author = {Dau, Hoang Anh and Keogh, Eamonn J},
booktitle = {Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD)},
pages = {125--134},
title = {{Matrix Profile {\{}V:{\}} {\{}A{\}} Generic Technique to Incorporate Domain Knowledge into Motif Discovery}},
year = {2017}
}
@article{Li2013a,
author = {Li, Keqiang and Lu, Xiaoqing and Ling, Haibin and Liu, Lu and Feng, Tianxiao and Tang, Zhi},
xxurl = {10.1109/ICDAR.2013.59},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2013 - Detection of Overlapped Quadrangles in Plane Geometric Figures.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {follows,introduces a number of,paper is organized as,parallelogram,plane geometric figure,rectangle,related works,section ii,section iii describes the,significance analysis,special quadrangle detection,the rest of the,trapezoid},
month = {aug},
pages = {260--264},
publisher = {Ieee},
title = {{Detection of Overlapped Quadrangles in Plane Geometric Figures}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628624},
year = {2013}
}
@article{Phan2013,
author = {Phan, Trung Quy and Shivakumara, Palaiahnakote and Lu, Tong and Tan, Chew Lim},
xxurl = {10.1109/ICDAR.2013.122},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phan et al. - 2013 - Recognition of Video Text through Temporal Integration.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-video text recognition,binarization,multiple frame integration,sift,stroke width transform,temporal integration,text,text enhancement,text probability,text tracking},
month = {aug},
pages = {589--593},
publisher = {Ieee},
title = {{Recognition of Video Text through Temporal Integration}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628687},
year = {2013}
}
@inproceedings{Campbell2014,
abstract = {The design and manipulation of typefaces and fonts is an area requiring substantial expertise; it can take many years of study to become a proficient typographer. At the same time, the use of typefaces is ubiquitous; there are many users who, while not experts, would like to be more involved in tweaking or changing existing fonts without suffering the learning curve of professional typography packages. Given the wealth of fonts that are available today, we would like to exploit the expertise used to produce these fonts, and to enable everyday users to create, explore, and edit fonts. To this end, we build a generative manifold of standard fonts. Every location on the manifold corresponds to a unique and novel typeface, and is obtained by learning a non-linear mapping that intelligently interpolates and extrapolates existing fonts. Using the manifold, we can smoothly interpolate and move between existing fonts. We can also use the manifold as a constraint that makes a variety of new applications possible. For instance, when editing a single character, we can update all the other glyphs in a font simultaneously to keep them compatible with our changes. Copyright {\textcopyright} ACM.},
author = {Campbell, Neill D.F. and Kautz, Jan},
booktitle = {ACM Transactions on Graphics},
xxurl = {10.1145/2601097.2601212},
issn = {15577333},
keywords = {Digital typography,Modeling,Shape matching},
title = {{Learning a manifold of fonts}},
year = {2014}
}
@article{Epshtein,
author = {Epshtein, Boris},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Epshtein - Unknown - Detecting Text in Natural Scenes with{\_}Epshtein{\_}2010.pdf:pdf},
isbn = {9781424469857},
number = {d},
pages = {1--8},
title = {{Detecting Text in Natural Scenes with{\_}Epshtein{\_}2010}}
}
@article{Ratha,
author = {Rath, T M and Manmatha, R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rath, Manmatha - 2003 - Word image matching using dynamic time warping.pdf:pdf},
isbn = {0-7695-1900-8},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {521--527},
publisher = {IEEE Comput. Soc},
title = {{Word image matching using dynamic time warping}},
volume = {2},
year = {2003}
}
@article{Bullinaria2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1409.2329v5},
author = {Bullinaria, John A.},
xxurl = {10.1201/9781420049176},
eprint = {arXiv:1409.2329v5},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bullinaria - 2015 - Recurrent Neural Networks.pdf:pdf},
isbn = {0849371813},
journal = {Neural Computation : Lecture 12},
pages = {1--20},
title = {{Recurrent Neural Networks}},
url = {https://www.cs.bham.ac.uk/{~}jxb/inc.html},
year = {2015}
}
@inproceedings{Latecki2007a,
author = {Latecki, Longin Jan and Koknar-tezel, Suzan and Wang, Qiang and Megalooikonomou, Vasileios},
booktitle = {Int. Conf. on Knowledge Discovery and Data Mining (KDD)},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Latecki et al. - 2007 - Sequence Matching Capable of Excluding Outliers.pdf:pdf},
title = {{Sequence Matching Capable of Excluding Outliers}},
year = {2007}
}
@article{Kulis2012,
abstract = {Fast retrieval methods are critical for many large-scale and data-driven vision applications. Recent work has explored ways to embed high-dimensional features or complex distance functions into a low-dimensional Hamming space where items can be efficiently searched. However, existing methods do not apply for high-dimensional kernelized data when the underlying feature embedding for the kernel is unknown. We show how to generalize locality-sensitive hashing to accommodate arbitrary kernel functions, making it possible to preserve the algorithm's sublinear time similarity search guarantees for a wide class of useful similarity functions. Since a number of successful image-based kernels have unknown or incomputable embeddings, this is especially valuable for image retrieval tasks. We validate our technique on several data sets, and show that it enables accurate and fast performance for several vision problems, including example-based object classification, local feature matching, and content-based retrieval.},
author = {Kulis, Brian and Grauman, Kristen},
xxurl = {10.1109/TPAMI.2011.219},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulis, Grauman - 2012 - Kernelized locality-sensitive hashing.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = {jun},
number = {6},
pages = {1092--104},
pmid = {22064796},
title = {{Kernelized locality-sensitive hashing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22064796},
volume = {34},
year = {2012}
}
@article{Imani2018,
abstract = {Perhaps the most basic query made by a data analyst confronting a new data source is "Show me some representative/typical data." Answering this question is trivial in many domains, but surprisingly, it is very difficult in large time series datasets. The major difficulty is not time or space complexity, but defining what it means to be representative data in this domain. In this work, we show that the obvious candidate definitions: motifs, shapelets, cluster centers, random samples etc., are all poor choices. Thus motivated, we introduce time series snippets, a novel representation of typical time series subsequences. Beyond their utility for visualizing and summarizing massive time series collections, we show that time series snippets have utility for high-level comparison of large time series collections.},
author = {Imani, Shima and Madrid, Frank and Ding, Wei and Crouter, Scott and Keogh, Eamonn},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Imani et al. - 2018 - Matrix Profile XIII Time Series Snippets A New Primitive for Time Series Data Mining.pdf:pdf},
journal = {2018 IEEE International Conference on Data Mining (ICDM)},
keywords = {all the,data looks like that,diversification,for a sleep study,heartbeats,it may be that,motifs,or it may be,quantifiability,regions,sampling,shows some typical healthy,suppose the top-1 snippet,that there were also,time series},
title = {{Matrix Profile XIII : Time Series Snippets : A New Primitive for Time Series Data Mining}},
year = {2018}
}
@article{Yin2002,
abstract = {Since the number of registered trademarks is increasing rapidly, the job of identifying infringement of similar trademarks by human inspection becomes laborious and time-consuming. To deal with the problem, we propose an automatic content-based trademark retrieval method. The proposed method automatically selects appropriate features based on feature selection principles to discriminate trademarks. The database trademarks are softly clustered into classes using a fuzzy approach to increase the retrieval speed. The user can submit a query through trademark examples to get a list of database trademarks ordered by similarity ranks. The query results can be iteratively refined by the feedback presented by the user until the trademarks of interest are retrieved. Experiments are conducted on a trademark database containing 1000 images and the retrieval results are very encouraging. ?? 2002 Elsevier Science B.V. All rights reserved.},
author = {Yin, Peng Yeng and Yeh, Cheng Chung},
xxurl = {10.1016/S0167-8655(01)00091-5},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin, Yeh - 2002 - Content-based retrieval from trademark databases.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {2-level contour representation strings,Content-based image retrieval,Fuzzy c-means clustering,Relevance feedback,Trademark},
number = {1-3},
pages = {113--126},
title = {{Content-based retrieval from trademark databases}},
volume = {23},
year = {2002}
}
@article{Gorecki2014c,
author = {G{\'{o}}recki, Thomasz and {\L}uczak, Maciej},
xxurl = {10.2478/bile-2013-00xx},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}recki, {\L}uczak - 2014 - A variant of gravitational classification.pdf:pdf},
issn = {1896-3811},
keywords = {dynamic classi-,fier,gravitational classification,machine learning,nearest neighbor method},
number = {1},
pages = {1--12},
title = {{A variant of gravitational classification}},
volume = {51},
year = {2014}
}
@article{Isola2016,
abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
archivePrefix = {arXiv},
arxivId = {1611.07004},
author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
xxurl = {arXiv:1611.07004},
eprint = {1611.07004},
title = {{Image-to-Image Translation with Conditional Adversarial Networks}},
url = {http://arxiv.org/abs/1611.07004},
year = {2016}
}
@article{Diem2013,
author = {Diem, Markus and Kleber, Florian and Sablatnig, Robert},
xxurl = {10.1109/ICDAR.2013.152},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diem, Kleber, Sablatnig - 2013 - Text Line Detection for Heterogeneous Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {743--747},
publisher = {Ieee},
title = {{Text Line Detection for Heterogeneous Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628717},
year = {2013}
}
@article{Tombre2003,
abstract = { In this paper, we discuss how the focus in document analysis in graphics recognition has moved from re-engineering problems to indexing and information retrieval. After a few reviews of ongoing work on these topics, we propose some challenges for the years to come.},
author = {Tombre, Karl and Lamiroy, Bart},
xxurl = {10.1109/ICDAR.2003.1227650},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tombre, Lamiroy - 2003 - Graphics recognition - From re-engineering to retrieval.pdf:pdf},
isbn = {0769519601},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
pages = {148--155},
title = {{Graphics recognition - From re-engineering to retrieval}},
volume = {2003-Janua},
year = {2003}
}
@article{Graham2019,
abstract = {Nuclear segmentation and classification within Haematoxylin {\&} Eosin stained histology images is a fundamental prerequisite in the digital pathology work-flow. The development of automated methods for nuclear segmentation and classification enables the quantitative analysis of tens of thousands of nuclei within a whole-slide pathology image, opening up possibilities of further analysis of large-scale nuclear morphometry. However, automated nuclear segmentation and classification is faced with a major challenge in that there are several different types of nuclei, some of them exhibiting large intra-class variability such as the nuclei of tumour cells. Additionally, some of the nuclei are often clustered together. To address these challenges, we present a novel convolutional neural network for simultaneous nuclear segmentation and classification that leverages the instance-rich information encoded within the vertical and horizontal distances of nuclear pixels to their centres of mass. These distances are then utilised to separate clustered nuclei, resulting in an accurate segmentation, particularly in areas with overlapping instances. Then, for each segmented instance the network predicts the type of nucleus via a devoted up-sampling branch. We demonstrate state-of-the-art performance compared to other methods on multiple independent multi-tissue histology image datasets. As part of this work, we introduce a new dataset of Haematoxylin {\&} Eosin stained colorectal adenocarcinoma image tiles, containing 24,319 exhaustively annotated nuclei with associated class labels.},
archivePrefix = {arXiv},
arxivId = {1812.06499},
author = {Graham, Simon and Vu, Quoc Dang and Raza, Shan E.Ahmed and Azam, Ayesha and Tsang, Yee Wah and Kwak, Jin Tae and Rajpoot, Nasir},
xxurl = {10.1016/j.media.2019.101563},
eprint = {1812.06499},
file = {:home/mondal/Downloads/1812.06499.pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Computational pathology,Deep learning,Nuclear classification,Nuclear segmentation},
pages = {1--18},
title = {{Hover-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images}},
volume = {58},
year = {2019}
}
@article{Pratikakis2010,
abstract = {H-DIBCO 2010 is the International Document Image Binarization Contest which is dedicated to handwritten document images organized in conjunction with ICFHR 2010 conference. The general objective of the contest is to identify current advances in handwritten document image binarization using meaningful evaluation performance measures. This paper reports on the contest details including the evaluation measures used as well as the performance of the 17 submitted methods along with a short description of each method.},
author = {Pratikakis, Ioannis and Gatos, Basilis and Ntirogiannis, Konstantinos},
xxurl = {10.1109/ICFHR.2010.118},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratikakis, Gatos, Ntirogiannis - 2010 - H-DIBCO 2010 - Handwritten document image binarization competition.pdf:pdf},
isbn = {9780769542218},
journal = {Proceedings - 12th International Conference on Frontiers in Handwriting Recognition, ICFHR 2010},
keywords = {Binarization,Handwritten document image,Performance evaluation},
number = {May},
pages = {727--732},
title = {{H-DIBCO 2010 - Handwritten document image binarization competition}},
year = {2010}
}
@article{Elzobi2013,
author = {Elzobi, Moftah and Al-Hamadi, Ayoub and Dings, Laslo and Elmezain, Mahmoud and Saeed, Anwar},
xxurl = {10.1109/ICDAR.2013.192},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elzobi et al. - 2013 - A Hidden Markov Model-Based Approach with an Adaptive Threshold Model for Off-Line Arabic Handwriting Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {945--949},
publisher = {Ieee},
title = {{A Hidden Markov Model-Based Approach with an Adaptive Threshold Model for Off-Line Arabic Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628757},
year = {2013}
}
@article{Boubaker2009,
author = {Boubaker, Houcine and Kherallah, Monji and Alimi, Adel M.},
xxurl = {10.1109/ICDAR.2009.265},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boubaker, Kherallah, Alimi - 2009 - New Algorithm of Straight or Curved Baseline Detection for Short Arabic Handwritten Writing.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
pages = {778--782},
publisher = {Ieee},
title = {{New Algorithm of Straight or Curved Baseline Detection for Short Arabic Handwritten Writing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277507},
year = {2009}
}
@article{Chen2016,
abstract = {This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.},
archivePrefix = {arXiv},
arxivId = {1606.03657},
author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
xxurl = {10.1007/978-3-319-16817-3},
eprint = {1606.03657},
isbn = {978-3-319-16816-6},
issn = {978-3-319-16807-4},
pmid = {23459267},
title = {{InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets}},
url = {http://arxiv.org/abs/1606.03657},
year = {2016}
}
@article{Fischer2012a,
author = {Fischer, Andreas and Keller, Andreas and Frinken, Volkmar and Bunke, Horst},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {handwriting recognition},
month = {may},
number = {7},
pages = {934--942},
publisher = {Elsevier B.V.},
title = {{Lexicon-free handwritten word spotting using character HMMs}},
volume = {33},
year = {2012}
}
@article{Graves2007,
abstract = {Recurrent neural networks (RNNs) have proved effective at one dimensional sequence learning tasks, such as speech and online handwriting recognition. Some of the properties that make RNNs suitable for such tasks, for example robustness to input warping, and the ability to access contextual information, are also desirable in multidimensional domains. However, there has so far been no direct way of applying RNNs to data with more than one spatio-temporal dimension. This paper introduces multi-dimensional recurrent neural networks (MDRNNs), thereby extending the potential applicability of RNNs to vision, video processing, medical imaging and many other areas, while avoiding the scaling problems that have plagued other multi-dimensional models. Experimental results are provided for two image segmentation tasks.},
archivePrefix = {arXiv},
arxivId = {0705.2011},
author = {Graves, Alex and Fernandez, Santiago and Schmidhuber, Juergen},
xxurl = {10.1007/978-3-540-74690-4_56},
eprint = {0705.2011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graves, Fernandez, Schmidhuber - 2007 - Multi-Dimensional Recurrent Neural Networks.pdf:pdf},
isbn = {978-3-540-74689-8},
issn = {03029743},
pages = {1--10},
title = {{Multi-Dimensional Recurrent Neural Networks}},
url = {http://arxiv.org/abs/0705.2011},
year = {2007}
}
@article{Papandreou2013a,
author = {Papandreou, a. and Gatos, B. and Louloudis, G. and Stamatopoulos, N.},
xxurl = {10.1109/ICDAR.2013.291},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papandreou et al. - 2013 - ICDAR 2013 Document Image Skew Estimation Contest (DISEC 2013).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {contest,document image preprocessing,performance evaluation,skew estimation},
month = {aug},
pages = {1444--1448},
publisher = {Ieee},
title = {{ICDAR 2013 Document Image Skew Estimation Contest (DISEC 2013)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628852},
year = {2013}
}
@inproceedings{Srihari2006,
author = {Srihari, Sargur and Srinivasan, Harish and Babu, Pavithra and Bhole, Chetan},
booktitle = {Electronic Imaging},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srihari, Srinivasan - 2006 - Spotting words in handwritten Arabic documents.pdf:pdf},
isbn = {0819461075},
issn = {0277786X},
month = {jan},
pages = {606702--606702--12},
publisher = {International Society for Optics and Photonics},
title = {{Spotting words in handwritten Arabic documents}},
year = {2006}
}
@article{Hauser2017,
abstract = {This study deals with neural networks in the sense of diierential transformations for systems of diierential equations. It forms part of an attempt to construct a formalized general theory of neural networks as a branch of Riemannian geometry. From this perspective, the following theoretical results are developed and proven for feedforward networks, in the limit as the number of network layers goes to innnity. First it is shown that residual neural networks are dynamical systems of order diierential equations, as opposed to ordinary networks that are static, implying that the network is learning systems of diierential equations to organize data. Second it is shown that, in the limit, the metric tensor for residual networks converges and is smooth, and thus deenes a Riemannian manifold. Third it is shown that, in the limit, backpropagation on graphs converges on diierentiable tensor relds. These results suggest an analogy with Einstein's General Relativity, where particle trajectories are geodesics on curved space-time manifolds, while neural networks are learning curved space-layer manifolds which determine the trajectory of the data as it moves through the network.},
author = {Hauser, Michael and Ray, Asok},
xxurl = {S1063-4584(04)00257-2 [pii] 10.1016/j.joca.2004.11.004},
isbn = {9780438134935},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {2804--2813},
pmid = {15836427},
title = {{Principles of Riemannian Geometry in Neural Networks}},
url = {http://www.mne.psu.edu/ray/journalAsokRay/2017/279HauserRay17.pdf{\%}0Ahttp://papers.nips.cc/paper/6873-principles-of-riemannian-geometry-in-neural-networks.pdf},
year = {2017}
}
@article{Nassu2013,
author = {Nassu, Bogdan Tomoyuki and Minetto, Rodrigo and Oliveira, Luiz Eduardo Soares De},
xxurl = {10.1109/ICDAR.2013.131},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nassu, Minetto, Oliveira - 2013 - Text Line Detection in Document Images Towards a Support System for the Blind.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {638--642},
publisher = {Ieee},
title = {{Text Line Detection in Document Images: Towards a Support System for the Blind}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628696},
year = {2013}
}
@article{Ntirogiannis2012a,
abstract = {There are many challenges addressed in handwritten document image binarization, such as faint characters, bleed-through and large background ink stains. Usually, binarization methods cannot deal with all the degradation types effectively. Motivated by the low detection rate of faint characters in binarization of handwritten document images, a combination of a global and a local adaptive binarization method at connected component level is proposed that aims in an improved overall performance. Initially, background estimation is applied along with image normalization based on background compensation. Afterwards, global binarization is performed on the normalized image. In the binarized image very small components are discarded and representative characteristics of a document image such as the stroke width and the contrast are computed. Furthermore, local adaptive binarization is performed on the normalized image taking into account the aforementioned characteristics. Finally, the two binarization outputs are combined at connected component level. Our method achieves top performance after extensive testing on the DIBCO (Document Image Binarization Contest) series datasets which include a variety of degraded handwritten document images. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Ntirogiannis, K. and Gatos, B. and Pratikakis, I.},
xxurl = {10.1016/j.patrec.2012.09.026},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ntirogiannis, Gatos, Pratikakis - 2012 - A combined approach for the binarization of handwritten document images.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ntirogiannis, Gatos, Pratikakis - 2014 - A combined approach for the binarization of handwritten document images.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Background estimation,Document image binarization,Document image pre-processing,Inpainting,background estimation,document image binarization,document image pre-processing},
month = {oct},
number = {1},
pages = {3--15},
publisher = {Elsevier B.V.},
title = {{A Combined Approach for the Binarization of Handwritten Document Images}},
volume = {35},
year = {2014}
}
@article{Senior1998,
author = {Senior, A.W. and Robinson, A.J.},
issn = {01628828},
journal = {TPAMI},
language = {English},
month = {mar},
number = {3},
pages = {309--321},
publisher = {IEEE},
title = {{An off-line cursive handwriting recognition system}},
volume = {20},
year = {1998}
}
@inproceedings{Struzik2008,
abstract = {For the majority of data mining applications, there are no models of data which would facilitate the task of comparing records of time series. We propose a generic approach to comparing noise time series using the largest deviations from consistent statistical behaviour. For this purpose we use a powerful framework based on wavelet decomposition, which allows filtering polynomial bias, while capturing the essential singular behaviour. In addition, we are able to reveal scale-wise ranking of singular events including their scale free characteristic: the Holder exponent. We use a set of such characteristics to design a compact representation of the time series suitable for direct comparison, e.g. evaluation of the correlation product. We demonstrate that the distance between such representations closely corresponds with the subjective feeling of similarity between the time series. In order to test the validity of subjective criteria, we test the records of currency exchanges, finding convincing levels of (local) correlation},
author = {Struzik, Z.R. and Siebes, A.},
booktitle = {Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99},
xxurl = {10.1109/DEXA.1999.795160},
isbn = {0-7695-0281-4},
pages = {162--166},
publisher = {IEEE},
title = {{Measuring time series similarity through large singular features revealed with wavelet transformation}},
url = {http://ieeexplore.ieee.org/document/795160/},
year = {1999}
}
@inproceedings{Mondal2019,
author = {Mondal, Tanmoy and Coustaty, Micka{\"{e}}l and Gomez-Kr{\"{a}}mer, Petra and Ogier, Jean-marc},
booktitle = {ICDAR},
xxurl = {10.1109/ICDAR.2019.00223},
file = {:home/mondal/Documents/AllPapers/ICDAR-2019/Document{\_}Binarization/Document{\_}Binarization.pdf:pdf},
keywords = {background re-,binarization,fuzzy c-means,moval,stroke width estimation},
pages = {1384--1389},
publisher = {IEEE},
title = {{Learning Free Document Image Binarization Based on Fast Fuzzy C-Means Clustering}},
year = {2019}
}
@inproceedings{Indyk1998,
address = {New York, USA},
author = {Indyk, Piotr and Motwani, Rajeev},
booktitle = {Proceedings of the thirtieth annual ACM symposium on Theory of computing - STOC '98},
xxurl = {10.1145/276698.276876},
isbn = {0897919629},
month = {may},
pages = {604--613},
publisher = {ACM Press},
title = {{Approximate nearest neighbors}},
url = {http://dl.acm.org/citation.cfm?id=276698.276876},
year = {1998}
}
@article{Warbhe2016,
abstract = {Copy-Move forgery is the most common image tampering method to create forged images. The images may be forged to conceal or change the meaning of the photographs. Hence, it becomes important to verify the integrity and authenticity of the images. The copy-move forgery detection can be classified under two heads viz., block based and keypoint based. The block based methods use mostly the similar kind of frameworks but differ in applying feature extraction schemes. The block-based methods are good at detecting the forged regions with high accuracy but is having tremendously high computational complexity. In this paper we review the keypoint approach which is an alternative to block-based approach. The keypoint based copy-move forgery detection schemes involve, detecting and describing the local features of the images by using the algorithms like SIFT and SURF.},
author = {Warbhe, Anil Dada and Dharaskar, R. V. and Thakare, V. M.},
xxurl = {10.1016/j.procs.2016.02.011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Warbhe, Dharaskar, Thakare - 2016 - A Survey on Keypoint Based Copy-paste Forgery Detection Techniques.pdf:pdf},
issn = {18753892},
journal = {Physics Procedia},
keywords = {Copy-Paste Forgery,Digital Image forensics,Image Forgery,Image Tampering},
number = {December 2015},
pages = {61--67},
publisher = {Elsevier Masson SAS},
title = {{A Survey on Keypoint Based Copy-paste Forgery Detection Techniques}},
url = {http://dx.xxurl.org/10.1016/j.procs.2016.02.011},
volume = {78},
year = {2016}
}
@article{Schmidhuber2015a,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidhuber, J??rgen},
xxurl = {10.1016/j.neunet.2014.09.003},
eprint = {1404.7828},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2015 - Deep Learning in neural networks An overview.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2015 - Deep Learning in neural networks An overview(2).pdf:pdf},
isbn = {0893-6080},
issn = {18792782},
journal = {Neural Networks},
keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning},
pages = {85--117},
pmid = {25462637},
publisher = {Elsevier Ltd},
title = {{Deep Learning in neural networks: An overview}},
url = {http://dx.xxurl.org/10.1016/j.neunet.2014.09.003},
volume = {61},
year = {2015}
}
@article{Bukhari2009,
abstract = {As compared to scanners, cameras offer fast, flexible and non-contact document imaging, but with distortions like uneven shading and warped shape. Therefore, camera-captured document images need preprocessing steps like binarization and textline detection for dewarping so that traditional document image processing steps can be applied on them. Previous approaches of binarization and curled textline detection are sensitive to distortions and loose some crucial image information during each step, which badly affects dewarping and further processing. Here we introduce a novel algorithm for curled textline region detection directly from a grayscale camera-captured document image, in which matched filter bank approach is used for enhancing textline structure and then ridges detection is applied for finding central line of curled textlines. The resulting ridges can be potentially used for binarization, dewarping or designing new techniques for camera-captured document image processing. Our approach is robust against bad shading and high degrees of curl. We have achieved around 91{\%} detection accuracy on the dataset of CBDAR 2007 document image dewarping contest.},
author = {Bukhari, Syed Saqib and Shafait, Faisal and Breuel, Thomas M.},
xxurl = {10.1007/978-3-642-03767-2_21},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bukhari, Shafait, Breuel - 2009 - Ridges based curled textline region detection from grayscale camera-captured document images.pdf:pdf},
isbn = {3642037666},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Anisotropic Gaussian Smoothing,Camera-Captured Document Images,Curled Textline Finding,Grayscale Document Images,Ridges},
pages = {173--180},
title = {{Ridges based curled textline region detection from grayscale camera-captured document images}},
volume = {5702 LNCS},
year = {2009}
}
@article{Fujimoto2007,
abstract = {Methods to rectify distortion of digital camera document images of curved papers have become important for camera-based image recognition. In this paper we propose a novel distortion rectification method based on "shape from parallel geodesies." This method considers the following features: parallel lines corresponding to character strings or ruled lines of tables on extended surface become parallel geodesies on a curved paper surface and a smoothly curved paper can be modeled by a ruled surface, that is, a sweep surface of rulings. The projected geodesies and the projected rulings exist in the input image derived from perspective transformation. The presented method extracts the projected geodesies, estimates the projected rulings in the input image, estimates the ruled surface that models the curved paper, and generates the corrected image, in this order. It can estimate the ruled surface model directly by numerical operations of differentiation, integration and matrix inversion without any iterative calculation. We also report on experiments that show the effectiveness of the proposed method.},
author = {Fujimoto, Katsuhito and Sun, Jun and Takebe, Hiroaki and Suwa, Misako and Naoi, Satoshi},
xxurl = {10.1109/ICDAR.2007.4378717},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fujimoto et al. - 2007 - Curved paper rectification for digital camera document images by shape from parallel geodesics using continuous.pdf:pdf},
isbn = {0769528228},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
number = {Icdar},
pages = {267--271},
title = {{Curved paper rectification for digital camera document images by shape from parallel geodesics using continuous dynamic programming}},
volume = {1},
year = {2007}
}
@article{Feild2013,
author = {Feild, Jacqueline L. and Learned-Miller, Erik G.},
xxurl = {10.1109/ICDAR.2013.125},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feild, Learned-Miller - 2013 - Improving Open-Vocabulary Scene Text Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {604--608},
publisher = {Ieee},
title = {{Improving Open-Vocabulary Scene Text Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628690},
year = {2013}
}
@article{Rusinol2010a,
abstract = {In this paper we propose a new approach to recognize symbols by the use of a concept lattice. We propose to build a concept lattice in terms of graphical patterns. Each model symbol is decomposed in a set of composing graphical patterns taken as primitives. Each one of these primitives is described by boundary moment invariants. The obtained concept lattice relates which symbolic patterns compose a given graphical symbol. A Hasse diagram is derived from the context and is used to recognize symbols affected by noise. We present some preliminary results over a variation of the dataset of symbols from the GREC 2005 symbol recognition contest. {\textcopyright} 2010 Springer-Verlag.},
author = {Rusi{\~{n}}ol, Mar{\c{c}}al and Bertet, Karell and Ogier, Jean Marc and Llad{\'{o}}s, Josep},
xxurl = {10.1007/978-3-642-13728-0_17},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusi{\~{n}}ol et al. - 2010 - Symbol recognition using a concept lattice of graphical patterns.pdf:pdf},
isbn = {364213727X},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Concept Lattices,Graphics Recognition,Shape Descriptors,Symbol Classification,imp-logo-paper},
mendeley-tags = {imp-logo-paper},
pages = {187--198},
title = {{Symbol recognition using a concept lattice of graphical patterns}},
volume = {6020 LNCS},
year = {2010}
}
@article{Rokach2005,
author = {Rokach, L. and Maimon, O.},
xxurl = {10.1109/TSMCC.2004.843247},
issn = {1094-6977},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part C (Applications and Reviews)},
month = {nov},
number = {4},
pages = {476--487},
title = {{Top-Down Induction of Decision Trees Classifiers—A Survey}},
url = {http://ieeexplore.ieee.org/document/1522531/},
volume = {35},
year = {2005}
}
@article{ZHANG2011,
abstract = {This paper presents an improved adaptive method for fast document image binarization. The proposed method first uses wiener filter to reduce noises; second uses an improved adaptive Otsu's method for binarization; and third uses dilation and erosion operators to preserve stroke connectivity and fill possible breaks, gaps, and holes. Besides, packed binary format and destination word accumulation are used to hasten the dilation and erosion processing. The experiments demonstrate that our method is effective and outperforms global Otsu's method and adaptive Otsu's method, and the computation time of morphological operators is faster than traditional morphological operators.},
author = {ZHANG, Yudong and WU, Lenan},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ZHANG, WU - 2011 - Fast Document Image Binarization based on an improved adaptive Otsu's method and destination word accumulation.pdf:pdf},
issn = {15539105},
journal = {Journal of Computational Information Systems},
keywords = {Destination Word Accumulation,Document Image Binarization,Mathematical Morphology,Otsu's Method,Wiener Filter},
number = {6},
pages = {1886--1892},
title = {{Fast Document Image Binarization based on an improved adaptive Otsu's method and destination word accumulation}},
url = {http://www.jofcis.com/downloadpaper.aspx?id=1232{\&}name=2011{\_}7{\_}6{\_}1886{\_}1892.pdf},
volume = {7},
year = {2011}
}
@article{Roy2011a,
abstract = {This paper deals with automatic detection of seal (stamp) from documents with cluttered background. Seal detection involves a difficult challenge due to its multi-oriented nature, arbitrary shape, overlapping of its part with signature, noise, etc. Here, a seal object is characterized by scale and rotation invariant spatial feature descriptors computed from recognition result of individual connected components (characters). Scale and rotation invariant features are used in a Support Vector Machine (SVM) classifier to recognize multi-scale and multi-oriented text characters. The concept of generalized Hough transform (GHT) is used to detect the seal and a voting scheme is designed for finding possible location of the seal in a document based on the spatial feature descriptor of neighboring component pairs. The peak of votes in GHT accumulator validates the hypothesis to locate the seal in a document. Experiment is performed in an archive of historical documents of handwritten/printed English text. Experimental results show that the method is robust in locating seal instances of arbitrary shape and orientation in documents, and also efficient in indexing a collection of documents for retrieval purposes. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {Roy, Partha Pratim and Pal, Umapada and Llad{\'{o}}s, Josep},
xxurl = {10.1016/j.patcog.2010.12.004},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy, Pal, Llad{\'{o}}s - 2011 - Document seal detection using GHT and character proximity graphs.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Generalized Hough transform,Graphical symbol spotting,Multi-oriented character recognition,Seal recognition},
number = {6},
pages = {1282--1295},
title = {{Document seal detection using GHT and character proximity graphs}},
volume = {44},
year = {2011}
}
@inproceedings{DBLP:conf/icdip/2010,
editor = {Jusoff, Kamaruzaman and Xie, Yi},
isbn = {978-0-8194-7942-6},
publisher = {SPIE},
series = {{\{}SPIE{\}} Proceedings},
title = {{Second International Conference on Digital Image Processing, {\{}ICDIP{\}} 2010, Singapore, Singapore, February 26-28, 2010}},
url = {http://proceedings.spiedigitallibrary.org/volume.aspx?volume=7546},
volume = {7546},
year = {2010}
}
@article{Nieto2008,
abstract = {Logotypes superimposed to broadcasted videos supply important information for semantic video annotation, such as the content creator. In this work a novel logo classification and learning system for TV broadcast videos is presented. Logos are segmented from the video stream but scale change, position shift, clutter and noise makes difficult to classify and to recognize them. Several robust features that use edges and shape information have been selected, and a Bayesian network classifier is used to classify the logos. New logos are recognized as such for the first time they appear and passed to a semi-supervised learning system. The learning process clusters the set of new logos to group different instances of the same new logo. A logo model is obtained for each cluster that must be validated by a human to incorporate them into the classification system. Comprehensive tests with a set of 724 TV logos show the high performance of our classification and learning system.},
author = {Nieto, P. and C??zar, J. R. and Gonz??lez-Linares, J. M. and Guil, N.},
xxurl = {10.1109/ICIP.2008.4712313},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nieto et al. - 2008 - A TV-logo classification and learning system.pdf:pdf},
isbn = {1424417643},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {Bayesian network classifier,Clustering,Logo classification,Logo learning},
pages = {2548--2551},
title = {{A TV-logo classification and learning system}},
year = {2008}
}
@inproceedings{Agrawal2008,
abstract = {Abstract We explore the suitability of different feature detectors for the task of image registration, and in particular for visual odometry, using two criteria: stability (persistence across viewpoint change) and accuracy (consistent localization across viewpoint change). ...},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Agrawal, Motilal and Konolige, Kurt and Blas, Morten Rufus},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
xxurl = {10.1007/978-3-540-88693-8-8},
eprint = {1311.2901},
isbn = {3540886923},
issn = {03029743},
number = {PART 4},
pages = {102--115},
pmid = {16546397},
title = {{CenSurE: Center surround extremas for realtime feature detection and matching}},
volume = {5305 LNCS},
year = {2008}
}
@article{Lee2011,
abstract = {Similarity joins are important operations with a broad range of applications. In this paper, we study the problem of vec-tor similarity join size estimation (VSJ). It is a generaliza-tion of the previously studied set similarity join size estima-tion (SSJ) problem and can handle more interesting cases such as TF-IDF vectors. One of the key challenges in sim-ilarity join size estimation is that the join size can change dramatically depending on the input similarity threshold. We propose a sampling based algorithm that uses Locality-Sensitive-Hashing (LSH). The proposed algorithm LSH-SS uses an LSH index to enable effective sampling even at high thresholds. We compare the proposed technique with ran-dom sampling and the state-of-the-art technique for SSJ (adapted to VSJ) and demonstrate LSH-SS offers more ac-curate estimates throughout the similarity threshold range and small variance using real-world data sets. {\textcopyright} 2011 VLDB Endowment.},
author = {Lee, Hongrae and Ng, Raymond T. and Shim, Kyuseok},
xxurl = {10.14778/1978665.1978666},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
title = {{Similarity join size estimation using locality sensitive hashing}},
year = {2011}
}
@inproceedings{DBLP:conf/icfhr/2014,
isbn = {978-1-4799-4335-7},
publisher = {{\{}IEEE{\}} Computer Society},
title = {{14th International Conference on Frontiers in Handwriting Recognition, {\{}ICFHR{\}} 2014, Crete, Greece, September 1-4, 2014}},
url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6979380},
year = {2014}
}
@article{Wang2013a,
author = {Wang, Shandong and Gong, Lujin and Zhang, Hui and Zhang, Yongjie and Ren, Haibing and Rhee, Seon-Min and Lee, Hyong-Euk},
xxurl = {10.1117/12.2037133},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2013 - SDTP a robust method for interest point detection on 3D range images.pdf:pdf},
isbn = {9780819499424},
issn = {0277786X},
keywords = {detector,interest point,key point,range image,repeatability},
number = {February},
pages = {90250O},
title = {{SDTP: a robust method for interest point detection on 3D range images}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?xxurl=10.1117/12.2037133},
volume = {9025},
year = {2013}
}
@article{Bappy2017,
abstract = {The advent of high-tech journaling tools facilitates an image to be manipulated in a way that can easily evade state-of-the-art image tampering detection approaches. The recent success of the deep learning approaches in different recognition tasks inspires us to develop a high confidence detection framework which can localize manipulated regions in an image. Unlike semantic object segmentation where all meaningful regions (objects) are segmented, the localization of image manipulation focuses only the possible tampered region which makes the problem even more challenging. In order to formulate the framework, we employ a hybrid CNN-LSTM model to capture discriminative features between manipulated and non-manipulated regions. One of the key properties of manipulated regions is that they exhibit discriminative features in boundaries shared with neighboring non-manipulated pixels. Our motivation is to learn the boundary discrepancy, i.e., the spatial structure, between manipulated and non-manipulated regions with the combination of LSTM and convolution layers. We perform end-to-end training of the network to learn the parameters through back-propagation given ground-truth mask information. The overall framework is capable of detecting different types of image manipulations, including copy-move, removal and splicing. Our model shows promising results in localizing manipulated regions, which is demonstrated through rigorous experimentation on three diverse datasets.},
author = {Bappy, Jawadul H. and Roy-Chowdhury, Amit K. and Bunk, Jason and Nataraj, Lakshmanan and Manjunath, B. S.},
xxurl = {10.1109/ICCV.2017.532},
file = {:home/mondal/Downloads/5a73cb7417c44a0b3035a2b0{\_}0.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {4980--4989},
title = {{Exploiting Spatial Structure for Localizing Manipulated Image Regions}},
volume = {2017-Octob},
year = {2017}
}
@article{Cao2007,
abstract = {As the OCR technique is not yet adequate for handwritten scripts with$\backslash$nlarge lexicon, word spotting has been introduced as an alternative to$\backslash$nOCR. This paper proposes a novel approach to word spotting that, instead$\backslash$nof matching features of the word image to features extracted from$\backslash$npredefined templates, uses the estimated posterior probability as the$\backslash$noutput of well trained. classifier for spotting. Gabor features are$\backslash$nextracted from gray scale image in order to yield higher performance on,$\backslash$ndegraded, low quality document image.},
author = {Cao, Huaigu and Govindaraju, Venu},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao, Govindaraju - 2007 - Template-free word spotting in low-quality manuscripts.pdf:pdf},
isbn = {978-981-270-553-2},
journal = {ICPR},
keywords = {keyword spotting,ocr},
pages = {1--5},
title = {{Template-free word spotting in low-quality manuscripts}},
year = {2007}
}
@article{Linghui2016,
abstract = {Existing learning-based super-resolution (SR) reconstruction algorithms are mainly designed for single image, which ignore the spatio-temporal relationship between video frames. Aiming at applying the advantages of learning-based algorithms to video SR field, a novel video SR reconstruction algorithm based on deep convolutional neural network (CNN) and spatio-temporal similarity (STCNN-SR) was proposed in this paper. It is a deep learning method for video SR reconstruction, which considers not only the mapping relationship among associated low-resolution (LR) and high-resolution (HR) image blocks, but also the spatio-temporal non-local complementary and redundant information between adjacent low-resolution video frames. The reconstruction speed can be improved obviously with the pre-trained end-to-end reconstructed coefficients. Moreover, the performance of video SR will be further improved by the optimization process with spatio-temporal similarity. Experimental results demonstrated that the proposed algorithm achieves a competitive SR quality on both subjective and objective evaluations, when compared to other state-of-the-art algorithms.},
author = {Linghui, Li and Junping, Du and Meiyu, Liang and Nan, Ren and Dan, Fan},
xxurl = {10.1016/S1005-8885(16)60060-2},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Linghui et al. - 2016 - Video super-resolution reconstruction based on deep convolutional neural network and spatio-temporal similarity.pdf:pdf},
issn = {10058885},
journal = {Journal of China Universities of Posts and Telecommunications},
keywords = {Zernike moment feature,deep convolutional neural network,spatio-temporal similarity,video SR reconstruction},
number = {5},
pages = {68--81},
title = {{Video super-resolution reconstruction based on deep convolutional neural network and spatio-temporal similarity}},
volume = {23},
year = {2016}
}
@article{Staden1989,
abstract = {no abstract},
author = {Staden, Rodger},
xxurl = {10.1093/bioinformatics/5.4.293},
issn = {1367-4803},
journal = {Bioinformatics},
number = {4},
pages = {293--298},
title = {{Methods for discovering novel motifs in nucleic acid sequences}},
url = {https://academic.oup.com/bioinformatics/article-lookup/xxurl/10.1093/bioinformatics/5.4.293},
volume = {5},
year = {1989}
}
@article{Ahmed2013a,
author = {Ahmed, Sheraz and Shafait, Faisal and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/ICDAR.2013.145},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed et al. - 2013 - A Generic Method for Stamp Segmentation Using Part-Based Features.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {708--712},
publisher = {Ieee},
title = {{A Generic Method for Stamp Segmentation Using Part-Based Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628710},
year = {2013}
}
@article{Liang2006,
author = {Liang, Jian},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang - 2006 - Title of dissertation PROCESSING CAMERA-CAPTURED DOCUMENT IMAGES GEOMETRIC RECTIFICATION , MOSAICING , AND LAYOUT STRUC.pdf:pdf},
isbn = {0-542-61900-8},
pages = {187},
title = {{Title of dissertation : PROCESSING CAMERA-CAPTURED DOCUMENT IMAGES : GEOMETRIC RECTIFICATION , MOSAICING , AND LAYOUT STRUCTURE RECOGNITION Jian Liang , Doctor of Philosophy , 2006 Dr . David Doermann Professor Rama Chellappa Institute for Advanced Comput}},
year = {2006}
}
@article{Kasar2013,
author = {Kasar, T. and Barlas, P. and Adam, S. and Chatelain, C. and Paquet, T.},
xxurl = {10.1109/ICDAR.2013.240},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kasar et al. - 2013 - Learning to Detect Tables in Scanned Document Images Using Line Information.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-table detection,line detection},
month = {aug},
pages = {1185--1189},
publisher = {Ieee},
title = {{Learning to Detect Tables in Scanned Document Images Using Line Information}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628801},
year = {2013}
}
@article{Sønderby2015,
abstract = {We integrate the recently proposed spatial transformer network (SPN) [Jaderberg et. al 2015] into a recurrent neural network (RNN) to form an RNN-SPN model. We use the RNN-SPN to classify digits in cluttered MNIST sequences. The proposed model achieves a single digit error of 1.5{\%} compared to 2.9{\%} for a convolutional networks and 2.0{\%} for convolutional networks with SPN layers. The SPN outputs a zoomed, rotated and skewed version of the input image. We investigate different down-sampling factors (ratio of pixel in input and output) for the SPN and show that the RNN-SPN model is able to down-sample the input images without deteriorating performance. The down-sampling in RNN-SPN can be thought of as adaptive down-sampling that minimizes the information loss in the regions of interest. We attribute the superior performance of the RNN-SPN to the fact that it can attend to a sequence of regions of interest.},
archivePrefix = {arXiv},
arxivId = {1509.05329},
author = {S{\o}nderby, S{\o}ren Kaae and S{\o}nderby, Casper Kaae and Maal{\o}e, Lars and Winther, Ole},
xxurl = {10.1038/nbt.3343},
eprint = {1509.05329},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/S{\o}nderby et al. - 2015 - Recurrent Spatial Transformer Networks.pdf:pdf},
isbn = {9781627480031},
issn = {1087-0156},
pages = {1--15},
pmid = {26571099},
title = {{Recurrent Spatial Transformer Networks}},
url = {http://arxiv.org/abs/1509.05329},
year = {2015}
}
@article{Gargouri2013,
author = {Gargouri, Mariem and Kanoun, Slim and Ogier, Jean-Marc},
xxurl = {10.1109/ICDAR.2013.93},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gargouri, Kanoun, Ogier - 2013 - Text-Independent Writer Identification on Online Arabic Handwriting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- online handwriting,classifiers,features study,global approach,independent,text-,writer identification},
month = {aug},
pages = {428--432},
publisher = {Ieee},
title = {{Text-Independent Writer Identification on Online Arabic Handwriting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628658},
year = {2013}
}
@article{Larochelle2011,
abstract = {We describe a new approach for modeling the distribution of high-dimensional vectors of discrete variables. This model is inspired by the restricted Boltzmann machine (RBM), which has been shown to be a powerful model of such distributions. However, an RBM typically does not provide a tractable distribution estimator, since evaluating the probability it assigns to some given observation requires the computation of the so-called partition function, which itself is intractable for RBMs of even moderate size. Our model circumvents this difficulty by decomposing the joint distribution of observations into tractable conditional distributions and modeling each conditional using a non-linear function similar to a conditional of an RBM. Our model can also be interpreted as an autoencoder wired such that its output can be used to assign valid probabilities to observations. We show that this new model outperforms other multivariate binary distribution estimators on several datasets and performs similarly to a large (but intractable) RBM.},
author = {Larochelle, Hugo and Murray, Iain},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Larochelle, Murray - 2011 - The Neural Autoregressive Distribution Estimator.pdf:pdf},
issn = {15324435},
journal = {International Conference on Machine Learning},
pages = {29--37},
title = {{The Neural Autoregressive Distribution Estimator}},
volume = {15},
year = {2011}
}
@inproceedings{Afzal2015,
address = {New York, New York, USA},
author = {Afzal, Muhammad Zeshan and Pastor-Pellicer, Joan and Shafait, Faisal and Breuel, Thomas M. and Dengel, Andreas and Liwicki, Marcus},
booktitle = {HIP '15},
xxurl = {10.1145/2809544.2809561},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Afzal et al. - Unknown - Document Image Binarization using LSTM A Sequence Learning Approach.pdf:pdf},
isbn = {9781450336024},
keywords = {Document Image Binarization,Long Short Term Memory,Neural Network,Optical Character Recognition},
pages = {79--84},
publisher = {ACM Press},
title = {{Document Image Binarization using LSTM: A Sequence Learning Approach}},
year = {2015}
}
@inproceedings{Hu2013b,
abstract = {Most literature on time series classification assumes that the beginning and ending points of the pattern of interest can be correctly identified, both during the training phase and later deployment. In this work, we argue that this assumption is unjustified, and this has in many cases led to unwarranted optimism about the performance of the proposed algorithms. As we shall show, the task of correctly extracting individual gait cycles, heartbeats, gestures, behaviors, etc., is generally much more difficult than the task of actually classifying those patterns. We propose to mitigate this problem by introducing an alignment-free time series classification framework. The framework requires only very weakly annotated data, such as “in this ten minutes of data, we see mostly normal heartbeats...,” and by generalizing the classic machine learning idea of data editing to streaming/continuous data, allows us to build robust, fast and accurate classifiers. We demonstrate on several diverse real-world problems that beyond removing unwarranted assumptions and requiring essentially no human intervention, our framework is both significantly faster and significantly more accurate than current state-of-the-art approaches.},
address = {Philadelphia, PA},
author = {Hu, Bing and Chen, Yanping and Keogh, Eamonn},
booktitle = {Proceedings of the 2013 SIAM International Conference on Data Mining},
xxurl = {10.1137/1.9781611972832.64},
isbn = {978-1-61197-262-7},
issn = {13845810},
month = {may},
pages = {578--586},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Time Series Classification under More Realistic Assumptions}},
url = {https://epubs.siam.org/xxurl/10.1137/1.9781611972832.64},
year = {2013}
}
@inproceedings{Chan2006,
abstract = {Currently an abundance of historical manuscripts, journals, and scientific notes remain largely unaccessible in library archives. Manual transcription and publication of such documents is unlikely, and automatic transcription with high enough accuracy to support a traditional text search is difficult. In this work we describe a lexicon-free system for performing text queries on off-line printed and handwritten Arabic documents. Our segmentation-based approach utilizes gHMMs with a bigram letter transition model, and KPCA/LDA for letter discrimination. The segmentation stage is integrated with inference. We show that our method is robust to varying letter forms, ligatures, and overlaps. Additionally, we find that ignoring letters beyond the adjoining neighbors has little effect on inference and localization, which leads to a significant performance increase over standard dynamic programming. Finally, we discuss an extension to perform batch searches of large word lists for indexing purposes.},
author = {Chan, Jim and Ziftci, Celai and Forsyth, David},
booktitle = {CVPR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan, Ziftci, Forsyth - 2006 - Searching off-line arabic documents.pdf:pdf},
isbn = {0769525970},
issn = {10636919},
pages = {1455--1462},
title = {{Searching off-line arabic documents}},
volume = {2},
year = {2006}
}
@article{Miao2013,
abstract = {This paper proposes a novel nonlinear filter, named rank order Laplacian of Gaussian (ROLG) filter, based on which a new interest point detector is developed. The ROLG filter is a weighted rank order filter. It is used to detect the image local structures where a significant majority of pixels are brighter or darker than a significant majority of pixels in their corresponding surroundings. Compared to linear filter based detectors, e.g. SIFT detector, the proposed rank order filter based detector is more robust to abrupt variations of images caused by illumination and geometric changes. Experiments on the benchmark databases demonstrate that the proposed ROLG detector achieves superior performance comparing to four state-of-the-art detectors. Evaluation experiments are also conducted on face recognition problems. The results on five face databases further demonstrate that the ROLG detector significantly outperforms the other detectors. {\textcopyright} 2013 Elsevier Ltd.},
author = {Miao, Zhenwei and Jiang, Xudong},
xxurl = {10.1016/j.patcog.2013.03.024},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miao, Jiang - 2013 - Interest point detection using rank order LoG filter.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Image matching,Interest point detection,Repeatability,Weighted rank order filter},
number = {11},
pages = {2890--2901},
publisher = {Elsevier},
title = {{Interest point detection using rank order LoG filter}},
url = {http://dx.xxurl.org/10.1016/j.patcog.2013.03.024},
volume = {46},
year = {2013}
}
@article{Belongie2002,
abstract = {We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by 1) solving for correspondences between points on the two shapes, 2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Belongie, Serge and Malik, Jitendra and Puzicha, Jan},
xxurl = {10.1109/34.993558},
eprint = {arXiv:1011.1669v3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belongie, Malik, Puzicha - 2002 - Shape matching and object recognition using shape contexts.pdf:pdf},
isbn = {9781424455409},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Correspondence problem,Deformable templates,Digit recognition,Image registration,MPEG7,Object recognition,Shape},
number = {4},
pages = {509--522},
pmid = {15376597},
title = {{Shape matching and object recognition using shape contexts}},
volume = {24},
year = {2002}
}
@article{Chauhan2016,
abstract = {One of the problem in image forensics is to check the authenticity of image. This can be very important task when images are used as an evidence which cause change in judgment like, for example in a court of law. Image is forged by using different techniques but in that most common technique is copy-move forgery. Copy-move forgery is created by copying the region from a particular image and pasting that region on same image to mislead the user. This type of forgery is done using availability of new sophisticated software and applications. This type of forgery is also done in video. In this paper we survey on different keypoint based copy-move forgery detection methods with different parameters.},
author = {Chauhan, Devanshi and Kasat, Dipali and Jain, Sanjeev and Thakare, Vilas},
xxurl = {10.1016/j.procs.2016.05.213},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chauhan et al. - 2016 - Survey on Keypoint Based Copy-move Forgery Detection Methods on Image.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {copy-move forgery,copy-move forgery detection,copy-move forgery methods,image forgery,image forgery detection,image retouching,image splicing,keypoint based methods},
number = {Cms},
pages = {206--212},
publisher = {Elsevier Masson SAS},
title = {{Survey on Keypoint Based Copy-move Forgery Detection Methods on Image}},
url = {http://dx.xxurl.org/10.1016/j.procs.2016.05.213},
volume = {85},
year = {2016}
}
@article{Pratikakis2013a,
abstract = {DIBCO 2011 is the International Document Image Binarization Contest organized in the context of ICDAR 2011 conference. The general objective of the contest is to identify current advances in document image binarization for both machine-printed and handwritten document images using evaluation performance measures that conform to document image analysis and recognition. This paper describes the contest details including the evaluation measures used as well as the performance of the 18 submitted methods along with a short description of each method.},
author = {Pratikakis, Ioannis and Gatos, Basilis and Ntirogiannis, Konstantinos},
xxurl = {10.1109/ICDAR.2013.219},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratikakis, Gatos, Ntirogiannis - 2013 - ICDAR 2013 document image binarization contest (DIBCO 2013).pdf:pdf},
isbn = {9780769545202},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {document image binarisation,performance evaluation},
number = {Dibco},
pages = {1471--1476},
pmid = {30007343},
title = {{ICDAR 2013 document image binarization contest (DIBCO 2013)}},
year = {2013}
}
@article{Ahmed2011,
abstract = {Patients with peptic ulcer disease are often advised to avoid cola , coffee, and alcoholic beverages. How-ever, the effect of many popular beverages on gastric acid secretion has not been systematically studied. This study was undertaken to determine the effect of nine commonly ingested beverages on gastric acid secretion in humans. Six healthy subjects were each studied on 11 separate days and in random order. Test substances included 360 m1 of Coke, Tab, 7-Up, instant Maxwell House coffee (4.5 g), instant Kava coffee (4.5 g), instant Sanka coffee (4.5 g), tea (4.25 g), milk, and beer. Water served as a control. Mean ± SE maximal acid output to pentagastric was 27.0 ± 6.1 mmollh . Each beverage was swallowed at its usually consumed temperature. Gastric acid secre-tion was measured by intragastric titration until either the liquid had left the stomach or for 1 h. Phenol red was used as a marker to measure empty-ing. All beverages had emptied by {\textgreater}90{\%} by 1 h, except milk that had emptied by 77{\%}. Gastric acid secretion during the 3.5 h after each beverage was significantly (p {\textless} 0.05) greater than the water con-trol. Tab, coffee, Kava , beer, and milk increased gastric acid secretion to {\textgreater}70{\%} of maximum acid output to pentagastrin while beer and milk in-creased gastric acid secretion to {\textgreater} 95{\%} of the penta- These studies were supported by National Institutes of Arthri-tis , Metabolism, and Digestive Diseases Grants AM 17328 to the Center for Ulcer Research and Edu cation (CURE) and NIH Train-ing Grant AM 07202 . The authors wish to thank Dr. Nathan Gochman for ionized ca lcium measurements, and Mrs . Jennifer Abcarian-Lagos for secretarial help . This work was presented in abstract form at the 82nd Annual Meeting of the American Gastroenterological Association in New York, May 18-20, 1981. ' {\textcopyright} 1982 by the American Gastroenterological Association. 0016-5085/82/070199-05{\$}0 2.50 gastrin response. Several properties of each bever-age were determined: calorie and caffeine content, osmolality, ionized calcium, initial pH, and buffer-ing capacity to pH 1.5. No single property was an adequate predictor of the secretory response. It was concluded that many commonly ingested beverages are potent stimuli of gastric acid secretion.},
author = {Ahmed, Sheraz and Weber, Markus and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/ICDAR.2011.153},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed et al. - 2011 - Textgraphics segmentation in architectural floor plans.pdf:pdf},
isbn = {9780769545202},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {Text/Graphics separation},
pages = {734--738},
pmid = {17276342},
title = {{Text/graphics segmentation in architectural floor plans}},
year = {2011}
}
@article{Suk2017b,
abstract = {Artificial neural networks, conceptually and structurally inspired by neural systems, are of great interest along with deep learning, thanks to their great successes in various fields including medical imaging analysis. In this chapter, we describe the fundamental concepts and ideas of (deep) neural networks and explain algorithmic advances to learn network parameters efficiently by avoiding overfitting. Specifically, this chapter focuses on introducing (i) feed-forward neural networks, (ii) gradient descent-based parameter optimization algorithms, (iii) different types of deep models, (iv) technical tricks for fast and robust training of deep models, and (v) open source deep learning frameworks for quick practice.},
author = {Suk, Heung Il},
xxurl = {10.1016/B978-0-12-810408-8.00002-X},
file = {:home/mondal/Documents/MATHS/appendix{\_}d{\_}calculus.pdf:pdf},
isbn = {9780128104095},
journal = {Deep Learning for Medical Image Analysis},
keywords = {Convolutional neural network,Deep Boltzmann machine,Deep belief network,Deep learning,Neural networks},
pages = {3--24},
title = {{An Introduction to Neural Networks and Deep Learning}},
year = {2017}
}
@article{Karaoglu2017,
author = {Karaoglu, Sezer and Tao, Ran and Gevers, Theo and Smeulders, Arnold W M},
xxurl = {10.1109/TMM.2016.2638622},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karaoglu et al. - 2017 - Words Matter Scene Text for Image Classification and Retrieval.pdf:pdf},
issn = {15209210},
number = {5},
pages = {1063--1076},
title = {{Words Matter : Scene Text for Image Classification and Retrieval}},
volume = {19},
year = {2017}
}
@article{Shekhar2012,
author = {Shekhar, Ravi and Jawahar, C V},
xxurl = {10.1109/DAS.2012.96},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shekhar, Jawahar - 2012 - Word Image Retrieval Using Bag of Visual Words.pdf:pdf},
isbn = {978-0-7695-4661-2},
journal = {2012 10th IAPR International Workshop on Document Analysis Systems},
keywords = {-word image retrieval,Bag of Visual Words,Scalabi,Word Image Retrieval},
month = {mar},
pages = {297--301},
publisher = {Ieee},
title = {{Word Image Retrieval Using Bag of Visual Words}},
year = {2012}
}
@article{Senobari2018,
author = {Senobari, Nader Shakibay and Funning, Gareth J. and Keogh, Eamonn and Zhu, Yan and Yeh, Chin‐Chia Michael and Zimmerman, Zachary and Mueen, Abdullah},
xxurl = {10.1785/0220180122},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Senobari et al. - 2018 - Super‐Efficient Cross‐Correlation (SEC‐C) A Fast Matched Filtering Code Suitable for Desktop Computers.pdf:pdf},
issn = {0895-0695},
journal = {Seismological Research Letters},
number = {Xx},
title = {{Super‐Efficient Cross‐Correlation (SEC‐C): A Fast Matched Filtering Code Suitable for Desktop Computers}},
url = {https://pubs.geoscienceworld.org/ssa/srl/article/566118/SuperEfficient-CrossCorrelation-SECC-A-Fast},
volume = {XX},
year = {2018}
}
@article{Bhunia2018,
abstract = {Binarization of degraded document images is an elementary step in most of the problems in document image analysis domain. The paper re-visits the binarization problem by introducing an adversarial learning approach. We construct a Texture Augmentation Network that transfers the texture element of a degraded reference document image to a clean binary image. In this way, the network creates multiple versions of the same textual content with various noisy textures, thus enlarging the available document binarization datasets. At last, the newly generated images are passed through a Binarization network to get back the clean version. By jointly training the two networks we can increase the adversarial robustness of our system. Also, it is noteworthy that our model can learn from unpaired data. Experimental results suggest that the proposed method achieves superior performance over widely used DIBCO datasets.},
archivePrefix = {arXiv},
arxivId = {1810.11120},
author = {Bhunia, Ankan Kumar and Bhunia, Ayan Kumar and Sain, Aneeshan and Roy, Partha Pratim},
eprint = {1810.11120},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhunia et al. - 2018 - Improving Document Binarization via Adversarial Noise-Texture Augmentation.pdf:pdf},
pages = {1--5},
title = {{Improving Document Binarization via Adversarial Noise-Texture Augmentation}},
url = {http://arxiv.org/abs/1810.11120{\%}0Ahttps://github.com/ankanbhunia/AdverseBiNet},
year = {2018}
}
@article{NikNailahAbdullahMuhammadRezaZaba2012,
author = {{Nik Nailah Abdullah, Muhammad Reza Z'aba}, Mohamed Ridza Wahiddin},
xxurl = {10.2991/978-94-91216-71-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nik Nailah Abdullah, Muhammad Reza Z'aba - 2012 - Trustworthy Ubiquitous Computing.pdf:pdf},
isbn = {978-94-91216-70-1},
journal = {Reasoning of Collaborative Human Behaviour in Security-CriticalWork Practices: A Framework},
pages = {99--106},
title = {{Trustworthy Ubiquitous Computing}},
url = {http://link.springer.com/chapter/10.2991/978-94-91216-71-8{\_}6},
year = {2012}
}
@article{Romero2008,
author = {Romero, Javier and Kragic, Danica and Kyrki, Ville and Argyros, Antonis},
xxurl = {10.1109/ROBOT.2008.4543555},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Romero et al. - 2008 - Dynamic time warping for binocular hand tracking and reconstruction.pdf:pdf},
isbn = {978-1-4244-1646-2},
journal = {2008 IEEE International Conference on Robotics and Automation},
month = {may},
pages = {2289--2294},
publisher = {Ieee},
title = {{Dynamic time warping for binocular hand tracking and reconstruction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4543555},
year = {2008}
}
@article{Wang2012,
author = {Wang, Junwei and Bai, Xiang and You, Xinge and Liu, Wenyu and Latecki, Longin Jan},
xxurl = {10.1016/j.patrec.2011.09.042},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2012 - Shape matching and classification using height functions.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = {jan},
number = {2},
pages = {134--143},
publisher = {Elsevier B.V.},
title = {{Shape matching and classification using height functions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865511003412},
volume = {33},
year = {2012}
}
@article{Yin2013b,
author = {Yin, Weichong and Lu, Tong and Su, Feng},
xxurl = {10.1109/ICDAR.2013.222},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin, Lu, Su - 2013 - A Novel Multi-view Object Class Detection Framework for Document Image Content Analysis.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-document image analysis,multi-view,natural ob-},
month = {aug},
pages = {1095--1099},
publisher = {Ieee},
title = {{A Novel Multi-view Object Class Detection Framework for Document Image Content Analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628783},
year = {2013}
}
@article{Jia2018,
abstract = {This paper presents an effective approach for the local threshold binarization of degraded document images. We utilize the structural symmetric pixels (SSPs) to calculate the local threshold in neighborhood and the voting result of multiple thresholds will determine whether one pixel belongs to the foreground or not. The SSPs are defined as the pixels around strokes whose gradient magnitudes are large enough and orientations are symmetric opposite. The compensated gradient map is used to extract the SSP so as to weaken the influence of document degradations. To extract SSP candidates with large magnitudes and distinguish the faint characters and bleed-through background, we propose an adaptive global threshold selection algorithm. To further extract pixels with opposite orientations, an iterative stroke width estimation algorithm is applied to ensure the proper size of neighborhood used in orientation judgement. At last, we present a multiple threshold vote based framework to deal with some inaccurate detections of SSP. The experimental results on seven public document image binarization datasets show that our method is accurate and robust compared with many traditional and state-of-the-art document binarization approaches based on multiple evaluation measures.},
author = {Jia, Fuxi and Shi, Cunzhao and He, Kun and Wang, Chunheng and Xiao, Baihua},
xxurl = {10.1016/j.patcog.2017.09.032},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2018 - Degraded document image binarization using structural symmetry of strokes.pdf:pdf},
isbn = {9781509009817},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Document image binarization,Local threshold,Stroke width estimation,Structural symmetry of strokes},
pages = {225--240},
publisher = {Elsevier Ltd},
title = {{Degraded document image binarization using structural symmetry of strokes}},
url = {https://xxurl.org/10.1016/j.patcog.2017.09.032},
volume = {74},
year = {2018}
}
@article{Giotis2015,
author = {Giotis, Angelos P and Sfikas, Giorgos and Nikou, Christophoros and Gatos, Basilis},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giotis et al. - 2015 - Shape-based Word Spotting in Handwritten Document Images.pdf:pdf},
isbn = {9781479918058},
keywords = {-word spotting,contour features,handwritten text,local,non-rigid point matching},
pages = {561--565},
title = {{Shape-based Word Spotting in Handwritten Document Images}},
year = {2015}
}
@inproceedings{Leydier2005,
abstract = {This article introduces a new word spotting method designed for ancient manuscripts. We take advantage of the robustness of the gradient feature and propose a new segmentation-free matching algorithm that tolerates spatial variations. We test our algorithm on ancient Latin manuscripts and on George Washington's manuscripts.},
author = {Leydier, Yann and {Le Bourgeois}, Frank and Emptoz, Hubert},
booktitle = {ICDAR},
month = {aug},
pages = {533--537 Vol. 1},
publisher = {IEEE},
title = {{Omnilingual segmentation-free word spotting for ancient manuscripts indexation}},
volume = {2005},
year = {2005}
}
@article{Baluja2019,
abstract = {We present a system to hide a full color image inside another of the same size with minimal quality loss to either image. Deep neural networks are simultaneously trained to create the hiding and revealing processes and are designed to specifically work as a pair. The system is trained on images drawn randomly from the ImageNet database, and works well on natural images from a wide variety of sources. Beyond demonstrating the successful application of deep learning to hiding images, we examine how the result is achieved and apply numerous transformations to analyze if image quality in the host and hidden image can be maintained. These transformation range from simple image manipulations to sophisticated machine learning-based adversaries. Two extensions to the basic system are presented that mitigate the possibility of discovering the content of the hidden image. With these extensions, not only can the hidden information be kept secure, but the system can be used to hide even more than a single image. Applications for this technology include image authentication, digital watermarks, finding exact regions of image manipulation, and storing meta-information about image rendering and content.},
author = {Baluja, Shumeet},
xxurl = {10.1109/tpami.2019.2901877},
file = {:home/mondal/Downloads/08654686.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
pages = {1--1},
title = {{Hiding Images Within Images}},
year = {2019}
}
@article{Carton2013,
author = {Carton, Ceres and Lemaitre, Aurelie and Couasnon, Bertrand},
xxurl = {10.1109/ICDAR.2013.245},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carton, Lemaitre, Couasnon - 2013 - Fusion of Statistical and Structural Information for Flowchart Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1210--1214},
publisher = {Ieee},
title = {{Fusion of Statistical and Structural Information for Flowchart Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628806},
year = {2013}
}
@article{Hsu2019,
abstract = {Although Generative Adversarial Network (GAN) can be used to generate the realistic image, improper use of these technologies brings hidden concerns. For example, GAN can be used to generate a tampered video for specific people and inappropriate events, creating images that are detrimental to a particular person, and may even affect that personal safety. In this paper, we will develop a deep forgery discriminator (DeepFD) to efficiently and effectively detect the computer-generated images. Directly learning a binary classifier is relatively tricky since it is hard to find the common discriminative features for judging the fake images generated from different GANs. To address this shortcoming, we adopt contrastive loss in seeking the typical features of the synthesized images generated by different GANs and follow by concatenating a classifier to detect such computer-generated images. Experimental results demonstrate that the proposed DeepFD successfully detected 94.7{\%} fake images generated by several state-of-the-art GANs.},
archivePrefix = {arXiv},
arxivId = {1809.08754},
author = {Hsu, Chih Chung and Lee, Chia Yen and Zhuang, Yi Xiu},
xxurl = {10.1109/IS3C.2018.00104},
eprint = {1809.08754},
file = {:home/mondal/Downloads/1809.08754v3.pdf:pdf},
isbn = {9781538670361},
journal = {Proceedings - 2018 International Symposium on Computer, Consumer and Control, IS3C 2018},
keywords = {Contrastive loss,Deep learning,Forgery detection,Fully convolutional network,GAN},
pages = {388--391},
title = {{Learning to detect fake face images in the wild}},
year = {2019}
}
@article{Rusinol2011,
abstract = {In this paper, we present a segmentation-free word spotting method that is able to deal with heterogeneous document image collections. We propose a patch-based framework where patches are represented by a bag-of-visual-words model powered by SIFT descriptors. A later refinement of the feature vectors is performed by applying the latent semantic indexing technique. The proposed method performs well on both handwritten and typewritten historical document images. We have also tested our method on documents written in non-Latin scripts.},
author = {Rusi{\~{n}}ol, Mar{\c{c}}al and Aldavert, David and Toledo, Ricardo and Llad{\'{o}}s, Josep},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusinol et al. - 2011 - Browsing Heterogeneous Document Collections by a Segmentation-Free Word Spotting Method.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusi{\~{n}}ol et al. - 2011 - Browsing Heterogeneous Document Collections by a Segmentation-Free Word Spotting Method.pdf:pdf},
isbn = {978-1-4577-1350-7},
issn = {15205363},
journal = {2011 International Conference on Document Analysis and Recognition},
keywords = {-word spotting,Dense SIFT Features,Heterogeneous Document Collections,Latent Semantic Indexing,Word Spotting,dense sift features,heterogeneous document collec-,latent semantic indexing,tions},
month = {sep},
pages = {63--67},
publisher = {Ieee},
title = {{Browsing Heterogeneous Document Collections by a Segmentation-Free Word Spotting Method}},
year = {2011}
}
@article{Meng2018,
author = {Meng, Gaofeng and Yuan, Kun and Wu, Ying and Xiang, Shiming and Pan, Chunhong},
xxurl = {10.1109/ICDAR.2017.124},
isbn = {9781538635865},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {Convolutional neural networks,Document image binarization,Document image processing,Pyramid reconstruction},
pages = {727--732},
title = {{Deep Networks for Degraded Document Image Binarization through Pyramid Reconstruction}},
volume = {1},
year = {2018}
}
@article{Su2013,
author = {Su, Bolan and Tian, Shuangxuan and Lu, Shijian and Dinh, Thien Anh and Tan, Chew Lim},
xxurl = {10.1109/ICDAR.2013.38},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su et al. - 2013 - Self Learning Classification for Degraded Document Images by Sparse Representation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {155--159},
publisher = {Ieee},
title = {{Self Learning Classification for Degraded Document Images by Sparse Representation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628603},
year = {2013}
}
@article{Vamvakas2010,
author = {Vamvakas, Georgios and Gatos, Basilis and Perantonis, Stavros J.},
xxurl = {10.1016/j.patcog.2010.02.018},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vamvakas, Gatos, Perantonis - 2010 - Handwritten character recognition through two-stage foreground sub-sampling.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Feature extraction,Handwritten character/digit recognition,Two-stage classification,digit recognition,handwritten character},
month = {aug},
number = {8},
pages = {2807--2816},
publisher = {Elsevier},
title = {{Handwritten character recognition through two-stage foreground sub-sampling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320310000968},
volume = {43},
year = {2010}
}
@article{Manthalkar2003,
author = {Manthalkar, R and Biswas, P.K and Chatterji, B.N},
xxurl = {10.1016/S0167-8655(03)00090-4},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {rotation invariance,scale invariance,script identification,texture classification,wavelets},
month = {oct},
number = {14},
pages = {2455--2462},
publisher = {Elsevier Science Inc.},
title = {{Rotation and scale invariant texture features using discrete wavelet packet transform}},
url = {http://dl.acm.org/citation.cfm?id=899441.899467},
volume = {24},
year = {2003}
}
@inproceedings{Wang2014D,
author = {Wang, Peng; and Eglin, Veronique and Garcia, Christophe and Largeron, Christine and Llados, Josep and Fornes, Alicia and Veronique, Eglin and Christine, Largeron and Josep, Llados and Alicia, Fornes},
booktitle = {DAS},
xxurl = {10.1109/DAS.2014.46},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2014 - A Novel Learning-free Word Spotting Approach Based On Graph Representation.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang - 2014 - A Novel Learning-free Word Spotting Approach Based On Graph Representation.pdf:pdf},
isbn = {9781479932436},
keywords = {Barcelona Cathedral dataset,Context,DTW alignment result,George Washington dataset,Handwriting recognition,Image edge detection,Merging,Robustness,Shape,Skeleton,approximate graph edit distance approach,bipartite matching,computation complexity,computational complexity,document image processing,exhaustive merging process,graph matching,graph representation,graph theory,handwritten document images,handwritten word spotting approach,information retrieval,learning-free word spotting approach,marriage records,morphological signatures,shape context labelled vertexes,skeleton-based graphs,topological signatures},
language = {English},
month = {apr},
pages = {207--211},
publisher = {IEEE},
title = {{A Novel Learning-free Word Spotting Approach Based On Graph Representation}},
year = {2014}
}
@article{Yang2008,
abstract = {This work builds on the method of to create a prototype access control system, capable of handling variations in illumination and expression, as well as significant occlusion or disguise. Our demonstration will allow participants to interact with the algorithm, gaining a better understanding strengths and limitations of sparse representation as a tool for robust recognition.},
author = {Yang, Allen Y},
xxurl = {10.1109/AFGR.2008.4813404},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang - 2008 - Robust Face Recognition via Sparse Representation Face Recognition “ Where amazing happens.pdf:pdf},
isbn = {9781424421534},
issn = {01628828},
journal = {2008 8th IEEE International Conference on Automatic Face Gesture Recognition},
pages = {1--2},
pmid = {19110489},
title = {{Robust Face Recognition via Sparse Representation Face Recognition : “ Where amazing happens}},
year = {2008}
}
@article{Boudraa2017,
abstract = {{\textcopyright} 2017 IEEE. Document image binarization is a central problem in many document analysis systems. Indeed, it represents one of the basic challenges, especially in case of historical documents analysis. In this paper, we propose a novel robust multi stage framework that combines different existing document image thresholding methods for the purpose of getting a better binarization result. CLAHE technique is introduced to significantly enhance contrast in some poor images. The proposed method then uses a hybrid algorithm to partition image into foreground and background. A special procedure is finally applied in order to remove small noise and correct characters morphology. Experimental results prove the accuracy and the efficiency of our approach on document images binarization over three popular datasets compared to some well-known methods in literature.},
author = {Boudraa, Omar and Hidouci, Walid Khaled and Michelucci, Dominique},
xxurl = {10.1109/ICEE-B.2017.8192044},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boudraa, Hidouci, Michelucci - 2017 - A robust multi stage technique for image binarization of degraded historical documents.pdf:pdf},
isbn = {9781538606865},
journal = {2017 5th International Conference on Electrical Engineering - Boumerdes, ICEE-B 2017},
keywords = {Historical document image analysis,adaptive thresholding,contrast enhancement,global thresholding,hybrid algorithm},
pages = {1--6},
title = {{A robust multi stage technique for image binarization of degraded historical documents}},
volume = {2017-Janua},
year = {2017}
}
@article{Qi2010,
abstract = {Trademark image retrieval (TIR), a branch of content-based image retrieval (CBIR), is playing an important role in multimedia information retrieval. This paper proposes an effective solution for TIR by combining shape description and feature matching. We first present an effective shape description method which includes two shape descriptors. Second, we propose an effective feature matching strategy to compute the dissimilarity value between the feature vectors extracted from images. Finally, we combine the shape description method and the feature matching strategy to realize our solution. We conduct a large number of experiments on a standard image set to evaluate our solution and the existing solutions. By comparison of their experimental results, we can see that the proposed solution outperforms existing solutions for the widely used performance metrics. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {Qi, Heng and Li, Keqiu and Shen, Yanming and Qu, Wenyu},
xxurl = {10.1016/j.patcog.2010.01.007},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qi et al. - 2010 - An effective solution for trademark image retrieval by combining shape description and feature matching.pdf:pdf},
isbn = {00313203 (ISSN)},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Content-based image retrieval,Feature matching,Shape description,Trademark image retrieval},
number = {6},
pages = {2017--2027},
publisher = {Elsevier},
title = {{An effective solution for trademark image retrieval by combining shape description and feature matching}},
url = {http://dx.xxurl.org/10.1016/j.patcog.2010.01.007},
volume = {43},
year = {2010}
}
@article{Hassaine2013,
author = {Hassaine, Abdelaali and {Al Maadeed}, Somaya and Aljaam, Jihad and Jaoua, Ali},
xxurl = {10.1109/ICDAR.2013.286},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassaine et al. - 2013 - ICDAR 2013 Competition on Gender Prediction from Handwriting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1417--1421},
publisher = {Ieee},
title = {{ICDAR 2013 Competition on Gender Prediction from Handwriting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628847},
year = {2013}
}
@article{Xiao2018,
abstract = {We introduce FontCode, an information embedding technique for text documents. Provided a text document with specific fonts, our method embeds user-specified information in the text by perturbing the glyphs of text characters while preserving the text content. We devise an algorithm to choose unobtrusive yet machine-recognizable glyph perturbations, leveraging a recently developed generative model that alters the glyphs of each character continuously on a font manifold. We then introduce an algorithm that embeds a user-provided message in the text document and produces an encoded document whose appearance is minimally perturbed from the original document. We also present a glyph recognition method that recovers the embedded information from an encoded document stored as a vector graphic or pixel image, or even on a printed paper. In addition, we introduce a new error-correction coding scheme that rectifies a certain number of recognition errors. Lastly, we demonstrate that our technique enables a wide array of applications, using it as a text document metadata holder, an unobtrusive optical barcode, a cryptographic message embedding scheme, and a text document signature.},
author = {Xiao, Chang and Zhang, Cheng and Zheng, Changxi},
xxurl = {10.1145/3152823},
file = {:home/mondal/Downloads/fontcode.pdf:pdf},
issn = {15577368},
journal = {ACM Transactions on Graphics},
keywords = {Error correction coding,Font manifold,Glyph perturbation,Text document signature},
title = {{FontCode: Embedding information in text documents using glyph perturbation}},
year = {2018}
}
@article{Zhou2013a,
author = {Zhou, Ming-Ke and Yin, Fei and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.172},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Yin, Liu - 2013 - GPU-Based Fast Training of Discriminative Learning Quadratic Discriminant Function for Handwritten Chinese Chara.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {2,3,4,and modified,discrim-,gpu,gradient direction feature extraction,handwritten chinese character recognition,inative learning,modified quadratic discriminant function,parallel computing,sample synthesis},
month = {aug},
number = {Ml},
pages = {842--846},
publisher = {Ieee},
title = {{GPU-Based Fast Training of Discriminative Learning Quadratic Discriminant Function for Handwritten Chinese Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628737},
year = {2013}
}
@article{Jia2016,
author = {Jia, Fuxi and Shi, Cunzhao and He, Kun and Wang, Chunheng and Xiao, Baihua},
xxurl = {10.1109/ICFHR.2016.78},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2016 - Document image binarization using structural symmetry of strokes.pdf:pdf},
isbn = {1509009817},
issn = {21676453},
journal = {ICFHR-2016},
keywords = {-document image binarization,background estimation,local threshold,stroke structure},
pages = {411--416},
title = {{Document Image Binarization Using Structural Symmetry of Strokes}},
year = {2016}
}
@article{Escalera,
author = {Escalera, Sergio and Forn, Alicia and Pujol, Oriol and Escudero, Alberto and Radeva, Petia and Via, Gran},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Escalera et al. - Unknown - Computer Vision Center , Campus UAB , edifici O , 08193 , Bellaterra , Spain atica Aplicada i An ` Dept . Co.pdf:pdf},
isbn = {9781424456543},
journal = {Seminar},
pages = {1--4},
title = {{Computer Vision Center , Campus UAB , edifici O , 08193 , Bellaterra , Spain atica Aplicada i An ` Dept . Computer Science , Campus UAB , Edifici Q , 08193 , Bellaterra , Spain}}
}
@article{Zagoris2012,
annote = {From Duplicate 1 ( 

Handwritten and Machine Printed Text Separation in Document Images Using the Bag of Visual Words Paradigm

- Zagoris, Konstantinos; Pratikakis, Ioannis; Antonacopoulos, Apostolos; Gatos, Basilis; Papamarkos, Nikos )

},
author = {Zagoris, Konstantinos and Pratikakis, Ioannis and Antonacopoulos, Apostolos and Gatos, Basilis and Papamarkos, Nikos},
xxurl = {10.1109/ICFHR.2012.207},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zagoris et al. - 2012 - Handwritten and Machine Printed Text Separation in Document Images Using the Bag of Visual Words Paradigm.pdf:pdf},
isbn = {978-1-4673-2262-1},
journal = {2012 International Conference on Frontiers in Handwriting Recognition},
month = {sep},
pages = {103--108},
publisher = {Ieee},
title = {{Handwritten and Machine Printed Text Separation in Document Images Using the Bag of Visual Words Paradigm}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6424377},
year = {2012}
}
@article{Tataw2013,
author = {Tataw, Oben M. and Rakthanmanon, Thanawin and Keogh, Eamonn J.},
xxurl = {10.1109/ICDAR.2013.43},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tataw, Rakthanmanon, Keogh - 2013 - Clustering of Symbols Using Minimal Description Length.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {clustering,image similarity,mdl},
month = {aug},
pages = {180--184},
publisher = {Ieee},
title = {{Clustering of Symbols Using Minimal Description Length}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628608},
year = {2013}
}
@misc{Nagendar2015,
author = {Nagendar, G and Jawahar, C V},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nagendar, Jawahar - 2015 - Efficient Word Image Retrieval using Fast DTW Distance.pdf:pdf},
isbn = {9781479918058},
title = {{Efficient Word Image Retrieval using Fast DTW Distance}},
year = {2015}
}
@article{Bowyer2001,
abstract = {We demonstrate a method for evaluating edge detector performance based on receiver operating characteristic (ROC) curves. Edge detector output is matched against ground truth to count true positive and false positive edge pixels. A detector's parameter settings are trained to give a best ROC curve on one image and then tested on separate images. We compute aggregate ROC curves based on 1 set of 50 object images and another set of 10 aerial images. We analyze the performance of 11 different edge detectors reported in the literature.},
author = {Bowyer, Kevin and Kranenburg, Christine and Dougherty, Sean},
xxurl = {10.1006/CVIU.2001.0931},
issn = {1077-3142},
journal = {Computer Vision and Image Understanding},
month = {oct},
number = {1},
pages = {77--103},
publisher = {Academic Press},
title = {{Edge Detector Evaluation Using Empirical ROC Curves}},
url = {https://www.sciencedirect.com/science/article/pii/S1077314201909312},
volume = {84},
year = {2001}
}
@article{Biswas2011,
abstract = {Paper land maps are useful documents for collecting geographical information. Land map images provide information like place names, country or states borders etc. A land map image can be considered as a complex document image as the texts may have the myriad background consists of various intensity values and different orientations. Text orientations, fonts and sizes may not unique for all place names within same map images. Text segmentation from such images is not an easy task. This paper presents an approach for text segmentation from scanned land map images using Radon transform based projection profile. Using this projection profile, localization of the text positions are done. Then Euler number of each component is computed for eliminating the non-text components. The proposed approach is tested on a set of collected map images (containing texts in Indian regional scripts; like Bangla) and it gives an encouraging result.},
author = {Biswas, Samit and Das, Amit Kumar},
xxurl = {10.1109/SoCPaR.2011.6089279},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biswas, Das - 2011 - Text segmentation from scanned land map images using radon transform based projection profile.pdf:pdf},
isbn = {9781457711947},
journal = {Proceedings of the 2011 International Conference of Soft Computing and Pattern Recognition, SoCPaR 2011},
keywords = {Land map image,Pixel Classification,Radon transform},
pages = {413--418},
title = {{Text segmentation from scanned land map images using radon transform based projection profile}},
year = {2011}
}
@article{Yanping2015,
abstract = {The options for treatment of the young patient with late-stage avascular necrosis of the femoral head are limited. The authors performed a conservative type of femoral hemiarthroplasty on a select group of patients. They chose for the series only patients with Ficat stage III and IV avascular necrosis, particularly those who had an intact acetabulum and femoral-head involvement only. Of 19 procedures followed for an average of 36 months, there were 84{\%} good and excellent results. The authors feel that this operative procedure may have a role in the treatment of this specific group of young patients.},
author = {Yanping, Chen and Keogh, Eamonn and Hu, Bing and Begum, Nurjahan and Bagnall, Anthony and Mueen, Abdullah and Batista, Gustavo},
journal = {URL:www.cs.ucr.edu/{\~{}}eamonn/time{\_}series{\_}data/},
title = {{UCR Time Series Classification Archive}},
year = {2015}
}
@article{Folkers2002,
abstract = { A system that enables the pictorial specification of queries in an image database is described. The queries are comprised of rectangle, polygon, ellipse, and B-spline shapes. The queries specify which shapes should appear in the target image as well as spatial constraints on the distance between them and their relative position. The retrieval process makes use of an abstraction of the contour of the shape which is invariant against translation, scale, rotation, and starting point, that is based on the use of Fourier descriptors. These abstractions are used in a system to locate logos in an image database. The utility of this approach is illustrated using some sample queries.},
author = {Folkers, a. and Samet, H.},
xxurl = {10.1109/ICPR.2002.1047991},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Folkers, Samet - 2002 - Content-based image retrieval using Fourier descriptors on a logo database.pdf:pdf},
isbn = {0-7695-1695-X},
issn = {1051-4651},
journal = {Object recognition supported by user interaction for service robots},
number = {August},
pages = {521--524},
title = {{Content-based image retrieval using Fourier descriptors on a logo database}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1047991},
volume = {3},
year = {2002}
}
@article{Studi2010,
author = {Studi, Degli and Firenze, D I and Miotti, Beatrice},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Studi, Firenze, Miotti - 2010 - A general framework for graphical item retrieval and identification in printed and handwritten documents.pdf:pdf},
title = {{A general framework for graphical item retrieval and identification in printed and handwritten documents}},
year = {2010}
}
@article{Yan2016,
abstract = {State-of-the-art results of semantic segmentation are established by Fully Convolutional neural Networks (FCNs). FCNs rely on cascaded convolutional and pooling layers to gradually enlarge the receptive fields of neurons, resulting in an indirect way of modeling the distant contextual dependence. In this work, we advocate the use of spatially recurrent layers (i.e. ReNet layers) which directly capture global contexts and lead to improved feature representations. We demonstrate the effectiveness of ReNet layers by building a Naive deep ReNet (N-ReNet), which achieves competitive performance on Stanford Background dataset. Furthermore, we integrate ReNet layers with FCNs, and develop a novel Hybrid deep ReNet (H-ReNet). It enjoys a few remarkable properties, including full-image receptive fields, end-to-end training, and efficient network execution. On the PASCAL VOC 2012 benchmark, the H-ReNet improves the results of state-of-the-art approaches Piecewise, CRFasRNN and DeepParsing by 3.6{\%}, 2.3{\%} and 0.2{\%}, respectively, and achieves the highest IoUs for 13 out of the 20 object classes.},
archivePrefix = {arXiv},
arxivId = {1603.04871},
author = {Yan, Zhicheng and Zhang, Hao and Jia, Yangqing and Breuel, Thomas and Yu, Yizhou},
eprint = {1603.04871},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan et al. - 2016 - Combining the Best of Convolutional Layers and Recurrent Layers A Hybrid Network for Semantic Segmentation.pdf:pdf},
keywords = {cnn,crf,rnn,semantic segmentation},
title = {{Combining the Best of Convolutional Layers and Recurrent Layers: A Hybrid Network for Semantic Segmentation}},
url = {http://arxiv.org/abs/1603.04871},
year = {2016}
}
@article{Argamon2009,
abstract = {Modern terrorist networks pose an unprecedented threat to international$\backslash$nsecurity. The question of how to neutralize that threat is complicated$\backslash$nradically by their fluid, non-hierarchical structures, religious$\backslash$nand ideological motivations, and predominantly non-territorial objectives.$\backslash$nGovernments and militaries are crafting new policies and doctrines$\backslash$nto combat terror, but they desperately need new technologies to make$\backslash$nthese efforts effective. This book collects a wide range of the most$\backslash$ncurrent computational research that addresses critical issues for$\backslash$ncountering terrorism, including: * Finding, summarizing, and evaluating$\backslash$nrelevant information from large and changing data stores; * Simulating$\backslash$nand predicting enemy acts and outcomes; and * Producing actionable$\backslash$nintelligence by finding meaningful patterns hidden in huge amounts$\backslash$nof noisy data. The book�s four sections describe current research$\backslash$non discovering relevant information buried in vast amounts of unstructured$\backslash$ndata; extracting meaningful information from digitized documents$\backslash$nin multiple languages; analyzing graphs and networks to shed light$\backslash$non adversaries� goals and intentions; and developing software systems$\backslash$nthat enable analysts to model, simulate, and predict the effects$\backslash$nof real-world conflicts. The research described in this book is invaluable$\backslash$nreading for governmental decision-makers designing new policies to$\backslash$ncounter terrorist threats, for members of the military, intelligence,$\backslash$nand law enforcement communities devising counterterrorism strategies,$\backslash$nand for researchers developing more effective methods for knowledge$\backslash$ndiscovery in complicated and diverse datasets.},
author = {Argamon, Shlomo and Howard, Newton},
xxurl = {10.1007/978-3-642-01141-2},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Argamon, Howard - 2009 - Computational methods for counterterrorism.pdf:pdf},
isbn = {9783642011405},
journal = {Computational Methods for Counterterrorism},
pages = {1--306},
title = {{Computational methods for counterterrorism}},
year = {2009}
}
@misc{denoisingAutoencoder_1,
title = {{Denoising Autoencoders explained – Towards Data Science}},
url = {https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2},
urldate = {2018-03-29}
}
@inproceedings{Goodfellow2015,
abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples—inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
archivePrefix = {arXiv},
arxivId = {1412.6572},
author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
eprint = {1412.6572},
title = {{Explaining and harnessing adversarial examples}},
year = {2015}
}
@article{Gorecki2013,
author = {G{\'{o}}recki, Tomasz and {\L}uczak, Maciej},
xxurl = {10.2478/amcs-2013-0035},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}recki, {\L}uczak - 2013 - Linear discriminant analysis with a generalization of the Moore–Penrose pseuxxurlnverse.pdf:pdf},
issn = {2083-8492},
journal = {International Journal of Applied Mathematics and Computer Science},
keywords = {linear discriminant analysis,machine learning,moore,penrose pseuxxurlnverse},
number = {2},
pages = {463--471},
title = {{Linear discriminant analysis with a generalization of the Moore–Penrose pseuxxurlnverse}},
url = {http://www.degruyter.com/view/j/amcs.2013.23.issue-2/amcs-2013-0035/amcs-2013-0035.xml},
volume = {23},
year = {2013}
}
@article{Ng,
abstract = {Beschreibt Neuronale Netze, Backpropagation und (Sparse) Auto-Encoders},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.03733v1},
author = {Ng, Andrew},
xxurl = {10.1371/journal.pone.0006098},
eprint = {arXiv:1506.03733v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng - 2011 - Sparse autoencoder.pdf:pdf},
isbn = {1595937935},
issn = {19326203},
journal = {CS294A Lecture notes},
pages = {1--19},
pmid = {19568420},
title = {{Sparse autoencoder}},
url = {http://www.stanford.edu/class/cs294a/sae/sparseAutoencoderNotes.pdf},
year = {2011}
}
@article{Li2013e,
author = {Li, Hailin and Yang, Libin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Yang - 2013 - Accurate and Fast Dynamic Time Warping.pdf:pdf},
journal = {Advanced Data Mining and Applications},
keywords = {computational complexity,data mining,dynamic time warping,similarity measure,time series},
pages = {133--144},
title = {{Accurate and Fast Dynamic Time Warping}},
year = {2013}
}
@article{Almazan2013a,
author = {Almazan, Jon and Fornes, Alicia and Valveny, Ernest},
xxurl = {10.1109/ICDAR.2013.205},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almazan, Fornes, Valveny - 2013 - Deformable HOG-Based Shape Descriptor.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {ICDAR},
month = {aug},
pages = {1022--1026},
publisher = {Ieee},
title = {{Deformable HOG-Based Shape Descriptor}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628770},
year = {2013}
}
@article{Thies2019,
abstract = {The modern computer graphics pipeline can synthesize images at remarkable visual quality; however, it requires well-defined, high-quality 3D content as input. In this work, we explore the use of imperfect 3D content, for instance, obtained from photo-metric reconstructions with noisy and incomplete surface geometry, while still aiming to produce photo-realistic (re-)renderings. To address this challenging problem, we introduce Deferred Neural Rendering, a new paradigm for image synthesis that combines the traditional graphics pipeline with learnable components. Specifically, we propose Neural Textures, which are learned feature maps that are trained as part of the scene capture process. Similar to traditional textures, neural textures are stored as maps on top of 3D mesh proxies; however, the high-dimensional feature maps contain significantly more information, which can be interpreted by our new deferred neural rendering pipeline. Both neural textures and deferred neural renderer are trained end-to-end, enabling us to synthesize photo-realistic images even when the original 3D content was imperfect. In contrast to traditional, black-box 2D generative neural networks, our 3D representation gives us explicit control over the generated output, and allows for a wide range of application domains. For instance, we can synthesize temporally-consistent video re-renderings of recorded 3D scenes as our representation is inherently embedded in 3D space. This way, neural textures can be utilized to coherently re-render or manipulate existing video content in both static and dynamic environments at real-time rates. We show the effectiveness of our approach in several experiments on novel view synthesis, scene editing, and facial reenactment, and compare to state-of-the-art approaches that leverage the standard graphics pipeline as well as conventional generative neural networks.},
archivePrefix = {arXiv},
arxivId = {1904.12356},
author = {Thies, Justus and Zollh{\"{o}}fer, Michael and Nie{\ss}ner, Matthias},
xxurl = {10.1145/3306346.3323035},
eprint = {1904.12356},
file = {:home/mondal/Downloads/1904.12356.pdf:pdf},
issn = {15577368},
journal = {ACM Transactions on Graphics},
keywords = {Facial reenactment,Neural rendering,Neural texture,Novel view synthesis},
number = {4},
title = {{Deferred neural rendering: Image Synthesis using Neural Textures}},
volume = {38},
year = {2019}
}
@article{Rigaud2013,
author = {Rigaud, Christophe and Burie, Jean-Christophe and Ogier, Jean-Marc and Karatzas, Dimosthenis and {Van De Weijer}, Joost},
xxurl = {10.1109/ICDAR.2013.251},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rigaud et al. - 2013 - An Active Contour Model for Speech Balloon Detection in Comics.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {active contour,cases,comics,good clue to guess,implicit,including when contours are,multi-scale,non-closed contour,speech balloon,text is generally a,the location of,where the balloon is},
month = {aug},
pages = {1240--1244},
publisher = {Ieee},
title = {{An Active Contour Model for Speech Balloon Detection in Comics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628812},
year = {2013}
}
@article{Vo2017,
abstract = {a b s t r a c t The binarization of degraded document images is a challenging problem in terms of document anal-ysis. Binarization is a classification process in which intra-image pixels are assigned to either of the two following classes: foreground text and background. Most of the algorithms are constructed on low-level features in an unsupervised manner, and the consequent disenabling of full utilization of input-domain knowledge considerably limits distinguishing of background noises from the foreground. In this paper, a novel supervised-binarization method is proposed, in which a hierarchical deep supervised net-work (DSN) architecture is learned for the prediction of the text pixels at different feature levels. With higher-level features, the network can differentiate text pixels from background noises, whereby severe degradations that occur in document images can be managed. Alternatively, foreground maps that are predicted at lower-level features present a higher visual quality at the boundary area. Compared with those of traditional algorithms, binary images generated by our architecture have cleaner background and better-preserved strokes. The proposed approach achieves state-of-the-art results over widely used DIBCO datasets, revealing the robustness of the presented method.},
author = {Vo, Quang Nhat and Kim, Soo Hyung and Yang, Hyung Jeong and Lee, Gueesang},
xxurl = {10.1016/j.patcog.2017.08.025},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vo et al. - 2017 - Binarization of degraded document images based on hierarchical deep supervised network.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Convolutional neural n,Document image binarization,convolutional neural network,document image binarization},
pages = {568--586},
publisher = {Elsevier Ltd},
title = {{Binarization of degraded document images based on hierarchical deep supervised network}},
volume = {74},
year = {2017}
}
@article{Pantke2013,
author = {Pantke, Werner and Margner, Volker and Fingscheidt, Tim},
xxurl = {10.1109/ICDAR.2013.263},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pantke, Margner, Fingscheidt - 2013 - On Evaluation of Segmentation-Free Word Spotting Approaches without Hard Decisions.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1300--1304},
publisher = {Ieee},
title = {{On Evaluation of Segmentation-Free Word Spotting Approaches without Hard Decisions}},
year = {2013}
}
@article{Tencer2013,
author = {Tencer, Lukas and Renakova, Marta and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.149},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tencer, Renakova, Cheriet - 2013 - Sketch-Based Retrieval of Document Illustrations and Regions of Interest.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {an ideal,bow,ddt,ehd,feature evaluation,for which the input,have a technique,hog,indexing,inverted index,is visual,second category,sift,situation would be to,sketch-based retrieval,visual retrieval,which does not},
month = {aug},
pages = {728--732},
publisher = {Ieee},
title = {{Sketch-Based Retrieval of Document Illustrations and Regions of Interest}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628714},
year = {2013}
}
@article{Suk2017,
abstract = {Artificial neural networks, conceptually and structurally inspired by neural systems, are of great interest along with deep learning, thanks to their great successes in various fields including medical imaging analysis. In this chapter, we describe the fundamental concepts and ideas of (deep) neural networks and explain algorithmic advances to learn network parameters efficiently by avoiding overfitting. Specifically, this chapter focuses on introducing (i) feed-forward neural networks, (ii) gradient descent-based parameter optimization algorithms, (iii) different types of deep models, (iv) technical tricks for fast and robust training of deep models, and (v) open source deep learning frameworks for quick practice.},
author = {Suk, Heung Il},
xxurl = {10.1016/B978-0-12-810408-8.00002-X},
file = {:home/mondal/Documents/MATHS/appendix{\_}a{\_}math{\_}notation.pdf:pdf},
isbn = {9780128104095},
journal = {Deep Learning for Medical Image Analysis},
keywords = {Convolutional neural network,Deep Boltzmann machine,Deep belief network,Deep learning,Neural networks},
pages = {3--24},
title = {{An Introduction to Neural Networks and Deep Learning}},
year = {2017}
}
@article{Daniels2013,
author = {Daniels, Zachary a. and Baird, Henry S.},
xxurl = {10.1109/ICDAR.2013.280},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daniels, Baird - 2013 - Discriminating Features for Writer Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {docu-,feature extraction,handwriting analysis,ment image processing,writer identification},
month = {aug},
pages = {1385--1389},
publisher = {Ieee},
title = {{Discriminating Features for Writer Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628841},
year = {2013}
}
@inproceedings{Rothfeder2003a,
abstract = {Libraries contain enormous amounts of handwritten historical documents which cannot be made available on-line because they do not have a searchable index. The wordspotting idea has previously been proposed as a solution to creating indexes for such documents and collections by matching word images. In this paper we present an algorithm which compares whole word-images based on their appearance. This algorithm recovers correspondences of points of interest in two images, and then uses these correspondences to construct a similarity measure. This similarity measure can then be used to rank word-images in order of their closeness to a querying image. We achieved an average precision of 62.57{\&}{\#}x025; on a set of 2372 images of reasonable quality and an average precision of 15.49{\&}{\#}x025; on a set of 3262 images from documents of poor quality that are even hard to read for humans.},
author = {Rothfeder, Jamie L. and Feng, Shaolei and Rath, Toni M.},
booktitle = {CVPR},
isbn = {0-7695-1900-8},
issn = {1063-6919},
keywords = {Character recognition,Detectors,Handwriting recognition,Image retrieval,Image segmentation,Indexing,Information retrieval,Libraries,Optical character recognition software,Pixel},
language = {English},
month = {jun},
pages = {30--30},
publisher = {IEEE},
title = {{Using Corner Feature Correspondences to Rank Word Images by Similarity}},
volume = {3},
year = {2003}
}
@article{Subramanyam2015,
author = {Subramanyam, Muthukumar},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Subramanyam - 2015 - Advances in Natural and Applied Sciences.pdf:pdf},
keywords = {face detection,forehead,image processing,skin segmentation,wrinkle},
number = {August},
pages = {71--80},
title = {{Advances in Natural and Applied Sciences}},
volume = {9},
year = {2015}
}
@article{Meng2012,
abstract = {In this paper, we propose a metric rectification method to restore an image from a single camera-captured document image. The core idea is to construct an isometric image mesh by exploiting the geometry of page surface and camera. Our method uses a general cylindrical surface (GCS) to model the curved page shape. Under a few proper assumptions, the printed horizontal text lines are shown to be line convergent symmetric. This property is then used to constrain the estimation of various model parameters under perspective projection. We also introduce a paraperspective projection to approximate the nonlinear perspective projection. A set of close-form formulas is thus derived for the estimate of GCS directrix and document aspect ratio. Our method provides a straightforward framework for image metric rectification. It is insensitive to camera positions, viewing angles, and the shapes of document pages. To evaluate the proposed method, we implemented comprehensive experiments on both synthetic and real-captured images. The results demonstrate the efficiency of our method. We also carried out a comparative experiment on the public CBDAR2007 data set. The experimental results show that our method outperforms the state-of-the-art methods in terms of OCR accuracy and rectification errors.},
author = {Meng, Gaofeng and Pan, Chunhong and Xiang, Shiming and Duan, Jiangyong and Zheng, Nanning},
xxurl = {10.1109/TPAMI.2011.151},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meng et al. - 2012 - Metric rectification of curved document images.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Document image analysis,geometric correction,imaging geometry,mesh warping,shape-from-X},
number = {4},
pages = {707--722},
pmid = {21808093},
title = {{Metric rectification of curved document images}},
volume = {34},
year = {2012}
}
@article{Yoon2015,
abstract = {Seismology is experiencing rapid growth in the quantity of data, which has outpaced the development of processing algorithms. Earthquake detection-identification of seismic events in continuous data-is a fundamental operation for observational seismology. We developed an efficient method to detect earthquakes using waveform similarity that overcomes the disadvantages of existing detection methods. Our method, called Fingerprint And Similarity Thresholding (FAST), can analyze a week of continuous seismic waveform data in less than 2 hours, or 140 times faster than autocorrelation. FAST adapts a data mining algorithm, originally designed to identify similar audio clips within large databases; it first creates compact "fingerprints" of waveforms by extracting key discriminative features, then groups similar fingerprints together within a database to facilitate fast, scalable search for similar fingerprint pairs, and finally generates a list of earthquake detections. FAST detected most (21 of 24) cataloged earthquakes and 68 uncataloged earthquakes in 1 week of continuous data from a station located near the Calaveras Fault in central California, achieving detection performance comparable to that of autocorrelation, with some additional false detections. FAST is expected to realize its full potential when applied to extremely long duration data sets over a distributed network of seismic stations. The widespread application of FAST has the potential to aid in the discovery of unexpected seismic signals, improve seismic monitoring, and promote a greater understanding of a variety of earthquake processes.},
author = {Yoon, Clara E. and O'Reilly, Ossian and Bergen, Karianne J. and Beroza, Gregory C.},
xxurl = {10.1126/sciadv.1501057},
issn = {23752548},
journal = {Science Advances},
title = {{Earthquake detection through computationally efficient similarity search}},
year = {2015}
}
@article{Kunze2013b,
author = {Kunze, Kai and Shiga, Yuki and Ishimaru, Shoya and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.27},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kunze et al. - 2013 - Reading Activity Recognition Using an Off-the-Shelf EEG -- Detecting Reading Activities and Distinguishing Genres.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {96--100},
publisher = {Ieee},
title = {{Reading Activity Recognition Using an Off-the-Shelf EEG -- Detecting Reading Activities and Distinguishing Genres of Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628592},
year = {2013}
}
@article{Sun2013,
author = {Sun, Weihan and Burie, Jean-Christophe and Ogier, Jean-Marc and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.62},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2013 - Specific Comic Character Detection Using Local Feature Matching.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {cific character detection,comic analysis,comic book,comic character,local feature matching,spe-},
month = {aug},
pages = {275--279},
publisher = {Ieee},
title = {{Specific Comic Character Detection Using Local Feature Matching}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628627},
year = {2013}
}
@misc{CDIP2006,
author = {Agam, G and Argamon, S and Frieder, O and Grossman, D and Lewis, D},
institution = {Illinois Institute of Technology},
title = {{The Complex Document Image Processing ({\{}CDIP{\}}) Test Collection Project}},
url = {http://ir.iit.edu/projects/CDIP.html},
year = {2006}
}
@article{Laptev2003,
author = {Laptev, Ivan and Lindeberg, Tony},
xxurl = {10.1007/3-540-44935-3_26},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laptev, Lindeberg - 2003 - Interest Point Detection and Scale Selection in Space-Time.pdf:pdf},
isbn = {978-3-540-40368-5},
issn = {03029743},
journal = {Scale Space Methods in Computer Vision},
pages = {372--387},
title = {{Interest Point Detection and Scale Selection in Space-Time}},
url = {http://dx.xxurl.org/10.1007/3-540-44935-3{\_}26},
volume = {2695},
year = {2003}
}
@article{Yeh,
author = {Yeh, Chin-chia Michael and Herle, Helga Van and Keogh, Eamonn},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh, Herle, Keogh - Unknown - Matrix Profile III The Matrix Profile Allows Visualization of Salient Subsequences in Massive Time Series.pdf:pdf},
keywords = {feature extraction,time series,visualization},
title = {{Matrix Profile III : The Matrix Profile Allows Visualization of Salient Subsequences in Massive Time Series}}
}
@article{Mosa2015a,
abstract = {The presence of a large number of broken characters in a digital document image represents the main problem in Optical Character Recognition (OCR) of historical documents. This problem still continues a challenge for recent OCR solutions. Broken character restoration from historical documents it is substantial because these documents contain important facts and leaving them leads to losing invaluable information. Gradient Vector Flow (GVF) snake has much more capture range than traditional snake therefore widely used in image segmentation. In this paper we used balloon with triangle steps to improve GVF snake to converge of deep concavity area and Restore broken characters using the improved GVF.},
author = {Mosa, Qusay O. and Nasrudin, Mohammad F.},
file = {:home/mondal/Downloads/13Vol73No3.pdf:pdf},
issn = {18173195},
journal = {Journal of Theoretical and Applied Information Technology},
keywords = {Balloon force,Deep concavity,Divergence,GVF,Snake algorithm},
number = {3},
pages = {441--446},
title = {{Broken character restoration using gradient vector flow and balloon force algorithm}},
volume = {73},
year = {2015}
}
@article{Malik2013,
author = {Malik, Rakesh and Roy, Partha Pratim and Pal, Umapada and Kimura, Fumitaka},
xxurl = {10.1109/ICDAR.2013.170},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malik et al. - 2013 - Handwritten Musical Document Retrieval Using Music-Score Spotting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {any research work on,approximate string matching,best of our knowledge,effort towards the work,indexing etc,like recognition,musical document retrieval,staff removal,symbol classification,there has not been,to the},
month = {aug},
pages = {832--836},
publisher = {Ieee},
title = {{Handwritten Musical Document Retrieval Using Music-Score Spotting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628735},
year = {2013}
}
@article{Chiu2003,
abstract = {Several important time series data mining problems reduce to the core task of finding approximately repeated subsequences in a longer time series. In an earlier work, we formalized the idea of approximately repeated subsequences by introducing the notion of time series motifs. Two limitations of this work were the poor scalability of the motif discovery algorithm, and the inability to discover motifs in the presence of noise. Here we address these limitations by introducing a novel algorithm inspired by recent advances in the problem of pattern discovery in biosequences. Our algorithm is probabilistic in nature, but as we show empirically and theoretically, it can find time series motifs with very high probability even in the presence of noise or dont care symbols. Not only is the algorithm fast, but it is an anytime algorithm, producing likely candidate motifs almost immediately, and gradually improving the quality of results over time.},
author = {Chiu, Bill and Keogh, Eamonn and Lonardi, Stefano},
xxurl = {10.1145/956750.956808},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiu, Keogh, Lonardi - 2003 - Probabilistic discovery of time series motifs.pdf:pdf},
isbn = {1581137370},
journal = {Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining  - KDD '03},
keywords = {application domains mentioned above,data mining,discovery can be very,in addition to the,motif,motifs,randomized algorithms,right as an exploratory,time series,useful in its own},
pages = {493},
title = {{Probabilistic discovery of time series motifs}},
url = {http://portal.acm.org/citation.cfm?xxurld=956750.956808},
year = {2003}
}
@article{Eads2002a,
abstract = {We introduce an algorithm for classifying time series data. Since our initial application is for lightning data, we call the algorithm Zeus. Zeus is a hybrid algorithm that employs evolutionary computation for feature extraction, and a support vector machine for the final "backend" classification. Support vector machines have a reputation for classifying in high-dimensional spaces without overfitting, so the utility of reducing dimensionality with an intermediate feature selection step has been questioned. We address this question by testing Zeus on a lightning classification task using data acquired from the Fast On-orbit Recording of Transient Events (FORTE) satellite.},
author = {Eads, Damian and Hill, Daniel and Davis, Sean and Perkins, Simon and Ma, Junshui and Porter, Reid and Theiler, James},
xxurl = {10.1117/12.453526},
isbn = {0769520006},
issn = {0277786X},
journal = {Proceedings of SPIE},
keywords = {feature,genetic algorithm,genetic programming,lightning,n fold cross validation,selection,support vector machines,time series classification,tornado},
pages = {74--85},
title = {{Genetic Algorithms and Support Vector Machines for Time Series Classification}},
url = {http://link.aip.org/link/?PSI/4787/74/1{\&}Agg=xxurl},
volume = {4787},
year = {2002}
}
@article{Du2013,
author = {Du, Jun and Huo, Qiang},
xxurl = {10.1109/ICDAR.2013.22},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Huo - 2013 - An Irrelevant Variability Normalization Based Discriminative Training Approach for Online Handwritten Chinese Character.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {chinese character recognition,handwritten,irrelevant variability normalization,minimum classification error,ration margin,rprop,sample sepa-},
month = {aug},
pages = {69--73},
publisher = {Ieee},
title = {{An Irrelevant Variability Normalization Based Discriminative Training Approach for Online Handwritten Chinese Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628587},
year = {2013}
}
@article{Spitz1997,
author = {Spitz, A.L.},
xxurl = {10.1109/34.584100},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Asian scripts.,Han-based languages,Latin-based languages,Multilingual,language classification,machine printed OCR,script classification},
month = {mar},
number = {3},
pages = {235--245},
publisher = {IEEE Computer Society},
title = {{Determination of the script and language content of document images}},
url = {http://dl.acm.org/citation.cfm?id=248860.248869},
volume = {19},
year = {1997}
}
@inproceedings{Dang2015,
author = {Dang, Q.B. and Le, V.P. and Luqman, M.M. and Coustaty, M. and Tran, C.D. and Ogier, J-M.},
booktitle = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
xxurl = {10.1109/ICDAR.2015.7333956},
isbn = {978-1-4799-1805-8},
keywords = {Accuracy,Indexes,LLAH,ORB,SIFT,SRIF,SURF,amera-based Document Image Retrieval,camera-based document image retrieval system,cameras,document image processing,image retrieval,indexing,indexing method,indexing.C,indexing.amera-based Document Image Retrieval,local features,scale-and-rotation invariant feature,transforms},
language = {English},
month = {aug},
pages = {1211--1215},
publisher = {IEEE},
title = {{Camera-based document image retrieval system using local features - comparing SRIF with LLAH, SIFT, SURF and ORB}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=7333956},
year = {2015}
}
@article{Lee2003,
abstract = { The quantification of abundance, distribution, and movement of fish is critical to ecological and environmental studies of fish communities. To properly manage, regulate, and protect migratory fisheries it is essential to accurately monitor numbers, size, and species of fish at specific fish passages during migratory seasons. Currently, all monitoring is done manually with significant time and financial constraints. An automated fish classification system will simplify data gathering and improve data accuracy. In this research, 22 images of 9 target species were recorded. The contour of each image was extracted to form a closed curve for shape analysis. A new shape analysis algorithm was developed for removing edge noise and redundant data points such as short straight lines. A curvature function analysis was used to locate critical landmark points. The fish contour segments of interest were then extracted based on these landmark points for species classification. By comparing individual contour segments to the curves in the database, accurate pattern matching was achieved.},
author = {Lee, D.J. and Redd, S. and Schoenberger, R. and Xu, Xiaoqian Xu Xiaoqian and Zhan, Pengcheng Zhan Pengcheng},
xxurl = {10.1109/IECON.2003.1280195},
isbn = {0-7803-7906-3},
journal = {IECON'03. 29th Annual Conference of the IEEE Industrial Electronics Society (IEEE Cat. No.03CH37468)},
title = {{An automated fish species classification and migration monitoring system}},
volume = {2},
year = {2003}
}
@article{Liu2013a,
author = {Liu, Zongyi and Smith, Ray},
xxurl = {10.1109/ICDAR.2013.56},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Smith - 2013 - A Simple Equation Region Detector for Printed Document Images in Tesseract.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-document image processing,different languages,equa-,layout analysis,needed when parsing books,no additional classifier is,of,tion region detection},
month = {aug},
pages = {245--249},
publisher = {Ieee},
title = {{A Simple Equation Region Detector for Printed Document Images in Tesseract}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628621},
year = {2013}
}
@article{Zeng2006,
author = {Zeng, Wei and Meng, XiangXu and Yang, ChengLei and Huang, Lei},
xxurl = {10.1016/j.cag.2006.07.007},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeng et al. - 2006 - Feature extraction for online handwritten characters using Delaunay triangulation.pdf:pdf},
issn = {00978493},
journal = {Computers {\&} Graphics},
keywords = {delaunay triangulation,feature extraction,online handwritten characters},
number = {5},
pages = {779--786},
title = {{Feature extraction for online handwritten characters using Delaunay triangulation}},
volume = {30},
year = {2006}
}
@article{Zimmerman2019,
abstract = {The discovery of conserved (repeated) patterns in time series is arguably the most important primitive in time series data mining. Called time series motifs, these primitive patterns are useful in their own right, and are also used as inputs into classification, clustering, segmentation, visualization, and anomaly detection algorithms. Recently the Matrix Profile has emerged as a promising representation to allow the efficient exact computation of the top-k motifs in a time series. The state-of-the-art algorithms for computing the Matrix Profile are STAMP and STOMP which are fast enough for many tasks. However, in a handful of domains, including astronomy and seismology, there is an insatiable appetite to consider ever larger datasets. In this work we show that with several novel insights we can push the motif discovery envelope using a novel scalable framework in conjunction with a deployment to commercial GPU clusters in the cloud. We demonstrate the utility of our ideas with detailed case studies in seismology, demonstrating that the efficiency of our algorithm allows us to exhaustively consider datasets that are currently only approximately searchable, allowing us to find subtle precursor earthquakes that had previously escaped attention, and other novel seismic regularities.},
author = {Zimmerman, Zachary and Kamgar, Kaveh and Senobari, Nader Shakibay and Crites, Brian and Funning, Gareth and Brisk, Philip and Keogh, Eamonn},
xxurl = {10.1145/3357223.3362721},
file = {:home/mondal/Downloads/SCAMP-camera-ready-final1.pdf:pdf},
isbn = {9781450369732},
journal = {Proceedings of the ACM Symposium on Cloud Computing - SoCC'19},
keywords = {ab-join,cloud,computing,entomology,fault-tolerance,gpu,matrix pro fi le,numerical optimization,scamp,seismology,self-join,spot instance,tiling,time series},
pages = {74--86},
title = {{Matrix Profile XIV: Scaling Time Series Motif Discovery with GPUs to Break a Quintillion Pairwise Comparisons a Day and Beyond}},
url = {http://dl.acm.org/citation.cfm?xxurld=3357223.3362721},
year = {2019}
}
@article{Moysset2013,
author = {Moysset, Bastien and Kermorvant, Christopher},
xxurl = {10.1109/ICDAR.2013.44},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moysset, Kermorvant - 2013 - On the Evaluation of Handwritten Text Line Detection Algorithms.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-document layout analysis,evaluation metrics,handwriting recognition,how much a good,recognition results,text line detection,text line segmentation improves,the},
month = {aug},
pages = {185--189},
publisher = {Ieee},
title = {{On the Evaluation of Handwritten Text Line Detection Algorithms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628609},
year = {2013}
}
@article{Buhler2002,
abstract = {The DNA motif discovery problem abstracts the task of discovering short, conserved sites in genomic DNA. Pevzner and Sze recently described a precise combinatorial formulation of motif discovery that motivates the following algorithmic challenge: find twenty planted occurrences of a motif of length fifteen in roughly twelve kilobases of genomic sequence, where each occurrence of the motif differs from its consensus in four randomly chosen positions. Such "subtle" motifs, though statistically highly significant, expose a weakness in existing motif-finding algorithms, which typically fail to discover them. Pevzner and Sze introduced new algorithms to solve their (15,4)-motif challenge, but these methods do not scale efficiently to more difficult problems in the same family, such as the (14,4)-, (16,5)-, and (18,6)-motif problems. We introduce a novel motif-discovery algorithm, PROJECTION, designed to enhance the performance of existing motif finders using random projections of the input's substrings. Experiments on synthetic data demonstrate that PROJECTION remedies the weakness observed in existing algorithms, typically solving the difficult (14,4)-, (16,5)-, and (18,6)-motif problems. Our algorithm is robust to nonuniform background sequence distributions and scales to larger amounts of sequence than that specified in the original challenge. A probabilistic estimate suggests that related motif-finding problems that PROJECTION fails to solve are in all likelihood inherently intractable. We also test the performance of our algorithm on realistic biological examples, including transcription factor binding sites in eukaryotes and ribosome binding sites in prokaryotes.},
author = {Buhler, Jeremy and Tompa, Martin},
xxurl = {10.1089/10665270252935430},
issn = {1066-5277},
journal = {Journal of Computational Biology},
month = {apr},
number = {2},
pages = {225--242},
title = {{Finding Motifs Using Random Projections}},
url = {http://www.liebertpub.com/xxurl/10.1089/10665270252935430},
volume = {9},
year = {2002}
}
@article{Banerjee2009,
abstract = {We propose an approach to restore severely degraded document images using a probabilistic context model. Unlike traditional approaches that use previously learned prior models to restore an image, we are able to learn the text model from the degraded document itself, making the approach independent of script, font, style, etc. We model the contextual relationship using an MRF. The ability to work with larger patch sizes allows us to deal with severe degradations including cuts, blobs, merges and vandalized documents. Our approach can also integrate document restoration and super-resolution into a single framework, thus directly generating high quality images from degraded documents. Experimental results show significant improvement in image quality on document images collected from various sources including magazines and books, and comprehensively demonstrate the robustness and adaptability of the approach. It works well with document collections such as books, even with severe degradations, and hence is ideally suited for repositories such as digital libraries.},
author = {Banerjee, Jyotirmoy and Namboodiri, Anoop M. and Jawahar, C. V.},
xxurl = {10.1109/CVPRW.2009.5206601},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banerjee, Namboodiri, Jawahar - 2009 - Contextual restoration of severely degraded document images.pdf:pdf},
isbn = {9781424439935},
issn = {1063-6919},
journal = {2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2009},
pages = {517--524},
title = {{Contextual restoration of severely degraded document images}},
volume = {2009 IEEE },
year = {2009}
}
@article{Oprean2013,
author = {Oprean, Cristina and Likforman-Sulem, Laurence and Popescu, Adrian and Mokbel, Chafic},
xxurl = {10.1109/ICDAR.2013.199},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oprean et al. - 2013 - Using the Web to Create Dynamic Dictionaries in Handwritten Out-of-Vocabulary Word Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {989--993},
publisher = {Ieee},
title = {{Using the Web to Create Dynamic Dictionaries in Handwritten Out-of-Vocabulary Word Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628764},
year = {2013}
}
@article{Zhu2018,
abstract = {Since their introduction over a decade ago, time series motifs have become a fundamental tool for time series analytics, finding diverse uses in dozens of domains. In this work we introduce Time Series Chains, which are related to, but distinct from, time series motifs. Informally, time series chains are a temporally ordered set of subsequence patterns, such that each pattern is similar to the pattern that preceded it, but the first and last patterns are arbitrarily dissimilar. In the discrete space, this is similar to extracting the text chain “hit, hot, dot, dog” from a paragraph. The first and last words have nothing in common, yet they are connected by a chain of words with a small mutual difference. Time series chains can capture the evolution of systems, and help predict the future. As such, they potentially have implications for prognostics. In this work, we introduce a robust definition of time series chains, and a scalable algorithm that allows us to discover them in massive datasets.},
author = {Zhu, Yan and Imamura, Makoto and Nikovski, Daniel and Keogh, Eamonn},
xxurl = {10.1007/s10115-018-1224-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2018 - Matrix Profile VII Time Series Chains A New Primitive for Time Series Data Mining.pdf:pdf},
isbn = {9781538638347},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {Data Streams,Machine Learning: Data Mining,Machine Learning: Time-series,link analysis,motifs,prognostics,time series},
pages = {1--27},
title = {{Matrix Profile VII: Time Series Chains: A New Primitive for Time Series Data Mining}},
year = {2018}
}
@article{Zhang2013e,
abstract = {Building patterns are important features that should be preserved in the map generalization process. However, the patterns are not explicitly accessible to automated systems. This paper proposes a framework and several algorithms that automatically recognize building patterns from topographic data, with a focus on collinear and curvilinear alignments. For both patterns two algorithms are developed, which are able to recognize alignment-of-center and alignment-of-side patterns. The presented approach integrates aspects of computational geometry, graph-theoretic concepts and theories of visual perception. Although the individual algorithms for collinear and curvilinear patterns show great potential for each type of the patterns, the recognized patterns are neither complete nor of enough good quality. We therefore advocate the use of a multi-algorithm paradigm, where a mechanism is proposed to combine results from different algorithms to improve the recognition quality. The potential of our method is demonstrated by an application of the framework to several real topographic datasets. The quality of the recognition results are validated in an expert survey.},
author = {Zhang, Xiang and Ai, Tinghua and Stoter, Jantien and Kraak, Menno Jan and Molenaar, Martien},
xxurl = {10.1007/s10707-011-0146-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2013 - Building pattern recognition in topographic data Examples on collinear and curvilinear alignments.pdf:pdf},
isbn = {1384-6175},
issn = {13846175},
journal = {GeoInformatica},
keywords = {Building alignments,Building patterns,Computational geometry,Data enrichment,Map generalization,Pattern recognition,Visual perception theory},
number = {1},
pages = {1--33},
pmid = {6813814},
title = {{Building pattern recognition in topographic data: Examples on collinear and curvilinear alignments}},
volume = {17},
year = {2013}
}
@article{Liang2008,
abstract = {Compared to typical scanners, handheld cameras offer convenient, flexible, portable, and non-contact image capture, which enables many new applications and breathes new life into existing ones. However, camera-captured documents may suffer from distortions caused by non-planar document shape and perspective projection, which lead to failure of current OCR technologies. We present a geometric rectification framework for restoring the frontal-flat view of a document from a single camera-captured image. Our approach estimates 3D document shape from texture flow information obtained directly from the image without requiring additional 3D/metric data or prior camera calibration. Our framework provides a unified solution for both planar and curved documents and can be applied in many, especially mobile, camera-based document analysis applications. Experiments show that our method produces results that are significantly more OCR compatible than the original images.},
author = {Liang, Jian and DeMenthon, Daniel and Doermann, David},
xxurl = {10.1109/TPAMI.2007.70724},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, DeMenthon, Doermann - 2008 - Geometric rectification of camera-captured document images.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Camera-based OCR,Image rectification,Shape estimation,Texture flow analysis},
number = {4},
pages = {591--605},
pmid = {18276966},
title = {{Geometric rectification of camera-captured document images}},
volume = {30},
year = {2008}
}
@article{Yeh2017b,
abstract = {In academic settings over the last decade, there has been significant progress in time series classification. However, much of this work makes assumptions that are simply unrealistic for deployed industrial applications. Examples of these unrealistic assumptions include the following: assuming that data subsequences have a single fixed-length, are precisely extracted from the data, and are correctly labeled according to their membership in a set of equal- size classes. In real-world industrial settings, these patterns can be of different lengths, the class annotations may only belong to a general region of the data, may contain errors, and finally, the class distribution is typically highly skewed. Can we learn from such weakly labeled data? In this work, we introduce SDTS, a scalable algorithm that can learn in such challenging settings. We demonstrate the utility of our ideas by learning from diverse datasets with millions of datapoints. As we shall demonstrate, our domain-agnostic parameter-free algorithm can be competitive with domain-specific algorithms used in neuroscience and entomology, even when those algorithms have been tuned by domain experts to incorporate domain knowledge.},
author = {Yeh, Chin-chia Michael and Kavantzas, Nickolas and Keogh, Eamonn},
xxurl = {10.14778/3137765.3137784},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh, Kavantzas, Keogh - 2017 - Matrix Profile IV Using Weakly Labeled Time Series to Predict Outcomes.pdf:pdf},
issn = {21508097},
journal = {Proceedings of VLDB Endowment},
number = {12},
pages = {1802--1812},
title = {{Matrix Profile IV: Using Weakly Labeled Time Series to Predict Outcomes}},
volume = {10},
year = {2017}
}
@article{Liu2019,
abstract = {Over the past 20 years we have moved from a situation in which we had no therapy for alcoholic liver disease, through a period when any therapy we had was purely empirical, to an era where we have specific therapies for different aspects of this disease based upon sound pathogenic principles. In this short review, an attempt has been made to summarize these advances in the understanding of the pathogenesis of alcoholic liver disease. In particular, they explain why patients with severe acute alcoholic hepatitis continue to deteriorate in hospital despite withdrawal from alcohol, why they respond to corticosteroids, why only a small percentage of patients develop cirrhosis, and why propylthiouracil may offer protection.},
address = {Cham},
author = {Blendis, L M},
xxurl = {10.1007/978-3-319-97982-3},
editor = {Lotfi, Ahmad and Bouchachia, Hamid and Gegov, Alexander and Langensiepen, Caroline and McGinnity, Martin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pastor-Pellicer et al. - 2015 - Insights on the use of convolutional neural networks for document image binarization.pdf:pdf},
isbn = {978-3-319-97981-6},
issn = {0269-2813},
journal = {Alimentary pharmacology {\&} therapeutics},
month = {oct},
number = {5},
pages = {541--8},
pmid = {1420746},
publisher = {Springer International Publishing},
series = {Advances in Intelligent Systems and Computing},
title = {{Review article: the treatment of alcoholic liver disease.}},
url = {http://link.springer.com/10.1007/978-3-319-97982-3 http://www.ncbi.nlm.nih.gov/pubmed/1420746},
volume = {6},
year = {1992}
}
@article{Almazan2012b,
author = {Almaz{\'{a}}n, Jon and Gordo, Albert and Forn{\'{e}}s, Alicia and Valveny, Ernest},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almaz{\'{a}}n et al. - 2012 - Efficient Exemplar Word Spotting.pdf:pdf},
journal = {Procedings of the British Machine Vision Conference 2012},
pages = {67.1----67.11},
publisher = {British Machine Vision Association},
title = {{Efficient Exemplar Word Spotting}},
year = {2012}
}
@article{Fern,
abstract = {The goal of keyword spotting is to detect the presence of specific spoken words in unconstrained speech. The majority of keyword spotting systems are based on generative hidden Markov models and lack discriminative capabilities. However, discriminative keyword spotting systems are currently based on frame-level posterior probabilities of sub-word units. This paper presents a discriminative keyword spotting system based on recurrent neural networks only, that uses information from long time spans to estimate word-level posterior probabilities. In a keyword spotting task on a large database of unconstrained speech the system achieved a keyword spotting accuracy of 84.5{\%}.},
author = {Fern{\'{a}}ndez, Santiago and Graves, Alex and Schmidhuber, J{\"{u}}rgen},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fern{\'{a}}ndez, Graves, Schmidhuber - 2007 - An application of recurrent neural networks to discriminative keyword spotting.pdf:pdf},
isbn = {9783540746935},
issn = {03029743},
journal = {The 17th international conference on Artificial neural networks},
keywords = {5,84,achieves a word accuracy,an hmm-based speech recogniser,keyword spotting accuracy of,large database of unconstrained,of only 65,speech where,spotting task in a,the system achieved a},
pages = {220--229},
title = {{An application of recurrent neural networks to discriminative keyword spotting}},
year = {2007}
}
@article{Gatos2009,
abstract = {DIBCO 2009 is the first International Document Image Binarization Contest organized in the context of ICDAR 2009 conference. The general objective of the contest is to identify current advances in document image binarization using established evaluation performance measures. This paper describes the contest details including the evaluation measures used as well as the performance of the 43 submitted methods along with a short description of each method.},
author = {Gatos, B. and Ntirogiannis, K. and Pratikakis, I.},
xxurl = {10.1109/ICDAR.2009.246},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos, Ntirogiannis, Pratikakis - 2009 - ICDAR 2009 Document Image Binarization Contest (DIBCO 2009).pdf:pdf},
isbn = {9780769537252},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
number = {Dibco},
pages = {1375--1382},
title = {{ICDAR 2009 Document Image Binarization Contest (DIBCO 2009)}},
year = {2009}
}
@inproceedings{Kalpakis2002,
abstract = {Much environmental and socioeconomic time-series data can be$\backslash$nadequately modeled using autoregressive integrated moving average$\backslash$n(ARIMA) models. We call such time series "ARIMA time series". We propose$\backslash$nthe use of the linear predictive coding (LPC) cepstrum for clustering$\backslash$nARIMA time series, by using the Euclidean distance between the LPC$\backslash$ncepstra of two time series as their dissimilarity measure. We$\backslash$ndemonstrate that LPC cepstral coefficients have the desired features for$\backslash$naccurate clustering and efficient indexing of ARIMA time series. For$\backslash$nexample, just a few LPC cepstral coefficients are sufficient in order to$\backslash$ndiscriminate between time series that are modeled by different ARIMA$\backslash$nmodels. In fact, this approach requires fewer coefficients than$\backslash$ntraditional approaches, such as DFT (discrete Fourier transform) and DWT$\backslash$n(discrete wavelet transform). The proposed distance measure can be used$\backslash$nfor measuring the similarity between different ARIMA models as well. We$\backslash$ncluster ARIMA time series using the "partition around mexxurlds" method$\backslash$nwith various similarity measures. We present experimental results$\backslash$ndemonstrating that, using the proposed measure, we achieve significantly$\backslash$nbetter clusterings of ARIMA time series data as compared to clusterings$\backslash$nobtained by using other traditional similarity measures, such as DFT,$\backslash$nDWT, PCA (principal component analysis), etc. Experiments were performed$\backslash$nboth on simulated and real data},
author = {Kalpakis, K. and Gada, D. and Puttagunta, V.},
booktitle = {Proceedings 2001 IEEE International Conference on Data Mining},
xxurl = {10.1109/ICDM.2001.989529},
isbn = {0-7695-1119-8},
pages = {273--280},
publisher = {IEEE Comput. Soc},
title = {{Distance measures for effective clustering of ARIMA time-series}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=989529},
year = {2002}
}
@article{Capitaine2011,
author = {Capitaine, Hoel Le and Fr{\'{e}}licot, Carl and Laboratoire, M and A, I and Rochelle, Universit{\'{e}} De La},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Capitaine et al. - 2011 - A fast fuzzy c-means algorithm for color image segmentation.pdf:pdf},
number = {July},
title = {{A fast fuzzy c-means algorithm for color image segmentation}},
year = {2011}
}
@inproceedings{yangText,
address = {Arequipa, Peru},
author = {Yang, Tao and Lee, Dongwon},
booktitle = {Proceedings of the 3rd Alberto Mendelzon International Workshop on Foundations of Data Management},
title = {{T3 : On Mapping Text To Time Series}}
}
@article{Winder,
author = {Winder, Simon a J and Way, Microsoft},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Winder, Way - Unknown - Learning Local Image Descriptors.pdf:pdf},
journal = {Transformation},
pages = {3--10},
title = {{Learning Local Image Descriptors}}
}
@book{Duda2001,
abstract = {2nd ed. "A Wiley-Interscience Publication." This edition has been completely revised, enlarged and formatted in two colours. It is a systematic account of the major topics in pattern recognition, based on the fundamental principles. It includes extensive examples. Introduction -- Bayesian decision theory -- Maximum-likelihood and Bayesian parameter estimation -- Nonparametric techniques -- Linear discriminant functions -- Multilayer neural networks -- Stochastic methods -- Nonmetric methods -- Algorithm-independent machine learning -- Unsupervised learning and clustering -- Mathematical foundations.},
author = {Duda, Richard O. and Hart, Peter E. (Peter Elliot) and Stork, David G.},
pages = {654},
publisher = {Wiley},
title = {{Pattern classification}},
year = {2001}
}
@article{Ramalingam2018,
author = {Ramalingam, Kaviya and Bhojan, Ramamurthy},
xxurl = {10.22266/ijies2018.0630.14},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramalingam, Bhojan - 2018 - Identification of Broken Characters in Degraded Documents.pdf:pdf},
issn = {21853118},
journal = {International Journal of Intelligent Engineering and Systems},
keywords = {chain code,heuristic information,horizontal projection profile,mean-based thresholding,ocr,vertical projection profile},
number = {3},
pages = {130--137},
title = {{Identification of Broken Characters in Degraded Documents}},
url = {http://www.inass.org/2018/2018063014.pdf},
volume = {11},
year = {2018}
}
@article{Aggarwal2011,
author = {Aggarwal, Charu C. and Wang, Haixun},
xxurl = {10.1109/ICDE.2011.5767834},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal, Wang - 2011 - On dimensionality reduction of massive graphs for indexing and retrieval.pdf:pdf},
isbn = {978-1-4244-8959-6},
journal = {2011 IEEE 27th International Conference on Data Engineering},
month = {apr},
pages = {1091--1102},
publisher = {Ieee},
title = {{On dimensionality reduction of massive graphs for indexing and retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5767834},
year = {2011}
}
@article{Stamatopoulos2010,
address = {New York, New York, USA},
author = {Stamatopoulos, N. and Gatos, B. and Georgiou, T.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamatopoulos, Gatos, Georgiou - 2010 - Page frame detection for double page document images.pdf:pdf},
journal = {DAS},
pages = {401--408},
publisher = {ACM Press},
title = {{Page frame detection for double page document images}},
year = {2010}
}
@article{Bay2008,
abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision. ?? 2007 Elsevier Inc. All rights reserved.},
author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and {Van Gool}, Luc},
xxurl = {10.1016/j.cviu.2007.09.014},
isbn = {9783540338321},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Camera calibration,Feature description,Interest points,Local features,Object recognition},
number = {3},
pages = {346--359},
pmid = {16081019},
title = {{Speeded-Up Robust Features (SURF)}},
volume = {110},
year = {2008}
}
@article{Falas2007,
abstract = {Data entry for mobile phones has always been limited by the phone's numeric keypad. One way to overcome this is through two-dimensional bar-codes read by the phone's camera. This paper presents two-dimensional bar-code reading using camera phones. Bar-code reading applications use the phone's camera to capture an image of a bar-code, and then use the phone's processor for decoding. They have been mostly developed in native code for a limited number of phone platforms. In contrast, development for Java-enabled phones allows bar-code reading regardless of the phone manufacturer and/or platform. It is argued that Java is a viable alternative if software is carefully crafted. A review of attempts in the use of mobile phones as bar-code readers, and a novel implementation of this technology, with very promising results, are presented},
author = {Falas, Tasos and Kashani, Hossein},
xxurl = {10.1109/PERCOMW.2007.119},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Falas, Kashani - 2007 - Two-dimensional bar-code decoding with camera-equipped mobile phones.pdf:pdf},
isbn = {0769527884},
journal = {Proceedings - Fifth Annual IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2007},
pages = {597--600},
title = {{Two-dimensional bar-code decoding with camera-equipped mobile phones}},
year = {2007}
}
@article{Impedovo2013,
author = {Impedovo, S. and Mangini, F.M. and Pirlo, G. and Barbuzzi, D. and Impedovo, D.},
xxurl = {10.1109/ICDAR.2013.94},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Impedovo et al. - 2013 - Voronoi Tessellation for Effective and Efficient Handwritten Digit Classification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {435--439},
publisher = {Ieee},
title = {{Voronoi Tessellation for Effective and Efficient Handwritten Digit Classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628659},
year = {2013}
}
@article{Yin2013,
author = {Yin, Fei and Zhou, Ming-Ke and Wang, Qiu-Feng and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.210},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin et al. - 2013 - Style Consistent Perturbation for Handwritten Chinese Character Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {distortions on the test,field classification,handwritten chinese character recognition,of the distortions,pattern with the expectation,performance by generating multiple,perturbation,style consistent,that at least one},
month = {aug},
pages = {1051--1055},
publisher = {Ieee},
title = {{Style Consistent Perturbation for Handwritten Chinese Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628775},
year = {2013}
}
@article{Shijian2008,
abstract = {This paper reports an identification technique that detects scripts and languages of noisy and degraded document images. In the proposed technique, scripts and languages are identified through the document vectorization, which converts each document image into a document vector that characterizes the shape and frequency of the conta ned character or word images. Document images are vectorized by using vertical component cuts and character extremum points, which are both tolerant to the variation in text fonts and styles, noise, and various types of document degradation. For each script or language under study, a script or language template is first constructed through a training process. Scripts and languages of document images are then determined according to the distances between converted document vectors and the pre-constructed script and language templates. Experimental results show that the proposed technique is accurate, easy for extension, and tolerant to noise and various types of document degradation.},
author = {Shijian, Lu and {Lim Tan}, Chew},
xxurl = {10.1109/TPAMI.2007.1158},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Computer Simulation,Documentation,Documentation: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Language,Models, Statistical,Natural Language Processing,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,User-Computer Interface},
language = {English},
month = {jan},
number = {1},
pages = {14--24},
pmid = {18000321},
publisher = {IEEE},
title = {{Script and language identification in noisy and degraded document images.}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4359308},
volume = {30},
year = {2008}
}
@article{Ramaiah2013,
author = {Ramaiah, Chetan and Shivram, Arti and Govindaraju, Venu},
xxurl = {10.1109/ICDAR.2013.187},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramaiah, Shivram, Govindaraju - 2013 - A Bayesian Framework for Modeling Accents in Handwriting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {917--921},
publisher = {Ieee},
title = {{A Bayesian Framework for Modeling Accents in Handwriting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628752},
year = {2013}
}
@article{Dec2004,
abstract = {Multiple realizations of continuous-valued time series from a stochastic process often contain systematic variations in rate and amplitude. To leverage the information contained in such noisy replicate sets, we need to align them in an appropriate way (for example, to allow the data to be properly combined by adaptive averaging). We present the Continuous Profile Model (CPM), a generative model in which each observed time series is a non-uniformly subsampled version of a single latent trace, to which local rescaling and additive noise are applied. After unsupervised training, the learned trace represents a canonical, high resolution fusion of all the replicates. As well, an alignment in time and scale of each observation to this trace can be found by inference in the model. We apply CPM to successfully align speech signals from multiple speakers and sets of Liquid Chromatography-Mass Spectrometry proteomic data.},
author = {Listgarten, Jennifer and Neal, Radford M and Roweis, Sam T and Emili, Andrew},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Listgarten et al. - 2005 - Multiple Alignment of Continuous Time Series.pdf:pdf},
isbn = {0262195348},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {17},
pages = {817--824},
title = {{Multiple Alignment of Continuous Time Series}},
volume = {17},
year = {2005}
}
@article{Parvez2013,
author = {Parvez, Mohammad Tanvir and Mahmoud, Sabri a.},
xxurl = {10.1109/ICDAR.2013.256},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parvez, Mahmoud - 2013 - Lexicon Reduction Using Segment Descriptors for Arabic Handwriting Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-segment descriptor,canonical descriptor,dot assignment,lexicon,reduction},
month = {aug},
pages = {1265--1269},
publisher = {Ieee},
title = {{Lexicon Reduction Using Segment Descriptors for Arabic Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628817},
year = {2013}
}
@article{Gao2013a,
author = {Gao, Song and Wang, Chunheng and Xiao, Baihua and Shi, Cunzhao and Zhang, Yang and Lv, Zhijian and Shi, Yanqin},
xxurl = {10.1109/ICDAR.2013.85},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao et al. - 2013 - Adaptive Scene Text Detection Based on Transferring Adaboost.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {388--392},
publisher = {Ieee},
title = {{Adaptive Scene Text Detection Based on Transferring Adaboost}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628650},
year = {2013}
}
@article{Belkin,
author = {Belkin, Mikhail and Niyogi, Partha and Que, Qichao and Sindwani, Vikas and Sun, Jian and Wang, Yusu and Zhou, Xueyuan},
title = {{Machine Learning and the Geometry of Data}},
url = {http://cs.au.dk/fileadmin/madalgo/PDF/14Aug{\_}Madalgo{\_}Manifolds.pdf}
}
@article{Ciocca2001,
abstract = {This paper addresses the problem of how to efficiently and effectively retrieve images similar to a query from a trademark database purely on the basis of low-level feature analysis. It investigates the hypothesis that the low-level image features used to index the trademark images can be correlated with image contents by applying a relevance feedback mechanism that evaluates the feature distributions of the images the user has judged relevant, or not relevant and dynamically updates, both the similarity measure and query in order to better represent the user's particular information needs. Experimental results on a database of 1100 trademarks are reported and commended ?? 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
author = {Ciocca, G. and Schettini, R.},
xxurl = {10.1016/S0031-3203(00)00055-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ciocca, Schettini - 2001 - Content-based similarity retrieval of trademarks using relevance feedback.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Content-based retrieval,Image similarity,Relevance feedback,Trademarks},
number = {8},
pages = {1639--1655},
title = {{Content-based similarity retrieval of trademarks using relevance feedback}},
volume = {34},
year = {2001}
}
@article{Rebelo2013b,
author = {Rebelo, Ana and Cardoso, Jaime S.},
xxurl = {10.1109/ICDAR.2013.20},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rebelo, Cardoso - 2013 - Staff Line Detection and Removal in the Grayscale Domain.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {57--61},
publisher = {Ieee},
title = {{Staff Line Detection and Removal in the Grayscale Domain}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628585},
year = {2013}
}
@article{Fischer2009a,
author = {Fischer, Andreas and Wuthrich, Markus and Liwicki, Marcus and Frinken, Volkmar and Bunke, Horst and Viehhauser, Gabriel and Stolz, Michael},
xxurl = {10.1109/VSMM.2009.26},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer et al. - 2009 - Automatic Transcription of Handwritten Medieval Documents.pdf:pdf},
isbn = {978-0-7695-3790-0},
journal = {2009 15th International Conference on Virtual Systems and Multimedia},
month = {sep},
pages = {137--142},
publisher = {Ieee},
title = {{Automatic Transcription of Handwritten Medieval Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5306020},
year = {2009}
}
@article{Tan2003,
abstract = {In this paper, we propose a method of text retrieval from document images using a similarity measure based on word shape analysis. We directly extract image features instead of using optical character recognition. Document images are segmented into word units and then features called vertical bar patterns are extracted from theseword units through local extrema points detection. All vertical bar patterns are used to build document vectors. Lastly,we obtain the pair-wise similarity of document images by means of the scalar product of the document vectors. Four corpora of news articles were used to test the validity of our method. During the test, the similarity of document images using this method was compared with the result of ASCII version of those documents based on the N-gram algorithm for text documents.},
author = {Tan, Chew L I M and Huang, Weihua and Sung, S A M Yuan and Yu, Zhaohui and Xu, Y I},
journal = {Applied Intelligence},
keywords = {document image analysis,document vector,similarity measure,text retrieval},
number = {3},
pages = {257--270},
title = {{Text Retrieval from Document Images Based on Word Shape Analysis}},
volume = {18},
year = {2003}
}
@article{Hassner2013,
author = {Hassner, Tal and Wolf, Lior and Dershowitz, Nachum},
xxurl = {10.1109/ICDAR.2013.265},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassner, Wolf, Dershowitz - 2013 - OCR-Free Transcript Alignment.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1310--1314},
publisher = {Ieee},
title = {{OCR-Free Transcript Alignment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628826},
year = {2013}
}
@article{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Viola, P. and Jones, M.},
xxurl = {10.1109/CVPR.2001.990517},
eprint = {arXiv:1011.1669v3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viola, Jones - 2001 - Rapid object detection using a boosted cascade of simple features.pdf:pdf},
isbn = {0-7695-1272-0},
issn = {1063-6919},
journal = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
pages = {I--511--I--518},
pmid = {7143246},
title = {{Rapid object detection using a boosted cascade of simple features}},
url = {http://ieeexplore.ieee.org/document/990517/},
volume = {1},
year = {2001}
}
@article{Pal2012,
author = {Pal, Umapada and Jayadevan, Ramachandran and Sharma, Nabin},
issn = {15300226},
journal = {ACM Transactions on Asian Language Information Processing},
month = {mar},
number = {1},
pages = {1--35},
publisher = {ACM},
title = {{Handwriting Recognition in Indian Regional Scripts}},
volume = {11},
year = {2012}
}
@article{Du2013a,
author = {Du, Xianzhi and Abdalmageed, Wael and Doermann, David},
xxurl = {10.1109/ICDAR.2013.197},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Abdalmageed, Doermann - 2013 - Large-Scale Signature Matching Using Multi-stage Hashing.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {image retrieval,locality,sensitive hashing,signature matching,tobacco litigation},
month = {aug},
pages = {976--980},
publisher = {Ieee},
title = {{Large-Scale Signature Matching Using Multi-stage Hashing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628762},
year = {2013}
}
@article{Moalla2013a,
author = {Moalla, Ikram and Lebourgeois, Frank and Alimi, Adel},
xxurl = {10.1109/ICDAR.2013.116},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moalla, Lebourgeois, Alimi - 2013 - Generalized Eigen Cooccurrence Application to Palaeography.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {2nd order statistics,concept of eigen coo-occurrence,cooccurrence,generalized eigen cooccurrence,handwriting characterisation,matrices is presented in,palaeography,section 3,the results of the},
month = {aug},
pages = {555--559},
publisher = {Ieee},
title = {{Generalized Eigen Cooccurrence: Application to Palaeography}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628681},
year = {2013}
}
@article{Zarai2013,
author = {Zarai, Yoram and Lavee, Tamar and Dershowitz, Nachum and Wolf, Lior},
xxurl = {10.1109/ICDAR.2013.18},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zarai et al. - 2013 - Integrating Copies Obtained from Old and New Preservation Efforts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {47--51},
publisher = {Ieee},
title = {{Integrating Copies Obtained from Old and New Preservation Efforts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628583},
year = {2013}
}
@article{Pratikakis2012,
abstract = {— H-DIBCO 2012 is the International Document Image Binarization Competition which is dedicated to handwritten document images organized in conjunction with ICFHR 2012 conference. The objective of the contest is to identify current advances in handwritten document image binarization using meaningful evaluation performance measures. This paper reports on the contest details including the evaluation measures used as well as the performance of the 24 submitted methods along with a short description of each method.},
author = {Pratikakis, Ioannis and Gatos, Basilis and Ntirogiannis, Konstantinos},
xxurl = {10.1109/ICFHR.2012.216},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratikakis, Gatos, Ntirogiannis - 2012 - ICFHR 2012 competition on handwritten document image binarization (H-DIBCO 2012).pdf:pdf},
isbn = {9780769547749},
issn = {15505235},
journal = {Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR},
keywords = {Binarization,Handwritten document image,Performance evaluation},
pages = {817--822},
title = {{ICFHR 2012 competition on handwritten document image binarization (H-DIBCO 2012)}},
year = {2012}
}
@article{Tieu1999,
author = {Tieu, K.H. and Viola, Paul},
xxurl = {10.1109/CVPR.2000.855824},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tieu, Viola - 1999 - Boosting Image Database Retrieval.pdf:pdf},
isbn = {0-7695-0662-3},
journal = {Aim-1669},
keywords = {feature selection,image database,relevance feedback,sparse representation},
number = {1669},
pages = {17--36},
title = {{Boosting Image Database Retrieval}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?xxurl=10.1.1.85.3601{\&}rep=rep1{\&}type=pdf},
volume = {56},
year = {1999}
}
@article{Kesidis2010,
author = {Kesidis, a. L. and Galiotou, E. and Gatos, B. and Pratikakis, I.},
xxurl = {10.1007/s10032-010-0134-4},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kesidis et al. - 2010 - A word spotting framework for historical machine-printed documents.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
keywords = {computational morphology,historical document indexing,natural language processing,word spotting},
month = {nov},
number = {2},
pages = {131--144},
title = {{A word spotting framework for historical machine-printed documents}},
url = {http://link.springer.com/10.1007/s10032-010-0134-4},
volume = {14},
year = {2010}
}
@article{Rusinol2010,
author = {Rusi{\~{n}}ol, Mar{\c{c}}al and Llad{\'{o}}s, Josep},
xxurl = {10.1145/1815330.1815358},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusi{\~{n}}ol, Llad{\'{o}}s - 2010 - Efficient logo retrieval through hashing shape context descriptors.pdf:pdf},
isbn = {9781605587738},
journal = {Proceedings of the 8th IAPR International Workshop on Document Analysis Systems - DAS '10},
keywords = {imp-logo-paper},
mendeley-tags = {imp-logo-paper},
pages = {215--222},
title = {{Efficient logo retrieval through hashing shape context descriptors}},
url = {http://portal.acm.org/citation.cfm?xxurld=1815330.1815358},
year = {2010}
}
@article{Liang2005a,
abstract = { Compared to scanned images, document pictures captured by camera can suffer from distortions due to perspective and page warping. It is necessary to restore a frontal planar view of the page before other OCR techniques can be applied. In this paper we describe a novel approach for flattening a curved document in a single picture captured by an uncalibrated camera. To our knowledge this is the first reported method able to process general curved documents in images without camera calibration. We propose to model the page surface by a developable surface, and exploit the properties (parallelism and equal line spacing) of the printed textual content on the page to recover the surface shape. Experiments show that the output images are much more OCR friendly than the original ones. While our method is designed to work with any general developable surfaces, it can be adapted for typical special cases including planar pages, scans of thick books, and opened books.},
author = {Liang, Jian and DeMenthon, Daniel and Doermann, David},
xxurl = {10.1109/CVPR.2005.163},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, DeMenthon, Doermann - 2005 - Flattening curved documents in images(2).pdf:pdf},
isbn = {0769523722},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {338--345},
title = {{Flattening curved documents in images}},
volume = {2},
year = {2005}
}
@article{Bukhari2013,
author = {Bukhari, Syed Saqib and Shafait, Faisal and Breuel, Thomas M.},
xxurl = {10.1109/ICDAR.2013.153},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bukhari, Shafait, Breuel - 2013 - Towards Generic Text-Line Extraction.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {collection,generci text line extrac-,generic layout analysis,of diverse documents,performance evaluation and benchmarking,ridge-based text-line extraction method,tion method},
month = {aug},
number = {c},
pages = {748--752},
publisher = {Ieee},
title = {{Towards Generic Text-Line Extraction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628718},
volume = {1},
year = {2013}
}
@article{Halcon,
author = {Halcon},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Halcon - Unknown - Solution Guide II-C 2D Data Codes.pdf:pdf},
title = {{Solution Guide II-C 2D Data Codes}}
}
@inproceedings{Sinha02,
author = {Sinha, Saurabh},
booktitle = {Proceedings of the Sixth Annual International Conference on Computational Biology, {\{}RECOMB{\}} 2002, Washington, DC, USA, April 18-21, 2002},
pages = {291--298},
title = {{Discriminative motifs}},
year = {2002}
}
@article{Su2013e,
author = {Su, Tonghua and Ma, Peijun and Wei, Tong and Liu, Shu and Deng, Shengchun},
xxurl = {10.1109/ICDAR.2013.258},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su et al. - 2013 - Exploring MPEMWE Training for Chinese Handwriting Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1275--1279},
publisher = {Ieee},
title = {{Exploring MPE/MWE Training for Chinese Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628819},
year = {2013}
}
@article{Oord2016a,
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
archivePrefix = {arXiv},
arxivId = {1606.05328},
author = {van den Oord, Aaron and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
eprint = {1606.05328},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oord et al. - 2016 - Conditional Image Generation with PixelCNN Decoders.pdf:pdf},
isbn = {9781510829008},
issn = {10495258},
title = {{Conditional Image Generation with PixelCNN Decoders}},
url = {http://arxiv.org/abs/1606.05328},
year = {2016}
}
@article{otsu1979,
author = {Nobuyuki, Otsu},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
keywords = {Displays,Gaussian distribution,Histograms,Least squares approximation,Marine vehicles,Q measurement,Radar tracking,Sea measurements,Surveillance,Target tracking},
number = {1},
pages = {62--66},
shorttitle = {Systems, Man and Cybernetics, IEEE Transactions on},
title = {{A Threshold Selection Method from Gray-Level Histograms}},
volume = {9},
year = {1979}
}
@article{Nakayama,
author = {Nakayama, Takehiro},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nakayama - 1994 - Modeling Content Identification from Document Images.pdf:pdf},
journal = {Proceedings Fourth Conference Applied Natural Language Processing (ANLP ',94)},
pages = {22--27},
title = {{Modeling Content Identification from Document Images}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.14.7214},
year = {1994}
}
@article{Rusinol2008,
author = {Rusi{\~{n}}ol, Mar{\c{c}}al and Llad{\'{o}}s, Josep},
xxurl = {10.1109/DAS.2008.24},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusi{\~{n}}ol, Llad{\'{o}}s - 2008 - Word and Symbol Spotting Using Spatial Organization of Local Descriptors.pdf:pdf},
isbn = {978-0-7695-3337-7},
journal = {2008 The Eighth IAPR International Workshop on Document Analysis Systems},
month = {sep},
pages = {489--496},
publisher = {Ieee},
title = {{Word and Symbol Spotting Using Spatial Organization of Local Descriptors}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4669998},
year = {2008}
}
@article{Moghaddam2009,
annote = {From Duplicate 1 ( 

















































































































Application of Multi-Level Classifiers and Clustering for Automatic Word Spotting in Historical Document Images

















































































































- Moghaddam, Reza Farrahi; Cheriet, Mohamed )































},
author = {Moghaddam, Reza Farrahi and Cheriet, Mohamed},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moghaddam, Cheriet - 2009 - Application of Multi-Level Classifiers and Clustering for Automatic Word Spotting in Historical Document (2).pdf:pdf},
journal = {ICDAR},
pages = {511--515},
publisher = {Ieee},
title = {{Application of Multi-Level Classifiers andClustering for Automatic Word Spotting in Historical Document Images}},
year = {2009}
}
@article{Reed2016,
abstract = {Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories, such as faces, album covers, and room interiors. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image model- ing, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.},
archivePrefix = {arXiv},
arxivId = {1605.05396},
author = {Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
eprint = {1605.05396},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reed et al. - 2016 - Generative Adversarial Text to Image Synthesis.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reed et al. - 2016 - Generative Adversarial Text to Image Synthesis(2).pdf:pdf},
isbn = {9781510829008},
title = {{Generative Adversarial Text to Image Synthesis}},
url = {http://arxiv.org/abs/1605.05396},
year = {2016}
}
@article{Yeh2016b,
author = {Yeh, CCM and Zhu, Y and Ulanova, L and Begum, N},
xxurl = {10.1109/ICDM.2016.0179},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh et al. - 2016 - Matrix Profile I All Pairs Similarity Joins for Time Series A Unifying View that Includes Motifs, Discords and Shape.pdf:pdf},
isbn = {978-1-5090-5473-2},
issn = {15504786},
journal = {Ieee},
title = {{Matrix Profile I: All Pairs Similarity Joins for Time Series: A Unifying View that Includes Motifs, Discords and Shapelets}},
url = {https://pdfs.semanticscholar.org/6152/3cfe6f51859e00aa8ce320114c03151208fa.pdf},
year = {2016}
}
@misc{AnuragBhardwaj2008,
author = {{Anurag Bhardwaj, Damien Jose}, Venu Govindaraju},
booktitle = {Second International Workshop Cross Lingual Information Access},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anurag Bhardwaj, Damien Jose - 2008 - Script Independent Word Spotting in Multilingual Documents.pdf:pdf},
pages = {48--54},
title = {{Script Independent Word Spotting in Multilingual Documents}},
url = {http://clair.eecs.umich.edu/aan/paper.php?paper{\_}id=I08-6007},
urldate = {2014-04-16},
year = {2008}
}
@article{Cecotti2013a,
author = {Cecotti, Hubert and Vajda, Szilard},
xxurl = {10.1109/ICDAR.2013.137},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cecotti, Vajda - 2013 - A Radial Neural Convolutional Layer for Multi-oriented Character Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {668--672},
publisher = {Ieee},
title = {{A Radial Neural Convolutional Layer for Multi-oriented Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628702},
year = {2013}
}
@article{Kleban2008,
author = {Kleban, Jim},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kleban - 2008 - Spatial Pyramid Mining for Logo Detection in Natural Scenes.pdf:pdf},
isbn = {9781424425716},
pages = {1077--1080},
title = {{Spatial Pyramid Mining for Logo Detection in Natural Scenes}},
year = {2008}
}
@inproceedings{Le2013c,
abstract = {Digital document categorization based on logo spotting and recognition has raised a great interest in the research community because logos in documents are sources of information for categorizing documents with low costs. In this paper, we present an approach to improve the result of our method for logo spotting and recognition based on key point matching and presented in our previous paper [7]. First, the key points from both the query document images and a given set of logos (logo gallery) are extracted and described by SIFT, and are matched in the SIFT feature space. Secondly, logo segmentation is performed using spatial density-based clustering. The contribution of this paper is to add a third step where homography is used to filter the matched key points as a post-processing. And finally, in the decision stage, logo classification is performed by using an accumulating histogram. Our approach is tested using a well-known benchmark database of real world documents containing logos, and achieves good performances compared to state-of-the-art approaches.},
author = {Le, Viet Phuong and Visani, Muriel and Tran, Cao De and Ogier, Jean Marc},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
xxurl = {10.1109/ICDAR.2013.61},
isbn = {978-0-7695-4999-6},
issn = {15205363},
keywords = {document analysis,homography,logo spotting,pattern recognition},
pages = {270--274},
title = {{Improving logo spotting and matching for document categorization by a post-filter based on homography}},
year = {2013}
}
@article{Gori2003,
abstract = {In this paper, we propose a new approach to improve the performance of multilayer perceptrons operating as autoassociators to classify graphical items in presence of spot noise on the image. The improvement is obtained by introducing a weighed norm instead of using the Euclidean norm to measure the input-output accuracy of the neural network. The weights used in the computation depend on the gradient of the image so as to give less importance to uniform colour regions, like the spots. A modified learning algorithm (edge-backpropagation) is derived from the classical backpropagation by considering the new weighed error function. We report a set of experimental results on a database of 134 company logos corrupted by artificial noise which show the effectiveness of the proposed approach. ?? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
author = {Gori, M. and Maggini, M. and Marinai, S. and Sheng, J. Q. and Soda, G.},
xxurl = {10.1016/S0031-3203(02)00062-6},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gori et al. - 2003 - Edge-backpropagation for noisy logo recognition.pdf:pdf},
isbn = {0577233602},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Autoassociator neural networks,Edge-backpropagation,Learning from examples,Logo recognition,Spot noise},
number = {1},
pages = {103--110},
title = {{Edge-backpropagation for noisy logo recognition}},
volume = {36},
year = {2003}
}
@article{Chowdhury2013,
author = {Chowdhury, S. Dutta and Bhattacharya, U. and Parui, S.K.},
xxurl = {10.1109/ICDAR.2013.24},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chowdhury, Bhattacharya, Parui - 2013 - Online Handwriting Recognition Using Levenshtein Distance Metric.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {1},
pages = {79--83},
publisher = {Ieee},
title = {{Online Handwriting Recognition Using Levenshtein Distance Metric}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628589},
year = {2013}
}
@article{Makhzani2015,
abstract = {In this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.},
archivePrefix = {arXiv},
arxivId = {1511.05644},
author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
eprint = {1511.05644},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makhzani et al. - 2015 - Adversarial Autoencoders.pdf:pdf},
isbn = {9781509008063},
title = {{Adversarial Autoencoders}},
url = {http://arxiv.org/abs/1511.05644},
year = {2015}
}
@article{Gatos2006,
author = {Gatos, B. and Pratikakis, I. and Perantonis, S.J.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos, Pratikakis, Perantonis - 2006 - Adaptive degraded document image binarization.pdf:pdf},
journal = {Pattern Recognition},
keywords = {degraded document images,local adaptive binarization},
month = {mar},
number = {3},
pages = {317--327},
title = {{Adaptive degraded document image binarization}},
volume = {39},
year = {2006}
}
@article{Henniger2007a,
annote = {From Duplicate 1 ( 

Effects of Time Normalization on the Accuracy of Dynamic Time Warping

- Henniger, Olaf; Muller, Sascha )

},
author = {Henniger, Olaf and Muller, Sascha},
xxurl = {10.1109/BTAS.2007.4401946},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henniger, Muller - 2007 - Effects of Time Normalization on the Accuracy of Dynamic Time Warping.pdf:pdf},
isbn = {978-1-4244-1596-0},
journal = {2007 First IEEE International Conference on Biometrics: Theory, Applications, and Systems},
month = {sep},
pages = {1--6},
publisher = {Ieee},
title = {{Effects of Time Normalization on the Accuracy of Dynamic Time Warping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4401946},
year = {2007}
}
@article{Munich1999,
annote = {From Duplicate 2 ( 

Continuous dynamic time warping for translation-invariant curve alignment with applications to signature verification

- Munich, ME; Perona, Pietro )

},
author = {Munich, ME and Perona, Pietro},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munich, Perona - 1999 - Continuous dynamic time warping for translation-invariant curve alignment with applications to signature verific.pdf:pdf},
journal = {ICCV},
pages = {108--115},
title = {{Continuous dynamic time warping for translation-invariant curve alignment with applications to signature verification}},
volume = {1},
year = {1999}
}
@misc{scimppp,
title = {{No Title}},
url = {https://sites.google.com/site/scrimpplusplus}
}
@article{Chu,
abstract = {Time series are a ubiquitous form of data occurring in virtually every scientific discipline and business application. There has been much recent work on adapting data mining algorithms to time series databases. For example, Das et al. attempt to show how association rules can be learned from time series 7. Debregeas and Hebrail 8 demonstrate a technique for scaling up time series clustering algorithms to massive datasets. Keogh and Pazzani introduced a new, scalable time series classification algorithm 16. Almost all algorithms that operate on time series data need to compute the similarity between them. Euclidean distance, or some extension or modification thereof, is typically used. However as we will demonstrate in Section 2.1, Euclidean distance can be an extremely brittle distance measure.},
author = {Chu, Selina and Keogh, Eamonn and Hart, David},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chu, Keogh, Hart - 2002 - Iterative Deepening Dynamic Time Warping for Time Series.pdf:pdf},
isbn = {978-0-89871-517-0},
journal = {Time},
pages = {195--212},
title = {{Iterative Deepening Dynamic Time Warping for Time Series}},
year = {2002}
}
@article{Achanta2012,
abstract = {Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.},
author = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and S{\"{u}}sstrunk, Sabine},
xxurl = {10.1109/TPAMI.2012.120},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Superpixels,clustering,k-means,segmentation},
number = {11},
pages = {2274--2281},
pmid = {22641706},
title = {{SLIC superpixels compared to state-of-the-art superpixel methods}},
volume = {34},
year = {2012}
}
@article{Mueen2011,
abstract = {Time series shapelets are small, local patterns in a time series that are highly predictive of a class and are thus very useful features for building classifiers and for certain visualization and summarization tasks. While shapelets were introduced only recently, they have already seen significant adoption and extension in the community. Despite their immense potential as a data mining primitive, there are two important limitations of shapelets. First, their expressiveness is limited to simple binary presence/absence questions. Second, even though shapelets are computed offline, the time taken to compute them is significant. In this work, we address the latter problem by introducing a novel algorithm that finds shapelets in less time than current methods by an order of magnitude. Our algorithm is based on intelligent caching and reuse of computations, and the admissible pruning of the search space. Because our algorithm is so fast, it creates an opportunity to consider more expressive shapelet queries. In particular, we show for the first time an augmented shapelet representation that distinguishes the data based on conjunctions or disjunctions of shapelets. We call our novel representation Logical-Shapelets. We demonstrate the efficiency of our approach on the classic benchmark datasets used for these problems, and show several case studies where logical shapelets significantly outperform the original shapelet representation and other time series classification techniques. We demonstrate the utility of our ideas in domains as diverse as gesture recognition, robotics, and biometrics. Copyright 2011 ACM.},
author = {Mueen, Abdullah and Keogh, Eamonn and Young, Neal},
xxurl = {10.1145/2020408.2020587},
file = {:home/mondal/Downloads/Logical-Shapelet.pdf:pdf},
isbn = {9781450308137},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Classification,Information gain,Logic expression,Time series},
pages = {1154--1162},
title = {{Logical-shapelets: An expressive primitive for time series classification}},
year = {2011}
}
@article{Celik2016,
author = {Celik, Enes and Atalay, Muhammet and Kondiloglu, Adil},
file = {:home/mondal/Documents/climate/pdf/THE{\_}EARTHQUAKE{\_}MAGNITUDE{\_}PREDICTION{\_}USED.pdf:pdf},
isbn = {9786059207638},
number = {December},
title = {{the Earthquake Magnitude Prediction Used Seismic Time Series and Machine the Earthquake Magnitude Prediction Used Seismic Time Series and Machine Learning}},
year = {2016}
}
@article{Wang2006,
abstract = {This paper describes an algorithm for the determination of zone content type of a given zone within a document image. We take a statistical based approach and represent each zone with 25 dimensional feature vectors. An optimized decision tree classifier is used to classify each zone into one of nine zone content classes. A performance evaluation protocol is proposed. The training and testing data sets include a total of 24,177 zones from the University of Washington English Document Image database III. The algorithm accuracy is 98.45{\%} with a mean false alarm rate of 0.50{\%}. {\textcopyright} 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Wang, Yalin and Phillips, Ihsin T. and Haralick, Robert M.},
xxurl = {10.1016/j.patcog.2005.06.009},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Phillips, Haralick - 2006 - Document zone content classification and its performance evaluation.pdf:pdf},
isbn = {0-7695-1263-1},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Background analysis,Decision tree classifier,Document image analysis,Document layout analysis,Pattern recognition,Viterbi algorithm,Zone content classification},
number = {1},
pages = {57--73},
title = {{Document zone content classification and its performance evaluation}},
volume = {39},
year = {2006}
}
@article{Liu2012a,
author = {Liu, Wei and Wang, Jun and Ji, Rongrong and Chang, Yu-gang Jiang Shih-fu},
xxurl = {10.1109/CVPR.2012.6247912},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2012 - Supervised hashing with kernels.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = {jun},
pages = {2074--2081},
publisher = {Ieee},
title = {{Supervised hashing with kernels}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247912},
year = {2012}
}
@inproceedings{Kim2012,
abstract = {There is a wide range of applications that require finding the top-k most similar pairs of records in a given database. However, computing such top-k similarity joins is a challenging problem today, as there is an increasing trend of applications that expect to deal with vast amounts of data. For such data-intensive applications, parallel executions of programs on a large cluster of commodity machines using the MapReduce paradigm have recently received a lot of attention. In this paper, we investigate how the top-k similarity join algorithms can get benefits from the popular MapReduce framework. We first develop the divide-and-conquer and branch-and-bound algorithms. We next propose the all pair partitioning and essential pair partitioning methods to minimize the amount of data transfers between map and reduce functions. We finally perform the experiments with not only synthetic but also real-life data sets. Our performance study confirms the effectiveness and scalability of our MapReduce algorithms. {\textcopyright} 2012 IEEE.},
author = {Kim, Younghoon and Shim, Kyuseok},
booktitle = {Proceedings - International Conference on Data Engineering},
xxurl = {10.1109/ICDE.2012.87},
issn = {10844627},
title = {{Parallel top-K similarity join algorithms using MapReduce}},
year = {2012}
}
@article{Kumar2014,
author = {Kumar, Gaurav and Govindaraju, Venu},
xxurl = {10.1109/ICFHR.2014.66},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Govindaraju - 2014 - A Bayesian Approach to Script Independent Multilingual Keyword Spotting.pdf:pdf},
isbn = {978-1-4799-4334-0},
journal = {2014 14th International Conference on Frontiers in Handwriting Recognition},
keywords = {-keyword spotting,Spotting, Handwritten Multilingual Documents, Scri,a,arabic ama dataset,b,bayesian active learning,english iam dataset,handwritten multilingual doc-,script independent,uments},
pages = {357--362},
title = {{A Bayesian Approach to Script Independent Multilingual Keyword Spotting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6981045},
year = {2014}
}
@article{Turner2014,
author = {Turner, Richard E},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Turner - 2014 - Lecture 14 Convolutional neural networks for computer vision.pdf:pdf},
title = {{Lecture 14 : Convolutional neural networks for computer vision}},
year = {2014}
}
@article{Antonacopoulos2013,
author = {Antonacopoulos, a. and Clausner, C. and Papadopoulos, C. and Pletschacher, S.},
xxurl = {10.1109/ICDAR.2013.294},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antonacopoulos et al. - 2013 - ICDAR 2013 Competition on Historical Book Recognition (HBR 2013).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- performance evaluation,datasets,historical documents,layout analysis,ocr,page segmentation,recognition,region classification},
month = {aug},
pages = {1459--1463},
publisher = {Ieee},
title = {{ICDAR 2013 Competition on Historical Book Recognition (HBR 2013)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628855},
year = {2013}
}
@article{Zhang2015,
abstract = {Text in a scene provides vital information of its contents. With the increasing popularity of vision systems, detecting general text in images becomes a critical yet challenging task. Most existing methods have focused on extracting neatly arranged text string for compactly constructed characters. Motivated by the need to consider the widely varying forms of scene text, we propose a stroke-based text detection method which detects arbitrary orientations text strings with loosely constructed characters in images. Our approach employs result of stroke width transform (SWT) as basic stroke candidates. These candidates are then merged using adaptive structuring elements to generate compactly constructed characters. Individual characters are chained using k-nearest neighbors algorithm to identify arbitrary orientations text strings, which are subsequently separated into words if necessary. To better evaluate our system and compare it with other competing algorithms, we generate a new dataset, which includes various characters and text strings in diverse scenes. Experiments on ICDAR datasets and the proposed dataset demonstrate that our approach compares favorably with the state-of-the-art algorithms when handling arbitrary orientations text strings and achieves significantly enhanced performance on loosely constructed characters in scenes.},
author = {Zhang, Yong and Lai, Jianhuang and Yuen, Pong C.},
xxurl = {10.1016/j.neucom.2015.05.028},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Lai, Yuen - 2015 - Text string detection for loosely constructed characters with arbitrary orientations.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Complex character,K-Nearest neighbors,Stroke width transform,Text detection,Text string},
pages = {970--978},
publisher = {Elsevier},
title = {{Text string detection for loosely constructed characters with arbitrary orientations}},
url = {http://dx.xxurl.org/10.1016/j.neucom.2015.05.028},
volume = {168},
year = {2015}
}
@article{Mikolajczyk2004,
abstract = {interest points invariant scale affine scale affine invariant detectors Interest points detector ...},
author = {Mikolajczyk, Krystian and Mikolajczyk, K and Schmid, C and Schmid, Cordelia},
xxurl = {10.1023/B:VISI.0000027790.02288.f2},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolajczyk et al. - 2004 - Scale {\&}amp affine invariant interest point detectors.pdf:pdf},
isbn = {0920-5691},
issn = {09205691},
journal = {Ijcv},
keywords = {hybrid,kernel,mean shift,particle filter,tracking},
number = {1},
pages = {1--6},
pmid = {1313188},
title = {{Scale {\&} affine invariant interest point detectors}},
url = {http://www.springerlink.com/index/H37T7833M7037173.pdf},
volume = {60},
year = {2004}
}
@article{Su2013a,
author = {Su, Bing and Ding, Xiaoqing and Peng, Liangrui and Liu, Changsong},
xxurl = {10.1109/ICDAR.2013.58},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su et al. - 2013 - Cross-Language Sensitive Words Distribution Map A Novel Recognition-Based Document Understanding Method for Uighur an.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {character recognition,cross-language sensitive words distribution,document understanding,ethnic language,map},
month = {aug},
pages = {255--259},
publisher = {Ieee},
title = {{Cross-Language Sensitive Words Distribution Map: A Novel Recognition-Based Document Understanding Method for Uighur and Tibetan}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628623},
year = {2013}
}
@article{Doermann1996,
abstract = {The problem of logo recognition is of great interest in the document$\backslash$ndomain, especially for document databases. By recognizing the logo$\backslash$nwe obtain semantic information about the document which may be useful$\backslash$nin deciding whether or not to analyze the textual components. Given$\backslash$na logo block candidate from a document image and a logo database,$\backslash$nwe would like to determine whether the region corresponds to a logo$\backslash$nin the database. Similarly, if we are given a logo block candidate$\backslash$nand a document database, we wish to determine whether there are any$\backslash$ndocuments in the database of similar origin. Both problems require$\backslash$nindexing into a possibly large model space. In this contribution,$\backslash$nwe present a novel application of algebraic and differential invariants$\backslash$nto the problem of logo recognition. By using invariants we have shape$\backslash$ndescriptors for matching that are unique and independent of the point$\backslash$nof view. The algebraic invariants handle cases in which the whole$\backslash$nshape of the logo is given and it is easy to describe. The differential$\backslash$ninvariants cover complex arbitrary logo shape and handle situations$\backslash$nin which only part of the logo is recovered. We outline a hierarchical$\backslash$napproach to logo recognition and define methods for page segmentation,$\backslash$nfeature extraction, and indexing. We demonstrate our approach and$\backslash$npresent results on a database of approximately 100 logos},
author = {Doermann and D. and Rivlin, E. and Et al},
xxurl = {10.1007/s001380050030},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doermann et al. - 1996 - Applying algebraic and differential invariants for logo recognition.pdf:pdf},
issn = {0932-8092},
journal = {Machine Vision and Applications},
keywords = {cbir,color histogram,direction histogram,edge,edge histogram,performance evaluation},
number = {2},
pages = {73--86},
title = {{Applying algebraic and differential invariants for logo recognition}},
volume = {9},
year = {1996}
}
@article{Nishii2010,
author = {Nishii, Takuma and Hiroyasu, Tomoyuki and Yoshimi, Masato and Miki, Mitsunori and Yokouchi, Hisatake},
xxurl = {10.1109/ICSMC.2010.5641809},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nishii et al. - 2010 - Similar subsequence retrieval from two time series data using homology search.pdf:pdf},
isbn = {978-1-4244-6586-6},
journal = {2010 IEEE International Conference on Systems, Man and Cybernetics},
month = {oct},
pages = {1062--1067},
publisher = {Ieee},
title = {{Similar subsequence retrieval from two time series data using homology search}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5641809},
year = {2010}
}
@inproceedings{L.Benedikt,
author = {Benedikt, L. and Kajic, V. and Cosker, D. and Rosin, P. L. and Marshall, D.},
booktitle = {Proceedings of the British Machine Vision Conference},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Benedikt et al. - 2008 - Facial Dynamics in Biometric Identification.pdf:pdf},
title = {{Facial Dynamics in Biometric Identification}},
year = {2008}
}
@article{Keogh2007,
abstract = {In this work we introduce the new problem of finding time series discords. Time series discords are subsequences of longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. While discords have many uses for data mining, they are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. While the brute force algorithm to discover time series discords is quadratic in the length of the time series, we show a simple algorithm that is three to four orders of magnitude faster than brute force, while guaranteed to produce identical results. We evaluate our work with a comprehensive set of experiments on diverse data sources including electrocardiograms, space telemetry, respiration physiology, anthropological and video datasets. {\textcopyright} Springer-Verlag London Limited 2006.},
author = {Keogh, Eamonn and Lin, Jessica and Lee, Sang Hee and {Van Herle}, Helga},
xxurl = {10.1007/s10115-006-0034-6},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keogh et al. - 2007 - Finding the most unusual time series subsequence Algorithms and applications.pdf:pdf},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Anomaly detection,Clustering,Time series data mining},
number = {1},
pages = {1--27},
title = {{Finding the most unusual time series subsequence: Algorithms and applications}},
volume = {11},
year = {2007}
}
@article{Morillot2013,
author = {Morillot, Olivier and Likforman-Sulem, Laurence and Grosicki, Emmanuele},
xxurl = {10.1109/ICDAR.2013.160},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morillot, Likforman-Sulem, Grosicki - 2013 - Comparative Study of HMM and BLSTM Segmentation-Free Approaches for the Recognition of Hand.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {783--787},
publisher = {Ieee},
title = {{Comparative Study of HMM and BLSTM Segmentation-Free Approaches for the Recognition of Handwritten Text-Lines}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628725},
year = {2013}
}
@article{Dutta2012,
author = {Dutta, Shrey and Sankaran, Naveen and Sankar, K Pramod and Jawahar, C V},
xxurl = {10.1109/DAS.2012.76},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dutta et al. - 2012 - Robust Recognition of Degraded Documents Using Character N-Grams.pdf:pdf},
isbn = {978-0-7695-4661-2},
journal = {2012 10th IAPR International Workshop on Document Analysis Systems},
keywords = {-ocr,character n-grams,degraded documents,despite degradations,examples of words where,figure 1,n-gram based recognition scheme,our algorithm correctly recognizes,popular ocrs have failed,that addresses,to recognize these images,we propose a novel},
month = {mar},
pages = {130--134},
publisher = {Ieee},
title = {{Robust Recognition of Degraded Documents Using Character N-Grams}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6195349},
year = {2012}
}
@article{Razafindramanana2013,
author = {Razafindramanana, Octavio and Rayar, Freseric and Venturini, Gilles},
xxurl = {10.1109/ICDAR.2013.95},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Razafindramanana, Rayar, Venturini - 2013 - Alpha-Approximated Delaunay Triangulation Based Descriptors for Handwritten Character Recogn.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {440--444},
publisher = {Ieee},
title = {{Alpha*-Approximated Delaunay Triangulation Based Descriptors for Handwritten Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628660},
year = {2013}
}
@article{Oliveira2009,
author = {Oliveira, Dm and Lins, Rd},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliveira, Lins - 2009 - A new method for shading removal and binarization of documents acquired with portable digital cameras.pdf:pdf},
journal = {Proceedings of International Workshop on Camera-Based Document Analysis and Recognition},
pages = {3--10},
title = {{A new method for shading removal and binarization of documents acquired with portable digital cameras}},
url = {http://wwwmath.tau.ac.il/{~}turkel/imagepapers/binarization.pdf},
year = {2009}
}
@article{Nayef2013,
author = {Nayef, Nibal and Breuel, Thomas M.},
xxurl = {10.1109/ICDAR.2013.158},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nayef, Breuel - 2013 - Constructing a Hierarchical Structure from Symbol Alphabets of Technical Line Drawings.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {773--777},
publisher = {Ieee},
title = {{Constructing a Hierarchical Structure from Symbol Alphabets of Technical Line Drawings}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628723},
year = {2013}
}
@article{Das1998,
abstract = {good summary about feature selection from time series (sliding window), notion of time-series similarity, and clustering methods. rule discovery from discretized sequences (cluster sets represented by some alphabets). a little of experimental results},
author = {Das, Gautam and Lin, King-ip and Mannila, H},
journal = {In Proceedings of Fourth Int'l Conf. Knowledge Discovery and Data Mining},
keywords = {cations and in science,clustering,discretiza-,frequently in business appli-,rules,time series,time series data occurs,tion,vector quantization,well-known examples include},
title = {{Rule Discovery from Time Series}},
year = {1998}
}
@article{ShijianLu,
author = {{Shijian Lu, Chew Lim Tan}, Weihua Huang},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shijian Lu, Chew Lim Tan - 2006 - Script and language identification in degraded and distorted document images.pdf:pdf},
journal = {National Conference on Artificial Intelligence},
pages = {769--774},
title = {{Script and language identification in degraded and distorted document images}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.89.9337},
year = {2006}
}
@article{Bouguelia2013,
author = {Bouguelia, Mohamed-Rafik and Belaid, Yolande and Belaid, Abdel},
xxurl = {10.1109/ICDAR.2013.126},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouguelia, Belaid, Belaid - 2013 - A Stream-Based Semi-supervised Active Learning Approach for Document Classification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {611--615},
publisher = {Ieee},
title = {{A Stream-Based Semi-supervised Active Learning Approach for Document Classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628691},
year = {2013}
}
@article{Arora2016,
abstract = {In this paper we investigate the family of functions representable by deep neural networks (DNN) with rectified linear units (ReLU). We give the first-ever polynomial time (in the size of data) algorithm to train to global optimality a ReLU DNN with one hidden layer, assuming the input dimension and number of nodes of the network as fixed constants. We also improve on the known lower bounds on size (from exponential to super exponential) for approximating a ReLU deep net function by a shallower ReLU net. Our gap theorems hold for smoothly parametrized families of "hard" functions, contrary to countable, discrete families known in the literature. An example consequence of our gap theorems is the following: for every natural number {\$}k{\$} there exists a function representable by a ReLU DNN with {\$}k{\^{}}2{\$} hidden layers and total size {\$}k{\^{}}3{\$}, such that any ReLU DNN with at most {\$}k{\$} hidden layers will require at least {\$}\backslashfrac{\{}1{\}}{\{}2{\}}k{\^{}}{\{}k+1{\}}-1{\$} total nodes. Finally, we construct a family of {\$}\backslashmathbb{\{}R{\}}{\^{}}n\backslashto \backslashmathbb{\{}R{\}}{\$} piecewise linear functions for {\$}n\backslashgeq 2{\$} (also smoothly parameterized), whose number of affine pieces scales exponentially with the dimension {\$}n{\$} at any fixed size and depth. To the best of our knowledge, such a construction with exponential dependence on {\$}n{\$} has not been achieved by previous families of "hard" functions in the neural nets literature. This construction utilizes the theory of zonotopes from polyhedral theory.},
archivePrefix = {arXiv},
arxivId = {1611.01491},
author = {Arora, Raman and Basu, Amitabh and Mianjy, Poorya and Mukherjee, Anirbit},
eprint = {1611.01491},
pages = {1--21},
title = {{Understanding Deep Neural Networks with Rectified Linear Units}},
url = {http://arxiv.org/abs/1611.01491},
year = {2016}
}
@article{Ozugur1997,
abstract = {We present a new method for feature extraction of two-dimensional shape information based on segmentation of the boundary curve. This approach partitions closed shapes into segments and finds their angular spans. The number of segments and the angular spans form the first two feature parameters of a given shape. Fourier coefficients of all segments constitute the final feature parameters. The algorithm renders the shapes independent of scale, rotation and translation. The main advantage of this method is to speed up substantially the recognition process of the shapes, mainly because it is possible to design the classification rule in a hierarchical way. It is therefore suitable for objects to be sorted in a factory environment where the silhouette boundary supplies sufficient information for identification.},
author = {{\"{O}}zuğur, Timu{\c{c}}in and Denizhan, Yağmur and Panayirci, Erdal},
xxurl = {10.1016/S0167-8655(97)00129-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/{\"{O}}zuğur, Denizhan, Panayirci - 1997 - Feature extraction in shape recognition using segmentation of the boundary curve.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {boundary curve segmentation,fourier descriptors,shape recognition},
number = {10},
pages = {1049--1056},
title = {{Feature extraction in shape recognition using segmentation of the boundary curve}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865597001293},
volume = {18},
year = {1997}
}
@article{Cao2009,
author = {Cao, Huaigu and Bhardwaj, Anurag and Govindaraju, Venu},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao, Bhardwaj, Govindaraju - 2009 - A probabilistic method for keyword retrieval in handwritten document images.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Handwriting recognition,Information retrieval,Word spotting},
month = {dec},
number = {12},
pages = {3374--3382},
publisher = {Elsevier},
title = {{A probabilistic method for keyword retrieval in handwritten document images}},
volume = {42},
year = {2009}
}
@article{Ishwar2013,
author = {Ishwar, Vignesh and Dutta, Shrey and Bellur, Ashwin and Murthy, Ha},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ishwar et al. - 2013 - Motif Spotting in an Alapana in Carnatic Music.pdf:pdf},
journal = {Ismir 2013},
title = {{Motif Spotting in an Alapana in Carnatic Music}},
url = {http://compmusic.upf.edu/system/files/static{\_}files/Ishwar-ISMIR-2013.pdf},
year = {2013}
}
@article{Chaudhuri1997,
abstract = {An OCR system is proposed that can read two Indian language scripts: Bangla and Devnagari (Hindi), the most popular ones in the Indian subcontinent. These scripts, having the same origin in ancient Brahmi script, have many features in common and hence a single system can be modeled to recognize them. In the proposed model, document digitization, skew detection, text line segmentation and zone separation, word and character segmentation, character grouping into basic, modifier and compound character category are done for both scripts by the same set of algorithms. The feature sets and classification tree as well as the knowledge base required for error correction (such as lexicon) differ for Bangla and Devnagari. The system shows a good performance for single font scripts printed on clear documents},
author = {Chaudhuri, B.B. and Pal, U.},
xxurl = {10.1109/ICDAR.1997.620662},
isbn = {0-8186-7898-4},
journal = {Proceedings of the Fourth International Conference on Document Analysis and Recognition},
pages = {1011 -- 1015},
title = {{An OCR system to read two Indian language scripts: Bangla and Devnagari (Hindi)}},
volume = {2},
year = {1997}
}
@inproceedings{Bai2009,
author = {Bai, Shuyong and Li, Linlin and Tan, Chew Lim},
booktitle = {2009 10th International Conference on Document Analysis and Recognition},
xxurl = {10.1109/ICDAR.2009.54},
isbn = {978-1-4244-4500-4},
issn = {1520-5363},
keywords = {Delay,Document Image Retrival,Handwriting recognition,Image coding,Ink,Keyword Spotting,Partial Word Matching,Robustness,Shape,Support vector machine classification,Support vector machines,Text analysis,Voting,Word Searching,Word Shape Coding,document image database,document image processing,feature descriptor,feature extraction,image coding,image matching,indexing,keyword spotting,optical character recognition,sequence alignment similarity measure,shape recognition,visual databases,word matching,word shape coding},
language = {English},
pages = {331--335},
publisher = {IEEE},
title = {{Keyword Spotting in Document Images through Word Shape Coding}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5277679},
year = {2009}
}
@article{Cutter2013,
author = {Cutter, Michael P. and Manduchi, Roberto},
xxurl = {10.1109/ICDAR.2013.89},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cutter, Manduchi - 2013 - Real Time Camera Phone Guidance for Compliant Document Image Acquisition without Sight.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {408--412},
publisher = {Ieee},
title = {{Real Time Camera Phone Guidance for Compliant Document Image Acquisition without Sight}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628654},
year = {2013}
}
@article{Sivasankar2011a,
author = {Sivasankar, E. and Sridhar, H. and Balakrishnan, V. and Ashwin, K. and Rajesh, R. S.},
xxurl = {10.1142/S0219878911002410},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sivasankar et al. - 2011 - Comparison of Dimensionality Reduction Techniques Using a Backpropagation Neural Network Based Classifier.pdf:pdf},
issn = {0219-8789},
journal = {International Journal of Information Acquisition},
keywords = {back propaga-,credit data set,data mining,dimensionality reduction,principal component analysis,tion neural networks},
month = {jun},
number = {02},
pages = {161--169},
title = {{Comparison of Dimensionality Reduction Techniques Using a Backpropagation Neural Network Based Classifier}},
url = {http://www.worldscientific.com/xxurl/abs/10.1142/S0219878911002410},
volume = {08},
year = {2011}
}
@article{Freund1996a,
abstract = {In an earlier paper [9], we introduced a new "boosting" algorithm called {\{}AdaBoost{\}} which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a "pseudo-loss" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe...},
archivePrefix = {arXiv},
arxivId = {10.1007/978-0-387-09823-4{\_}45},
author = {Freund, Yoav and Schapire, Re Robert E},
xxurl = {10.1.1.133.1040},
eprint = {978-0-387-09823-4{\_}45},
isbn = {1558604197},
issn = {0706-652X, 1205-7533},
journal = {International Conference on Machine Learning},
keywords = {boosting},
pages = {148--156},
pmid = {15003161},
primaryClass = {10.1007},
title = {{Experiments with a New Boosting Algorithm}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.51.6252},
year = {1996}
}
@article{Choudhary2013,
abstract = {Character Segmentation is the most crucial step for any OCR (Optical Character Recognition) System. The selection of segmentation algorithm being used is the key factor in deciding the accuracy of OCR system. If there is a good segmentation of characters, the recognition accuracy will also be high. Segmentation of words into characters becomes very difficult due to the cursive and unconstrained nature of the handwritten script. This paper proposes a new vertical segmentation algorithm in which the segmentation points are located after thinning the word image to get the stroke width of a single pixel. The knowledge of shape and geometry of English characters is used in the segmentation process to detect ligatures. The proposed segmentation approach is tested on a local benchmark database and high segmentation accuracy is found to be achieved.},
author = {Choudhary, Amit and Rishi, Rahul and Ahlawat, Savita},
xxurl = {10.1016/j.procs.2013.05.013},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choudhary, Rishi, Ahlawat - 2013 - A New Character Segmentation Approach for Off-Line Cursive Handwritten Words.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
pages = {88--95},
publisher = {Elsevier B.V.},
title = {{A New Character Segmentation Approach for Off-Line Cursive Handwritten Words}},
volume = {17},
year = {2013}
}
@article{Engineering2011,
author = {Engineering, Information},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Engineering - 2011 - Music Matching Based on Rough Longest Common Subsequence.pdf:pdf},
isbn = {1016-2364},
keywords = {content-based music retrieval,filtering algorithm,information retrieval,local alignment,musical similarity,rlcs,rough longest common subsequence},
pages = {95--110},
title = {{Music Matching Based on Rough Longest Common Subsequence}},
volume = {110},
year = {2011}
}
@article{Habibi2012,
author = {Habibi, Maryam},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Habibi - 2012 - Content Based Document Image Retrieval with Support Vectors Clustering.pdf:pdf},
keywords = {document feature vector,document image retrieval,keywords spotting,support vector clustering,wavelet transform},
number = {May},
pages = {308--314},
title = {{Content Based Document Image Retrieval with Support Vectors Clustering}},
year = {2012}
}
@article{Hu2013a,
author = {Hu, Juan and Chen, Youbin},
xxurl = {10.1109/ICDAR.2013.272},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Chen - 2013 - Offline Signature Verification Using Real Adaboost Classifier Combination of Pseudo-dynamic Features.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {curvature on the basis,for instance,gray level,necessary and useful to,of stroke,offline signture verification,on,pseudo-dynamic,real adaboost,recover temporal features based,strokes,writer-independent},
month = {aug},
pages = {1345--1349},
publisher = {Ieee},
title = {{Offline Signature Verification Using Real Adaboost Classifier Combination of Pseudo-dynamic Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628833},
year = {2013}
}
@article{Denton2015,
abstract = {In this paper we introduce a generative parametric model capable of producing high quality samples of natural images. Our approach uses a cascade of convolutional networks within a Laplacian pyramid framework to generate images in a coarse-to-fine fashion. At each level of the pyramid, a separate generative convnet model is trained using the Generative Adversarial Nets (GAN) approach (Goodfellow et al.). Samples drawn from our model are of significantly higher quality than alternate approaches. In a quantitative assessment by human evaluators, our CIFAR10 samples were mistaken for real images around 40{\%} of the time, compared to 10{\%} for samples drawn from a GAN baseline model. We also show samples from models trained on the higher resolution images of the LSUN scene dataset.},
archivePrefix = {arXiv},
arxivId = {1506.05751},
author = {Denton, Emily and Chintala, Soumith and Szlam, Arthur and Fergus, Rob},
eprint = {1506.05751},
isbn = {1505.05770},
issn = {10495258},
pages = {1--10},
title = {{Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks}},
url = {http://arxiv.org/abs/1506.05751},
year = {2015}
}
@inproceedings{Kin-PongChan2008,
abstract = {Time series stored as feature vectors can be indexed by$\backslash$nmultidimensional index trees like R-Trees for fast retrieval. Due to the$\backslash$ndimensionality curse problem, transformations are applied to time series$\backslash$nto reduce the number of dimensions of the feature vectors. Different$\backslash$ntransformations like Discrete Fourier Transform (DFT) Discrete Wavelet$\backslash$nTransform (DWT), Karhunen-Loeve (KL) transform or Singular Value$\backslash$nDecomposition (SVD) can be applied. While the use of DFT and K-L$\backslash$ntransform or SVD have been studied on the literature, to our knowledge,$\backslash$nthere is no in-depth study on the application of DWT. In this paper we$\backslash$npropose to use Haar Wavelet Transform for time series indexing. The$\backslash$nmajor contributions are: (1) we show that Euclidean distance is$\backslash$npreserved in the Haar transformed domain and no false dismissal will$\backslash$noccur, (2) we show that Haar transform can outperform DFT through$\backslash$nexperiments, (3) a new similarity model is suggested to accommodate$\backslash$nvertical shift of time series, and (4) a two-phase method is proposed$\backslash$nfor efficient n-nearest neighbor query in time series databases},
author = {{Kin-Pong Chan} and {Ada Wai-Chee Fu}},
booktitle = {Proceedings 15th International Conference on Data Engineering (Cat. No.99CB36337)},
xxurl = {10.1109/ICDE.1999.754915},
isbn = {0-7695-0071-4},
pages = {126--133},
publisher = {IEEE},
title = {{Efficient time series matching by wavelets}},
url = {http://ieeexplore.ieee.org/document/754915/},
year = {1999}
}
@article{Visaniy2013,
author = {Visaniy, Muriel and Kieu, V.C and Fornes, Alicia and Journet, Nicholas},
xxurl = {10.1109/ICDAR.2013.284},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Visaniy et al. - 2013 - ICDAR 2013 Music Scores Competition Staff Removal.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-competition,for the 2013 music,grec 2013 m usic,ii,music scores,presented in section ii-c,s cores d atabase,scores competitionl,semi-synthetic database,staff removal,t he icdar,using the,we generated a},
month = {aug},
pages = {1407--1411},
publisher = {Ieee},
title = {{ICDAR 2013 Music Scores Competition: Staff Removal}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628845},
year = {2013}
}
@article{Alaei2011,
abstract = {Variations in inter-line gaps and skewed or curled text-lines are some of the challenging issues in segmentation of handwritten text-lines. Moreover, overlapping and touching text-lines that frequently appear in unconstrained handwritten text documents significantly increase segmentation complexities. In this paper, we propose a novel approach for unconstrained handwritten text-line segmentation. A new painting technique is employed to smear the foreground portion of the document image. The painting technique enhances the separability between the foreground and background portions enabling easy detection of text-lines. A dilation operation is employed on the foreground portion of the painted image to obtain a single component for each text-line. Thinning of the background portion of the dilated image and subsequently some trimming operations are performed to obtain a number of separating lines, called candidate line separators. By using the starting and ending points of the candidate line separators and analyzing the distances among them, related candidate line separators are connected to obtain segmented text-lines. Furthermore, the problems of overlapping and touching components are addressed using some novel techniques. We tested the proposed scheme on text-pages of English, French, German, Greek, Persian, Oriya and Bangla and remarkable results were obtained. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {Alaei, Alireza and Pal, Umapada and Nagabhushan, P.},
xxurl = {10.1016/j.patcog.2010.10.014},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaei, Pal, Nagabhushan - 2011 - A new scheme for unconstrained handwritten text-line segmentation.pdf:pdf},
isbn = {00313203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Handwritten document processing,Mathematical morphology,Piece-wise painting,Thinning,Unconstrained handwritten line segmentation},
number = {4},
pages = {917--928},
title = {{A new scheme for unconstrained handwritten text-line segmentation}},
volume = {44},
year = {2011}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Lowe, David G},
xxurl = {http://dx.xxurl.org/10.1023/B:VISI.0000029664.99615.94},
eprint = {0112017},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowe - 2004 - Distinctive image features from scale invariant keypoints.pdf:pdf},
isbn = {1568811012},
issn = {0920-5691},
journal = {Int'l Journal of Computer Vision},
pages = {91--11020042},
pmid = {20064111},
primaryClass = {cs},
title = {{Distinctive image features from scale invariant keypoints}},
url = {http://portal.acm.org/citation.cfm?id=996342},
volume = {60},
year = {2004}
}
@article{Dinh2016,
abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
archivePrefix = {arXiv},
arxivId = {1605.08803},
author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
xxurl = {1605.08803},
eprint = {1605.08803},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Sohl-Dickstein, Bengio - 2016 - Density estimation using Real NVP.pdf:pdf},
title = {{Density estimation using Real NVP}},
url = {http://arxiv.org/abs/1605.08803},
year = {2016}
}
@article{Patel2003,
abstract = {The provlem of efficiently locating previously known patterns in a time series database (i.e. query by content) has received much attention and may not largerly be rgarded as a solved provlem. However, from a knowledge discovery viewpoint, a more interesting problem is the enumeration of previously unkown, frequently occurring patterns. We call such patterns "motifis", because of their close analoag to their discrete counterparts in computation biology. An efficient motif discovery algorithm for time series would be useful as a tool for summarizing and visualing massive time series databases. In addition, it could be uses as a subroutine in various other data mining tasks, including the discovery of association rules, clustering and classificiation. In this work, we carfully motivate, the introduce a non-trivial dfinition of time series motifs. We proose an efficient algorithm to discover them, and we demonstrate the utility and efficienty of our arpproach on several real world datasets.},
author = {Patel, P. and Keogh, E. and Lin, J. and Lonardi, S.},
xxurl = {10.1109/icdm.2002.1183925},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patel et al. - 2003 - Mining motifs in massive time series databases.pdf:pdf},
pages = {370--377},
title = {{Mining motifs in massive time series databases}},
year = {2003}
}
@article{Biederman1995,
abstract = {The visual recognition problem is central to computer vision research. From robotics to information retrieval, many desired applications demand the ability to identify and localize categories, places, and objects. This tutorial overviews computer vision algorithms for visual object recognition and image classification. We introduce primary representations and learning approaches, with an emphasis on recent advances in the field. The target audience consists of researchers or students working in AI, robotics, or vision who would like to understand what methods and representations are available for these problems. This lecture summarizes what is and isn't possible to do reliably today, and overviews key concepts that could be employed in systems requiring visual categorization. Table of Contents: Introduction / Overview: Recognition of Specific Objects / Local Features: Detection and Description / Matching Local Features / Geometric Verification of Matched Features / Example Systems: Specific-Object Recognition / Overview: Recognition of Generic Object Categories / Representations for Object Categories / Generic Object Detection: Finding and Scoring Candidates / Learning Generic Object Category Models / Example Systems: Generic Object Recognition / Other Considerations and Current Challenges / Conclusions},
author = {Biederman, I},
xxurl = {10.2200/S00332ED1V01Y201103AIM011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biederman - 1995 - Visual Object Recognition.pdf:pdf},
isbn = {9781598299687},
issn = {1939-4608},
journal = {An Invitation to Cognitive Science, 2nd Edition},
pages = {121--165},
pmid = {8833455},
title = {{Visual Object Recognition}},
year = {1995}
}
@article{Ding2008b,
abstract = {The last decade has witnessed a tremendous growths of interests in applications that deal with querying and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures geared towards time series have been introduced. Each individual work introducing a particular method has made specific claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive set of time series experiments re-implementing 8 different representation methods and 9 similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this paper, we give an overview of these different techniques and present our comparative experimental findings regarding their effectiveness. Our experiments have provided both a unified validation of some of the existing achievements, and in some cases, suggested that certain claims in the literature may be unduly optimistic. {\textcopyright} 2008 VLDB Endowment.},
author = {Ding, Hui and Trajcevski, Goce and Scheuermann, Peter and Wang, Xiaoyue and Keogh, Eamonn},
xxurl = {10.14778/1454159.1454226},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
title = {{Querying and mining of time series data: Experimental comparison of representations and distance measures}},
year = {2008}
}
@article{Ntirogiannis2013a,
abstract = {Document image binarization is of great importance in the document image analysis and recognition pipeline since it affects further stages of the recognition process. The evaluation of a binarization method aids in studying its algorithmic behavior, as well as verifying its effectiveness, by providing qualitative and quantitative indication of its performance. This paper addresses a pixel-based binarization evaluation methodology for historical handwritten/machine-printed document images. In the proposed evaluation scheme, the recall and precision evaluation measures are properly modified using a weighting scheme that diminishes any potential evaluation bias. Additional performance metrics of the proposed evaluation scheme consist of the percentage rates of broken and missed text, false alarms, background noise, character enlargement, and merging. Several experiments conducted in comparison with other pixel-based evaluation measures demonstrate the validity of the proposed evaluation scheme.},
author = {Ntirogiannis, Konstantinos and Gatos, Basilis and Pratikakis, Ioannis},
xxurl = {10.1109/TIP.2012.2219550},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ntirogiannis, Gatos, Pratikakis - 2013 - Performance evaluation methodology for historical document image binarization.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Artificial Intelligence,Documentation,Documentation: methods,Handwriting,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Printing,Reproducibility of Results},
month = {feb},
number = {2},
pages = {595--609},
pmid = {23008259},
title = {{Performance evaluation methodology for historical document image binarization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23008259},
volume = {22},
year = {2013}
}
@article{Malik2013a,
author = {Malik, Muhammad Imran and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/ICDAR.2013.178},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malik, Liwicki, Dengel - 2013 - Part-Based Automatic System in Comparison to Human Experts for Forensic Signature Verification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {872--876},
publisher = {Ieee},
title = {{Part-Based Automatic System in Comparison to Human Experts for Forensic Signature Verification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628743},
year = {2013}
}
@article{Ray2013b,
author = {Ray, Anupama and Chandawala, Ankit and Chaudhury, Santanu},
xxurl = {10.1109/ICDAR.2013.13},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ray, Chandawala, Chaudhury - 2013 - Character Recognition Using Conditional Random Field Based Recognition Engine.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {18--22},
publisher = {Ieee},
title = {{Character Recognition Using Conditional Random Field Based Recognition Engine}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628578},
year = {2013}
}
@phdthesis{Li,
author = {Li, Lin-Lin and Lin-Lin, Li},
booktitle = {Ph.D. Thesis},
keywords = {Lin-Lin Li},
school = {National University of Singapore},
title = {{Extraction of Textual Information from Images for Information Retrieval}},
url = {http://scholarbank.nus.sg/bitstream/handle/10635/19226/Thesis.pdf?sequence=1},
year = {2009}
}
@article{Nion2013,
author = {Nion, Thibauld and Menasri, Fares and Louradour, Jerome and Sibade, Cedric and Retornaz, Thomas and Metaireau, Pierre-Yves and Kermorvant, Christopher},
xxurl = {10.1109/ICDAR.2013.168},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nion et al. - 2013 - Handwritten Information Extraction from Historical Census Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {"Historical document processing, Document layout a,-historical document processing,analysis,convolutional and recurrent,document layout,handwriting recognition},
month = {aug},
pages = {822--826},
publisher = {Ieee},
title = {{Handwritten Information Extraction from Historical Census Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628733},
year = {2013}
}
@article{DeBerg2000,
author = {de Berg, Mark and van Kreveld, Marc and Overmars, Mark and Schwarzkopf, Otfried Cheong},
xxurl = {10.1007/978-3-662-04245-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Berg et al. - 2000 - Computational Geometry.pdf:pdf},
isbn = {978-3-662-04247-2},
issn = {14337851},
journal = {New York, New York},
pages = {191--218},
title = {{Computational Geometry}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Computational+Geometry:+Algorithms+and+Applications{\#}3{\%}5Cnhttp://link.springer.com/10.1007/978-3-662-04245-8},
year = {2000}
}
@article{Itakura1975,
author = {Itakura, F.},
issn = {0096-3518},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
language = {English},
month = {feb},
number = {1},
pages = {67--72},
publisher = {IEEE},
title = {{Minimum prediction residual principle applied to speech recognition}},
volume = {23},
year = {1975}
}
@inproceedings{DBLP:conf/acpr/MondalTRRP15,
author = {Mondal, Tanmoy and Tarafdar, Arundhati and Ragot, Nicolas and Ramel, Jean-Yves and Pal, Umapada},
booktitle = {3rd {\{}IAPR{\}} Asian Conference on Pattern Recognition, {\{}ACPR{\}} 2015, Kuala Lumpur, Malaysia, November 3-6, 2015},
xxurl = {10.1109/ACPR.2015.7486490},
isbn = {978-1-4799-6100-9},
pages = {181--185},
publisher = {IEEE},
title = {{Improved shape code based word matching for multi-script documents}},
url = {https://xxurl.org/10.1109/ACPR.2015.7486490},
year = {2015}
}
@article{WHALEN1995,
abstract = {This paper focuses on the problem of information retrieval from databases containing images rather than text. We propose an error-tolerant alternative to menus and keywords - the feature-matching approach - in which users describe what they want to retrieve in response to a set of queries. The system matches the user's description with descriptions of images already in the database. Database images are then presented to the user in order of similarity to the user's description. The present paper serves four purposes: application of our feature matching approach to a new image domain (trademarks); systematisation of the process for developing these systems (articulation of five stages in the process of system development); specification of criteria for selecting features to maximize system performance; and introduction of concepts of power of discrimination and error tolerance to show how measures of these two factors can be used for evaluating system performance and optimising system development. Evaluation of the system (including experiments on a small pilot database of trademarks and simulations of large databases) show the proposed set of 150 features would, without modification, be capable of handling expansion of the database to over 50,000 trademarks while still retrieving the target within the first 10 items on average. Analysis suggested several changes that should further improve the feature set.},
author = {WHALEN, THOMAS and LEE, ERIC S. and SAFAYENI, FRANK},
xxurl = {10.1080/01449299508914620},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/WHALEN, LEE, SAFAYENI - 1995 - The retrieval of images from image databases trademarks.pdf:pdf},
issn = {0144-929X},
journal = {Behaviour {\&} Information Technology},
number = {1},
pages = {3--13},
title = {{The retrieval of images from image databases: trademarks}},
url = {http://www.tandfonline.com/xxurl/abs/10.1080/01449299508914620},
volume = {14},
year = {1995}
}
@article{Baker1998,
author = {Baker, Simon and Nayar, Shree K. and Murase, Hiroshi},
xxurl = {10.1023/A:1007901712605},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker, Nayar, Murase - 1998 - Parametric Feature Detection.pdf:pdf},
issn = {09205691},
journal = {International Journal of Computer Vision},
number = {1},
pages = {27--50},
publisher = {Kluwer Academic Publishers},
title = {{Parametric Feature Detection}},
url = {http://link.springer.com/10.1023/A:1007901712605},
volume = {27},
year = {1998}
}
@article{Roy2013a,
author = {Roy, Anandarup and Parui, Swapan K. and Roy, Utpal},
xxurl = {10.1109/ICDAR.2013.182},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy, Parui, Roy - 2013 - A Pair-Copula Based Scheme for Text Extraction from Digital Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {892--896},
publisher = {Ieee},
title = {{A Pair-Copula Based Scheme for Text Extraction from Digital Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628747},
volume = {1},
year = {2013}
}
@article{Shivram2013c,
author = {Shivram, Arti and Zhu, Bilan and Setlur, Srirangaraj and Nakagawa, Masaki and Govindaraju, Venu},
xxurl = {10.1109/ICDAR.2013.174},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shivram et al. - 2013 - Segmentation Based Online Word Recognition A Conditional Random Field Driven Beam Search Strategy.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {beam search,conditional random field,cursive,handwriting,key words,online,recognition,trie-lexicon,unconstrained},
month = {aug},
pages = {852--856},
publisher = {Ieee},
title = {{Segmentation Based Online Word Recognition: A Conditional Random Field Driven Beam Search Strategy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628739},
year = {2013}
}
@inproceedings{Xi2006,
abstract = {Many algorithms have been proposed for the problem of time series classification. However, it is clear that one-nearest-neighbor with Dynamic Time Warping (DTW) distance is exceptionally difficult to beat. This approach has one weakness, however; it is computationally too demanding for many realtime applications. One way to mitigate this problem is to speed up the DTW calculations. Nonetheless, there is a limit to how much this can help. In this work, we propose an additional technique, numerosity reduction, to speed up one-nearest-neighbor DTW. While the idea of numerosity reduction for nearest-neighbor classifiers has a long history, we show here that we can leverage off an original observation about the relationship between dataset size and DTW constraints to produce an extremely compact dataset with little or no loss in accuracy. We test our ideas with a comprehensive set of experiments, and show that it can efficiently produce extremely fast accurate classifiers.},
author = {Xi, Xiaopeng and Keogh, Eamonn and Shelton, Christian and Wei, Li and Ratanamahatana, Chotirat Ann},
booktitle = {Proceedings of the 23rd international conference on Machine learning (ICML)},
xxurl = {10.1145/1143844.1143974},
isbn = {1595933832},
pages = {1033----1040},
title = {{Fast time series classification using numerosity reduction}},
url = {http://dl.acm.org/citation.cfm?id=1143974},
year = {2006}
}
@article{Mouchere2013,
author = {Mouchere, Harold and Viard-Gaudin, Christian and Zanibbi, Richard and Garain, Utpal and Kim, Dae Hwan and Kim, Jin Hyung},
xxurl = {10.1109/ICDAR.2013.288},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mouchere et al. - 2013 - ICDAR 2013 CROHME Third International Competition on Recognition of Online Handwritten Mathematical Expressions.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1428--1432},
publisher = {Ieee},
title = {{ICDAR 2013 CROHME: Third International Competition on Recognition of Online Handwritten Mathematical Expressions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628849},
year = {2013}
}
@article{Kirby2013,
author = {Kirby, Richard and Henderson, Thomas C.},
xxurl = {10.1109/ICDAR.2013.224},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kirby, Henderson - 2013 - Analysis of Topographic Maps for Recreational Purposes Using Decision Trees.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {and altitude variations,are used,contours,decision trees,features,gps,machine learning,mountain bike,recreation,road size,route selection,the following topographic features,topographic maps,vegetation,water},
month = {aug},
pages = {1105--1109},
publisher = {Ieee},
title = {{Analysis of Topographic Maps for Recreational Purposes Using Decision Trees}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628785},
year = {2013}
}
@article{Yankov2007,
abstract = {Time series motifs are approximately repeated patterns foundwithin the data. Such motifs have utility for many data mining algorithms, including rule-discovery,novelty-detection, summarization and clustering. Since the formalization of the problem and the introduction of efficient linear time algorithms, motif discovery has been successfully applied tomany domains, including medicine, motion capture, robotics and meteorology. In this work we show that most previous applications of time series motifs have been severely limited by the definition's brittleness to even slight changes of uniform scaling, the speed at which the patterns develop. We introduce a new algorithm that allows discovery of time series motifs with invariance to uniform scaling, and show that it produces objectively superior results in several important domains. Apart from being more general than all other motifdiscovery algorithms, a further contribution of our work isthat it is simpler than previous approaches, in particular we have drastically reduced the number of parameters that need to be specified.},
author = {Yankov, Dragomir and Keogh, Eamonn and Medina, Jose and Chiu, Bill and Zordan, Victor},
xxurl = {10.1145/1281192.1281282},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yankov et al. - 2007 - Detecting time series motifs under uniform scaling.pdf:pdf},
isbn = {9781595936097},
keywords = {motifs,random projection,time series,uniform scaling},
pages = {844},
title = {{Detecting time series motifs under uniform scaling}},
year = {2007}
}
@article{Colutto2011a,
author = {Colutto, Sebastian and Gatos, Basilis},
xxurl = {10.1109/ICDAR.2011.224},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Colutto, Gatos - 2011 - Efficient Word Recognition Using a Pixel-Based Dissimilarity Measure.pdf:pdf},
isbn = {978-1-4577-1350-7},
journal = {2011 International Conference on Document Analysis and Recognition},
keywords = {-word recognition,distance met-,size normalization},
month = {sep},
pages = {1110--1114},
publisher = {Ieee},
title = {{Efficient Word Recognition Using a Pixel-Based Dissimilarity Measure}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065482},
year = {2011}
}
@article{Huang2010,
abstract = {This paper proposes a flexible sequence alignment approach for pattern mining and matching in the recognition of human activities. During pattern mining, the proposed sequence alignment algorithm is invoked to extract out the representative patterns which denote specific activities of a person from the training patterns. It features high performance and robustness on pattern diversity. Besides, the algorithm evaluates the appearance probability of each pattern as weight and allows adapting pattern length to various human activities. Both of them are able to improve the accuracy of activity recognition. In pattern matching, the proposed algorithm adopts a dynamic programming based strategy to evaluate the correlation degree between each representative activity pattern and the observed activity sequence. It can avoid the trouble on segmenting the observed sequence. Moreover, we are able to obtain recognition results continuously. Besides, the proposed matching algorithm favors recognition of concurrent human activities with parallel matching. The experimental result confirms the high accuracy of human activity recognition by the proposed approach. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Huang, Po Cheng and Lee, Sz Shian and Kuo, Yaw Huang and Lee, Kuan Rong},
xxurl = {10.1016/j.eswa.2009.05.057},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Activity recognition,Dynamic programming,Pattern matching,Pattern mining,Sequence alignment},
number = {1},
pages = {298--306},
title = {{A flexible sequence alignment approach on pattern mining and matching for human activity recognition}},
volume = {37},
year = {2010}
}
@article{Keogh2003A,
author = {Keogh, Eamonn and Kasetty, Shruti},
xxurl = {10.1023/A:1024988512476},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
keywords = {data mining,experimental evaluation,time series},
month = {oct},
number = {4},
pages = {349--371},
publisher = {Kluwer Academic Publishers},
title = {{On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration}},
url = {http://dl.acm.org/citation.cfm?id=861097.861112},
volume = {7},
year = {2003}
}
@article{Freund1996,
abstract = {In an earlier paper [9], we introduced a new "boosting" algorithm called {\{}AdaBoost{\}} which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a "pseudo-loss" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe...},
archivePrefix = {arXiv},
arxivId = {10.1007/978-0-387-09823-4{\_}45},
author = {Freund, Yoav and Schapire, Re Robert E},
xxurl = {10.1.1.133.1040},
eprint = {978-0-387-09823-4{\_}45},
isbn = {1558604197},
issn = {0706-652X, 1205-7533},
journal = {International Conference on Machine Learning},
keywords = {boosting},
pages = {148--156},
pmid = {15003161},
primaryClass = {10.1007},
title = {{Experiments with a New Boosting Algorithm}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.51.6252},
year = {1996}
}
@article{Salimans,
abstract = {Recent advances in stochastic gradient vari-ational inference have made it possible to perform variational Bayesian inference with posterior approximations containing auxil-iary random variables. This enables us to explore a new synthesis of variational infer-ence and Monte Carlo methods where we in-corporate one or more steps of MCMC into our variational approximation. By xxurlng so we obtain a rich class of inference algorithms bridging the gap between variational meth-ods and MCMC, and offering the best of both worlds: fast posterior approximation through the maximization of an explicit ob-jective, with the option of trading off addi-tional computation for additional accuracy. We describe the theoretical foundations that make this possible and show some promising first results.},
author = {Salimans, Tim and Diederik, Algoritmica and Kingma, P and Welling, Max},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salimans et al. - Unknown - Markov Chain Monte Carlo and Variational Inference Bridging the Gap.pdf:pdf},
title = {{Markov Chain Monte Carlo and Variational Inference: Bridging the Gap}}
}
@article{Kr2014,
author = {Kr, Rajeeva and Sagar, B M},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kr, Sagar - 2014 - Quick Response Code for Fast Detection and Recognition of Information.pdf:pdf},
keywords = {quick},
number = {2},
pages = {271--275},
title = {{Quick Response Code for Fast Detection and Recognition of Information}},
volume = {4},
year = {2014}
}
@article{Tabbone2003,
author = {Tabbone, S. and Wendling, L. and Tombre, K.},
xxurl = {10.1007/s10032-003-0105-0},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tabbone, Wendling, Tombre - 2003 - Matching of graphical symbols in line-drawing images using angular signature information.pdf:pdf},
issn = {14332833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {F-signatures,Fourier series,Graphics recognition,Symbol recognition},
number = {2},
pages = {115--125},
title = {{Matching of graphical symbols in line-drawing images using angular signature information}},
volume = {6},
year = {2003}
}
@article{Bai2013,
author = {Bai, Bo and Yin, Fei and Liu, Cheng Lin},
xxurl = {10.1109/ICDAR.2013.279},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai, Yin, Liu - 2013 - Scene Text Localization Using Gradient Local Correlation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {connected component grouping,gradient local correlation,sence text localization,stroke width consistency},
month = {aug},
pages = {1380--1384},
publisher = {Ieee},
title = {{Scene Text Localization Using Gradient Local Correlation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628840},
year = {2013}
}
@article{Prum2013,
author = {Prum, S. and Visani, M. and Fischer, a. and Ogier, J.M.},
xxurl = {10.1109/ICDAR.2013.80},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prum et al. - 2013 - A Discriminative Approach to On-Line Handwriting Recognition Using Bi-character Models.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {bi-character,combining on-,dynamic programming,line and off-line features,on-line handwriting recognition,recognition,support vector machine},
month = {aug},
pages = {364--368},
publisher = {Ieee},
title = {{A Discriminative Approach to On-Line Handwriting Recognition Using Bi-character Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628645},
year = {2013}
}
@article{Stamatopoulos2011a,
abstract = {Document digitization with either flatbed scanners or camera-based systems results in document images which often suffer from warping and perspective distortions that deteriorate the performance of current OCR approaches. In this paper, we present a goal-oriented rectification methodology to compensate for undesirable document image distortions aiming to improve the OCR result. Our approach relies upon a coarse-to-fine strategy. First, a coarse rectification is accomplished with the aid of a computationally low cost transformation which addresses the projection of a curved surface to a 2-D rectangular area. The projection of the curved surface on the plane is guided only by the textual content's appearance in the document image while incorporating a transformation which does not depend on specific model primitives or camera setup parameters. Second, pose normalization is applied on the word level aiming to restore all the local distortions of the document image. Experimental results on various document images with a variety of distortions demonstrate the robustness and effectiveness of the proposed rectification methodology using a consistent evaluation methodology that encounters OCR accuracy and a newly introduced measure using a semi-automatic procedure.},
author = {Stamatopoulos, Nikolaos and Gatos, Basilis and Pratikakis, Ioannis and Perantonis, Stavros J},
xxurl = {10.1109/TIP.2010.2080280},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamatopoulos et al. - 2011 - Goal-oriented rectification of camera-based document images.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Documentation,Documentation: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Photography,Photography: methods,Reproducibility of Results,Sensitivity and Specificity},
month = {apr},
number = {4},
pages = {910--20},
pmid = {20876019},
title = {{Goal-oriented rectification of camera-based document images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20876019},
volume = {20},
year = {2011}
}
@inproceedings{DavideRoverso,
author = {Roverso, Davide},
booktitle = {3rd ANS International Topical Meeting on Nuclear Plant Instrumentation, Control and Human-Machine Interface},
keywords = {and,by,classification,decomposition,multivariate,networks,neural,recurrent,temporal,wavelet,windowed},
title = {{Multivariate Temporal Classification By Windowed Wavelet Decomposition And Recurrent Neural Networks}},
year = {2000}
}
@article{Govindaraju,
author = {Govindaraju, V.},
xxurl = {10.1109/CVPR.2004.324},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Govindaraju - Unknown - Direct Image Matching by Dynamic Warping.pdf:pdf},
journal = {2004 Conference on Computer Vision and Pattern Recognition Workshop},
number = {1},
pages = {76--76},
publisher = {Ieee},
title = {{Direct Image Matching by Dynamic Warping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1384869}
}
@article{Keogh2006,
abstract = {The problem of similarity search in large time series databases has attracted much attention recently. It is a non-trivial problem because of the inherent high dimensionality of the data. The most promising solutions involve first performing dimensionality reduction on the data, and then indexing the reduced data with a spatial access method. Three major dimensionality reduction techniques have been proposed: Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), and more recently the Discrete Wavelet Transform (DWT). In this work we introduce a new dimensionality reduction technique which we call Piecewise Aggregate Approximation (PAA). We theoretically and empirically compare it to the other techniques and demonstrate its superiority. In addition to being competitive with or faster than the other methods, our approach has numerous other advantages. It is simple to understand and to implement, it allows more flexible distance measures, including weighted Euclidean queries, and the index can be built in linear time.},
author = {Keogh, Eamonn and Chakrabarti, Kaushik and Pazzani, Michael and Mehrotra, Sharad},
xxurl = {10.1007/PL00011669},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
month = {aug},
number = {3},
pages = {263--286},
title = {{Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases}},
url = {http://link.springer.com/10.1007/PL00011669},
volume = {3},
year = {2001}
}
@inproceedings{Dalal,
author = {Dalal, N. and Triggs, B.},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
isbn = {0-7695-2372-2},
issn = {1063-6919},
keywords = {High performance computing,Histograms,Humans,Image databases,Image edge detection,Object detection,Object recognition,Robustness,Support vector machines,Testing,coarse spatial binning,contrast normalization,edge based descriptors,feature extraction,fine orientation binning,fine-scale gradients,gradient based descriptors,gradient methods,histograms of oriented gradients,human detection,linear SVM,overlapping descriptor,pedestrian database,robust visual object recognition},
language = {English},
pages = {886--893},
publisher = {IEEE},
title = {{Histograms of Oriented Gradients for Human Detection}},
volume = {1},
year = {2005}
}
@article{Weinman2013,
author = {Weinman, Jerod},
xxurl = {10.1109/ICDAR.2013.209},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinman - 2013 - Toponym Recognition in Historical Maps by Gazetteer Alignment.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {1,1896 bicycle trail map,cartography associates,correspondence,detail,figure 1,gazetteer,generalized ransac,georectification,historical,image 1592006,maps,mlesac,of california,s central valley and,toponym recognition},
month = {aug},
pages = {1044--1048},
publisher = {Ieee},
title = {{Toponym Recognition in Historical Maps by Gazetteer Alignment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628774},
year = {2013}
}
@inproceedings{Rosten2006a,
abstract = {Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7{\%} of the available processing time. By comparison neither the Harris detector (120{\%}) nor the detection stage of SIFT (300{\%}) can operate at full frame rate. Clearly a high-speed detector is of limited use if the features produced are unsuitable for downstream processing. In particular, the same scene viewed from two different positions should yield features which correspond to the same real-world 3D locations [1]. Hence the second contribution of this paper is a comparison corner detectors based on this criterion applied to 3D scenes. This comparison supports a number of claims made elsewhere concerning existing corner detectors. Further, contrary to our initial expectations, we show that despite being principally constructed for speed, our detector significantly outperforms existing feature detectors according to this criterion.},
author = {Rosten, Edward and Drummond, Tom},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
xxurl = {10.1007/11744023_34},
isbn = {3540338322},
issn = {16113349},
pages = {430--443},
pmid = {18684738},
title = {{Machine learning for high-speed corner detection}},
volume = {3951 LNCS},
year = {2006}
}
@article{Wang2010a,
abstract = {This paper presents a simple, dynamic approach to logo detection and recognition in document images. Although there are literatures on both logo detection and logo recognition issues, Current methods lack the adaptability to variable real-world documents. In this paper we initially observe this deficiency from a different point of view and reveal its inherent causation. Then we reorganize the structure of the logo detection and recognition procedures and integrate them into a unified framework. By applying feedback and selecting proper features, we make our framework dynamic and interactive. Experiments show that the proposed method outperforms existing methods in document processing domain.},
author = {Wang, Hongye},
xxurl = {10.1109/ICPR.2010.483},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang - 2010 - Document Logo Detection and Recognition Using Bayesian Model.pdf:pdf},
isbn = {978-1-4244-7542-1},
issn = {10514651},
journal = {2010 20th International Conference on Pattern Recognition},
keywords = {imp-logo-paper},
mendeley-tags = {imp-logo-paper},
number = {c},
pages = {1961--1964},
pmid = {5597239},
title = {{Document Logo Detection and Recognition Using Bayesian Model}},
url = {http://ieeexplore.ieee.org/document/5597239/},
year = {2010}
}
@article{Ferraz2009,
author = {Ferraz, Luis and Binefa, Xavier},
xxurl = {10.1007/978-3-642-02172-5_31},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferraz, Binefa - 2009 - A scale invariant interest point detector for discriminative blob detection.pdf:pdf},
isbn = {3642021719},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Blob detection,Blob trajectory,Discriminative features,Gaussian curvature},
pages = {233--240},
title = {{A scale invariant interest point detector for discriminative blob detection}},
volume = {5524 LNCS},
year = {2009}
}
@article{Yi2013,
author = {Yi, Chucai and Yang, Xiaodong and Tian, Yingli},
xxurl = {10.1109/ICDAR.2013.185},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yi, Yang, Tian - 2013 - Feature Representations for Scene Text Character Recognition A Comparative Study.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {coding-pooling,dictionary of visual words,evaluation,feature descriptors,global,hog,performance,scene text character recognition,text feature representation},
month = {aug},
pages = {907--911},
publisher = {Ieee},
title = {{Feature Representations for Scene Text Character Recognition: A Comparative Study}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628750},
year = {2013}
}
@article{Pratikakis2013b,
abstract = {DIBCO 2011 is the International Document Image Binarization Contest organized in the context of ICDAR 2011 conference. The general objective of the contest is to identify current advances in document image binarization for both machine-printed and handwritten document images using evaluation performance measures that conform to document image analysis and recognition. This paper describes the contest details including the evaluation measures used as well as the performance of the 18 submitted methods along with a short description of each method.},
author = {Pratikakis, Ioannis and Gatos, Basilis and Ntirogiannis, Konstantinos},
xxurl = {10.1109/ICDAR.2013.219},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratikakis, Gatos, Ntirogiannis - 2013 - ICDAR 2013 document image binarization contest (DIBCO 2013)(2).pdf:pdf},
isbn = {9780769545202},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {document image binarisation,performance evaluation},
number = {Dibco},
pages = {1471--1476},
pmid = {30007343},
title = {{ICDAR 2013 document image binarization contest (DIBCO 2013)}},
year = {2013}
}
@article{Francesconi1998,
author = {Francesconi, E and Frasconi, P and Gori, M},
xxurl = {10.1007/3-540-64381-8},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Francesconi, Frasconi, Gori - 1998 - Logo recognition by recursive neural networks.pdf:pdf},
isbn = {3540643818},
issn = {16113349},
journal = {Graphics Recognition {\ldots}},
title = {{Logo recognition by recursive neural networks}},
url = {http://link.springer.com/chapter/10.1007/3-540-64381-8{\_}43},
year = {1998}
}
@article{Hangarge2013,
author = {Hangarge, Mallikarjun and Santosh, K.C. and Pardeshi, Rajmohan},
xxurl = {10.1109/ICDAR.2013.76},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hangarge, Santosh, Pardeshi - 2013 - Directional Discrete Cosine Transform for Handwritten Script Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {344--348},
publisher = {Ieee},
title = {{Directional Discrete Cosine Transform for Handwritten Script Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628641},
year = {2013}
}
@article{Demigny1997,
author = {Demigny, D. and Kamle, T.},
xxurl = {10.1109/34.632980},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1199--1211},
title = {{A discrete expression of Canny's criteria for step edge detector performances evaluation}},
url = {http://ieeexplore.ieee.org/document/632980/},
volume = {19},
year = {1997}
}
@article{Mikolajczyk2004a,
abstract = {In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.},
archivePrefix = {arXiv},
arxivId = {arXiv:1112.2903v1},
author = {Mikolajczyk, Krystian and Schmid, Cordelia},
xxurl = {10.1023/B:VISI.0000027790.02288.f2},
eprint = {arXiv:1112.2903v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolajczyk, Schmid - 2004 - Scale {\&} affine invariant interest point detectors.pdf:pdf},
isbn = {3540479694},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Affine invariance,Interest points,Local features,Matching,Recognition,Scale invariance},
number = {1},
pages = {63--86},
pmid = {1313188},
title = {{Scale {\&} affine invariant interest point detectors}},
volume = {60},
year = {2004}
}
@book{Rizzi1998,
address = {Berlin, Heidelberg},
author = {Pierpaolo, D'Urso and Vichi, Maurizio},
xxurl = {10.1007/978-3-642-72253-0},
editor = {Rizzi, Alfredo and Vichi, Maurizio and Bock, Hans-Hermann},
isbn = {978-3-540-64641-9},
publisher = {Springer Berlin Heidelberg},
series = {Studies in Classification, Data Analysis, and Knowledge Organization},
title = {{Dissimilarities Between Trajectories of a Three-Way Longitudinal Data Set}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-72253-0},
year = {1998}
}
@article{Raza2013,
author = {Raza, Ahsen and Siddiqi, Imran and Djeddi, Chawki and Ennaji, Abdellatif},
xxurl = {10.1109/ICDAR.2013.69},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raza et al. - 2013 - Multilingual Artificial Text Detection Using a Cascade of Transforms.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {fractal dimension,glcm,multilingual artificial text detection,spatial,transforms},
month = {aug},
pages = {309--313},
publisher = {Ieee},
title = {{Multilingual Artificial Text Detection Using a Cascade of Transforms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628634},
year = {2013}
}
@article{Ozertem2009a,
author = {Ozertem, U. and Erdogmus, D.},
xxurl = {10.1109/TSP.2009.2016268},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ozertem, Erdogmus - 2009 - Principal Curve Time Warping.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
month = {jun},
number = {6},
pages = {2041--2049},
title = {{Principal Curve Time Warping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4787143},
volume = {57},
year = {2009}
}
@article{Goswami2018,
abstract = {Thousands of human lives are lost every year around the globe, apart from significant damage on property, animal life, etc., due to natural disasters (e.g., earthquake, flood, tsunami, hurricane and other storms, landslides, cloudburst, heat wave, forest fire). In this paper, we focus on reviewing the application of data mining and analytical techniques designed so far for (i) prediction, (ii) detection, and (iii) development of appropriate disaster management strategy based on the collected data from disasters. A detailed description of availability of data from geological observatories (seismological, hydrological), satellites, remote sensing and newer sources like social networking sites as twitter is presented. An extensive and in-depth literature study on current techniques for disaster prediction, detection and management has been done and the results are summarized according to various types of disasters. Finally a framework for building a disaster management database for India hosted on open source Big Data platform like Hadoop in a phased manner has been proposed. The study has special focus on India which ranks among top five counties in terms of absolute number of the loss of human life.},
author = {Goswami, Saptarsi and Chakraborty, Sanjay and Ghosh, Sanhita and Chakrabarti, Amlan and Chakraborty, Basabi},
xxurl = {10.1016/j.asej.2016.01.012},
file = {:home/mondal/Documents/climate/pdf/1610.09974.pdf:pdf},
issn = {20904479},
journal = {Ain Shams Engineering Journal},
keywords = {Big Data,Data mining,India,Natural disaster,Twitter},
number = {3},
pages = {365--378},
title = {{A review on application of data mining techniques to combat natural disasters}},
volume = {9},
year = {2018}
}
@book{Yeh2018,
abstract = {The last decade has seen a flurry of research on all-pairs-similarity-search (or similarity joins) for text, DNA and a handful of other datatypes, and these systems have been applied to many diverse data mining problems. However, there has been 123 84 C.-C. M. Yeh et al. surprisingly little progress made on similarity joins for time series subsequences. The lack of progress probably stems from the daunting nature of the problem. For even modest sized datasets the obvious nested-loop algorithm can take months, and the typical speed-up techniques in this domain (i.e., indexing, lower-bounding, triangular-inequality pruning and early abandoning) at best produce only one or two orders of magnitude speedup. In this work we introduce a novel scalable algorithm for time series subsequence all-pairs-similarity-search. For exceptionally large datasets, the algorithm can be trivially cast as an anytime algorithm and produce high-quality approximate solutions in reasonable time and/or be accelerated by a trivial porting to a GPU framework. The exact similarity join algorithm computes the answer to the time series motif and time series discord problem as a side-effect, and our algorithm incidentally provides the fastest known algorithm for both these extensively-studied problems. We demonstrate the utility of our ideas for many time series data mining problems, including motif discovery, novelty discovery, shapelet discovery, semantic segmentation, density estimation, and contrast set mining. Moreover, we demonstrate the utility of our ideas on domains as diverse as seismology, music processing, bioinfor-matics, human activity monitoring, electrical power-demand monitoring and medicine.},
author = {Yeh, Chin Chia Michael and Zhu, Yan and Ulanova, Liudmila and Begum, Nurjahan and Ding, Yifei and Dau, Hoang Anh and Zimmerman, Zachary and Silva, Diego Furtado and Mueen, Abdullah and Keogh, Eamonn},
booktitle = {Data Mining and Knowledge Discovery},
xxurl = {10.1007/s10618-017-0519-9},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh et al. - 2018 - Time series joins, motifs, discords and shapelets a unifying view that exploits the matrix profile.pdf:pdf},
isbn = {1061801705},
issn = {1573756X},
keywords = {Anomaly detection,Joins,Motif discovery,Time series},
number = {1},
pages = {83--123},
publisher = {Springer US},
title = {{Time series joins, motifs, discords and shapelets: a unifying view that exploits the matrix profile}},
volume = {32},
year = {2018}
}
@inproceedings{Mueen2010a,
abstract = {We consider the problem of computing all-pair correlations in a warehouse containing a large number (e.g., tens of thousands) of time-series (or, signals). The problem arises in automatic discovery of patterns and anomalies in data intensive applications such as data center management, environmental monitoring, and scientific experiments. However, with existing techniques, solving the problem for a large stream warehouse is extremely expensive, due to the problem's inherent quadratic I/O and CPU complexities. We propose novel algorithms, based on Discrete Fourier Transformation (DFT) and graph partitioning, to reduce the end-to-end response time of an all-pair correlation query. To minimize I/O cost, we partition a massive set of input signals into smaller batches such that caching the signals one batch at a time maximizes data reuse and minimizes disk I/O. To reduce CPU cost, we propose two approximation algorithms. Our first algorithm efficiently computes approximate correlation coefficients of similar signal pairs within a given error bound. The second algorithm efficiently identifies, without any false positives or negatives, all signal pairs with correlations above a given threshold. For many real applications, our approximate solutions are as useful as corresponding exact solutions, due to our strict error guarantees. However, compared to the state-of-the-art exact algorithms, our algorithms are up to 17x faster for several real datasets. {\textcopyright} 2010 ACM.},
author = {Mueen, Abdullah and Nath, Suman and Liu, Jie},
booktitle = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
xxurl = {10.1145/1807167.1807188},
isbn = {9781450300322},
issn = {07308078},
keywords = {correlation matrix,discrete fourier transform},
title = {{Fast approximate correlation for massive time-series data}},
year = {2010}
}
@inproceedings{Keogh2005b,
abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. Discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.},
author = {Keogh, Eamonn and Lin, Jessica and Fu, Ada},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
xxurl = {10.1109/ICDM.2005.79},
isbn = {0769522785},
issn = {15504786},
keywords = {Anomaly detection,Clustering,Time series data mining},
title = {{HOT SAX: Efficiently finding the most unusual time series subsequence}},
year = {2005}
}
@article{Li2011,
abstract = {We propose a new method to calculate the similarity of time series based on piecewise linear approximation (PLA) and derivative dynamic time warping (DDTW). The proposed method includes two phases. One is the divisive approach of piecewise linear approximation based on the middle curve of original time series. Apart from the attractive results, it can create line segments to approximate time series faster than conventional linear approximation. Meanwhile, high dimensional space can be reduced into a lower one and the line segments approximating the time series are used to calculate the similarity. In the other phase, we utilize the main idea of DDTW to provide another similarity measure based on the line segments just we got from the first phase. We empirically compare our new approach to other techniques and demonstrate its superiority. Crown Copyright {\textcopyright} 2011 Published by Elsevier Ltd. All rights reserved.},
author = {Li, Hailin and Guo, Chonghui and Qiu, Wangren},
xxurl = {10.1016/j.eswa.2011.05.007},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Guo, Qiu - 2011 - Similarity measure based on piecewise linear approximation and derivative dynamic time warping for time series min.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Dynamic time warping,Piecewise linear approximation,Similarity measure,Time series mining},
number = {12},
pages = {14732--14743},
publisher = {Elsevier Ltd},
title = {{Similarity measure based on piecewise linear approximation and derivative dynamic time warping for time series mining}},
url = {http://dx.xxurl.org/10.1016/j.eswa.2011.05.007},
volume = {38},
year = {2011}
}
@article{Rath2006,
annote = {From Duplicate 2 ( 





















Word spotting for historical documents





















- Rath, Tony M; Manmatha, R )







},
author = {Rath, Tony M and Manmatha, R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rath, Manmatha - 2006 - Word spotting for historical documents.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rath, Manmatha - 2006 - Word spotting for historical documents(2).pdf:pdf},
issn = {1433-2833},
journal = {IJDAR},
month = {aug},
number = {2-4},
pages = {139--152},
title = {{Word spotting for historical documents}},
volume = {9},
year = {2006}
}
@article{Gandhi2013a,
author = {Gandhi, Ankit and Jawahar, C.V.},
xxurl = {10.1109/ICDAR.2013.134},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gandhi, Jawahar - 2013 - Detection of Cut-and-Paste in Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {camera-based document image,document retrieval,linear programming and op-,plagiarism detection,timization},
month = {aug},
pages = {653--657},
publisher = {Ieee},
title = {{Detection of Cut-and-Paste in Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628699},
year = {2013}
}
@article{Zhu2016a,
abstract = {Time series motifs have been in the literature for about fifteen years, but have only recently begun to receive significant attention in the research community. This is perhaps due to the growing realization that they implicitly offer solutions to a host of time series problems, including rule discovery, anomaly detection, density estimation, semantic segmentation, etc. Recent work has improved the scalability to the point where exact motifs can be computed on datasets with up to a million data points in tenable time. However, in some domains, for example seismology, there is an insatiable need to address even larger datasets. In this work we show that a combination of a novel algorithm and a high-performance GPU allows us to significantly improve the scalability of motif discovery. We demonstrate the scalability of our ideas by finding the full set of exact motifs on a dataset with one hundred million subsequences, by far the largest dataset ever mined for time series motifs. Furthermore, we demonstrate that our algorithm can produce actionable insights in seismology and other domains.},
author = {Zhu, Yan and Zimmerman, Zachary and Senobari, Nader Shakibay and Yeh, Chin-chia Michael and Funning, Gareth},
xxurl = {10.1109/ICDM.2016.126},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2016 - Matrix Profile II Exploiting a Novel Algorithm and GPUs to Break the One Hundred Million Barrier for Time Series Mo.pdf:pdf},
isbn = {9781509054725},
issn = {0219-1377},
journal = {Icdm},
keywords = {GPUs,Joins,Motifs,Time series,gpus,joins,motifs,time series},
number = {1},
pages = {739--748},
title = {{Matrix Profile II : Exploiting a Novel Algorithm and GPUs to Break the One Hundred Million Barrier for Time Series Motifs and Joins}},
url = {http://link.springer.com/10.1007/s10115-017-1138-x},
volume = {54},
year = {2016}
}
@article{Rao1991,
abstract = {The first step is the analysis of oriented texture consists of the extraction of an orientation field. The orientation field is comprised of the angle and coherence images, which describe at each point the dominant local orientation and degree of anisotropy, respectively. A new algorithm for computing the orientation field for a flow-like texture is presented. The basic idea behind the algorithm is to use an oriented filter, namely the gradient of Gaussian, and perform manipulations on the resulting gradient vector field. The most important aspect of the new algorithm is that it is provably optimal in estimating the local orientation of an oriented texture. An added strength of the algorithm is that it is simpler and has a better signal-to-noise ratio than previous approaches, because it employs fewer derivative operations. We also propose a new measure of coherence, which works better than previous measures. The estimates for orientation and coherence are related to measures in the statistical theory of directional data. We advocate the use of the angle and coherence images as intrinsic images. An analysis of oriented textures will require the computation of these intrinsic images as a first step. In this sense, the computation of the orientation field, resulting in the intrinsic images, is indispensible in the analysis of oriented textures. We provide results from several experiments to indicate the usefulness of the angle and coherence intrinsic images. These results show that the notion of scale plays an important role in the interpretation of textures. Further, measures defined on these intrinsic images are useful for the inspection of surfaces. {\textcopyright} 1991.},
archivePrefix = {arXiv},
arxivId = {1610.07584},
author = {Rao, A. Ravishankar and Schunck, Brian G.},
xxurl = {10.1016/1049-9652(91)90059-S},
eprint = {1610.07584},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rao, Schunck - 1991 - Computing oriented texture fields.pdf:pdf},
isbn = {0-8186-1918-X},
issn = {10499652},
journal = {CVGIP: Graphical Models and Image Processing},
number = {2},
pages = {157--185},
pmid = {26154937},
title = {{Computing oriented texture fields}},
volume = {53},
year = {1991}
}
@misc{FaceSwap,
author = {Github-FaceSwap},
title = {{GitHub - MarekKowalski/FaceSwap: 3D face swapping implemented in Python}},
url = {https://github.com/MarekKowalski/FaceSwap/},
urldate = {2020-03-24}
}
@article{Ferrer2013,
author = {Ferrer, Miguel a. and Morales, Aythami and Pal, Umapada},
xxurl = {10.1109/ICDAR.2013.81},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferrer, Morales, Pal - 2013 - LBP Based Line-Wise Script Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {document analysis,lbp,multi-script,script identification,texture measures},
month = {aug},
pages = {369--373},
publisher = {Ieee},
title = {{LBP Based Line-Wise Script Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628646},
year = {2013}
}
@book{Meghanathan2013,
address = {Berlin, Heidelberg},
author = {Sarkar, Sayantan},
xxurl = {10.1007/978-3-642-31600-5},
editor = {Meghanathan, Natarajan and Nagamalai, Dhinaharan and Chaki, Nabendu},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarkar - 2013 - Word Spotting in Cursive Handwritten Documents Using Modified Character Shape Codes.pdf:pdf},
isbn = {978-3-642-31599-2},
keywords = {character shape code,handwritten documents,levenshtein distance,modified character shape code,query,search,segmentation,shape token,word,word spot},
pages = {269--278},
publisher = {Springer Berlin Heidelberg},
series = {Advances in Intelligent Systems and Computing},
title = {{Word Spotting in Cursive Handwritten Documents Using Modified Character Shape Codes}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-31600-5},
volume = {178},
year = {2013}
}
@article{Mori2005,
abstract = {We demonstrate that shape contexts can be used to quickly prune a search for similar shapes. We present two algorithms for rapid shape retrieval: representative shape contexts, performing comparisons based on a small number of shape contexts, and shapemes, using vector quantization in the space of shape contexts to obtain prototypical shape pieces.},
author = {Mori, Greg and Belongie, Serge and Malik, Jitendra},
xxurl = {10.1109/TPAMI.2005.220},
isbn = {0-7695-0695-X},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Object recognition,Optical character recognition,Shape},
number = {11},
pages = {1832--1837},
pmid = {16285381},
title = {{Efficient shape matching using shape contexts}},
volume = {27},
year = {2005}
}
@article{Loncaric1998,
abstract = {This paper provides a review of shape analysis methods. Shape analysis methods play an important role in systems for object recognition, matching, registration, and analysis. Research in shape analysis has been motivated, in part, by studies of human visual form perception systems. Several theories of visual form perception are briefly mentioned. Shape analysis methods are classified into several groups. Classification is determined according to the use of shape boundary or interior, and according to the type of result. An overview of the most representative methods is presented.},
author = {Loncaric, Sven},
xxurl = {10.1016/S0031-2023(97)00122-2},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loncaric - 1998 - A survey of shape analysis techniques.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
number = {8},
pages = {983--1001},
title = {{A survey of shape analysis techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031202397001222},
volume = {31},
year = {1998}
}
@article{Kamihira2013,
author = {Kamihira, Yuta and Ohyama, Wataru and Wakabayashi, Tetsushi and Kimura, Fumitaka},
xxurl = {10.1109/ICDAR.2013.83},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamihira et al. - 2013 - Improvement of Japanese Signature Verification by Segmentation-Verification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {gradient feature,seg-,signature verification,svm},
month = {aug},
pages = {379--382},
publisher = {Ieee},
title = {{Improvement of Japanese Signature Verification by Segmentation-Verification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628648},
year = {2013}
}
@article{Wang2014,
abstract = {This paper presents an effective approach for unsupervised language model adaptation (LMA) using multiple models in offline recognition of unconstrained handwritten Chinese texts. The domain of the document to recognize is variable and usually unknown a priori, so we use a two-pass recognition strategy with a pre-defined multi-domain language model set. We propose three methods to dynamically generate an adaptive language model to match the text output by first-pass recognition: model selection, model combination and model reconstruction. In model selection, we use the language model with minimum perplexity on the first-pass recognized text. By model combination, we learn the combination weights via minimizing the sum of squared error with both L2-norm and L1-norm regularization. For model reconstruction, we use a group of orthogonal bases to reconstruct a language model with the coefficients learned to match the document to recognize. Moreover, we reduce the storage size of multiple language models using two compression methods of split vector quantization (SVQ) and principal component analysis (PCA). Comprehensive experiments on two public Chinese handwriting databases CASIA-HWDB and HIT-MW show that the proposed unsupervised LMA approach improves the recognition performance impressively, particularly for ancient domain documents with the recognition accuracy improved by 7 percent. Meanwhile, the combination of the two compression methods largely reduces the storage size of language models with little loss of recognition accuracy. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
author = {Wang, Qiu-Feng and Yin, Fei and Liu, Cheng-Lin},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Character string recognition,Chinese handwriting recognition,Language model compression,Unsupervised language model adaptation},
pages = {1202--1216},
title = {{Unsupervised language model adaptation for handwritten Chinese text recognition}},
volume = {47},
year = {2014}
}
@article{Ma2013,
author = {Ma, Long-Long and Wu, Jian},
xxurl = {10.1109/ICDAR.2013.271},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma, Wu - 2013 - Semi-automatic Tibetan Component Annotation from Online Handwritten Tibetan Character Database by Optimizing Segmentatio.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {annotation,component,optimizing segmentation hypotheses,over-segmentation},
month = {aug},
pages = {1340--1344},
publisher = {Ieee},
title = {{Semi-automatic Tibetan Component Annotation from Online Handwritten Tibetan Character Database by Optimizing Segmentation Hypotheses}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628832},
year = {2013}
}
@inproceedings{Fx,
author = {Nakayama, Takehiro},
booktitle = {Proceedings of the 16th International Conference on Computational Linguistics},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nakayama - 1996 - Content-Oriented Categorization of Document Images.pdf:pdf},
pages = {818--823},
title = {{Content-Oriented Categorization of Document Images}},
year = {1996}
}
@article{Kovar2002,
author = {Kovar, B. and Hanjalic, A},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kovar, Hanjalic - 2002 - Logo Appearance Detection and Classification in a Sport Video.pdf:pdf},
title = {{Logo Appearance Detection and Classification in a Sport Video}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?xxurl=10.1.1.86.7953{\&}rep=rep1{\&}type=pdf},
year = {2002}
}
@article{Yu2007,
abstract = {In this paper, a new method, named granular dynamic time warping is proposed. This method is based on the granular approach of information granulation and has the characteristics of dynamic time warping approach. Thus it can be used to cluster time series with different lengths on the granular level. To cluster time series, this method first builds the corresponding granular time series, and then does the clustering on the granular time series. With this method, higher efficiency will be achieved in clustering time series, which is a goal pursued in clustering of large amount of time series. We also illustrate the prior performance of the new method with experiments.},
author = {Yu, Fusheng Yu Fusheng and Dong, Keqiang Dong Keqiang and Chen, Fei Chen Fei and Jiang, Yongke Jiang Yongke and Zeng, Wenyi Zeng Wenyi},
xxurl = {10.1109/GrC.2007.34},
isbn = {978-0-7695-3032-1},
journal = {2007 IEEE International Conference on Granular Computing (GRC 2007)},
title = {{Clustering Time Series with Granular Dynamic Time Warping Method}},
year = {2007}
}
@article{Ho2013,
author = {Ho, Anh Khoi Ngo and Ragot, Nicolas and Ramel, Jean-Yves and Eglin, Veronique and Sidere, Nicolas},
xxurl = {10.1109/ICDAR.2013.127},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ho et al. - 2013 - Document Classification in a Non-stationary Environment A One-Class SVM Approach.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {document,incremental learning,one-class svm},
month = {aug},
pages = {616--620},
publisher = {Ieee},
title = {{Document Classification in a Non-stationary Environment: A One-Class SVM Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628692},
year = {2013}
}
@article{Keogh2000a,
address = {New York, New York, USA},
author = {{Eamonn J. Keogh}, Michael J. Pazzani},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keogh, Pazzani - 2000 - Derivative Dynamic Time Warping.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keogh, Pazzani - 2000 - Scaling up dynamic time warping for datamining applications.pdf:pdf},
isbn = {1581132336},
journal = {KDD},
keywords = {dynamic time warping,similarity measures,time series},
pages = {285--289},
publisher = {ACM Press},
title = {{Scaling up dynamic time warping for datamining applications}},
year = {2000}
}
@article{VINCENZOPENTERIANI,
author = {Vincenzo, Penteriani},
journal = {Ethology, Ecology {\&} Evolution},
number = {3},
pages = {275--281},
title = {{Variation in the function of Eagle Owl vocal behaviour: territorial defence and intra-pair communication?}},
volume = {14},
year = {2002}
}
@article{Sharma2013a,
author = {Sharma, Nabin and Chanda, Sukalpa and Pal, Umapada and Blumenstein, Michael},
xxurl = {10.1109/ICDAR.2013.177},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma et al. - 2013 - Word-Wise Script Identification from Video Frames.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {script identification,video document analysis,word},
month = {aug},
pages = {867--871},
publisher = {Ieee},
title = {{Word-Wise Script Identification from Video Frames}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628742},
year = {2013}
}
@article{Tang2014,
author = {Tang, Siyu and Andriluka, Mykhaylo and Schiele, Bernt},
xxurl = {10.1007/s11263-013-0664-6},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang, Andriluka, Schiele - 2014 - Detection and Tracking of Occluded People.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = {oct},
number = {1},
pages = {58--69},
publisher = {Springer US},
title = {{Detection and Tracking of Occluded People}},
url = {http://link.springer.com/10.1007/s11263-013-0664-6},
volume = {110},
year = {2014}
}
@article{Gebhardt2013,
author = {Gebhardt, Johann and Goldstein, Markus and Shafait, Faisal and Dengel, Andreas},
xxurl = {10.1109/ICDAR.2013.102},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gebhardt et al. - 2013 - Document Authentication Using Printing Technique Features and Unsupervised Anomaly Detection.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {479--483},
publisher = {Ieee},
title = {{Document Authentication Using Printing Technique Features and Unsupervised Anomaly Detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628667},
year = {2013}
}
@article{Zhang2013a,
author = {Zhang, Xu-Yao and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.11},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Liu - 2013 - Locally Smoothed Modified Quadratic Discriminant Function.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {8--12},
publisher = {Ieee},
title = {{Locally Smoothed Modified Quadratic Discriminant Function}},
year = {2013}
}
@article{Galkina2019,
abstract = {Earthquakes are one of the most dangerous natural disasters, primarily due to the fact that they often occur without an explicit warning, leaving no time to react. This fact makes the problem of earthquake prediction extremely important for the safety of humankind. Despite the continuing interest in this topic from the scientific community, there is no consensus as to whether it is possible to find the solution with sufficient accuracy. However, successful application of machine learning techniques to different fields of research indicates that it would be possible to use them to make more accurate short-term forecasts. This paper reviews recent publications where application of various machine learning based approaches to earthquake prediction was studied. The aim is to systematize the methods used and analyze the main trends in making predictions. We believe that this research will be useful and encouraging for both earthquake scientists and beginner researchers in this field.},
author = {Galkina, Alyona and Grafeeva, Natalia},
file = {:home/mondal/Documents/climate/pdf/SEIM{\_}2019{\_}paper{\_}31.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
keywords = {Data mining,Earthquake prediction,Neural networks,Seismology,Time series},
pages = {25--32},
title = {{Machine learning methods for earthquake prediction: A survey}},
volume = {2372},
year = {2019}
}
@article{Gorecki2014e,
abstract = {In our previous work, we developed a new distance function based on a derivative and showed that our algorithm is effective. In contrast to well-known measures from the literature, our approach considers the general shape of a time series rather than standard distance of function (value) comparison. The new distance was used in classification with the nearest neighbor rule. Now we improve on our previous technique by adding the second derivative. In order to provide a comprehensive comparison, we conducted a set of experiments, testing effectiveness on 47 time series datasets from a wide variety of application domains. Our experiments show that this new method provides a significantly more accurate classification on the examined datasets. {\textcopyright} Taylor {\&} Francis Group, LLC.},
author = {G{\'{o}}recki, Tomasz and Luczak, Maciej and {\L}uczak, Maciej},
xxurl = {10.1080/03610918.2013.775296},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}recki, Luczak, {\L}uczak - 2014 - First and Second Derivatives in Time Series Classification Using DTW.pdf:pdf},
issn = {0361-0918},
journal = {Communications in Statistics - Simulation and Computation},
keywords = {Data mining,Derivative dynamic time warping,Dynamic time warping,Time series},
month = {apr},
number = {9},
pages = {2081--2092},
publisher = {Taylor {\&} Francis},
title = {{First and Second Derivatives in Time Series Classification Using DTW}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84898957686{\&}partnerID=tZOtx3y1},
volume = {43},
year = {2014}
}
@article{Xie2010,
abstract = {Dynamic time warping (DTW) has been widely used in various pattern recognition and time series data mining applications. However, as examples will illustrate, both the classic DTW and its later alternative, derivative DTW, may fail to align a pair of sequences on their common trends or patterns. Furthermore, the learning capability of any supervised learning algorithm based on classic/derivative DTW is very limited. In order to capture trends or patterns that a sequence presents during the alignment process, we first derive a global feature and a local feature for each point in a sequence. Then, a method called feature based dynamic time warping (FBDTW) is designed to align two sequences based on each points local and global features instead of its value or derivative. Experimental study shows that FDBTW outperforms both classic DTW and derivative DTW on pairwise distance evaluation of time series sequences. In order to enhance the capacity of supervised learning based on DTW, we further design a method called adaptive feature based dynamic time warping (AFDBTW) by equipping the FDBTW with a novel feature selection algorithm. This feature selection algorithm is able to expand the learning capability of any DTW based supervised learning algorithm by a dual learning process. The first-fold learning process learns the significances of both the local feature and global feature towards classification; then the second-fold learning process learns a classification model based on the pairwise distances generated by the AFDBTW. A comprehensive experimental study shows that the AFDBTW is able to make further improvement over the FDBTW in time series classification.},
author = {Xie, Ying and Wiltgen, Bryan},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie, Wiltgen - 2010 - Adaptive Feature Based Dynamic Time Warping.pdf:pdf},
journal = {Ijcsns},
number = {1},
pages = {264--273},
title = {{Adaptive Feature Based Dynamic Time Warping}},
url = {http://paper.ijcsns.org/07{\_}book/201001/20100135.pdf},
volume = {10},
year = {2010}
}
@article{Seiden1997,
author = {Seiden, Steve},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seiden - 1997 - Logo Detection in Document Images 1 Introduction 2 Feature Extraction.pdf:pdf},
journal = {Interpretation A Journal Of Bible And Theology},
keywords = {document processing,feature based classi cation,logo detection},
pages = {1--6},
title = {{Logo Detection in Document Images 1 Introduction 2 Feature Extraction}},
year = {1997}
}
@article{Lin2013c,
abstract = {Barcode technology is one of the most important parts of Automatic Identification and Data Capture (AIDC). Quick Response code (QR code) is one of the most popular types of two-dimensional barcodes. How to decode various QR code images efficiently and accurately is a challenge. In this paper, we revise the traditional decoding procedure by proposing a serial of carefully designed preprocessing methods. The decoding procedure consists of image binarization, QR code extraction, perspective transformation and resampling, and error correction. By these steps, we can recognize different types of QR code images. The experiment results show that our method has better accuracy than Google open-source 1D/2D barcode image processing library Zxing-2.1. Moreover, we evaluate the execution time for different-size images. Our method can decode these images in real time.},
author = {Lin, Jeng An and Fuh, Chiou Shann},
xxurl = {10.1155/2013/848276},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Fuh - 2013 - 2D barcode image decoding.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Fuh - 2013 - 2D barcode image decoding(2).pdf:pdf},
issn = {1024123X},
journal = {Mathematical Problems in Engineering},
number = {3},
title = {{2D barcode image decoding}},
volume = {2013},
year = {2013}
}
@article{Fleury2013,
author = {Fleury, Sylvain and Ghorbel, Achraf and Lemaitre, Aurelie and Anquetil, Eric and Jamet, Eric},
xxurl = {10.1109/ICDAR.2013.214},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fleury et al. - 2013 - User-Centered Design of an Interactive Off-Line Handwritten Architectural Floor Plan Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {architectural floor plan,described,for interpreting sketches,interactive recognition,solicitation user,teractive analysis method imisketch,the interpretation results is,the manner to present,uses tests},
month = {aug},
pages = {1073--1077},
publisher = {Ieee},
title = {{User-Centered Design of an Interactive Off-Line Handwritten Architectural Floor Plan Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628779},
year = {2013}
}
@inproceedings{Charikar2002a,
address = {New York, New York, USA},
author = {Charikar, Moses S.},
booktitle = {Proceedings of the thiry-fourth annual ACM symposium on Theory of computing - STOC '02},
xxurl = {10.1145/509907.509965},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Charikar - 2002 - Similarity estimation techniques from rounding algorithms.pdf:pdf},
isbn = {1581134959},
month = {may},
pages = {380},
publisher = {ACM Press},
title = {{Similarity estimation techniques from rounding algorithms}},
url = {http://portal.acm.org/citation.cfm?xxurld=509907.509965 http://dl.acm.org/citation.cfm?id=509907.509965},
year = {2002}
}
@article{Louloudis2009a,
annote = {From Duplicate 1 ( 

A Novel Two Stage Evaluation Methodology for Word Segmentation Techniques

- Louloudis, Georgios; Stamatopoulos, Nikolaos; Gatos, Basilis )

},
author = {Louloudis, Georgios and Stamatopoulos, Nikolaos and Gatos, Basilis},
xxurl = {10.1109/ICDAR.2009.219},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Louloudis, Stamatopoulos, Gatos - 2009 - A Novel Two Stage Evaluation Methodology for Word Segmentation Techniques.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
pages = {686--690},
publisher = {Ieee},
title = {{A Novel Two Stage Evaluation Methodology for Word Segmentation Techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277480},
year = {2009}
}
@article{Dtw2007a,
author = {Dtw, Classical},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dtw - 2007 - 4 Dynamic Time Warping.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dtw - 2007 - 4 Dynamic Time Warping(2).pdf:pdf},
journal = {Time},
title = {{4 Dynamic Time Warping}},
year = {2007}
}
@article{Lazebnik2006,
abstract = { This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting "spatial pyramid" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba{\&}{\#}146;s "gist" and Lowe{\&}{\#}146;s SIFT descriptors.},
author = {Lazebnik, Svetlana and Schmid, Cordelia and Ponce, Jean},
xxurl = {10.1109/CVPR.2006.68},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lazebnik, Schmid, Ponce - 2006 - Beyond bags of features Spatial pyramid matching for recognizing natural scene categories.pdf:pdf},
isbn = {0769525970},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2169--2178},
title = {{Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories}},
volume = {2},
year = {2006}
}
@article{Lazebnik2014,
abstract = {Lecture @ University of Illinois at Urbana-Champaign},
author = {Lazebnik, Svetlana},
xxurl = {10.1109/ICPR.2014.546},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lazebnik - 2014 - Deep Convolutional Neural Networks for Image Classification.pdf:pdf},
isbn = {978-1-4799-5209-0},
issn = {16877268},
pages = {1--10},
title = {{Deep Convolutional Neural Networks for Image Classification}},
url = {http://www.cs.illinois.edu/{~}slazebni/spring14/},
year = {2014}
}
@article{Mondal2013a,
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean-Yves and Pal, Umapada},
xxurl = {10.1109/ICDAR.2013.242},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2013 - A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing(2).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {fast word spotting,gabor wavelet,hashing,kernelized locality sensitive,klsh},
month = {aug},
pages = {1195--1199},
publisher = {Ieee},
title = {{A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628803},
year = {2013}
}
@article{Lavrenko,
author = {Lavrenko, V. and Rath, T.M. and Manmatha, R.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lavrenko, Rath, Manmatha - 2004 - Holistic word recognition for handwritten historical documents.pdf:pdf},
isbn = {0-7695-2088-X},
journal = {First International Workshop on Document Image Analysis for Libraries, Proceedings.},
pages = {278--287},
publisher = {Ieee},
title = {{Holistic word recognition for handwritten historical documents}},
year = {2004}
}
@article{Diamantatos2013,
author = {Diamantatos, Paraskevas and Verras, Vasileios and Kavallieratou, Ergina},
xxurl = {10.1109/ICDAR.2013.235},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diamantatos, Verras, Kavallieratou - 2013 - Detecting Main Body Size in Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-document image processing,baseline detection,estimation,historical document images,word main body},
month = {aug},
pages = {1160--1164},
publisher = {Ieee},
title = {{Detecting Main Body Size in Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628796},
year = {2013}
}
@article{Nguyen2013a,
author = {Nguyen, Nhu-Van and Coustaty, Mickael and Boucher, Alain and Ogier, Jean-Marc},
xxurl = {10.1109/ICDAR.2013.67},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2013 - Interactive Knowledge Learning for Ancient Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {2,3,ancient document indexing,bag of patterns,box,but an automatic system,digitization,extraction of information and,interactive learning,key-,of information,organization,relevance feedback,seen as a black,word visual representation},
month = {aug},
pages = {300--304},
publisher = {Ieee},
title = {{Interactive Knowledge Learning for Ancient Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628632},
year = {2013}
}
@article{Xi2013a,
abstract = {The problem of efficiently finding images that are similar to a target$\backslash$nimage has attracted much attention in the image processing community$\backslash$nand is rightly considered an information retrieval task. However,$\backslash$nthe problem of finding structure and regularities in large image$\backslash$ndatasets is an area in which data mining is beginning to make fundamental$\backslash$ncontributions. In this work, we consider the new problem of discovering$\backslash$nshape motifs, which are approximately repeated shapes within (or$\backslash$nbetween) image collections. As we shall show, shape motifs can have$\backslash$napplications in tasks as diverse as anthropology, law enforcement,$\backslash$nand historical manuscript mining. Brute force discovery of shape$\backslash$nmotifs could be untenably slow, especially as many domains may require$\backslash$nan expensive rotation invariant distance measure. We introduce an$\backslash$nalgorithm that is two to three orders of magnitude faster than brute$\backslash$nforce search, and demonstrate the utility of our approach with several$\backslash$nreal world datasets from diverse domains. 1},
author = {Xi, Xiaopeng and Keogh, Eamonn and Wei, Li and Mafra-Neto, Agenor},
xxurl = {10.1137/1.9781611972771.23},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xi et al. - 2013 - Finding Motifs in a Database of Shapes.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xi et al. - 2013 - Finding Motifs in a Database of Shapes(2).pdf:pdf},
keywords = {data mining,motif,shape,time series},
pages = {249--260},
title = {{Finding Motifs in a Database of Shapes}},
year = {2013}
}
@article{Lou2014,
author = {Lou, Xiong-wei and Huang, De-cai and Fan, Lu-ming and Xu, Ai-jun},
xxurl = {10.4304/jmm.9.2.269-277},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lou et al. - 2014 - An Image Classification Algorithm Based on Bag of Visual Words and Multi-kernel Learning.pdf:pdf},
issn = {1796-2048},
journal = {Journal of Multimedia},
number = {2},
pages = {269--277},
title = {{An Image Classification Algorithm Based on Bag of Visual Words and Multi-kernel Learning}},
url = {http://ojs.academypublisher.com/index.php/jmm/article/view/11803},
volume = {9},
year = {2014}
}
@article{Mikolajczyk2005,
abstract = {The paper gives a snapshot of the state of the art in affine covariant region detectors, and$\backslash$r$\backslash$ncompares their performance on a set of test images under varying imaging conditions. Six$\backslash$r$\backslash$ntypes of detectors are included: detectors based on affine normalization around Harris [24,$\backslash$r$\backslash$n34] and Hessian points [24], as proposed by Mikolajczyk and Schmid and by Schaffalitzky$\backslash$r$\backslash$nand Zisserman; a detector of ‘maximally stable extremal regions', proposed by Matas et$\backslash$r$\backslash$nal. [21]; an edge-based region detector [45] and a detector based on intensity extrema [47],$\backslash$r$\backslash$nproposed by Tuytelaars and Van Gool; and a detector of ‘salient regions', proposed by Kadir,$\backslash$r$\backslash$nZisserman and Brady [12]. The performance is measured against changes in viewpoint, scale,$\backslash$r$\backslash$nillumination, defocus and image compression.$\backslash$r$\backslash$nThe objective of this paper is also to establish a reference test set of images and performance$\backslash$r$\backslash$nsoftware, so that future detectors can be evaluated in the same framework.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Mikolajczyk, K. and Tuytelaars, T. and Schmid, C. and Zisserman, A. and Matas, J. and Schaffalitzky, F. and Kadir, T. and {Van Gool}, L.},
xxurl = {10.1007/s11263-005-3848-x},
eprint = {arXiv:1011.1669v3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolajczyk et al. - 2005 - A comparison of affine region detectors.pdf:pdf},
isbn = {0920-5691},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Affine region detectors,Invariant image description,Local features,Performance evaluation},
number = {1-2},
pages = {43--72},
pmid = {1000199072},
title = {{A comparison of affine region detectors}},
volume = {65},
year = {2005}
}
@article{Sydow1995,
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Sydow, Marcin},
xxurl = {10.1007/3-540-60220-8},
eprint = {9780201398298},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sydow - 1995 - Algorithms and Data Structures.pdf:pdf},
isbn = {978-3-540-60220-0},
issn = {0302-9743},
pmid = {4520227},
title = {{Algorithms and Data Structures}},
url = {http://link.springer.com/10.1007/3-540-60220-8},
volume = {955},
year = {1995}
}
@techreport{Ding,
abstract = {Different from salient object detection methods for still images , a key challenging for video saliency detection is how to extract and combine spatial and temporal features. In this paper, we present a novel and effective approach for salient object detection for video sequences based on 3D convolutional neural networks. First, we design a 3D convolutional network (Conv3DNet) with the input as three video frame to learn the spatiotemporal features for video sequences. Then, we design a 3D deconvolutional network (Deconv3DNet) to combine the spatiotemporal features to predict the final saliency map for video sequences. Experimental results show that the proposed saliency detection model performs better in video saliency prediction compared with the state-of-the-art video saliency detection methods.},
archivePrefix = {arXiv},
arxivId = {1807.04514v1},
author = {Ding, Guanqun and Fang, Yuming},
eprint = {1807.04514v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding, Fang - Unknown - Video Saliency Detection by 3D Convolutional Neural Networks.pdf:pdf},
keywords = {3D convolutional neural networks,Deep learning,Video saliency detection,Visual attention},
title = {{Video Saliency Detection by 3D Convolutional Neural Networks}},
url = {https://arxiv.org/pdf/1807.04514.pdf}
}
@article{Garz2013,
author = {Garz, Angelika and Fischer, Andreas and Bunke, Horst and Ingold, Rolf},
xxurl = {10.1109/ICDAR.2013.261},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garz et al. - 2013 - A Binarization-Free Clustering Approach to Segment Curved Text Lines in Historical Manuscripts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1290--1294},
publisher = {Ieee},
title = {{A Binarization-Free Clustering Approach to Segment Curved Text Lines in Historical Manuscripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628822},
year = {2013}
}
@article{Bhattacharya2013,
author = {Bhattacharya, Nilanjana and Pal, Umapada and Kimura, Fumitaka},
xxurl = {10.1109/ICDAR.2013.270},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharya, Pal, Kimura - 2013 - A System for Bangla Online Handwritten Text.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- online,bangla script,compound character,handwriting recognition,indian text,recognition},
month = {aug},
pages = {1335--1339},
publisher = {Ieee},
title = {{A System for Bangla Online Handwritten Text}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628831},
year = {2013}
}
@article{Jain2013c,
author = {Jain, Rajiv and Doermann, David},
xxurl = {10.1109/ICDAR.2013.17},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Doermann - 2013 - VisualDiff Document Image Verification and Change Detection.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {change detection,document,document image},
month = {aug},
pages = {40--44},
publisher = {Ieee},
title = {{VisualDiff: Document Image Verification and Change Detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628582},
year = {2013}
}
@article{Lehal2013,
author = {Lehal, Gurpreet Singh},
xxurl = {10.1109/ICDAR.2013.229},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lehal - 2013 - Ligature Segmentation for Urdu OCR.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1130--1134},
publisher = {Ieee},
title = {{Ligature Segmentation for Urdu OCR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628790},
year = {2013}
}
@article{Resources2013,
author = {Resources, Agricultural and Planning, Regional},
xxurl = {10.1007/s00376-012-1252-3.1.Introduction},
file = {:home/mondal/Documents/climate/pdf/55711665.pdf:pdf},
keywords = {arima,climate,fourier method,polynomial trend,statistical model,time series analysis},
number = {2},
pages = {382--396},
title = {{Time-Series Modeling and Prediction of {\~{a}}}},
volume = {30},
year = {2013}
}
@inproceedings{DBLP:conf/icdip/MondalJS10,
author = {Mondal, Tanmoy and Jain, Ashish and Sardana, H K},
booktitle = {Second International Conference on Digital Image Processing, {\{}ICDIP{\}} 2010, Singapore, Singapore, February 26-28, 2010},
xxurl = {10.1117/12.853786},
editor = {Jusoff, Kamaruzaman and Xie, Yi},
isbn = {978-0-8194-7942-6},
pages = {75460Z},
publisher = {SPIE},
series = {{\{}SPIE{\}} Proceedings},
title = {{Generation algorithm of craniofacial structure contour in cephalometric images}},
url = {https://xxurl.org/10.1117/12.853786},
volume = {7546},
year = {2010}
}
@article{JiahongYuan,
author = {{Jiahong Yuan}, Mark Liberman},
journal = {Proceedings of Acoustics},
title = {{Speaker identification on the SCOTUS corpus}},
year = {2008}
}
@article{Chang2001,
abstract = {A new deformed trademark retrieval method based on two-dimensional pseudo-hidden Markov model (2D PHMM) is proposed in this paper. Most trademark retrieval systems focus on color features, shape silhouettes, or the combination of color and shape. However, these approaches adopted individual silhouettes as shape features, leading to the following two crucial problems. First, most trademarks have various numbers of decomposed components, while the silhouette-based approaches cannot handle the variety correctly. Second, the infringement cases in which trademarks are changed by non-rigid deformation, in particular nonlinear deformation, may escape detection. Thus, our method focuses on the overall appearance of trademarks and incorporates color and shape features into 2D PHMM to tackle the above two problems. The reason to involve 2D PHMM is that it has high tolerance to noise and distortion, moreover, contextual information can be incorporated into it in a natural and elegant way. However, 2D PHMM is computation intensive and sensitive to rotation, scale and translation variations. Thus, it is the main originality of this paper to include the advantages of 2D PHMM but to exclude its disadvantages. As a result, similar trademarks can be retrieved effectively, even those with different numbers of components or non-rigid deformation. Various experiments have been conducted on a trademark databse to prove the effectiveness and practicability of the proposed method. ?? 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
author = {Chang, Min Ta and Chen, Shu Yuan},
xxurl = {10.1016/S0031-3203(00)00053-4},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang, Chen - 2001 - Deformed trademark retrieval based on 2D pseudo-hidden Markov model.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {2D hidden,Color,Color quantization,Deformed trademark,Invariance,Log-polar mapping,Markov model,Shape,Similarity measure},
number = {5},
pages = {953--967},
title = {{Deformed trademark retrieval based on 2D pseudo-hidden Markov model}},
volume = {34},
year = {2001}
}
@article{He2015,
abstract = {We develop a Deep-Text Recurrent Network (DTRN) that regards scene text reading as a sequence labelling problem. We leverage recent advances of deep convolutional neural networks to generate an ordered high-level sequence from a whole word image, avoiding the difficult character segmentation problem. Then a deep recurrent model, building on long short-term memory (LSTM), is developed to robustly recognize the generated CNN sequences, departing from most existing approaches recognising each character independently. Our model has a number of appealing properties in comparison to existing scene text recognition methods: (i) It can recognise highly ambiguous words by leveraging meaningful context information, allowing it to work reliably without either pre- or post-processing; (ii) the deep CNN feature is robust to various image distortions; (iii) it retains the explicit order information in word image, which is essential to discriminate word strings; (iv) the model does not depend on pre-defined dictionary, and it can process unknown words and arbitrary strings. Codes for the DTRN will be available.},
archivePrefix = {arXiv},
arxivId = {1506.04395},
author = {He, Pan and Huang, Weilin and Qiao, Yu and Loy, Chen Change and Tang, Xiaoou},
eprint = {1506.04395},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2015 - Reading Scene Text in Deep Convolutional Sequences.pdf:pdf},
isbn = {9781577357605},
keywords = {Technical Papers: Vision},
pages = {3501--3508},
title = {{Reading Scene Text in Deep Convolutional Sequences}},
url = {http://arxiv.org/abs/1506.04395},
year = {2015}
}
@article{AlKhateeb2011b,
author = {AlKhateeb, Jawad H and Ren, Jinchang and Jiang, Jianmin and Al-Muhtaseb, Husni},
xxurl = {10.1016/j.patrec.2011.02.006},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/AlKhateeb et al. - 2011 - Offline handwritten Arabic cursive text recognition using Hidden Markov Models and re-ranking.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {hidden markov models,hmm,off-line arabic handwritten recognition},
month = {jun},
number = {8},
pages = {1081--1088},
publisher = {Elsevier B.V.},
title = {{Offline handwritten Arabic cursive text recognition using Hidden Markov Models and re-ranking}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865511000432},
volume = {32},
year = {2011}
}
@article{Ravela2005,
abstract = {In this paper a system for multi-modal retrieval of trademark images is presented. Images are characterized and retrieved using associated text and visual appearance. A user initiates retrieval for similar trademarks by typing a text query. Subsequent searches can be performed by visual appearance or using both appearance and text information. Textual information associated with trademarks is searched using the INQUERY search engine. Images are searched visually using a method for global image similarity by appearance developed in this paper. Images are filtered with Gaussian derivatives and geometric features are computed from the filtered images. The geometric features used here are curvature and phase. Two images may be said to be similar if they have similar distributions of such features. Global similarity may, therefore, be deduced by comparing histograms of these features. This allows for rapid retrieval. The system's performance on a database of 2000 trademark images is shown. A trademark database obtained from the US Patent and Trademark Office containing 63000 design only trademark images and text is used to demonstrate scalability of the image search method and multi-modal retrieval.},
author = {Ravela, S and Manmatha, R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ravela, Manmatha - 2005 - Multi-modal retrieval of trademark images using global similarity.pdf:pdf},
journal = {Us Patent And Trademark Office},
pages = {1--17},
title = {{Multi-modal retrieval of trademark images using global similarity}},
url = {http://oai.dtic.mil/oai/oai?verb=getRecord{\&}metadataPrefix=html{\&}identifier=ADA440302},
year = {2005}
}
@misc{Duda1998,
abstract = {The first edition, published in 1973, has become a classic reference in the field. Now with the second edition, readers will find information on key new topics such as neural networks and statistical pattern recognition, the theory of machine learning, and the theory of invariances. Also included are worked examples, comparisons between different methods, extensive graphics, expanded exercises and computer project topics. An Instructor's Manual presenting detailed solutions to all the problems in the book is available from the Wiley editorial department.},
author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
booktitle = {Pattern Analysis and Applications},
xxurl = {10.1007/BF01237942},
isbn = {0471056693},
issn = {1433-7541},
number = {2},
pages = {142--143},
pmid = {2630878},
title = {{Pattern classification}},
volume = {1},
year = {1998}
}
@article{Shi2015,
abstract = {Image-based sequence recognition has been a long-standing research topic in computer vision. In this paper, we investigate the problem of scene text recognition, which is among the most important and challenging tasks in image-based sequence recognition. A novel neural network architecture, which integrates feature extraction, sequence modeling and transcription into a unified framework, is proposed. Compared with previous systems for scene text recognition, the proposed architecture possesses four distinctive properties: (1) It is end-to-end trainable, in contrast to most of the existing algorithms whose components are separately trained and tuned. (2) It naturally handles sequences in arbitrary lengths, involving no character segmentation or horizontal scale normalization. (3) It is not confined to any predefined lexicon and achieves remarkable performances in both lexicon-free and lexicon-based scene text recognition tasks. (4) It generates an effective yet much smaller model, which is more practical for real-world application scenarios. The experiments on standard benchmarks, including the IIIT-5K, Street View Text and ICDAR datasets, demonstrate the superiority of the proposed algorithm over the prior arts. Moreover, the proposed algorithm performs well in the task of image-based music score recognition, which evidently verifies the generality of it.},
archivePrefix = {arXiv},
arxivId = {1507.05717},
author = {Shi, Baoguang and Bai, Xiang and Yao, Cong},
xxurl = {10.1109/TPAMI.2016.2646371},
eprint = {1507.05717},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi, Bai, Yao - 2015 - An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Rec.pdf:pdf},
issn = {0162-8828},
number = {c},
pages = {1--8},
title = {{An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition}},
url = {http://arxiv.org/abs/1507.05717},
volume = {8828},
year = {2015}
}
@inproceedings{Le2013b,
abstract = {Digital document categorization based on logo spotting and recognition has raised a great interest in the research community because logos in documents are sources of information for categorizing documents with low costs. In this paper, we present an approach to improve the result of our method for logo spotting and recognition based on key point matching and presented in our previous paper [7]. First, the key points from both the query document images and a given set of logos (logo gallery) are extracted and described by SIFT, and are matched in the SIFT feature space. Secondly, logo segmentation is performed using spatial density-based clustering. The contribution of this paper is to add a third step where homography is used to filter the matched key points as a post-processing. And finally, in the decision stage, logo classification is performed by using an accumulating histogram. Our approach is tested using a well-known benchmark database of real world documents containing logos, and achieves good performances compared to state-of-the-art approaches.},
author = {Le, Viet Phuong and Visani, Muriel and Tran, Cao De and Ogier, Jean Marc},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
xxurl = {10.1109/ICDAR.2013.61},
isbn = {978-0-7695-4999-6},
issn = {15205363},
keywords = {document analysis,homography,logo spotting,pattern recognition},
pages = {270--274},
title = {{Improving logo spotting and matching for document categorization by a post-filter based on homography}},
year = {2013}
}
@article{Insurance2011,
author = {Insurance, Health},
xxurl = {10.1007/SpringerReference_44279},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Insurance - 2011 - Health Insurance.pdf:pdf},
title = {{Health Insurance}},
year = {2011}
}
@inproceedings{Leutenegger2011,
abstract = {Effective and efficient generation of keypoints from an image is a well-studied problem in the literature and forms the basis of numerous Computer Vision applications. Established leaders in the field are the SIFT and SURF algorithms which exhibit great performance under a variety of image transformations, with SURF in particular considered as the most computationally efficient amongst the high-performance methods to date. In this paper we propose BRISK{\textless}sup{\textgreater}1{\textless}/sup{\textgreater}, a novel method for keypoint detection, description and matching. A comprehensive evaluation on benchmark datasets reveals BRISK's adaptive, high quality performance as in state-of-the-art algorithms, albeit at a dramatically lower computational cost (an order of magnitude faster than SURF in cases). The key to speed lies in the application of a novel scale-space FAST-based detector in combination with the assembly of a bit-string descriptor from intensity comparisons retrieved by dedicated sampling of each keypoint neighborhood.},
author = {Leutenegger, Stefan and Chli, Margarita and Siegwart, Roland Y.},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
xxurl = {10.1109/ICCV.2011.6126542},
isbn = {9781457711015},
issn = {1550-5499},
pages = {2548--2555},
title = {{BRISK: Binary Robust invariant scalable keypoints}},
year = {2011}
}
@article{Soffer1998,
abstract = {A method for representing and matching logos based on positive and negative shape features is presented. Negative shape features represent an object that consists of several components enclosed in a simple geometric structure (e.g., a square) based on its interior with the components considered as holes. The goal is to find logos in a database that are most similar to a given sample logo. A border is added around logos that are not enclosed in a simple shape. Logos are segmented. Local and global shape features are computed for each component. Two methods for comparing logos represented by positive and negative components are presented and evaluated},
author = {Soffer, A and Samet, Hanan},
xxurl = {10.1109/ICPR.1998.711207},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soffer, Samet - 1998 - Using negative shape features for logo similarity matching.pdf:pdf},
isbn = {0-8186-8512-3},
issn = {1051-4651},
journal = {Proceedings of the Fourteenth International Conference on Pattern Recognition},
keywords = {logo matching,logo representation,logo similarity matching,negative shape features,simple geometric structure},
pages = {571--573},
title = {{Using negative shape features for logo similarity matching}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=711207{\%}5Cnhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=711207},
volume = {1},
year = {1998}
}
@inproceedings{DeFrancisciMorales2016,
abstract = {We introduce and study the problem of computing the simi- larity self-join in a streaming context (sssj), where the input is an unbounded stream of items arriving continuously. The goal is to find all pairs of items in the stream whose similarity is greater than a given threshold. The simplest formulation of the problem requires unbounded memory, and thus, it is intractable. To make the problem feasible, we introduce the notion of time-dependent similarity: the similarity of two items decreases with the difference in their arrival time. By leveraging the properties of this time-dependent sim- ilarity function, we design two algorithmic frameworks to solve the sssj problem. The first one, MiniBatch (MB), uses existing index-based filtering techniques for the static ver- sion of the problem, and combines them in a pipeline. The second framework, Streaming (STR), adds time filtering to the existing indexes, and integrates new time-based bounds deeply in the working of the algorithms. We also introduce a new indexing technique (L2), which is based on an existing state-of-the-art indexing technique (L2AP), but is optimized for the streaming case. Extensive experiments show that the STR algorithm, when instantiated with the L2 index, is the most scalable option across a wide array of datasets and parameters. {\textcopyright} 2016 VLDB Endowment.},
archivePrefix = {arXiv},
arxivId = {1601.04814},
author = {{De Francisci Morales}, Gianmarco and Gionis, Aristides},
booktitle = {Proceedings of the VLDB Endowment},
xxurl = {10.14778/2977797.2977805},
eprint = {1601.04814},
issn = {21508097},
title = {{Streaming similarity self-join}},
year = {2016}
}
@inproceedings{Kessentini,
author = {Kessentini, Yousri and Paquet, Thierry},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kessentini, Paquet - 2015 - Keyword spotting in handwritten documents based on a generic text line HMM and a SVM verification.pdf:pdf},
isbn = {9781479918058},
keywords = {based,france,line hmm and a,litis laboratory ea 4108,miracl laboratory,on a generic text,sfax,spotting in handwritten documents,st etienne du rouvray,svm verification,tunisia,university of sfax},
title = {{Keyword spotting in handwritten documents based on a generic text line HMM and a SVM verification}},
year = {2015}
}
@article{Tan2012,
author = {Tan, Chew Lim and Su, Bolan and Lu, Shijian and Tan, Chew Lim and Member, Senior},
xxurl = {10.1109/TIP.2012.2231089},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan et al. - 2012 - A Robust Document Image Binarization Technique for Degraded Document Images . Robust Document Image Binarization Tec.pdf:pdf},
number = {December},
pages = {1--27},
title = {{A Robust Document Image Binarization Technique for Degraded Document Images . Robust Document Image Binarization Technique for Degraded Document Images}},
year = {2012}
}
@article{Husken2003,
abstract = {Recurrent neural networks (RNN) are a widely used tool for the prediction of time series. In this paper we use the dynamic behaviour of the RNN to categorize input sequences into different specified classes. These two tasks do not seem to have much in common. However, the prediction task strongly supports the development of a suitable internal structure, representing the main features of the input sequence, to solve the classification problem. Therefore, the speed and success of the training as well as the generalization ability of the trained RNN are significantly improved. The trained RNN provides good classification performance and enables the user to assess efficiently the degree of reliability of the classification result. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {H{\"{u}}sken, Michael and Stagge, Peter},
xxurl = {10.1016/S0925-2312(01)00706-8},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Classification,Generalization,Multitask learning,Recurrent neural network,Time series},
pages = {223--235},
title = {{Recurrent neural networks for time series classification}},
volume = {50},
year = {2003}
}
@article{Dawson2009,
author = {Dawson, Deanna K. and Efford, Murray G.},
xxurl = {10.1111/j.1365-2664.2009.01731.x},
issn = {00218901},
journal = {Journal of Applied Ecology},
month = {nov},
number = {6},
pages = {1201--1209},
title = {{Bird population density estimated from acoustic signals}},
url = {http://xxurl.wiley.com/10.1111/j.1365-2664.2009.01731.x},
volume = {46},
year = {2009}
}
@article{Khreich2012a,
author = {Khreich, Wael and Granger, Eric and Miri, Ali and Sabourin, Robert},
xxurl = {10.1016/j.ins.2012.02.017},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khreich et al. - 2012 - A survey of techniques for incremental learning of HMM parameters.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {incremental learning},
month = {aug},
pages = {105--130},
publisher = {Elsevier Inc.},
title = {{A survey of techniques for incremental learning of HMM parameters}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002002551200120X},
volume = {197},
year = {2012}
}
@inproceedings{Luo2012,
abstract = {High-dimensional similarity join (HDSJ) is critical for many novel applications in the domain of mobile data management. Nowadays, performing HDSJs efficiently faces two challenges. First, the scale of datasets is increasing rapidly, making parallel computing on a scalable platform a must. Second, the dimensionality of the data can be up to hundreds or even thousands, which brings about the issue of dimensionality curse. In this paper, we address these challenges and study how to perform parallel HDSJs efficiently in the MapReduce paradigm. Particularly, we propose a cost model to demonstrate that it is important to take both communication and computation costs into account as dimensionality and data volume increases. To this end, we propose DAA (Dimension Aggregation Approximation), an efficient compression approach that can help significantly reduce both these costs when performing parallel HDSJs. Moreover, we design DAA-based parallel HDSJ algorithms which can scale up to massive data sizes and very high dimensionality. We perform extensive experiments using both synthetic and real datasets to evaluate the speedup and the scale up of our algorithms. {\textcopyright} 2012 IEEE.},
author = {Luo, Wuman and Tan, Haoyu and Mao, Huajian and Ni, Lionel M.},
booktitle = {Proceedings - 2012 IEEE 13th International Conference on Mobile Data Management, MDM 2012},
xxurl = {10.1109/MDM.2012.25},
isbn = {9780769547138},
title = {{Efficient similarity joins on massive high-dimensional datasets using MapReduce}},
year = {2012}
}
@article{Frinken2010,
author = {Frinken, Volkmar and Fischer, Andreas and Bunke, Horst},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frinken, Fischer, Bunke - 2010 - A novel word spotting algorithm using bidirectional long short-term memory neural networks.pdf:pdf},
journal = {Artificial Neural Networks in Pattern {\ldots}},
keywords = {as such it performs,derived from a neural,documents is described,e,i,ing recognition,it is,it is not,necessary for a keyword,network based system for,spotting system for handwritten,template-free spotting,the keyword spot-,to appear in the,training set,unconstrained handwrit-},
pages = {185--196},
title = {{A novel word spotting algorithm using bidirectional long short-term memory neural networks}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-12159-3{\_}17},
year = {2010}
}
@article{Cristea,
abstract = {An original tetrahedral representation of the Genetic Code (GC) that better describes its structure, degeneration and evolution trends is defined. The possibility to reduce the dimension of the representation by projecting the GC tetrahedron on an adequately oriented plane is also analyzed, leading to some equivalent complex representations of the GC. On these bases, optimal symbolic-to-digital mappings of the linear, nucleic acid strands into real or complex genomic signals are derived at nucleotide, codon and amino acid levels. By converting the sequences of nucleotides and polypeptides into digital genomic signals, this approach offers the possibility to use a large variety of signal processing methods for their handling and analysis. It is also shown that some essential features of the nucleotide sequences can be better extracted using this representation. Specifically, the paper reports for the first time the existence of a global helicoidal wrapping of the complex representations of the bases along DNA sequences, a large scale trend of genomic signals. New tools for genomic signal analysis, including the use of phase, aggregated phase, unwrapped phase, sequence path, stem representation of components' relative frequencies, as well as analysis of the transitions are introduced at the nucleotide, codon and amino acid levels, and in a multiresolution approach.},
author = {Cristea, P D},
issn = {1582-1838},
journal = {Journal of cellular and molecular medicine},
keywords = {Amino Acid Sequence,Base Sequence,Chromosomes,Codon,DNA,DNA: chemistry,Genetic Code,Genome,Genomics,Human,Humans,Models,Molecular,Nucleic Acid Conformation,Pair 11,Protein Biosynthesis,Protein Sorting Signals,Protein Sorting Signals: genetics},
month = {jan},
number = {2},
pages = {279--303},
pmid = {12169214},
title = {{Conversion of nucleotides sequences into genomic signals.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12169214},
volume = {6},
year = {2002}
}
@article{Kalchbrenner2015,
abstract = {This paper introduces Grid Long Short-Term Memory, a network of LSTM cells arranged in a multidimensional grid that can be applied to vectors, sequences or higher dimensional data such as images. The network differs from existing deep LSTM architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data. The network provides a unified way of using LSTM for both deep and sequential computation. We apply the model to algorithmic tasks such as 15-digit integer addition and sequence memorization, where it is able to significantly outperform the standard LSTM. We then give results for two empirical tasks. We find that 2D Grid LSTM achieves 1.47 bits per character on the Wikipedia character prediction benchmark, which is state-of-the-art among neural approaches. In addition, we use the Grid LSTM to define a novel two-dimensional translation model, the Reencoder, and show that it outperforms a phrase-based reference system on a Chinese-to-English translation task.},
archivePrefix = {arXiv},
arxivId = {1507.01526},
author = {Kalchbrenner, Nal and Danihelka, Ivo and Graves, Alex},
eprint = {1507.01526},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalchbrenner, Danihelka, Graves - 2015 - Grid Long Short-Term Memory.pdf:pdf},
pages = {1--15},
title = {{Grid Long Short-Term Memory}},
url = {http://arxiv.org/abs/1507.01526},
year = {2015}
}
@misc{phonetic_wikipedia,
title = {{International Phonetic Alphabet}},
url = {https://en.wikipedia.org/wiki/International{\_}Phonetic{\_}Alphabet}
}
@inproceedings{Weiss2009,
author = {Weiss, Yair and Torralba, Antonio and Fergus, Rob},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weiss, Torralba, Fergus - 2009 - Spectral Hashing.pdf:pdf},
pages = {1753--1760},
title = {{Spectral Hashing}},
url = {http://papers.nips.cc/paper/3383-spectral-hashing},
year = {2009}
}
@inproceedings{Ahmed2012a,
abstract = {In this paper we propose a novel part-based method for the extraction of text touching graphic components. The Speeded Up Robust Features (SURF) are used to localize the text components and distinguish them from graphics. We introduce several post-processing steps to finally detect the text. We have tested our method on a publicly available data set of architectural floor plans and on real geographical maps. On floor plans we have located more than 95{\%}ofthe text components which were not identified as text beforehand because they were touching graphic components.},
author = {Ahmed, Sheraz and Liwicki, Marcus and Dengel, Andreas},
booktitle = {2012 10th IAPR International Workshop on Document Analysis Systems},
xxurl = {10.1109/DAS.2012.39},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Liwicki, Dengel - 2012 - Extraction of text touching graphics using SURF(2).pdf:pdf},
isbn = {978-0-7695-4661-2},
keywords = {SURF,Text extraction,Text/graphics segmentation},
month = {mar},
number = {March},
pages = {349--353},
publisher = {IEEE},
title = {{Extraction of Text Touching Graphics Using SURF}},
year = {2012}
}
@article{Li2014a,
author = {Li, Hailin and Yang, Libin},
xxurl = {10.1007/s10844-014-0306-7},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Yang - 2014 - Extensions and relationships of some existing lower-bound functions for dynamic time warping.pdf:pdf},
issn = {0925-9902},
journal = {Journal of Intelligent Information Systems},
keywords = {dynamic time warping,lower-bound function,similarity measure,time series data mining},
number = {1},
pages = {59--79},
title = {{Extensions and relationships of some existing lower-bound functions for dynamic time warping}},
url = {http://link.springer.com/10.1007/s10844-014-0306-7},
volume = {43},
year = {2014}
}
@article{Zhang2014,
author = {Zhang, Xi and Pal, Umapada and Tan, Chew Lim},
xxurl = {10.1109/ICFHR.2014.70},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Pal, Tan - 2014 - Segmentation-Free Keyword Spotting for Bangla Handwritten Documents.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Pal, Tan - 2014 - Segmentation-Free Keyword Spotting for Bangla Handwritten Documents(2).pdf:pdf},
isbn = {978-1-4799-4334-0},
journal = {2014 14th International Conference on Frontiers in Handwriting Recognition},
pages = {381--386},
title = {{Segmentation-Free Keyword Spotting for Bangla Handwritten Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6981049},
year = {2014}
}
@article{Su2009,
abstract = {Character segmentation and recognition are two difficult key steps in extracting literal information from images. This paper proposes a method for effective segmentation and recognition of characters in complicated graphical contexts of line drawings. Text pixels are first separated from intersecting non-text objects with the holistic graphic recognition algorithm, and then character boxes are grouped into strings using various contextual constraints. The individual characters of a string are recognized with an adaptive recognition-based segmentation scheme based on the structural stroke characteristics. The efficiency and stability of the proposed method have been shown by the experiment results on practical drawings.},
author = {Su, Feng and Cai, Shijie},
xxurl = {10.1109/CISP.2009.5305624},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su, Cai - 2009 - A character extraction and recognition method for line drawings.pdf:pdf},
isbn = {9781424441310},
journal = {Proceedings of the 2009 2nd International Congress on Image and Signal Processing, CISP'09},
keywords = {Character recognition,Line drawing,Segmentation,Text/graphics separation},
pages = {0--4},
title = {{A character extraction and recognition method for line drawings}},
year = {2009}
}
@article{Miyoshi2013,
author = {Miyoshi, Toshinori and Nagasaki, Takeshi and Shinjo, Hiroshi},
xxurl = {10.1109/ICDAR.2013.213},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miyoshi, Nagasaki, Shinjo - 2013 - Moment-Based Character-Normalization Methods Using a Contour Image Combined with an Original Image.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1066--1070},
publisher = {Ieee},
title = {{Moment-Based Character-Normalization Methods Using a Contour Image Combined with an Original Image}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628778},
year = {2013}
}
@article{Renakova2013,
author = {Renakova, Marta and Tencer, Lukas and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.78},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Renakova, Tencer, Cheriet - 2013 - ARTIST ART-2A Driven Generation of Fuzzy Rules for Online Handwritten Gesture Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {and,handwritten gestures,incremental learning,neuro-fuzzy models,online learning,part is very important,recognition system the learning,recursive least squares,rls,sugeno,takagi-,ts},
month = {aug},
pages = {354--358},
publisher = {Ieee},
title = {{ARTIST: ART-2A Driven Generation of Fuzzy Rules for Online Handwritten Gesture Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628643},
year = {2013}
}
@article{Yeh2016,
abstract = {In this paper, we propose a novel method for image inpainting based on a Deep Convolutional Generative Adversarial Network (DCGAN). We define a loss function consisting of two parts: (1) a contextual loss that preserves similarity between the input corrupted image and the recovered image, and (2) a perceptual loss that ensures a perceptually realistic output image. Given a corrupted image with missing values, we use back-propagation on this loss to map the corrupted image to a smaller latent space. The mapped vector is then passed through the generative model to predict the missing content. The proposed framework is evaluated on the CelebA and SVHN datasets for two challenging inpainting tasks with random 80{\%} corruption and large blocky corruption. Experiments show that our method can successfully predict semantic information in the missing region and achieve pixel-level photorealism, which is impossible by almost all existing methods.},
archivePrefix = {arXiv},
arxivId = {1607.07539},
author = {Yeh, Raymond and Chen, Chen and Lim, Teck Yian and Hasegawa-Johnson, Mark and Do, Minh N.},
eprint = {1607.07539},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh et al. - 2016 - Semantic Image Inpainting with Perceptual and Contextual Losses.pdf:pdf},
title = {{Semantic Image Inpainting with Perceptual and Contextual Losses}},
url = {http://arxiv.org/abs/1607.07539},
year = {2016}
}
@article{Salvador,
author = {Salvador, Stan and Chan, Philip},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salvador, Chan - 2007 - FastDTW Toward Accurate Dynamic Time Warping in Linear Time and Space.pdf:pdf},
journal = {Intell. Data Anal.},
keywords = {dynamic time warping,time series},
number = {5},
pages = {561--580},
title = {{FastDTW : Toward Accurate Dynamic Time Warping in Linear Time and Space}},
volume = {11},
year = {2007}
}
@misc{lavenstien,
author = {Levenshtein},
keywords = {algorithmu,approximate,error tolerant,fault-tolerant,fuzzy,levenshtein,levenstein,levensthain,levensthein,lewenstein,online demo,phonetic,search,soundex,string matching},
title = {{Efficient Implementation of the Levenshtein-Algorithm}},
url = {http://www.levenshtein.net/index.html},
urldate = {2015-01-01}
}
@inproceedings{Kessentini2013,
abstract = {In this paper, we propose a novel system for word spotting and regular expression detection in Handwritten documents. The proposed approach is lexicon-free, i.e., able to spot arbitrary keywords that are not required to be known at the training stage. Furthermore, the proposed system is segmentation-free, i.e., text lines are not required to be segmented into words. The originalities of our approach is twofold. First we propose a new filler model which allows to speed-up the decoding process. Second, we extend the methodology to search for regular expressions. The system has been evaluated on a public handwritten document database used for the 2011 ICDAR handwriting recognition competitions.},
author = {Kessentini, Yousri and Chatelain, Clement and Paquet, Thierry},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kessentini, Chatelain, Paquet - 2013 - Word Spotting and Regular Expression Detection in Handwritten Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
issn = {1520-5363},
keywords = {2011 ICDAR handwriting recognition competitions,Computational modeling,Databases,Decoding,Handwriting recognition,Handwritten Documents,Hidden Markov models,Training,Vocabulary,decoding process,document image processing,filler model,image coding,object detection,public handwritten document database,regular expression,regular expression detection,visual databases,word spotting,wordspotting},
month = {aug},
pages = {516--520},
publisher = {IEEE},
shorttitle = {Document Analysis and Recognition (ICDAR), 2013 12},
title = {{Word Spotting and Regular Expression Detection in Handwritten Documents}},
year = {2013}
}
@article{Latecki2007b,
abstract = {We consider the problem of partial shape matching. We propose to transform shapes into sequences and utilize an algorithm that determines a subsequence of a target sequence that best matches a query. In the proposed algorithm we map the problem of the best matching subsequence to the problem of a cheapest path in a directed acyclic graph (DAG). The approach allows us to compute the optimal scale and translation of sequence values, which is a nontrivial problem in the case of subsequence matching. Our experimental results demonstrate that the proposed algorithm outperforms the commonly used techniques in retrieval accuracy.},
author = {Latecki, Longin Jan and Megalooikonomou, Vasileios and Wang, Qiang and Yu, Deguang},
xxurl = {10.1016/j.patcog.2007.03.004},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Latecki et al. - 2007 - r ' s Au th o rs on Au th o r ' s pe rs on.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Latecki et al. - 2007 - An elastic partial shape matching technique.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {DAG,Sequences matching,Shape similarity,Shortest path,a shape,and calculating its similarity,dag,most of them require,of shape descriptors,sequences matching,shape matching deals with,shape similarity,shortest path,the presence of the,the problem of describing,there are a huge,to others,variety},
month = {nov},
number = {11},
pages = {3069--3080},
title = {{An elastic partial shape matching technique}},
volume = {40},
year = {2007}
}
@article{Wahl1982,
author = {Wahl, Friedrich M. and Wong, Kwan Y. and Casey, Richard G.},
xxurl = {10.1016/0146-664X(82)90059-4},
issn = {0146664X},
journal = {Computer Graphics and Image Processing},
month = {dec},
number = {4},
pages = {375--390},
title = {{Block segmentation and text extraction in mixed text/image documents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0146664X82900594},
volume = {20},
year = {1982}
}
@article{Rusinol2009,
abstract = {In this paper we present a method for document categorization which processes incoming document images such as invoices or receipts. The categorization of these document images is done in terms of the presence of a certain graphical logo detected without segmentation. The graphical logos are described by a set of local features and the categorization of the documents is performed by the use of a bag-of-words model. Spatial coherence rules are added to reinforce the correct category hypothesis, aiming also to spot the logo inside the document image. Experiments which demonstrate the effectiveness of this system on a large set of real data are presented.},
author = {Rusi{\~{n}}ol, Mar{\c{c}}al and Llad{\'{o}}s, Josep},
xxurl = {10.1109/ICDAR.2009.103},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusi{\~{n}}ol, Llad{\'{o}}s - 2009 - Logo spotting by a bag-of-words approach for document categorization.pdf:pdf},
isbn = {9780769537252},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {imp-logo-paper},
mendeley-tags = {imp-logo-paper},
pages = {111--115},
title = {{Logo spotting by a bag-of-words approach for document categorization}},
year = {2009}
}
@article{Shivakumara2013,
author = {Shivakumara, P. and Basavaraju, H.T. and Guru, D.S. and Tan, C.L.},
xxurl = {10.1109/ICDAR.2013.123},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shivakumara et al. - 2013 - Detection of Curved Text in Video Quad Tree Based Method.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {clustering,curvedtext detection,k-means,quad tree technique,symmetry verification,text enhancement},
month = {aug},
pages = {594--598},
publisher = {Ieee},
title = {{Detection of Curved Text in Video: Quad Tree Based Method}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628688},
year = {2013}
}
@article{Shi2013,
author = {Shi, Zhixin and Setlur, Srirangaraj and Govindaraju, Venu},
xxurl = {10.1109/ICDAR.2013.195},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi, Setlur, Govindaraju - 2013 - A Model Based Framework for Table Processing in Degraded Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {963--967},
publisher = {Ieee},
title = {{A Model Based Framework for Table Processing in Degraded Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628760},
year = {2013}
}
@article{Kolter2008,
abstract = {Linear algebra provides a way of compactly representing and operating on sets of linear equations. For example, consider the following system of equations: 4x 1 − 5x 2 = −13 −2x 1 + 3x 2 = 9 . This is two equations and two variables, so as you know from high school algebra, you can find a unique solution for x 1 and x 2 (unless the equations are somehow degenerate, for example if the second equation is simply a multiple of the first, but in the case above there is in fact a unique solution). In matrix notation, we can write the system more compactly as: Ax = b with A = 4 −5 −2 3 , b = 13 −9 . As we will see shortly, there are many advantages (including the obvious space savings) to analyzing linear equations in this form.},
author = {Kolter, Zico},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolter - 2008 - Linear algebra review and reference.pdf:pdf},
journal = {Available online: http},
pages = {1--20},
title = {{Linear algebra review and reference}},
url = {http://eng.uok.ac.ir/mfathi/Courses/Advanced Eng Math/cs229-linalg.pdf},
year = {2008}
}
@article{Malik2013c,
author = {Malik, Muhammad Imran and Liwicki, Marcus and Alewijnse, Linda and Ohyama, Wataru and Blumenstein, Michael and Found, Bryan},
xxurl = {10.1109/ICDAR.2013.220},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malik et al. - 2013 - ICDAR 2013 Competitions on Signature Verification and Writer Identification for On- and Offline Skilled Forgeries.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1477--1483},
publisher = {Ieee},
title = {{ICDAR 2013 Competitions on Signature Verification and Writer Identification for On- and Offline Skilled Forgeries (SigWiComp 2013)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628858},
year = {2013}
}
@article{Yu2013,
author = {Yu, Kun and Epps, Julien and Chen, Fang},
xxurl = {10.1109/ICDAR.2013.225},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Epps, Chen - 2013 - Mental Workload Classification via Online Writing Features.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {curvature,load level measurement,mental workload,online feature examination},
month = {aug},
pages = {1110--1114},
publisher = {Ieee},
title = {{Mental Workload Classification via Online Writing Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628786},
year = {2013}
}
@article{Djeddi2013,
author = {Djeddi, Chawki and Siddiqi, Imran and Souici-Meslati, Labiba and Ennaji, Abdellatif},
xxurl = {10.1109/ICDAR.2013.92},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Djeddi et al. - 2013 - Codebook for Writer Characterization A Vocabulary of Patterns or a Mere Representation Space.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {codebook,handwritten samples,synthetic patterns,writer identification},
month = {aug},
pages = {423--427},
publisher = {Ieee},
title = {{Codebook for Writer Characterization: A Vocabulary of Patterns or a Mere Representation Space?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628657},
year = {2013}
}
@article{Xiang2008,
annote = {From Duplicate 1 ( 

Incremental and adaptive abnormal behaviour detection

- Xiang, Tao; Gong, Shaogang )

},
author = {Xiang, Tao and Gong, Shaogang},
xxurl = {10.1016/j.cviu.2007.06.004},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiang, Gong - 2008 - Incremental and adaptive abnormal behaviour detection.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiang, Gong - 2008 - Incremental and adaptive abnormal behaviour detection(2).pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {abnormality detection,behaviour analysis and recognition,dynamic bayesian networks,dynamic scene,dynamic scene modelling,incre-,incremental learning,likelihood ratio test,mental learning,modelling,visual surveillance},
month = {jul},
number = {1},
pages = {59--73},
title = {{Incremental and adaptive abnormal behaviour detection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314208000155},
volume = {111},
year = {2008}
}
@article{Limited2013,
abstract = {Use of time complexity makes it easy to estimate the running time of a program. Performing an accurate calculation of a program's operation time is a very labour-intensive process (it depends on the compiler and the type of computer or speed of the processor). Therefore, we will not make an accurate measurement; just a measurement of a certain order of magnitude. Complexity can be viewed as the maximum number of primitive operations that a program may execute. Regular operations are single additions, multiplications, assignments etc. We may leave some operations uncounted and concentrate on those that are performed the largest number of times. Such operations are referred to as dominant. The number of dominant operations depends on the specific input data. We usually want to know how the performance time depends on a particular aspect of the data. This is most frequently the data size, but it can also be the size of a square matrix or the value of some input variable. 3.1: Which is the dominant operation? 1 def dominant(n): 2 result = 0 3 for i in xrange(n): 4 result += 1 5 return result The operation in line 4 is dominant and will be executed n times. The complexity is described in Big-O notation: in this case O(n) — linear complexity. The complexity specifies the order of magnitude within which the program will perform its operations. More precisely, in the case of O(n), the program may perform c {\textperiodcentered} n opera-tions, where c is a constant; however, it may not perform n 2 operations, since this involves a di order of magnitude of data. In other words, when calculating the complexity we},
author = {Limited, Codility and Reserved, All Rights},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Limited, Reserved - 2013 - Time complexity.pdf:pdf},
pages = {1--4},
title = {{Time complexity}},
year = {2013}
}
@article{Callot2001,
author = {Callot, Olivier},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Callot - 2001 - Revised C Coding Conventions.pdf:pdf},
number = {April},
title = {{Revised C ++ Coding Conventions}},
year = {2001}
}
@article{Schmid1998,
abstract = {Many computer vision tasks rely on feature extraction. Interest$\backslash$npoints are such features. This paper shows that interest points are$\backslash$ngeometrically stable under different transformations and have high$\backslash$ninformation content (distinctiveness). These two properties make$\backslash$ninterest points very successful in the contest of image matching. To$\backslash$nmeasure these two properties quantitatively, we introduce two evaluation$\backslash$ncriteria: repeatability rate and information content. The quality of the$\backslash$ninterest points depends on the detector used. In this paper several$\backslash$ndetectors are compared according to the criteria specified above. We$\backslash$ndetermine which detector gives the best results and show that it$\backslash$nsatisfies the criteria well},
author = {Schmid, Cordelia and Mohr, Roger and Bauckhage, Christian},
xxurl = {10.1109/ICCV.1998.710723},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmid, Mohr, Bauckhage - 1998 - Comparing and Evaluating Interest Points.pdf:pdf},
isbn = {81-7319-221-9},
journal = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
pages = {230--235},
title = {{Comparing and Evaluating Interest Points}},
year = {1998}
}
@article{Chen2012,
abstract = {In order to lower the consumed threshold, a practical image preprocessing method was proposed for Quick Response (QR) barcode recognition. It could increase the speed of recognition by this decoder so as to embed this algorithm into mobile terminals. Instead of using the traditional methods such as edge detection and line detection, the encoding characteristic of QR had been used, thus the influence by background noise and geometric distortion was minimized. Moreover, it used alignment patterns to adaptively sample the barcode in terms of regions, which greatly improved the recognition rate. Experimental results demonstrate that the proposed approach can overcome the influence in noise, inhomogeneous light and geometric distortion, what is more, it meets the requirement of decoding in real time.},
author = {Chen, Weibing and Yang, Gaobo and Zhang, Ganglin},
xxurl = {10.2991/emeit.2012.46},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Yang, Zhang - 2012 - A Simple and Efficient Image Pre-processing for QR Decoder.pdf:pdf},
isbn = {978-90-78677-60-4},
journal = {Proceedings of the 2nd International Conference on Electronic and Mechanical Engineering and Information Technology (2012)},
keywords = {2d barcode,a practical image preprocessing,abstract,algorithm into mobile terminals,as to embed this,barcode recognition,binarization,by this decoder so,image preprocessing,in order to lower,instead of using the,it could increase the,localization,method was,proposed for quick response,qr,quick response,speed of recognition,the consumed threshold,traditional},
pages = {234--238},
title = {{A Simple and Efficient Image Pre-processing for QR Decoder}},
url = {http://www.atlantis-press.com/php/paper-details.php?id=3264},
year = {2012}
}
@article{Breuss2007,
abstract = {We describe a new approach to incorporate adaptivity into the partial differential equations (PDE) of morphological dilation and erosion. By multiplication of the image gradient with a space-variant matrix, the speed of the evolution is locally adapted to the data. This is used to create anisotropic morphological evolutions that enhance coherent, flow-like image structures. We show that our adaptive method can be implemented by means of a simple modification of the classical Rouy-Tourin finite difference scheme. Numerical experiments confirm that the proposed dilations and erosions are capable of real anisotropic behaviour that can be used for closing interrupted lines.},
author = {Breuss, M and Burgeth, B and Weickert, J},
xxurl = {10.1067/j.cpsurg.2004.04.002},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breuss, Burgeth, Weickert - 2007 - Anisotropic continuous-scale morphology.pdf:pdf},
isbn = {9783540728481},
issn = {03029743},
journal = {Pattern Recognition and Image Analysis. Proceedings Third Iberian Conference, IbPRIA 2007},
keywords = {finite difference methods,gradient methods,image p},
number = {3},
pages = {515--522},
title = {{Anisotropic continuous-scale morphology}},
volume = {2},
year = {2007}
}
@article{Toyama2013,
author = {Toyama, Takumi and Dengel, Andreas and Suzuki, Wakana and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.15},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Toyama et al. - 2013 - Wearable Reading Assist System Augmented Reality Document Combining Document Retrieval and Eye Tracking.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {30--34},
publisher = {Ieee},
title = {{Wearable Reading Assist System: Augmented Reality Document Combining Document Retrieval and Eye Tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628580},
year = {2013}
}
@article{Clausner2013,
author = {Clausner, C. and Pletschacher, S. and Antonacopoulos, a.},
xxurl = {10.1109/ICDAR.2013.141},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Clausner, Pletschacher, Antonacopoulos - 2013 - The Significance of Reading Order in Document Recognition and Its Evaluation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {detection,document layout analysis,performance evaluation,reading order,reading order evaluation},
month = {aug},
pages = {688--692},
publisher = {Ieee},
title = {{The Significance of Reading Order in Document Recognition and Its Evaluation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628706},
year = {2013}
}
@article{Keshet2009,
abstract = {This paper proposes a new approach for keyword spotting, which is based on large margin and kernel methods rather than on HMMs. Unlike previous approaches, the proposed method employs a discriminative learning procedure, in which the learning phase aims at achieving a high area under the ROC curve, as this quantity is the most common measure to evaluate keyword spotters. The keyword spotter we devise is based on mapping the input acoustic representation of the speech utterance along with the target keyword into a vector-space. Building on techniques used for large margin and kernel methods for predicting whole sequences, our keyword spotter distills to a classifier in this vector-space, which separates speech utterances in which the keyword is uttered from speech utterances in which the keyword is not uttered. We describe a simple iterative algorithm for training the keyword spotter and discuss its formal properties, showing theoretically that it attains high area under the ROC curve. Experiments on read speech with the TIMIT corpus show that the resulted discriminative system outperforms the conventional context-independent HMM-based system. Further experiments using the TIMIT trained model, but tested on both read (HTIMIT, WSJ) and spontaneous speech (OGI Stories), show that without further training or adaptation to the new corpus our discriminative system outperforms the conventional context-independent HMM-based system.},
author = {Keshet, Joseph and Grangier, David and Bengio, Samy},
xxurl = {10.1016/j.specom.2008.10.002},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keshet, Grangier, Bengio - 2009 - Discriminative keyword spotting.pdf:pdf},
issn = {01676393},
journal = {Speech Communication},
month = {apr},
number = {4},
pages = {317--329},
title = {{Discriminative keyword spotting}},
url = {http://www.sciencedirect.com/science/article/pii/S0167639308001489},
volume = {51},
year = {2009}
}
@inproceedings{Kurakin2019,
abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work has assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from a cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.},
archivePrefix = {arXiv},
arxivId = {1607.02533},
author = {Kurakin, Alexey and Goodfellow, Ian J. and Bengio, Samy},
booktitle = {5th International Conference on Learning Representations, ICLR 2017 - Workshop Track Proceedings},
eprint = {1607.02533},
title = {{Adversarial examples in the physical world}},
year = {2019}
}
@inproceedings{Le2013a,
abstract = {Digital document categorization based on logo spotting and recognition has raised a great interest in the research community because logos in documents are sources of information for categorizing documents with low costs. In this paper, we present an approach to improve the result of our method for logo spotting and recognition based on key point matching and presented in our previous paper [7]. First, the key points from both the query document images and a given set of logos (logo gallery) are extracted and described by SIFT, and are matched in the SIFT feature space. Secondly, logo segmentation is performed using spatial density-based clustering. The contribution of this paper is to add a third step where homography is used to filter the matched key points as a post-processing. And finally, in the decision stage, logo classification is performed by using an accumulating histogram. Our approach is tested using a well-known benchmark database of real world documents containing logos, and achieves good performances compared to state-of-the-art approaches.},
author = {Le, Viet Phuong and Visani, Muriel and Tran, Cao De and Ogier, Jean Marc},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
xxurl = {10.1109/ICDAR.2013.61},
isbn = {978-0-7695-4999-6},
issn = {15205363},
keywords = {document analysis,homography,logo spotting,pattern recognition},
pages = {270--274},
title = {{Improving logo spotting and matching for document categorization by a post-filter based on homography}},
year = {2013}
}
@article{Cruz2013,
author = {Cruz, Francisco and Terrades, Oriol Ramos},
xxurl = {10.1109/ICDAR.2013.147},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cruz, Terrades - 2013 - Handwritten Line Detection via an EM Algorithm.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {718--722},
publisher = {Ieee},
title = {{Handwritten Line Detection via an EM Algorithm}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628712},
year = {2013}
}
@article{Sun2014,
abstract = {Manifold learning seeks low-dimensional repre- sentations of high-dimensional data. The main tactics have been exploring the geometry in an input data space and an output embedding space. We develop a manifold learning the- ory in a hypothesis space consisting of models. A model means a specific instance of a collec- tion of points, e.g., the input data collectively or the output embedding collectively. The semi- Riemannian metric of this hypothesis space is uniquely derived in closed form based on the in- formation geometry of probability distributions. There, manifold learning is interpreted as a tra- jectory of intermediate models. The volume of a continuous region reveals an amount of informa- tion. It can be measured to define model com- plexity and embedding quality. This provides deep unified perspectives of manifold learning theory. Manifold},
author = {Sun, Ke and Marchand-Maillet, St{\'{e}}phane},
isbn = {9781634393973},
journal = {Icml},
pages = {1--9},
title = {{An Information Geometry of Statistical Manifold Learning}},
volume = {32},
year = {2014}
}
@inproceedings{Alcantarilla2013,
abstract = {We propose a novel and fast multiscale feature detection and description approach that exploits the benefits of nonlinear scale spaces. Previous attempts to detect and describe features in nonlinear scale spaces are highly time consuming due to the computational burden of creating the nonlinear scale space. In this paper we propose to use recent numerical schemes called Fast Explicit Diffusion (FED) embedded in a pyramidal framework to dramatically speed-up feature detection in nonlinear scale spaces. In addition, we introduce a Modified-Local Difference Binary (M-LDB) descriptor that is highly efficient, exploits gradient information from the nonlinear scale space, is scale and rotation invariant and has low storage requirements. We present an extensive evaluation that shows the excellent compromise between speed and performance of our approach compared to state-of-the-art methods such as BRISK, ORB, SURF, SIFT and KAZE.},
author = {Alcantarilla, Pablo and Nuevo, Jesus and Bartoli, Adrien},
booktitle = {Procedings of the British Machine Vision Conference 2013},
xxurl = {10.5244/C.27.13},
isbn = {1-901725-49-9},
pages = {13.1--13.11},
title = {{Fast Explicit Diffusion for Accelerated Features in Nonlinear Scale Spaces}},
url = {http://www.bmva.org/bmvc/2013/Papers/paper0013/index.html},
year = {2013}
}
@article{Chen2013a,
author = {Chen, Kai and Yin, Fei and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.194},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Yin, Liu - 2013 - Hybrid Page Segmentation with Efficient Whitespace Rectangles Extraction and Grouping.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {and how to group,in the brief description,in this method,page segmentation,rectangles is large,the number of whitespace,them is not specified,tion,whitespace rectangles extrac-,whitespace rectangles grouping},
month = {aug},
pages = {958--962},
publisher = {Ieee},
title = {{Hybrid Page Segmentation with Efficient Whitespace Rectangles Extraction and Grouping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628759},
year = {2013}
}
@article{Roe2013,
author = {Roe, Edward and a.B. Mello, Carlos},
xxurl = {10.1109/ICDAR.2013.48},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roe, Mello - 2013 - Binarization of Color Historical Document Images Using Local Image Equalization and XDoG.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {around each,binarization,color,color image processing,color restoration,constancy,differences in illumination,image restoration,the equalization is applied,the first time locally,twice,using a small neighborhood},
month = {aug},
pages = {205--209},
publisher = {Ieee},
title = {{Binarization of Color Historical Document Images Using Local Image Equalization and XDoG}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628613},
year = {2013}
}
@article{Luo2013,
author = {Luo, Xi and Ohyama, Wataru and Wakabayashi, Tetsushi and Kimura, Fumitaka},
xxurl = {10.1109/ICDAR.2013.73},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - 2013 - Automatic Chinese Text Classification Using Character-Based and Word-Based Approach.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {4,and s,categorization,chen et al,chinese text classification,component analysis,dimension reduction,dimensionality and sparse problem,feature transformation,gram,j,n-,principal,support vector machine},
month = {aug},
pages = {329--333},
publisher = {Ieee},
title = {{Automatic Chinese Text Classification Using Character-Based and Word-Based Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628638},
year = {2013}
}
@article{Rosin1999,
abstract = {We describe methods to measure the following properties of gray level corners: subtended angle, orientation, contrast, bluntness (or rounding of the apex), and boundary curvature (for cusps). Unlike most of the published methods for extracting these properties these new methods are relatively simple, efficient, and robust. They rely on the corner being predetected by a standard operator, thus making the measurement problem more tractable. Using 13,000 synthetic images the methods are assessed over a range of conditions: corners of varying orientations and subtended angles, as well as different degrees of noise. ?? 1999 Academic Press.},
author = {Rosin, Paul L.},
xxurl = {10.1006/cviu.1998.0719},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosin - 1999 - Measuring Corner Properties.pdf:pdf},
isbn = {0952189879},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
number = {2},
pages = {291--307},
title = {{Measuring Corner Properties}},
volume = {73},
year = {1999}
}
@article{Huang2013,
author = {Huang, Rong and Shivakumara, Palaiahnakote and Uchida, Seiichi},
xxurl = {10.1109/ICDAR.2013.99},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Shivakumara, Uchida - 2013 - Scene Character Detection by an Edge-Ray Filter.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {462--466},
publisher = {Ieee},
title = {{Scene Character Detection by an Edge-Ray Filter}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628664},
year = {2013}
}
@article{Dutta2013,
author = {Dutta, Anjan and Llados, Josep and Bunke, Horst and Pal, Umapada},
xxurl = {10.1109/ICDAR.2013.215},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dutta et al. - 2013 - Near Convex Region Adjacency Graph and Approximate Neighborhood String Matching for Symbol Spotting in Graphical D.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {region 1},
pages = {1078--1082},
publisher = {Ieee},
title = {{Near Convex Region Adjacency Graph and Approximate Neighborhood String Matching for Symbol Spotting in Graphical Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628780},
year = {2013}
}
@article{Saleem2009,
author = {Saleem, Shirin and Cao, Huaigu and Subramanian, Krishna and Kamali, Matin and Prasad, Rohit and Natarajan, Prem},
xxurl = {10.1109/ICDAR.2009.282},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saleem et al. - 2009 - Improvements in BBN's HMM-Based Offline Arabic Handwriting Recognition System.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
pages = {773--777},
publisher = {Ieee},
title = {{Improvements in BBN's HMM-Based Offline Arabic Handwriting Recognition System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277506},
year = {2009}
}
@article{Stamatopoulos2009a,
abstract = {One of the major challenges in camera document analysis is to deal with the page curl and perspective distortions. In spite of the prevalence of dewarping techniques, no standard for their performance evaluation method exists with most of the evaluation done to concentrate in visual pleasing impressions. This paper presents an objective evaluation methodology for document image dewarping techniques. First, manually selected sets of points of the initial warped image are matched with the corresponding points of the dewarping result using the scale invariant feature transform (SIFT). Each set corresponds to a representative text line of the image. Then, based on cubic polynomial curves that fit to the selected text lines, a comprehensive measure which reflects the entire performance of a dewarping technique in a concise quantitative manner is calculated. Experiments applying the proposed performance evaluation methodology on two state of the art dewarping techniques as well as a commercial package are presented.},
author = {Stamatopoulos, N. and Gatos, B. and Pratikakis, I.},
xxurl = {10.1109/ICDAR.2009.160},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamatopoulos, Gatos, Pratikakis - 2009 - A methodology for document image dewarping techniques performance evaluation.pdf:pdf},
isbn = {9780769537252},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
number = {i},
pages = {956--960},
title = {{A methodology for document image dewarping techniques performance evaluation}},
year = {2009}
}
@article{Ma2016,
author = {Ma, Youzhong and Meng, Xiaofeng and Wang, Shaoya},
xxurl = {10.1002/cpe.3663},
issn = {15320626},
journal = {Concurrency and Computation: Practice and Experience},
keywords = {MapReduce,high‐dimensional data,piecewise aggregate approximation,similarity join,symbolic aggregate approximation},
month = {jan},
number = {1},
pages = {166--183},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Parallel similarity joins on massive high-dimensional data using MapReduce}},
url = {http://xxurl.wiley.com/10.1002/cpe.3663},
volume = {28},
year = {2016}
}
@article{Edwards,
author = {{Edwards, J. Teh, Y. W. Forsyth, D. Bock, R. Maire, M. Vesom}, G.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edwards, J. Teh, Y. W. Forsyth, D. Bock, R. Maire, M. Vesom - 2004 - Making latin manuscripts searchable using gHMM's.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {385--392},
title = {{Making latin manuscripts searchable using gHMM's}},
volume = {17},
year = {2004}
}
@article{Gil2005,
abstract = {Anisotropic differential operators are widely used in image enhancement processes. Recently, their property of smoothly extending functions to the whole image domain has begun to be exploited. Strong ellipticity of differential operators is a requirement that ensures existence of a unique solution. This condition is too restrictive for operators designed to extend image level sets: their own functionality implies that they should restrict to some vector field. The diffusion tensor that defines the diffusion operator links anisotropic processes with Riemmanian manifolds. In this context, degeneracy implies restricting diffusion to the varieties generated by the vector fields of positive eigenvalues, provided that an integrability condition is satisfied. We will use that any smooth vector field fulfills this integrability requirement to design line connection algorithms for contour completion. As application we present a segmenting strategy that assures convergent snakes whatever the geometry of the object to be modelled is. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
author = {Gil, Debora and Radeva, Petia},
xxurl = {10.1016/j.cviu.2004.12.001},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gil, Radeva - 2005 - Extending anisotropic operators to recover smooth shapes.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Contour completion,Differential operators,Functional extension,Riemmanian manifolds,Snake segmentation},
number = {1},
pages = {110--125},
title = {{Extending anisotropic operators to recover smooth shapes}},
volume = {99},
year = {2005}
}
@article{Bouchiha2015,
author = {Bouchiha, Rochdi and Besbes, Kamel},
xxurl = {10.1007/s11760-013-0460-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouchiha, Besbes - 2015 - Comparison of local descriptors for automatic remote sensing image registration.pdf:pdf},
issn = {1863-1703},
journal = {Signal, Image and Video Processing},
month = {feb},
number = {2},
pages = {463--469},
publisher = {Springer London},
title = {{Comparison of local descriptors for automatic remote sensing image registration}},
url = {http://link.springer.com/10.1007/s11760-013-0460-3},
volume = {9},
year = {2015}
}
@article{Nalisnick2013,
author = {Nalisnick, Eric T. and Baird, Henry S.},
xxurl = {10.1109/ICDAR.2013.155},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nalisnick, Baird - 2013 - Extracting Sentiment Networks from Shakespeare's Plays.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {758--762},
publisher = {Ieee},
title = {{Extracting Sentiment Networks from Shakespeare's Plays}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628720},
year = {2013}
}
@article{Rodriguez-Serrano2009,
author = {Rodr{\'{i}}guez-Serrano, Jos{\'{e}} a. and Perronnin, Florent},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodr{\'{i}}guez-Serrano, Perronnin - 2009 - Handwritten word-spotting using hidden Markov models and universal vocabularies.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
month = {sep},
number = {9},
pages = {2106--2116},
title = {{Handwritten word-spotting using hidden Markov models and universal vocabularies}},
volume = {42},
year = {2009}
}
@article{Schuster2013b,
author = {Schuster, Daniel and Muthmann, Klemens and Esser, Daniel and Schill, Alexander and Berger, Michael and Weidling, Christoph and Aliyev, Kamil and Hofmeier, Andreas},
xxurl = {10.1109/ICDAR.2013.28},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schuster et al. - 2013 - Intellix -- End-User Trained Information Extraction for Document Archiving.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {101--105},
publisher = {Ieee},
title = {{Intellix -- End-User Trained Information Extraction for Document Archiving}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628593},
year = {2013}
}
@book{Graves2012a,
address = {Berlin, Heidelberg},
author = {Graves, Alex},
xxurl = {10.1007/978-3-642-24797-2},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graves - 2012 - Supervised Sequence Labelling with Recurrent Neural Networks.pdf:pdf},
isbn = {978-3-642-24796-5},
publisher = {Springer Berlin Heidelberg},
series = {Studies in Computational Intelligence},
title = {{Supervised Sequence Labelling with Recurrent Neural Networks}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-24797-2},
volume = {385},
year = {2012}
}
@article{Li2011a,
abstract = {Many researchers focus on dimensionality reduction techniques for the efficient data mining in large time series database. Meanwhile, corresponding distance measures are provided for describing the relationships between two different time series in reduced space. In this paper, we propose a novel approach which we call piecewise cloud approximation (PWCA) to reduce the dimensionality of time series. This representation not only allows dimensionality reduction but also gives a new way to measure the similarity between time series well. Cloud, a qualitative and quantitative transformation model, is used to describe the features of subsequences of time series. Furthermore, a new way to measure the similarity between two cloud models is defined by an overlapping area of their own expectation curves. We demonstrate the performance of the proposed representation and similarity measure used in time series mining tasks, including clustering, classification and similarity search. The results of experiments indicate that PWCA is an effective representation for time series mining. {\textcopyright} 2010 Published by Elsevier B.V. All rights reserved.},
author = {Li, Hailin and Guo, Chonghui},
xxurl = {10.1016/j.knosys.2010.12.008},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Guo - 2011 - Piecewise cloud approximation for time series mining.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Cloud model,Dimensionality reduction,Piecewise cloud approximation,Time series mining,Time series representation},
number = {4},
pages = {492--500},
publisher = {Elsevier B.V.},
title = {{Piecewise cloud approximation for time series mining}},
url = {http://dx.xxurl.org/10.1016/j.knosys.2010.12.008},
volume = {24},
year = {2011}
}
@article{Alaei2013,
abstract = {In this paper, a coarse-to-fine logo detection scheme for document images is proposed. At the coarse level of the proposed scheme, content of a document image is pruned utilizing a decision tree and a small number of features such as frequency probability (FP), Gaussian probability (GP), height, width, and average density computed for patches. The patches are extracted employing the piece-wise painting algorithm (PPA) used for text-line segmentation. The fine level of the proposed scheme refines the detection results by integrating shape context descriptors and a Nearest Neighbor (NN) classifier. We evaluated the proposed approach using a public and two large industrial datasets. From the experiment on Tobacco-800 dataset, the best precision and accuracy of 75.25{\%} and 91.50{\%} were obtained respectively.},
author = {Alaei, Alireza and Delalandre, Mathieu and Girard, Nathalie},
xxurl = {10.1109/ICDAR.2013.250},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaei, Delalandre, Girard - 2013 - Logo detection using painting based representation and probability features.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaei, Delalandre, Girard - 2013 - Logo detection using painting based representation and probability features(2).pdf:pdf},
isbn = {978-0-7695-4999-6},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {Frequency probability,Gaussian probability,Logo detection/recognition,Piece-wise painting,Shape context,frequency probability,gaussian probability,imp-logo-paper,logo detection,piece-wise painting,recognition,shape context},
mendeley-tags = {imp-logo-paper},
month = {aug},
number = {August},
pages = {1235--1239},
publisher = {Ieee},
title = {{Logo detection using painting based representation and probability features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628811},
year = {2013}
}
@article{Likforman-Sulem2008,
abstract = {In this paper, we investigate the application of dynamic Bayesian networks (DBNs) to the recognition of degraded characters. DBNs are an extension of one-dimensional hidden Markov models (HMMs) which can handle several observation and state sequences. In our study, characters are represented by the coupling of two HMM architectures into a single DBN model. The interacting HMMs are a vertical HMM and a horizontal HMM whose observable outputs are the image columns and image rows, respectively. Various couplings are proposed where interactions are achieved through the causal influence between state variables. We compare non-coupled and coupled models on two tasks: the recognition of artificially degraded handwritten digits and the recognition of real degraded old printed characters. Our models show that coupled architectures perform more accurately on degraded characters than basic HMMs, the linear combination of independent HMM scores, as well as discriminative methods such as support vector machines (SVMs). {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Likforman-Sulem, Laurence and Sigelle, Marc},
xxurl = {10.1016/j.patcog.2008.03.022},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Likforman-Sulem, Sigelle - 2008 - Recognition of degraded characters using dynamic Bayesian networks.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Broken character recognition,Dynamic Bayesian networks,Hidden Markov models,Historical documents,Markovian models},
number = {10},
pages = {3092--3103},
title = {{Recognition of degraded characters using dynamic Bayesian networks}},
volume = {41},
year = {2008}
}
@article{Haralick1992,
author = {Haralick, Robert M. and Shapiro, Linda G.},
isbn = {0201569434},
month = {oct},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
title = {{Computer and Robot Vision}},
year = {1992}
}
@misc{conditionalVariationalAE,
title = {{Conditional Variational Autoencoder: Intuition and Implementation - Agustinus Kristiadi's Blog}},
url = {https://wiseodd.github.io/techblog/2016/12/17/conditional-vae/},
urldate = {2018-03-29}
}
@article{Jaderberg,
abstract = {The goal of this work is text spotting in natural images. This is divided into two sequential tasks: detecting words regions in the image, and recognizing the words within these regions. We make the following contributions: first, we develop a Convolutional Neural Network (CNN) classifier that can be used for both tasks. The CNN has a novel architecture that enables efficient feature sharing (by using a number of layers in common) for text detection, character case-sensitive and insensitive classification, and bigram classification. It exceeds the state-of-the-art performance for all of these. Second, we make a number of technical changes over the traditional CNN architectures, including no downsampling for a per-pixel sliding window, and multi-mode learn- ing with a mixture of linear models (maxout). Third, we have a method of automated data mining of Flickr, that generates word and character level annotations. Finally, these components are used together to form an end-to-end, state-of-the-art text spotting system. We evaluate the text-spotting system on two standard benchmarks, the ICDAR Robust Reading data set and the Street View Text data set, and demonstrate improvements over the state-of-the-art on multiple measures.},
author = {Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew},
xxurl = {10.1007/978-3-319-10593-2_34},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaderberg, Vedaldi, Zisserman - 2014 - Deep Features for Text Spotting.pdf:pdf},
isbn = {9783319105925},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 4},
pages = {512--528},
title = {{Deep Features for Text Spotting}},
volume = {8692 LNCS},
year = {2014}
}
@article{Guler2005,
abstract = {This paper describes the application of adaptive neuro-fuzzy inference system (ANFIS) model for classification of electroencephalogram (EEG) signals. Decision making was performed in two stages: feature extraction using the wavelet transform (WT) and the ANFIS trained with the backpropagation gradient descent method in combination with the least squares method. Five types of EEG signals were used as input patterns of the five ANFIS classifiers. To improve diagnostic accuracy, the sixth ANFIS classifier (combining ANFIS) was trained using the outputs of the five ANFIS classifiers as input data. The proposed ANFIS model combined the neural network adaptive capabilities and the fuzzy logic qualitative approach. Some conclusions concerning the saliency of features on classification of the EEG signals were obtained through analysis of the ANFIS. The performance of the ANFIS model was evaluated in terms of training performance and classification accuracies and the results confirmed that the proposed ANFIS model has potential in classifying the EEG signals.},
author = {G{\"{u}}ler, Inan and Ubeyli, Elif Derya},
xxurl = {10.1016/j.jneumeth.2005.04.013},
issn = {0165-0270},
journal = {Journal of neuroscience methods},
pages = {113--121},
pmid = {16054702},
title = {{Adaptive neuro-fuzzy inference system for classification of EEG signals using wavelet coefficients.}},
volume = {148},
year = {2005}
}
@article{Sehad2013,
abstract = {In this paper, we present a promising method for binarization of historical and degraded document images, based on texture features. The proposed method is an adaptive threshold-based. This latter is computed by using a descriptor based on a co-occurrence matrix. The proposed method is tested objectively, using DIBCO dataset degraded documents and subjectively, using a set of ancient degraded documents provided by a national library. The results are satisfactory and promising, and present an improvement to classical methods.},
author = {Sehad, A and Chibani, Y and Cheriet, M and Yaddaden, Y and Ieee},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sehad et al. - 2013 - Ancient degraded document image binarization based on texture features.pdf:pdf},
isbn = {978-953-184-194-8; 978-953-184-187-0},
issn = {18492266},
journal = {2013 8th International Symposium on Image and Signal Processing and Analysis},
keywords = {binarization,degraded document,texture,thresh-},
number = {May},
pages = {189--193},
title = {{Ancient degraded document image binarization based on texture features}},
year = {2013}
}
@article{Hamdani2013,
author = {Hamdani, Mahdi and Mousa, Amr El-Desoky and Ney, Hermann},
xxurl = {10.1109/ICDAR.2013.63},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamdani, Mousa, Ney - 2013 - Open Vocabulary Arabic Handwriting Recognition Using Morphological Decomposition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {280--284},
publisher = {Ieee},
title = {{Open Vocabulary Arabic Handwriting Recognition Using Morphological Decomposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628628},
year = {2013}
}
@inproceedings{Mondal2015,
abstract = {In word spotting literature, classical DTW has been widely employed. However there exists several other improved versions of DTW along with other robust sequence matching techniques. Very few of them have been studied in the context of word spotting and this scarcity of research work is the motivation of the paper. This paper presents a comparative study of classical Dynamic Time Warping (DTW) technique and many of its improved modifications, as well as other sequence matching techniques in the context of word spotting. An experimental study on historical documents is performed to evaluate the behavior of DTW's variants and other sequence matching techniques. A detailed comparative analysis along with wide range of experi- mentation is performed, which shows that classical DTW remains a good choice when there are no segmentation problems and when features are very local. In case of word segmentation errors, Continuous Dynamic Programming (CDP) seems to be a better choice. This research work has introduced several other improved sequence matching algorithms in the context of word spotting, which show interesting and improved results.},
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean-Yves and Pal, Umapada},
booktitle = {ICDAR},
keywords = {Dynamic Time Warping,Sequence matching,Word spotting.},
language = {en},
month = {aug},
title = {{Performance Evaluation of DTW and its Variants for Word Spotting in Degraded Documents}},
year = {2015}
}
@article{Chattopadhyay2013,
author = {Chattopadhyay, T. and Reddy, V. Ramu and Garain, Utpal},
xxurl = {10.1109/ICDAR.2013.237},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chattopadhyay, Reddy, Garain - 2013 - Automatic Selection of Binarization Method for Robust OCR.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-automatic algorithm selection,automatic generation of training,binarization tech-,machine learning,niques},
month = {aug},
pages = {1170--1174},
publisher = {Ieee},
title = {{Automatic Selection of Binarization Method for Robust OCR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628798},
year = {2013}
}
@article{Liu2008,
author = {Liu, Hairong and Latecki, Longin Jan and Liu, Wenyu},
xxurl = {10.1007/s11263-008-0131-y},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Latecki, Liu - 2008 - A Unified Curvature Definition for Regular, Polygonal, and Digital Planar Curves.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {corner detection,curvature,multi-scale},
month = {mar},
number = {1},
pages = {104--124},
title = {{A Unified Curvature Definition for Regular, Polygonal, and Digital Planar Curves}},
url = {http://link.springer.com/10.1007/s11263-008-0131-y},
volume = {80},
year = {2008}
}
@article{Wei2006,
address = {New York, New York, USA},
author = {Wei, Li and Keogh, Eamonn},
xxurl = {10.1145/1150402.1150498},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei, Keogh - 2006 - Semi-supervised time series classification.pdf:pdf},
isbn = {1595933395},
journal = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '06},
keywords = {classification,data,semi-supervised learning,time series},
pages = {748--753},
publisher = {ACM Press},
title = {{Semi-supervised time series classification}},
url = {http://portal.acm.org/citation.cfm?xxurld=1150402.1150498},
year = {2006}
}
@article{Milyaev2013,
author = {Milyaev, Sergey and Barinova, Olga and Novikova, Tatiana and Kohli, Pushmeet and Lempitsky, Victor},
xxurl = {10.1109/ICDAR.2013.33},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Milyaev et al. - 2013 - Image Binarization for End-to-End Text Understanding in Natural Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-natural scene binarization,text localization},
month = {aug},
pages = {128--132},
publisher = {Ieee},
title = {{Image Binarization for End-to-End Text Understanding in Natural Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628598},
year = {2013}
}
@article{Zheng2005,
author = {Zheng, Y and Li, H and Doermann, D},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng, Li, Doermann - 2005 - A parallel-line detection algorithm based on HMM decoding.pdf:pdf},
journal = {Pattern Analysis and Machine {\ldots}},
title = {{A parallel-line detection algorithm based on HMM decoding}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1407880},
year = {2005}
}
@article{Lin2013,
author = {Lin, Xiaoyan and Gao, Liangcai and Tang, Zhi and Baker, Josef and Alkalai, Mohamed and Sorge, Volker},
xxurl = {10.1109/ICDAR.2013.75},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2013 - A Text Line Detection Method for Mathematical Formula Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {josef baker,mathematical formula identification,mathematical formula recogni-,mohamed alkalai,school of computer science,text line detection,tion,volker sorge},
month = {aug},
pages = {339--343},
publisher = {Ieee},
title = {{A Text Line Detection Method for Mathematical Formula Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628640},
year = {2013}
}
@inproceedings{Mondal2010,
abstract = {Anatomical structure tracing on cephalograms is a significant way to obtain cephalometric analysis. Computerized cephalometric analysis involves both manual and automatic approaches. The manual approach is limited in accuracy and repeatability. In this paper we have attempted to develop and test a novel method for automatic localization of craniofacial structure based on the detected edges on the region of interest. According to the grey scale feature at the different region of the cephalometric images, an algorithm for obtaining tissue contour is put forward. Using edge detection with specific threshold an improved bidirectional contour tracing approach is proposed by an interactive selection of the starting edge pixels, the tracking process searches repetitively for an edge pixel at the neighborhood of previously searched edge pixel to segment images, and then craniofacial structures are obtained. The effectiveness of the algorithm is demonstrated by the preliminary experimental results obtained with the proposed method. {\textcopyright} 2010 Copyright SPIE - The International Society for Optical Engineering.},
author = {Mondal, Tanmoy and Jain, Ashish and Sardana, H. K.},
booktitle = {Second International Conference on Digital Image Processing},
xxurl = {10.1117/12.853786},
isbn = {9780819479426},
issn = {0277786X},
title = {{Generation algorithm of craniofacial structure contour in cephalometric images}},
year = {2010}
}
@inproceedings{Le2014,
author = {Le, Viet Phuong and Nayef, Nibal and Visani, Muriel and Ogier, Jean-Marc and Tran, Cao De},
booktitle = {2014 22nd International Conference on Pattern Recognition},
xxurl = {10.1109/ICPR.2014.527},
isbn = {978-1-4799-5209-0},
month = {aug},
pages = {3056--3061},
publisher = {IEEE},
title = {{Document Retrieval Based on Logo Spotting Using Key-Point Matching}},
url = {http://ieeexplore.ieee.org/document/6977239/},
year = {2014}
}
@article{Alkalai2013,
author = {Alkalai, Mohamed and Baker, Josef B. and Sorge, Volker and Lin, Xiaoyan},
xxurl = {10.1109/ICDAR.2013.74},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alkalai et al. - 2013 - Improving Formula Analysis with Line and Mathematics Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {for-,line segmentation,math formula recognition},
month = {aug},
pages = {334--338},
publisher = {Ieee},
title = {{Improving Formula Analysis with Line and Mathematics Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628639},
year = {2013}
}
@article{Zhu2017,
abstract = {Time series motifs have been in the literature for about fifteen years, but have only recently begun to receive significant attention in the research community. This is perhaps due to the growing realization that they implicitly offer solutions to a host of time series problems, including rule discovery, anomaly detection, density estimation, semantic segmentation, etc. Recent work has improved the scalability to the point where exact motifs can be computed on datasets with up to a million data points in tenable time. However, in some domains, for example seismology, there is an insatiable need to address even larger datasets. In this work we show that a combination of a novel algorithm and a high-performance GPU allows us to significantly improve the scalability of motif discovery. We demonstrate the scalability of our ideas by finding the full set of exact motifs on a dataset with one hundred million subsequences, by far the largest dataset ever mined for time series motifs. Furthermore, we demonstrate that our algorithm can produce actionable insights in seismology and other domains.},
author = {Zhu, Yan and Zimmerman, Zachary and Senobari, Nader Shakibay and Yeh, Chin Chia Michael and Funning, Gareth and Mueen, Abdullah and Brisk, Philip and Keogh, Eamonn},
xxurl = {10.1109/ICDM.2016.126},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2017 - Matrix profile II Exploiting a novel algorithm and GPUs to break the one hundred million barrier for time series mot.pdf:pdf},
isbn = {9781509054725},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {GPUs,Joins,Motifs,Time series},
pages = {739--748},
title = {{Matrix profile II: Exploiting a novel algorithm and GPUs to break the one hundred million barrier for time series motifs and joins}},
year = {2017}
}
@article{Salah2002,
author = {Salah, Albert Ali and Alpaydin, Ethem and Akarun, Lale},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salah, Alpaydin, Akarun - 2002 - A Selective Attention-Based Method for Visual Pattern Recognition with Application to Handwritten Digi.pdf:pdf},
number = {3},
pages = {420--425},
title = {{A Selective Attention-Based Method for Visual Pattern Recognition with Application to Handwritten Digit Recognition and Face Recognition {\ae}}},
volume = {24},
year = {2002}
}
@article{Lowther2001,
author = {Lowther, S and Chandran, V and Sridharan, S},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowther, Chandran, Sridharan - 2001 - Recognition of Logo Images Using Invariants Defined from Higher-Order Spectra.pdf:pdf},
number = {January},
pages = {1--4},
title = {{Recognition of Logo Images Using Invariants Defined from Higher-Order Spectra}},
year = {2001}
}
@article{Frinken2012a,
abstract = {Keyword spotting refers to the process of retrieving all instances of a given keyword from a document. In the present paper, a novel keyword spotting method for handwritten documents is described. It is derived from a neural network-based system for unconstrained handwriting recognition. As such it performs template-free spotting, i.e., it is not necessary for a keyword to appear in the training set. The keyword spotting is done using a modification of the CTC Token Passing algorithm in conjunction with a recurrent neural network. We demonstrate that the proposed systems outperform not only a classical dynamic time warping-based approach but also a modern keyword spotting system, based on hidden Markov models. Furthermore, we analyze the performance of the underlying neural networks when using them in a recognition task followed by keyword spotting on the produced transcription. We point out the advantages of keyword spotting when compared to classic text line recognition.},
author = {Frinken, Volkmar and Fischer, Andreas and Manmatha, R and Bunke, Horst},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frinken et al. - 2012 - A novel word spotting method based on recurrent neural networks.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frinken et al. - 2012 - A novel word spotting method based on recurrent neural networks(2).pdf:pdf},
journal = {IEEE TPAMI},
keywords = {area,next,related work from this,spotting have been developed,we review},
month = {feb},
number = {2},
pages = {211--224},
title = {{A novel word spotting method based on recurrent neural networks.}},
volume = {34},
year = {2012}
}
@inproceedings{Zhang2013,
author = {Zhang, Xi and Tan, Chew Lim},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Tan - 2013 - Segmentation-Free Keyword Spotting for Handwritten Documents Based on Heat Kernel Signature.pdf:pdf},
keywords = {Feature extraction,HKS,Heating,Hidden Markov models,Image segmentation,Kernel,Lighting,SIFT,Text analysis,document image processing,document pages,handwritten documents,heat kernel signature,image matching,key point detector,local patch,query image,search problems,searching method,segmentation-free keyword spotting},
language = {English},
month = {aug},
pages = {827--831},
publisher = {IEEE},
title = {{Segmentation-Free Keyword Spotting for Handwritten Documents Based on Heat Kernel Signature}},
year = {2013}
}
@article{Plamondon2000,
author = {Plamondon, R. and Srihari, S.N.},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
language = {English},
number = {1},
pages = {63--84},
publisher = {IEEE},
title = {{Online and off-line handwriting recognition: a comprehensive survey}},
volume = {22},
year = {2000}
}
@inproceedings{Mondala,
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean-yves},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal, Ragot, Ramel - 2015 - Exemplary Sequence Cardinality An Effective Application for Word Spotting.pdf:pdf},
isbn = {9781479918058},
keywords = {cdp,continuous dynamic programming,dtw,dynamic time warping,elastic sequence matching,flexible sequence matching,fsm,minimal,mvm,optimal sequence bijection,osb,variance matching,word spotting},
title = {{Exemplary Sequence Cardinality : An Effective Application for Word Spotting}},
year = {2015}
}
@article{Flow2002b,
author = {Flow, Measuring Fluid and Spinners, Continuous and Bore, Full and Meters, Flow and Meters, Diverting Flow and Format, Log and Speed, Cable and Conventions, Sign and Principles, Fluid Flow and Tools, Radioactive Tracer and Logging, Oxygen Activation and Activation, Oxygen and Example, Log and Water, Schlumberger and Log, Flow and Principles, Operating and Oxygen, Stationary and Example, Activation and Oxygen, Stationary and Example, Activation},
file = {:home/mondal/Documents/MATHS/CalcII{\_}Complete.pdf:pdf},
number = {July},
pages = {1--12},
title = {{Table of Contents Table of Contents ی ﺮ ﺘ ﮐ د ﻪ ﺒ ﺣ ﺎ ﺼ ﻣ ر د ﺎ ﻫ ز ﺎ ﯿ ﺘ ﻣ ا ﻪ ﺴ ﯾ ﺎ ﻘ ﻣ ) ؟ ﻢ ﻨ ﮐ پ ﺎ ﭼ ب ﺎ ﺘ ﮐ ﺪ ﯾ ﺎ ﺑ ا ﺮ ﭼ )}},
year = {2002}
}
@article{Leydier2009,
annote = {From Duplicate 1 ( 

Towards an omnilingual word retrieval system for ancient manuscripts

- Leydier, Yann; Ouji, Asma; LeBourgeois, F; Emptoz, Hubert )

},
author = {Leydier, Yann and Ouji, Asma and LeBourgeois, Frank and Emptoz, Hubert},
xxurl = {10.1016/j.patcog.2009.01.026},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydier et al. - 2009 - Towards an omnilingual word retrieval system for ancient manuscripts.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydier et al. - 2009 - Towards an omnilingual word retrieval system for ancient manuscripts(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
month = {sep},
number = {9},
pages = {2089--2105},
title = {{Towards an omnilingual word retrieval system for ancient manuscripts}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320309000454 http://linkinghub.elsevier.com/retrieve/pii/S0031320309000454},
volume = {42},
year = {2009}
}
@article{Takacs2013,
abstract = {We present an end-to-end feature description pipeline which uses a novel interest point detector and rotation-invariant fast feature (RIFF) descriptors. The proposed RIFF algorithm is 15× faster than SURF [1] while producing large-scale retrieval results that are comparable to SIFT [2]. Such high-speed features benefit a range of applications from mobile augmented reality (MAR) to web-scale image retrieval and analysis. In particular, RIFF enables unified tracking and recognition for MAR.},
author = {Takacs, Gabriel and Chandrasekhar, Vijay and Tsai, Sam and Chen, David and Grzeszczuk, Radek and Girod, Bernd},
xxurl = {10.1016/j.image.2012.11.004},
isbn = {9780819492166},
issn = {09235965},
journal = {Signal Processing: Image Communication},
keywords = {Feature descriptors,Keypoints,Tracking,Visual search},
number = {4},
pages = {334--344},
title = {{Rotation-invariant fast features for large-scale recognition and real-time tracking}},
volume = {28},
year = {2013}
}
@article{Perona1990,
abstract = {A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in our approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Perona, Pietro and Malik, Jitendra},
xxurl = {10.1109/34.56205},
eprint = {1102.0183},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Adaptive filtering,Analog VLSI,Edge detection,Edge enhancement,Nonlinear diffusion,Nonlinear filtering,Parallel algorithm,Scale-space},
pmid = {19268610},
title = {{Scale-Space and Edge Detection Using Anisotropic Diffusion}},
year = {1990}
}
@article{Shirai2013,
author = {Shirai, K. and Endo, Y. and Kitadai, a. and Inoue, S. and Kurushima, N. and Baba, H. and Watanabe, a. and Nakagawa, M.},
xxurl = {10.1109/ICDAR.2013.260},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shirai et al. - 2013 - Character Shape Restoration of Binarized Historical Documents by Smoothing via Geodesic Morphology.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1285--1289},
publisher = {Ieee},
title = {{Character Shape Restoration of Binarized Historical Documents by Smoothing via Geodesic Morphology}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628821},
year = {2013}
}
@article{Shafait2008,
abstract = {Adaptive binarization is an important first step in many document analysis and OCR processes. This paper describes a fast adaptive binarization algorithm! that yields the same quality of binarization as the Sauvola method,1 but runs in time close to that of global thresholding methods (like Otsu's method2), independent of the window size. The algorithm combines the statistical constraints of Sauvola's method with integral images.3 Testing on the UW-1 dataset demonstrates a 20-fold speedup compared to the original Sauvola algorithm.},
author = {Shafait, Faisal and Keysers, Daniel and Breuel, Tm},
xxurl = {10.1117/12.767755},
editor = {Yanikoglu, Berrin A. and Berkner, Kathrin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shafait, Keysers, Breuel - 2008 - Efficient implementation of local adaptive thresholding techniques using integral images.pdf:pdf},
isbn = {9780819469878},
issn = {0277786X},
journal = {SPIE Document Imaging and Retrieval},
keywords = {adaptive thresholding,document binarization,integral images,local thresholding},
month = {jan},
pages = {1--5},
publisher = {International Society for Optics and Photonics},
title = {{Efficient implementation of local adaptive thresholding techniques using integral images}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=812244},
volume = {6815},
year = {2008}
}
@article{Rabaev2013,
author = {Rabaev, Irina and Biller, Ofer and El-Sana, Jihad and Kedem, Klara and Dinstein, Itshak},
xxurl = {10.1109/ICDAR.2013.166},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabaev et al. - 2013 - Text Line Detection in Corrupted and Damaged Historical Manuscripts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {812--816},
publisher = {Ieee},
title = {{Text Line Detection in Corrupted and Damaged Historical Manuscripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628731},
year = {2013}
}
@inproceedings{Vlachos2002a,
abstract = {We investigate techniques for analysis and retrieval of object trajectories in two or three dimensional space. Such data usually contain a large amount of noise, that has made previously used metrics fail. Therefore, we formalize non-metric similarity functions based on the longest common subsequence (LCSS), which are very robust to noise and furthermore provide an intuitive notion of similarity between trajectories by giving more weight to similar portions of the sequences. Stretching of sequences in time is allowed, as well as global translation of the sequences in space. Efficient approximate algorithms that compute these similarity measures are also provided. We compare these new methods to the widely used Euclidean and time warping distance functions (for real and synthetic data) and show the superiority of our approach, especially in the strong presence of noise. We prove a weaker version of the triangle inequality and employ it in an indexing structure to answer nearest neighbor queries. Finally, we present experimental results that validate the accuracy and efficiency of our approach},
annote = {From Duplicate 1 ( 





















Discovering similar multidimensional trajectories





















- Vlachos, M.; Kollios, G.; Gunopulos, D. )







},
author = {Vlachos, M. and Kollios, G. and Gunopulos, D.},
booktitle = {ICDE},
keywords = {2D space,3D space,Data engineering,Databases,Error correction,Euclidean distance,Euclidean distance functions,Humans,Multidimensional systems,Nearest neighbor searches,Robustness,Sampling methods,Trajectory,efficient approximate algorithms,global translation,indexing structure,longest common subsequence,nearest neighbor queries,noise,nonmetric similarity functions,object trajectory analysis,object trajectory retrieval,query processing,sequence stretching,sequences,similar multidimensional trajectory discovery,temporal databases,time series,time warping distance functions,triangle inequality,visual databases},
language = {English},
pages = {673--684},
publisher = {IEEE Comput. Soc},
shorttitle = {Data Engineering, 2002. Proceedings. 18th Internat},
title = {{Discovering similar multidimensional trajectories}},
year = {2002}
}
@article{Balasubramanian16,
author = {Balasubramanian, Arvind and Wang, Jun and Prabhakaran, Balakrishnan},
xxurl = {10.1109/JSTSP.2016.2543679},
journal = {J. Sel. Topics Signal Processing},
number = {5},
pages = {832--841},
title = {{Discovering Multidimensional Motifs in Physiological Signals for Personalized Healthcare}},
url = {https://xxurl.org/10.1109/JSTSP.2016.2543679},
volume = {10},
year = {2016}
}
@article{Kobayashi2013,
author = {Kobayashi, Takuya and Iwamura, Masakazu and Matsuda, Takahiro and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.231},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kobayashi et al. - 2013 - An Anytime Algorithm for Camera-Based Character Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {anytime algorithm,asift,local feature,scene character recognition,tracking,video input},
month = {aug},
pages = {1140--1144},
publisher = {Ieee},
title = {{An Anytime Algorithm for Camera-Based Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628792},
year = {2013}
}
@article{Graves2009c,
abstract = {Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters, combined with the need to exploit surrounding context, has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed, most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition, despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network, specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases, our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data, significantly outperforming a state-of-the-art HMM-based system. In addition, we demonstrate the network's robustness to lexicon size, measure the individual influence of its hidden layers, and analyze its use of context. Last, we provide an in-depth discussion of the differences between the network and HMMs, suggesting reasons for the network's superior performance.},
author = {Graves, Alex and Liwicki, Marcus and Fern{\'{a}}ndez, Santiago and Bertolami, Roman and Bunke, Horst and Schmidhuber, J{\"{u}}rgen},
xxurl = {10.1109/TPAMI.2008.137},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graves et al. - 2009 - A novel connectionist system for unconstrained handwriting recognition.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graves et al. - 2009 - A novel connectionist system for unconstrained handwriting recognition(2).pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Automated,Automated: methods,Automatic Data Processing,Automatic Data Processing: methods,Computer-Assisted,Computer-Assisted: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models,Pattern Recognition,Reading,Reproducibility of Results,Sensitivity and Specificity,Statistical,Subtraction Technique},
month = {may},
number = {5},
pages = {855--68},
pmid = {19299860},
title = {{A novel connectionist system for unconstrained handwriting recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19299860},
volume = {31},
year = {2009}
}
@article{JessicaLin2008,
author = {{Jessica Lin} and Keogh, Eamonn and Lonardi, Stefano and Patel, Pranav},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jessica Lin et al. - 2008 - Finding Motifs in Time Series.pdf:pdf},
isbn = {158113567X},
number = {December},
pages = {1--98},
title = {{Finding Motifs in Time Series}},
year = {2008}
}
@inproceedings{Shina,
author = {Shin, M.C. and Goldgof, D. and Bowyer, K.W.},
booktitle = {Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)},
xxurl = {10.1109/CVPR.1999.786964},
isbn = {0-7695-0149-4},
pages = {360--365},
publisher = {IEEE Comput. Soc},
title = {{Comparison of edge detectors using an object recognition task}},
url = {http://ieeexplore.ieee.org/document/786964/}
}
@article{H.WakuyaK.Shida,
author = {Wakuya, H. and Shida, K.},
journal = {Transacition IEE; Japan},
number = {10},
pages = {1794--1802},
title = {{Time Series Prediction with Neural Network Model Based on the Bi-directional Computation Style: An Analytical Study and Its Estimation on Acquired Signal Transformation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?xxurl=10.1.1.102.4448{\&}rep=rep1{\&}type=pdf},
volume = {122-C},
year = {2002}
}
@article{Górecki123,
author = {G{\'{o}}recki, T.},
journal = {Data Analysis Methods and Its Applications},
pages = {31--40},
title = {{Two parametrical derivative dynamic time warping}}
}
@article{Kurbalija2011,
abstract = {A time series consists of a series of values or events obtained over repeated measurements in time. Analysis of time series represents and important tool in many application areas, such as stock market analysis, process and quality control, observation of natural phenomena, medical treatments, etc. A vital component in many types of time-series analysis is the choice of an appropriate distance/similarity measure. Numerous measures have been proposed to date, with the most successful ones based on dynamic programming. Being of quadratic time complexity, however, global constraints are often employed to limit the search space in the matrix during the dynamic programming procedure, in order to speed up computation. Furthermore, it has been reported that such constrained measures can also achieve better accuracy. In this paper, we investigate two representative time-series distance/similarity measures based on dynamic programming, Dynamic Time Warping (DTW) and Longest Common Subsequence (LCS), and the effects of global constraints on them. Through extensive experiments on a large number of time-series data sets, we demonstrate how global constrains can significantly reduce the computation time of DTW and LCS. We also show that, if the constraint parameter is tight enough (less than 10-15{\%} of time-series length), the constrained measure becomes significantly different from its unconstrained counterpart, in the sense of producing qualitatively different 1-nearest neighbor graphs. This observation explains the potential for accuracy gains when using constrained measures, highlighting the need for careful tuning of constraint parameters in order to achieve a good trade-off between speed and accuracy.},
archivePrefix = {arXiv},
arxivId = {1107.0134},
author = {Kurbalija, Vladimir and Radovanovi{\'{c}}, Milo{\v{s}} and Geler, Zoltan and Ivanovi{\'{c}}, Mirjana},
eprint = {1107.0134},
month = {jul},
title = {{The Influence of Global Constraints on Similarity Measures for Time-Series Databases}},
url = {http://arxiv.org/abs/1107.0134},
year = {2011}
}
@article{Sun2013a,
author = {Sun, Lei and Huo, Qiang},
xxurl = {10.1109/ICDAR.2013.84},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun, Huo - 2013 - An Improved Component Tree Based Approach to User-Intention Guided Text Extraction from Natural Scene Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {383--387},
publisher = {Ieee},
title = {{An Improved Component Tree Based Approach to User-Intention Guided Text Extraction from Natural Scene Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628649},
year = {2013}
}
@article{F??rstner2009,
abstract = {This paper presents a novel method for detecting scale invariant keypoints. It fills a gap in the set of available methods, as it proposes a scale-selection mechanism for junction-type features. The method is a scale-space extension of the detector proposed by Fo{\&}{\#}x0308;rstner (1994) and uses the general spiral feature model of Bigu{\&}{\#}x0308;n (1990) to unify different types of features within the same framework. By locally optimising the consistency of image regions with respect to the spiral model, we are able to detect and classify image structures with complementary properties over scale-space, especially star and circular shapes as interpretable and identifiable subclasses. Our motivation comes from calibrating images of structured scenes with poor texture, where blob detectors alone cannot find sufficiently many keypoints, while existing corner detectors fail due to the lack of scale invariance. The procedure can be controlled by semantically clear parameters. One obtains a set of keypoints with position, scale, type and consistency measure. We characterise the detector and show results on common benchmarks. It competes in repeatability with the Lowe detector, but finds more stable keypoints in poorly textured areas, and shows comparable or higher accuracy than other recent detectors. This makes it useful for both object recognition and camera calibration.},
author = {F??rstner, Wolfgang and Dickscheid, Timo and Schindler, Falko},
xxurl = {10.1109/ICCV.2009.5459458},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frstner, Dickscheid, Schindler - 2009 - Detecting interpretable and accurate scale-invariant keypoints.pdf:pdf},
isbn = {9781424444205},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2256--2263},
title = {{Detecting interpretable and accurate scale-invariant keypoints}},
year = {2009}
}
@article{Slimane2013,
author = {Slimane, Fouad and Kanoun, Slim and {El Abed}, Haikal and Alimi, Adel M. and Ingold, Rolf and Hennebert, Jean},
xxurl = {10.1109/ICDAR.2013.289},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Slimane et al. - 2013 - ICDAR2013 Competition on Multi-font and Multi-size Digitally Represented Arabic Text.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-apti database,arabic text,competition,ocr system,tion,ultra-low resolu-},
month = {aug},
pages = {1433--1437},
publisher = {Ieee},
title = {{ICDAR2013 Competition on Multi-font and Multi-size Digitally Represented Arabic Text}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628850},
year = {2013}
}
@article{Aida-zade2009,
author = {Aida-zade, Kamil R KR and Hasanov, Jamaladdin Z JZ},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aida-zade, Hasanov - 2009 - Word base line detection in handwritten text recognition systems.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aida-zade, Hasanov - 2009 - Word base line detection in handwritten text recognition systems(2).pdf:pdf},
journal = {International Journal of Electrical and {\ldots}},
keywords = {3,4,and has ability to,and on-line recognition,ascender,azerbaijani,azeri,baseline,cursive,descender,handwritten,hwr,integrate,latin,on-line recognition deals,recognition,segmentation,symbols,with real-time data processing},
pages = {717--721},
title = {{Word base line detection in handwritten text recognition systems}},
year = {2009}
}
@article{Barboza2013,
author = {Barboza, Ricardo Da Silva and Lins, Rafael Dueire and Jesus, Darlisson Marinho De},
xxurl = {10.1109/ICDAR.2013.273},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barboza, Lins, Jesus - 2013 - A Color-Based Model to Determine the Age of Documents for Forensic Purposes.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {amazonas,darlisson marinho de jesus,documents,forensics,models,paper aging,universidade do estado do},
month = {aug},
pages = {1350--1354},
publisher = {Ieee},
title = {{A Color-Based Model to Determine the Age of Documents for Forensic Purposes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628834},
year = {2013}
}
@article{DueTrier1996,
abstract = {This paper presents an overview of feature extraction methods for off-line recognition of segmented (isolated) characters. Selection of a feature extraction method is probably the single most important factor in achieving high recognition performance in character recognition systems. Different feature extraction methods are designed for different representations 6f the characters, such as solid binary characters, character contours, skeletons (thinned characters) or gray-level subimages of each individual character. The feature extraction methods are discussed in terms of invariance properties, reconstructability and expected distortions and variability of the characters. The problem of choosing the appropriate feature extraction method for a given application is also discussed. When a few promising feature extraction methods have been identified, they need to be evaluated experimentally to find the best method for the given application},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Due Trier}, {\O}ivind and Jain, Anil K. and Taxt, Torfinn},
xxurl = {10.1016/0031-3203(95)00118-2},
eprint = {arXiv:1011.1669v3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Due Trier, Jain, Taxt - 1996 - Feature extraction methods for character recognition-A survey.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
number = {4},
pages = {641--662},
pmid = {25246403},
title = {{Feature extraction methods for character recognition-A survey}},
volume = {29},
year = {1996}
}
@article{Terasawa2005,
abstract = { A new method for text retrieval that does not need segmentation is described. Segmenting the images in historical documents into individual characters is difficult. Therefore, the conventional OCR method, which uses segmentation, does not work well. Our method instead divides the text image into a sequence of small slits. The image region that corresponds to the query image region is retrieved by solving the matching problem of these sequences. Applying the eigenspace method to the slit images enables us to solve the matching problem efficiently. Moreover, using dynamic time warping (DTW) further improves the results. Our method has higher accuracy than the simple template matching method, and it has far higher efficiency in computational cost.},
author = {Terasawa, Kengo and Nagasaki, Takeshi and Kawashima, Toshio},
xxurl = {10.1109/ICDAR.2005.99},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Terasawa, Nagasaki, Kawashima - 2005 - Eigenspace method for text retrieval in historical document images.pdf:pdf},
isbn = {0769524206},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
pages = {437--440},
title = {{Eigenspace method for text retrieval in historical document images}},
volume = {2005},
year = {2005}
}
@article{Durand2017,
abstract = {This paper introduces WILDCAT, a deep learning method which jointly aims at aligning image regions for gaining spatial invariance and learning strongly localized features. Our model is trained using only global image labels and is devoted to three main visual recognition tasks: image classification, weakly supervised pointwise object localization and semantic segmentation. WILDCAT extends state-of-the-art Convolutional Neural Networks at three major levels: the use of Fully Convolutional Networks for maintaining spatial resolution, the explicit design in the network of local features related to different class modalities, and a new way to pool these features to provide a global image prediction required for weakly supervised training. Extensive experiments show that our model significantly outperforms the state-of-the-art methods.},
author = {Durand, Thibaut and Mordan, Taylor and Thome, Nicolas and Cord, Matthieu},
xxurl = {10.1109/CVPR.2017.631},
file = {:home/mondal/Downloads/art{\_}3921.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
number = {1},
pages = {5957--5966},
title = {{WILDCAT: Weakly supervised learning of deep convnets for image classification, pointwise localization and segmentation}},
volume = {2017-Janua},
year = {2017}
}
@article{Rosten2006,
abstract = {Where feature points are used in real-time frame-rate appli- cations, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7{\%} of the available processing time. By comparison neither the Harris detector (120{\%}) nor the detection stage of SIFT (300{\%}) can operate at full frame rate. Clearly a high-speed detector is of limited use if the features produced are unsuitable for downstream processing. In particular, the same scene viewed from two different positions should yield features which corre- spond to the same real-world 3D locations[1]. Hence the second contri- bution of this paper is a comparison corner detectors based on this crite- rion applied to 3D scenes. This comparison supports a number of claims made elsewhere concerning existing corner detectors. Further, contrary to our initial expectations, we show that despite being principally con- structed for speed, our detector significantly outperforms existing feature detectors according to this criterion.},
author = {Rosten, Edward and Drummond, Tom},
xxurl = {10.1007/11744023_34},
isbn = {978-3-540-33832-1},
issn = {03029743},
journal = {Computer Vision -- ECCV 2006},
pages = {430--443},
pmid = {18684738},
title = {{Machine Learning for High Speed Corner Detection}},
volume = {1},
year = {2006}
}
@article{Ghosh2015,
author = {Ghosh, Pooja and Pandey, Achala and Pati, Umesh C},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosh, Pandey, Pati - 2015 - Comparison of Different Feature Detection Techniques for Image Mosaicing.pdf:pdf},
keywords = {corner detection,feature detection,image matching},
number = {1},
pages = {1--7},
title = {{Comparison of Different Feature Detection Techniques for Image Mosaicing}},
year = {2015}
}
@inproceedings{Mondal2015a,
abstract = {In this paper proposed. ESC combines several abilities of other sequence matching algorithms e.g. DTW, SSDTW, CDP, FSM, MVM, OSB1. Depending on the application domain, ESC can be tuned to∗∗a new sequence matching algorithm called as Exemplary Sequence Cardinality (ESC) is behave such as these different sequence matching algorithms. Its generality and robustness comes from its ability to find subsequences (as in CDP and SSDTW), to skip outliers inside the target sequences (as in MVM and FSM) and also in the query sequence (as in OSB ) and it has the ability to have many to one and one to many correspondences (as in DTW) between the elements of the query and the target sequences. It's special characteristic of skipping noisy elements from query sequence along with other afore mentioned properties gives it an edge over FSM. In case of word spotting application, the outliers skipping capability of ESC makes it less sensible to local variations in the spelling of words, and also to noise present in the query and/or in the target word images. Due to it's capability of sub-sequence matching, the ESC algorithm has the ability to retrieve a query inside a line or piece of line. Finally, its multiple matching facilities (many to one and one to many matching) is proven to be well advantageous in case of different length of target and query sequences due to the variability in scale, font, type/size factors. By experimenting on printed historical document images, we have demonstrated the interest of proposed ESC algorithm in specific cases when incorrect word segmentation and word level local variations occur regularly.},
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean Yves and Pal, Umapada},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
xxurl = {10.1109/ICDAR.2015.7333940},
isbn = {9781479918058},
issn = {15205363},
keywords = {Continuous dynamic programming (CDP),Dynamic time warping (DTW),Elastic sequence matching,Flexible sequence matching (FSM),Minimal variance matching (MVM),Optimal sequence bijection (OSB),Word spotting},
pages = {1146--1150},
title = {{Exemplary Sequence Cardinality: An effective application for word spotting}},
volume = {2015-Novem},
year = {2015}
}
@article{Mexicano2016,
author = {Mexicano, Torneo and Mexicano, El Torneo and Tecnol, Desarrollo and Kit, Standard Educational and Tipo, Lugar and Thball, Juego and Thball, Juego and Este, Cloclon},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mexicano et al. - 2016 - Matrix Profile I All Pairs Similarity Joins for Time Series A Unifying View that Includes Motifs, Discords and.pdf:pdf},
keywords = {arrival frequency was much,desktop,even if the data,faster than,motif discovery,similarity joins,time series},
pages = {1--4},
title = {{Matrix Profile I: All Pairs Similarity Joins for Time Series: A Unifying View that Includes Motifs, Discords and Shapelets}},
year = {2016}
}
@article{Le2015,
abstract = {Explain on Attention model, autoencoder},
author = {Le, Quoc V},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le - 2015 - A Tutorial on Deep Learning Part 2 Autoencoders, Convolutional Neural Networks and Recurrent Neural Networks.pdf:pdf},
journal = {Tutorial},
pages = {1--20},
title = {{A Tutorial on Deep Learning Part 2: Autoencoders, Convolutional Neural Networks and Recurrent Neural Networks}},
year = {2015}
}
@article{Fischer2013,
author = {Fischer, Andreas and Frinken, Volkmar and Bunke, Horst and Suen, Ching Y.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer et al. - 2013 - Improving HMM-Based Keyword Spotting with Character Language Models.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer et al. - 2013 - Improving HMM-Based Keyword Spotting with Character Language Models(2).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {ICDAR},
keywords = {alternative to locate specific,document images,handwriting recognition,hidden,high,keyword spotting,method for keyword spotting,models that showed a,ously proposed a learning-based,search terms within scanned,spotting is a promising,using character hidden markov,we have previ-},
month = {aug},
pages = {506--510},
publisher = {Ieee},
title = {{Improving HMM-Based Keyword Spotting with Character Language Models}},
year = {2013}
}
@article{Petitjean2011,
author = {Petitjean, Fran{\c{c}}ois and Ketterlin, Alain and Gan{\c{c}}arski, Pierre},
xxurl = {10.1016/j.patcog.2010.09.013},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ketterlin, Ganc - 2010 - A global averaging method for dynamic time warping , with applications to clustering.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {distance-based clustering,dtw barycenter averaging,dynamic time warping,global averaging,satellite image time series,sequence analysis,time series averaging,time series clustering},
month = {mar},
number = {3},
pages = {678--693},
title = {{A global averaging method for dynamic time warping, with applications to clustering}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003132031000453X},
volume = {44},
year = {2011}
}
@misc{convolutionalAE-Galeone,
title = {{Convolutional Autoencoders – P. Galeone's blog}},
url = {https://pgaleone.eu/neural-networks/2016/11/24/convolutional-autoencoders/},
urldate = {2018-03-29}
}
@article{DelasHeras2013,
author = {de las Heras, Lluis-Pere and Fernandez, David and Valveny, Ernest and Llados, Josep and Sanchez, Gemma},
xxurl = {10.1109/ICDAR.2013.252},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de las Heras et al. - 2013 - Unsupervised Wall Detector in Architectural Floor Plans.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1245--1249},
publisher = {Ieee},
title = {{Unsupervised Wall Detector in Architectural Floor Plans}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628813},
year = {2013}
}
@article{Szegedy2013,
abstract = {Abstract Deep Neural Networks (DNNs) have recently shown outstanding performance on image classification tasks [14]. In this paper we go one step further and address the problem of object detection using DNNs, that is not only classifying but also precisely localizing ... $\backslash$n},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.2249v1},
author = {Szegedy, Christian},
xxurl = {10.1109/CVPR.2014.276},
eprint = {arXiv:1312.2249v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szegedy - 2013 - Deep Neural Networks for Object Detection.pdf:pdf},
isbn = {978-1-4799-5118-5},
issn = {10636919},
journal = {Nips 2013},
pages = {1--9},
title = {{Deep Neural Networks for Object Detection}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=6909673},
year = {2013}
}
@inproceedings{LiUYG15,
author = {Li, Yuhong and U, Leong Hou and Yiu, Man Lung and Gong, Zhiguo},
booktitle = {31st {\{}IEEE{\}} International Conference on Data Engineering, {\{}ICDE{\}} 2015, Seoul, South Korea, April 13-17, 2015},
pages = {579--590},
title = {{Quick-motif: An efficient and scalable framework for exact motif discovery}},
year = {2015}
}
@article{Ahmad2013a,
author = {Ahmad, Irfan and Rothacker, Leonard and Fink, Gernot a. and Mahmoud, Sabri a.},
xxurl = {10.1109/ICDAR.2013.135},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmad et al. - 2013 - Novel Sub-character HMM Models for Arabic Text Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {arabic text recognition,area of arabic text,competitions held in the,hidden markov models,interesting and challenging,ocr,parameter sharing,recognition,recognition thanks to many,sub-character hmms},
month = {aug},
pages = {658--662},
publisher = {Ieee},
title = {{Novel Sub-character HMM Models for Arabic Text Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628700},
year = {2013}
}
@article{Tonazzini2003,
author = {Tonazzini, Anna and Vezzosi, Stefano and Bedini, Luigi},
xxurl = {10.1007/s10032-003-0115-y},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tonazzini, Vezzosi, Bedini - 2003 - Analysis and recognition of highly degraded printed characters.pdf:pdf},
issn = {14332833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Blind image restoration,Degraded printed texts,Neural networks,OCR,Wavelet denoising},
number = {4},
pages = {236--247},
pmid = {19932348},
title = {{Analysis and recognition of highly degraded printed characters}},
volume = {6},
year = {2003}
}
@article{Elton1972,
author = {Elton, R. A. and Chaston, I.},
xxurl = {10.2307/3213},
file = {:home/mondal/Documents/MATHS/mml-book.pdf:pdf},
issn = {00218790},
journal = {The Journal of Animal Ecology},
number = {3},
pages = {772},
title = {{Mathematics for Ecologists}},
volume = {41},
year = {1972}
}
@article{Liu2013b,
author = {Liu, Yang and Song, Yonghong and Zhang, Yuanlin and Meng, Quan},
xxurl = {10.1109/ICDAR.2013.274},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2013 - A Novel Multi-oriented Chinese Text Extraction Approach from Videos.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- text extraction,character,character segmentation,multi-oriented,text line merging},
month = {aug},
pages = {1355--1359},
publisher = {Ieee},
title = {{A Novel Multi-oriented Chinese Text Extraction Approach from Videos}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628835},
year = {2013}
}
@article{Kassis2014,
author = {Kassis, Majeed},
xxurl = {10.1109/ICFHR.2014.71},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kassis - 2014 - Word Spotting using Radial Descriptor.pdf:pdf},
isbn = {978-1-4799-4334-0},
keywords = {arabic docu-,feature descriptor,historical documents,keyword searching,ments,word spotting},
pages = {387--392},
title = {{Word Spotting using Radial Descriptor}},
year = {2014}
}
@inproceedings{Mondal2019a,
abstract = {In this paper, a novel local threshold binarization method using fast Fuzzy C-Means clustering is proposed. Historical document images with non-uniform background, stains, faded ink are first processed by removing the background using inpainting based method. Then using Fuzzy C-Means clustering is used to cluster out the pixels into three main clusters: sure text pixels, sure background pixels and confused pixels which may or may not be labeled as text. Based on the structural symmetry of pixels (SSP), these confused pixels are then classified into text or background pixels. The SSP is defined as those pixels around strokes whose gradient magnitudes are big enough and whose directions are opposite. As the gradient map is our basis for computing the SSP, we further propose to estimate the background surface first and to extract potential SSP in the compensated image so as to deal with degradations of document images such as uneven illumination, low contrast and stain. To prove the effectiveness of our method, tests on eight public document image datasets are preformed and the experimental results show that our method outperforms other local threshold binarization approaches on both F-measure and PSNR.},
author = {Mondal, Tanmoy and Coustaty, Mickael and Gomez-Kramer, Petra and Ogier, Jean Marc},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
xxurl = {10.1109/ICDAR.2019.00223},
isbn = {9781728128610},
issn = {15205363},
keywords = {Background Removal,Binarization,Fuzzy C-Means,Stroke Width Estimation},
title = {{Learning free document image binarization based on fast fuzzy C-means clustering}},
year = {2019}
}
@article{Doermann1993,
abstract = {The problem of logo recognition is of great interest in the document domain, especially for databases, because of its potential for identifying the source of the document and its generality as a recognition problem. By recognizing the logo, one obtains semantic information about the document, which may be useful in deciding whether or not to analyze the textual components. A multi-level stages approach to logo recognition which uses global invariants to prune the database and local affine invariants to obtain a more refined match is presented. An invariant signature which can be used for matching under a variety of transformations is obtained. The authors provide a method of computing Euclidean invariants and show how to extend them to capture similarity, affine, and projective invariants when necessary. They implement feature detection, feature extraction, and local invariant algorithms and successfully demonstrate the approach on a small database},
author = {Doermann, D.S. and Rivlin, E. and Weiss, I.},
xxurl = {10.1109/ICDAR.1993.395593},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doermann, Rivlin, Weiss - 1993 - Logo recognition using geometric invariants.pdf:pdf},
isbn = {0-8186-4960-7},
journal = {Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)},
pages = {894--897},
title = {{Logo recognition using geometric invariants}},
year = {1993}
}
@article{Li2014,
author = {Li, Hailin},
xxurl = {10.1007/s13042-014-0254-0},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li - 2014 - On-line and dynamic time warping for time series data mining.pdf:pdf},
isbn = {1304201402540},
issn = {1868-8071},
journal = {International Journal of Machine Learning and Cybernetics},
keywords = {dynamic time warping {\'{a}},similarity measure {\'{a}},time series data mining,{\'{a}} online measurement},
number = {1},
pages = {145--153},
title = {{On-line and dynamic time warping for time series data mining}},
url = {http://link.springer.com/10.1007/s13042-014-0254-0},
volume = {6},
year = {2014}
}
@article{Adamek2004,
author = {Adamek, T. and O'Connor, N.E.},
xxurl = {10.1109/TCSVT.2004.826776},
issn = {1051-8215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Character recognition,Data visualization,Humans,Image retrieval,Indexing,Information retrieval,MPEG-7 shape database,Multimedia databases,Object recognition,Shape measurement,Two dimensional displays,computational complexity,contour convexities,data visualisation,database indexing,descriptor matching,dissimilarity measure,dynamic programming,image representation,information retrieval,matrix algebra,multimedia databases,multiscale representation method,nonrigid shapes,object indexing,object retrieval,shape descriptor,similarity metric,single closed contour,two-dimensional matrix},
language = {English},
month = {may},
number = {5},
pages = {742--753},
publisher = {IEEE},
title = {{A Multiscale Representation Method for Nonrigid Shapes With a Single Closed Contour}},
volume = {14},
year = {2004}
}
@article{Kruger2007,
abstract = {We investigate the use of multi-linear models to represent human motion data. We show that naturally occurring modes in several classes of motion can be used to efficiently represent the motions for various animation task, such as dimensionality reduction or synthesis of new motions by morphing. We show that especially for the approximations of motions by few components the reduction based on a multi-linear model might be considerably better than one obtained by principal component analysis (PCA).},
author = {Kr{\"{u}}ger, B and Tautges, J and Weber, a},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kr{\"{u}}ger, Tautges, Weber - 2007 - Multi-Mode Representation of Motion Data.pdf:pdf},
isbn = {978-972-8865-72-6},
journal = {The 2nd International Conference on Computer Graphics Theory and Applications (GRAPP 2007)},
keywords = {MoCaDa,morphing,motion analysis,motion synthesis,tensor},
pages = {21--29},
title = {{Multi-Mode Representation of Motion Data}},
year = {2007}
}
@article{Hongye2009,
abstract = {A new method of logo detection in document images is proposed in this paper. It is based on the boundary extension of feature rectangles of which the definition is also given in this paper. This novel method takes advantage of a layout assumption that logos have background (white spaces) surrounding it in a document. Compared with other logo detection methods, this new method has the advantage that it is independent on logo shapes and very fast. After the logo candidates are detected, a simple decision tree is used to reduce the false positive from the logo candidate pool. We have tested our method on a public image database involving logos. Experiments show that our method is more precise and robust than the previous methods and is well qualified as an effective assistance in document retrieval.},
author = {Hongye, Wang and Youbin, Chen},
xxurl = {10.1109/ICDAR.2009.129},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hongye, Youbin - 2009 - Logo detection in document images based on boundary extension of feature rectangles.pdf:pdf},
isbn = {9780769537252},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {imp-logo-paper},
mendeley-tags = {imp-logo-paper},
number = {c},
pages = {1335--1339},
title = {{Logo detection in document images based on boundary extension of feature rectangles}},
year = {2009}
}
@article{Breuel,
author = {Breuel, Thomas M.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breuel - 2005 - The future of document imaging in the era of electronic documents.pdf:pdf},
journal = {Proceedings of International Workshop Document Analysis},
pages = {275--296},
title = {{The future of document imaging in the era of electronic documents}},
year = {2005}
}
@article{Linardi2018,
abstract = {In the last fifteen years, data series motif discovery has emerged as one of the most useful primitives for data series mining, with applications to many domains, including robotics, entomology, seis-mology, medicine, and climatology. Nevertheless, the state-of-the-art motif discovery tools still require the user to provide the motif length. Yet, in at least some cases, the choice of motif length is critical and unforgiving. Unfortunately, the obvious brute-force solution, which tests all lengths within a given range, is computa-tionally untenable. In this work, we introduce VALMOD, an exact and scalable motif discovery algorithm that efficiently finds all mo-tifs in a given range of lengths. We evaluate our approach with five diverse real datasets, and demonstrate that it is up to 20 times faster than the state-of-the-art. Our results also show that removing the unrealistic assumption that the user knows the correct length, can often produce more intuitive and actionable results, which could have been missed otherwise.},
author = {Linardi, Michele and Zhu, Yan and Palpanas, Themis and Keogh, Eamonn},
xxurl = {10.1145/3183713.3183744},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Linardi et al. - 2018 - Matrix Profile X VALMOD - Scalable Discovery of Variable-Length Motifs in Data Series.pdf:pdf},
isbn = {9781450347037},
issn = {07308078},
journal = {Proceedings of the 2018 International Conference on Management of Data - SIGMOD '18},
keywords = {data,data series,motif discovery,time series,variable length},
pages = {1053--1066},
title = {{Matrix Profile X: VALMOD - Scalable Discovery of Variable-Length Motifs in Data Series}},
url = {http://dl.acm.org/citation.cfm?xxurld=3183713.3183744},
year = {2018}
}
@article{Kumar2011,
author = {Kumar, Ranjeet and Tripathi, R.C. and Tiwari, M.D.},
xxurl = {10.5120/1786-2466},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Tripathi, Tiwari - 2011 - A Comprehensive Study on Content Based Trademark Retrieval System.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {content based image,information retrieval,retrieval,trademark,trademark retrieval,trademark search},
number = {6},
pages = {18--22},
title = {{A Comprehensive Study on Content Based Trademark Retrieval System}},
volume = {13},
year = {2011}
}
@article{Chherawala2013,
annote = {From Duplicate 1 ( 



















































Feature Design for Offline Arabic Handwriting Recognition: Handcrafted vs Automated?



















































- Chherawala, Youssouf; Roy, Partha Pratim; Cheriet, Mohamed )















},
author = {Chherawala, Youssouf and Roy, Partha Pratim and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.65},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chherawala, Roy, Cheriet - 2013 - Feature Design for Offline Arabic Handwriting Recognition Handcrafted vs Automated.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chherawala, Roy, Cheriet - 2013 - Feature Design for Offline Arabic Handwriting Recognition Handcrafted vs Automated(2).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {290--294},
publisher = {Ieee},
title = {{Feature Design for Offline Arabic Handwriting Recognition: Handcrafted vs Automated?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628630},
year = {2013}
}
@article{Wu2013,
author = {Wu, Zhaohui and Mitra, Prasenjit and Giles, C. Lee},
xxurl = {10.1109/ICDAR.2013.244},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Mitra, Giles - 2013 - Table of Contents Recognition and Extraction for Heterogeneous Book Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1205--1209},
publisher = {Ieee},
title = {{Table of Contents Recognition and Extraction for Heterogeneous Book Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628805},
year = {2013}
}
@article{Morales-Esteban2010,
abstract = {Earthquakes arrive without previous warning and can destroy a whole city in a few seconds, causing numerous deaths and economical losses. Nowadays, a great effort is being made to develop techniques that forecast these unpredictable natural disasters in order to take precautionary measures. In this paper, clustering techniques are used to obtain patterns which model the behavior of seismic temporal data and can help to predict medium-large earthquakes. First, earthquakes are classified into different groups and the optimal number of groups, a priori unknown, is determined. Then, patterns are discovered when medium-large earthquakes happen. Results from the Spanish seismic temporal data provided by the Spanish Geographical Institute and non-parametric statistical tests are presented and discussed, showing a remarkable performance and the significance of the obtained results. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {Morales-Esteban, A. and Mart{\'{i}}nez-{\'{A}}lvarez, F. and Troncoso, A. and Justo, J. L. and Rubio-Escudero, C.},
xxurl = {10.1016/j.eswa.2010.05.050},
file = {:home/mondal/Documents/climate/pdf/ESWA{\_}published.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Clustering,Earthquakes forecasting,Time series},
number = {12},
pages = {8333--8342},
publisher = {Elsevier Ltd},
title = {{Pattern recognition to forecast seismic time series}},
url = {http://dx.xxurl.org/10.1016/j.eswa.2010.05.050},
volume = {37},
year = {2010}
}
@inproceedings{Mondal2018a,
abstract = {There have been many published works on using Dynamic Time Warping (DTW) for word image matching. It has also been shown that constrained DTW works better than classical DTW, due to it's property to limit the warping path and to avoid pathological matching. Moreover, some studies also demonstrate that variants of DTW can perform better, compared to classical DTW. To take advantages from these techniques, we propose in this paper to study how combination of such approaches can even more improve the results. First, we propose to use pseudo Local DTW (LDTW: More efficient than DTW in our experiments) with a constraint band. Next, several other sequence matching techniques are parametrically combined to study their potential advantages. For this, we adapted the approach to the context of word image matching to obtain the value of the parameters. It is shown that, at least on Bentham and George Washington datasets, results can be improved by combining some algorithms. Please note that the goal of this research work is not to propose a competitive word spotting technique but to propose a dynamic programming based learning free approach for word spotting or image matching, which can perform moderately with respect to other existing approaches in this domain.},
author = {Mondal, Tanmoy and Coustaty, Mickael},
booktitle = {Proceedings of International Conference on Frontiers in Handwriting Recognition, ICFHR},
xxurl = {10.1109/ICFHR-2018.2018.00064},
isbn = {9781538658758},
issn = {21676453},
keywords = {Dynamic Time Warping,Itakura Parallelogram Band,Parametric combination,Pseudo Local Dynamic Time Warping (LDTW),Sakoe-Chiba band,Word Retrieval},
title = {{Constrained and parametric dynamic programming for word image retrieval}},
year = {2018}
}
@article{Stamatopoulos2013,
author = {Stamatopoulos, Nikolaos and Gatos, Basilis and Louloudis, Georgios and Pal, Umapada and Alaei, Alireza},
xxurl = {10.1109/ICDAR.2013.283},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamatopoulos et al. - 2013 - ICDAR 2013 Handwriting Segmentation Contest.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1402--1406},
publisher = {Ieee},
title = {{ICDAR 2013 Handwriting Segmentation Contest}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628844},
year = {2013}
}
@article{MohdAnuar2013,
abstract = {Trademarks are distinctive visual symbols with high reputational value, due to the perception of quality and innovation associated with them. They are important reputational assets used as a marketing tool to convey a certain assurance of quality, innovation, and the standards, which the manufacturer seeks to maintain. This motivates the need for trademark protection by providing a solution to prevent infringement. This problem can be addressed by developing retrieval systems capable of comparing the visual similarity of trademarks. This paper contributes to the research in this field by proposing an innovative trademark retrieval technique with improved retrieval performance due to the integration of global and local descriptors. The global descriptor employed is the Zernike moment's coefficients. The local descriptor is the edge-gradient co-occurrence matrix, derived from the contour information that is considered very important in human perception of visual similarity. The proposed retrieval technique is tested using the standard MPEG-7 shape database of 1400 images and the MPEG-7 trademark database of 3260 images. The results show 5{\%} precision/recall improvement in the case of the MPEG-7 shape database, as well as 2.35{\%} Bull's eye score improvement and 19.8{\%} NMRR score improvement for the 10 randomly selected trademarks from the MPEG-7 trademarks database. ?? 2012 Elsevier Ltd. All rights reserved.},
author = {{Mohd Anuar}, Fatahiyah and Setchi, Rossitza and Lai, Yu Kun},
xxurl = {10.1016/j.eswa.2012.07.031},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohd Anuar, Setchi, Lai - 2013 - Trademark image retrieval using an integrated shape descriptor.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Feature extraction,Feature matching,Image retrieval,Intellectual Property Management,Knowledge Management,Trademarks},
number = {1},
pages = {105--121},
publisher = {Elsevier Ltd},
title = {{Trademark image retrieval using an integrated shape descriptor}},
url = {http://dx.xxurl.org/10.1016/j.eswa.2012.07.031},
volume = {40},
year = {2013}
}
@article{Fink2014,
author = {Fink, Gernot a. and Rothacker, Leonard and Grzeszick, Rene},
xxurl = {10.1109/ICFHR.2014.85},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fink, Rothacker, Grzeszick - 2014 - Grouping Historical Postcards Using Query-by-Example Word Spotting.pdf:pdf},
isbn = {978-1-4799-4334-0},
journal = {2014 14th International Conference on Frontiers in Handwriting Recognition},
keywords = {-word spotting,handwriting,historical documents},
pages = {470--475},
title = {{Grouping Historical Postcards Using Query-by-Example Word Spotting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6981064},
year = {2014}
}
@article{Soutner2013,
author = {Soutner, Daniel and M{\"{u}}ller, Lud{\v{e}}k},
xxurl = {10.1007/978-3-642-40585-3_14},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soutner, M{\"{u}}ller - 2013 - Application of LSTM neural networks in language modelling.pdf:pdf},
isbn = {9783642405846},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {LSTM neural networks,language modelling,recurrent neural networks},
pages = {105--112},
title = {{Application of LSTM neural networks in language modelling}},
volume = {8082 LNAI},
year = {2013}
}
@article{Ubeyli2008a,
abstract = {Mixture of experts (ME) is a modular neural network architecture for supervised learning. This paper illustrates the use of ME network structure to guide model selection for classification of electroencephalogram (EEG) signals. Expectation-maximization (EM) algorithm was used for training the ME so that the learning process is decoupled in a manner that fits well with the modular structure. The EEG signals were decomposed into time–frequency representations using discrete wavelet transform and statistical features were calculated to depict their distribution. The ME network structure was implemented for classification of the EEG signals using the statistical features as inputs. To improve classification accuracy, the outputs of expert networks were combined by a gating network simultaneously trained in order to stochastically select the expert that is performing the best at solving the problem. Three types of EEG signals (EEG signals recorded from healthy volunteers with eyes open, epilepsy patients in the epileptogenic zone during a seizure-free interval, and epilepsy patients during epileptic seizures) were classified with the accuracy of 93.17{\%} by the ME network structure. The ME network structure achieved accuracy rates which were higher than that of the stand-alone neural network models.},
author = {{\"{U}}beyli, Elif Derya},
xxurl = {10.1016/j.eswa.2007.02.006},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/{\"{U}}beyli - 2008 - Waveletmixture of experts network structure for EEG signals classification.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
month = {apr},
number = {3},
pages = {1954--1962},
publisher = {Pergamon Press, Inc.},
title = {{Wavelet/mixture of experts network structure for EEG signals classification}},
url = {http://www.sciencedirect.com/science/article/pii/S0957417407000735 http://dl.acm.org/citation.cfm?id=1327543.1327767},
volume = {34},
year = {2008}
}
@article{Choo2004,
abstract = {This paper examines recent developments and applications of Hidden Markov Models (HMMs) to various problems in computational biology, including multiple sequence alignment, homology detection, protein sequences classification, and genomic annotation.},
author = {Choo, Khar Heng and Tong, Joo Chuan and Zhang, Louxin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choo, Tong, Zhang - 2004 - Recent applications of Hidden Markov Models in computational biology.pdf:pdf},
issn = {1672-0229},
journal = {Genomics, proteomics {\&} bioinformatics},
keywords = {Computational Biology,Markov Chains,Models, Biological,Protein Conformation,Sequence Alignment,Sequence Homology},
month = {may},
number = {2},
pages = {84--96},
pmid = {15629048},
title = {{Recent applications of Hidden Markov Models in computational biology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15629048},
volume = {2},
year = {2004}
}
@article{Stutz2014,
abstract = {Abstract This seminar paper focusses on convolutional neural networks and a visualization technique allowing further insights into their internal operation. After giving a brief introduction to neural networks and the multilayer perceptron, we review both supervised ... $\backslash$n},
archivePrefix = {arXiv},
arxivId = {1605.09081},
author = {Stutz, D},
xxurl = {10.1016/j.jvcir.2016.11.003},
eprint = {1605.09081},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stutz - 2014 - Understanding Convolutional Neural Networks.pdf:pdf},
isbn = {1532-4435},
issn = {1047-3203},
journal = {Nips 2016},
number = {3},
pages = {1--23},
title = {{Understanding Convolutional Neural Networks}},
url = {file:///Files/68/685AE136-2357-4758-8082-A028CC8F3518.pdf{\%}5Cnhttp://davidstutz.de/wordpress/wp-content/uploads/2014/07/seminar.pdf{\%}5Cnfile:///Files/56/56D57B15-598A-4206-899B-0A77AFB45A29.pdf},
year = {2014}
}
@article{Alvaro2013,
author = {Alvaro, Francisco and Sanchez, Joan-Andreu and Benedi, Jose-Miguel},
xxurl = {10.1109/ICDAR.2013.203},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alvaro, Sanchez, Benedi - 2013 - Classification of On-Line Mathematical Symbols with Hybrid Features and Recurrent Neural Networks.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1012--1016},
publisher = {Ieee},
title = {{Classification of On-Line Mathematical Symbols with Hybrid Features and Recurrent Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628768},
year = {2013}
}
@article{Shafait2009,
author = {Shafait, Faisal and Breuel, Thomas M.},
xxurl = {10.1109/INMIC.2009.5383115},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shafait, Breuel - 2009 - A simple and effective approach for border noise removal from document images.pdf:pdf},
isbn = {978-1-4244-4872-2},
journal = {2009 IEEE 13th International Multitopic Conference},
keywords = {actual contents of the,based search is performed,in a digitized collection,manually removing marginal noise,of,page,poses problems since the,returned,search results might correspond,textual noise in particular,to textual noise instead},
month = {dec},
pages = {1--5},
publisher = {Ieee},
title = {{A simple and effective approach for border noise removal from document images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5383115},
year = {2009}
}
@article{Zweng2010,
author = {Zweng, Andreas and Kampel, Martin},
xxurl = {10.1109/ICPR.2010.98},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zweng, Kampel - 2010 - Unexpected Human Behavior Recognition in Image Sequences Using Multiple Features.pdf:pdf},
isbn = {978-1-4244-7542-1},
journal = {2010 20th International Conference on Pattern Recognition},
keywords = {-behavior recognition,visual surveillance},
month = {aug},
pages = {368--371},
publisher = {Ieee},
title = {{Unexpected Human Behavior Recognition in Image Sequences Using Multiple Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5597808},
year = {2010}
}
@article{RakeshAgrawal,
author = {{Rakesh Agrawal}, King-ip Lin, Harpreet S. Sawhney, Kyuseok Shim},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rakesh Agrawal - Unknown - Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases.pdf:pdf},
title = {{Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.40.4034}
}
@misc{deepFake,
author = {Github-DeepFakes},
title = {{deepfakes/faceswap: Deepfakes Software For All}},
url = {https://github.com/deepfakes/faceswap},
urldate = {2020-03-24}
}
@article{Donahue2016,
abstract = {The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.},
archivePrefix = {arXiv},
arxivId = {1605.09782},
author = {Donahue, Jeff and Kr{\"{a}}henb{\"{u}}hl, Philipp and Darrell, Trevor},
xxurl = {10.1038/nphoton.2013.187},
eprint = {1605.09782},
isbn = {2334-2536},
issn = {2334-2536},
pages = {1--11},
pmid = {27377197},
title = {{Adversarial Feature Learning}},
url = {http://arxiv.org/abs/1605.09782},
year = {2016}
}
@article{Wang2009,
abstract = {This paper introduces an automated computer- assisted system for the diagnosis of cervical intraepithelial neoplasia (CIN) using ultra-large cervical histological digital slides. The system contains two parts: the segmentation of squamous epithelium and the diagnosis of CIN. For the segmentation, to reduce processing time, a multiresolution method is developed. The squamous epithelium layer is first segmented at a low (2X) resolution. The boundaries are further fine tuned at a higher (20X) resolution. The block-based segmentation method uses robust texture feature vectors in combination with support vector machines (SVMs) to perform classification. Medical rules are finally applied. In testing, segmentation using 31 digital slides achieves 94.25{\%} accuracy. For the diagnosis of CIN, changes in nuclei structure and morphology along lines perpendicular to the main axis of the squamous epithelium are quantified and classified. Using multi-category SVM, perpendicular lines are classified into Normal, CIN I, CIN II, and CIN III. The robustness of the system in term of regional diagnosis is measured against pathologists' diagnoses and inter-observer variability between two pathologists is considered. Initial results suggest that the system has potential as a tool both to assist in pathologists' diagnoses, and in training. {\textcopyright} 2009 IEEE.},
author = {Wang, Yinhai and Crookes, Danny and Eldin, Osama Sharaf and Wang, Shilan and Hamilton, Peter and Diamond, Jim},
xxurl = {10.1109/JSTSP.2008.2011157},
file = {:home/mondal/Documents/AllPapers/Oxyent{\_}Work/Segmentation of Nuclius.pdf:pdf},
issn = {19324553},
journal = {IEEE Journal on Selected Topics in Signal Processing},
keywords = {CIN,Cervical cancer,Diagnosis,Digital pathology,Digital slide,Image processing,SVM},
number = {1},
pages = {112--121},
title = {{Assisted diagnosis of cervical intraepithelial neoplasia (CIN)}},
volume = {3},
year = {2009}
}
@article{Cortelazzo1994,
abstract = {This work considers the possibility of measuring the shape similarity distances of two-dimensional objects. The method proposed is articulated in two stages: chain-coding the objects' contours, and applying string distances to the coded contours. The distance values obtained by such a procedure are then associated to the general geometrical characteristics of the object. Comparison of the distance values of two objects gives an indication of their similarity. The implementation of a shape similarity distance based on this concept is considered in depth. Its theoretical and practical implications are examined. The effectiveness of the method is tested with trademarks, a class of images of considerable practical interest. The results are encouraging and point to the feasibility of the task undertaken by using the proposed approach. {\textcopyright} 1994.},
author = {Cortelazzo, G. and Mian, G. A. and Vezzi, G. and Zamperoni, P.},
xxurl = {10.1016/0031-3203(94)90140-6},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortelazzo et al. - 1994 - Trademark shapes description by string-matching techniques.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Contour coding,Distance,Dynamic programming,Shape analysis,Trademark},
number = {8},
pages = {1005--1018},
title = {{Trademark shapes description by string-matching techniques}},
volume = {27},
year = {1994}
}
@article{Mara2013a,
author = {Mara, Hubert and Kromker, Susanne},
xxurl = {10.1109/ICDAR.2013.21},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mara, Kromker - 2013 - Vectorization of 3D-Characters by Integral Invariant Filtering of High-Resolution Triangular Meshes.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {62--66},
publisher = {Ieee},
title = {{Vectorization of 3D-Characters by Integral Invariant Filtering of High-Resolution Triangular Meshes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628586},
year = {2013}
}
@article{Li2013b,
author = {Li, Rongsha and Peng, Liangrui and Xun, Endong and Wein, Nan},
xxurl = {10.1109/ICDAR.2013.201},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2013 - A Stroke Order Verification Method for On-Line Handwritten Chinese Characters Based on Tempo-spatial Consistency Anal.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {chinese character,on-line handwritten,stroke order verification,tempo-spatial consistency},
month = {aug},
number = {61261130590},
pages = {999--1003},
publisher = {Ieee},
title = {{A Stroke Order Verification Method for On-Line Handwritten Chinese Characters Based on Tempo-spatial Consistency Analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628766},
year = {2013}
}
@article{Li2010,
abstract = {The scientific significance of automatic logo detection and recognition is more and more growing because of the increasing requirements of intelligent document image analysis and retrieval. In this paper, we introduce a system architecture which is aiming at segmentation-free and layout-independent logo detection and recognition. Along with the unique logo feature design, a novel way to ensure the geometrical relationships among the features, and different optimizations in the recognition process, this system can achieve improvements concerning both the recognition performance and the running time. The experimental results on several sets of real-word documents demonstrate the effectiveness of our approach.},
author = {Li, Zhe and Schulte-Austum, Matthias and Neschen, Martin},
xxurl = {10.1109/ICPR.2010.665},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Schulte-Austum, Neschen - 2010 - Fast logo detection and recognition in document images.pdf:pdf},
isbn = {9780769541099},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
keywords = {Document retrieval,Image processing,Logo detection,Logo recognition,imp-logo-paper},
mendeley-tags = {imp-logo-paper},
pages = {2716--2719},
pmid = {5597015},
title = {{Fast logo detection and recognition in document images}},
year = {2010}
}
@article{Pratikakis2013,
author = {Pratikakis, Ioannis and Gatos, Basilis and Ntirogiannis, Konstantinos},
xxurl = {10.1109/ICDAR.2013.219},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratikakis, Gatos, Ntirogiannis - 2013 - ICDAR 2013 Document Image Binarization Contest (DIBCO 2013).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {Dibco},
pages = {1471--1476},
publisher = {Ieee},
title = {{ICDAR 2013 Document Image Binarization Contest (DIBCO 2013)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628857},
year = {2013}
}
@article{Bimbo2011,
abstract = {• For region detection invariance transformations that should be considered are illumination changes, translation, rotation, scale and full affine transform (i.e. a region should correspond to the same pre-image for different viewpoints. Viewpoint changes can be locally approximated by affine transform if assuming locally planar objects and orthographic camera, that is perspective effects ignored) • Region detection should be repeatable and stable, and capable to discriminate between regions},
author = {Bimbo, Alberto Del},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bimbo - 2011 - Region detectors.pdf:pdf},
pages = {10},
title = {{Region detectors}},
url = {http://www.micc.unifi.it/delbimbo/wp-content/uploads/2011/03/slide{\_}corso/A34 MSER.pdf},
year = {2011}
}
@article{Bu2013,
abstract = {Finding discords in time series database is an important problem in a great variety of applications, such as space shuttle telemetry, mechanical industry, biomedicine, and financial data analysis. However, most previous methods for this problem suffer from too many parameter settings which are difficult for users. The best known approach to our knowledge that has comparatively fewer parameters still requires users to choose a word size for the compression of subsequences. In this paper, we propose a Haar wavelet and augmented trie based algorithm to mine the top-K discords from a time series database, which can dynamically determine the word size for compression. Due to the characteristics of Haar wavelet transform, our algorithm has greater pruning power than previous approaches. Through experiments with some annotated datasets, the effectiveness and efficiency of our algorithm are both attested.},
author = {Bu, Yingyi and Leung, Tat-Wing and Fu, Ada Wai-Chee and Keogh, Eamonn and Pei, Jian and Meshkin, Sam},
xxurl = {10.1137/1.9781611972771.43},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bu et al. - 2013 - WAT Finding Top- K Discords in Time Series Database.pdf:pdf},
pages = {449--454},
title = {{ WAT: Finding Top- K Discords in Time Series Database }},
year = {2013}
}
@article{Thadchanamoorthy2013,
author = {Thadchanamoorthy, S. and Kodikara, N.D. and Premaretne, H.L. and Pal, Umapada and Kimura, Fumitaka},
xxurl = {10.1109/ICDAR.2013.162},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thadchanamoorthy et al. - 2013 - Tamil Handwritten City Name Database Development and Recognition for Postal Automation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- handwriting recognition,city},
month = {aug},
pages = {793--797},
publisher = {Ieee},
title = {{Tamil Handwritten City Name Database Development and Recognition for Postal Automation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628727},
year = {2013}
}
@book{Hassaballah2016a,
author = {Hassaballah, M and Abdelmgeid, Aly Amin and Alshazly, Hammam A},
xxurl = {10.1007/978-3-319-28854-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassaballah, Abdelmgeid, Alshazly - 2016 - Image Feature Detectors and Descriptors.pdf:pdf},
isbn = {978-3-319-28852-9},
issn = {1860949X},
keywords = {feature descriptor,feature detector,feature extrac-,feature matching,interest points,tion},
pages = {11--46},
title = {{Image Feature Detectors and Descriptors}},
url = {http://link.springer.com/10.1007/978-3-319-28854-3},
volume = {630},
year = {2016}
}
@article{Hesson2008,
abstract = {In this paper, a system for the classification of logo and trademark images is proposed. Our proposed technique is based on using a co-occurrence histogram of the coefficients of the Haar wavelet decomposition of an image for indexing and classification. We call this histogram the wavelet co-occurrence histogram (WCH). The WCH produces a more accurate representation of the image features than does a histogram of edge direction angles in an image, since it captures the edge information and intensity variations in the image as well as the spatial separation of these features more accurately. We compare the results produced by our system to the results produced by the Edge Gradient Histogram (EGH); a histogram of the direction angles of edges in an image. We show that when tested on a database of logos and trademarks, the retrieval results produced by our proposed system are more accurate than the EGH.},
author = {Hesson, Ali and Androutsos, Dimitrios},
xxurl = {10.1109/CCECE.2008.4564672},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hesson, Androutsos - 2008 - Logo classification using haar wavelet co-occurrence histograms.pdf:pdf},
isbn = {9781424416431},
issn = {08407789},
journal = {Canadian Conference on Electrical and Computer Engineering},
keywords = {Co-occurrence histograms,Image retrieval,Logo classification,Pattern recognition,Wavelet transforms},
pages = {927--930},
title = {{Logo classification using haar wavelet co-occurrence histograms}},
year = {2008}
}
@article{Monner2012,
abstract = {The Long Short Term Memory (LSTM) is a second-order recurrent neural network architecture that excels at storing sequential short-term memories and retrieving them many time-steps later. LSTM's original training algorithm provides the important properties of spatial and temporal locality, which are missing from other training approaches, at the cost of limiting its applicability to a small set of network architectures. Here we introduce the Generalized Long Short-Term Memory(LSTM-g) training algorithm, which provides LSTM-like locality while being applicable without modification to a much wider range of second-order network architectures. With LSTM-g, all units have an identical set of operating instructions for both activation and learning, subject only to the configuration of their local environment in the network; this is in contrast to the original LSTM training algorithm, where each type of unit has its own activation and training instructions. When applied to LSTM architectures with peephole connections, LSTM-g takes advantage of an additional source of back-propagated error which can enable better performance than the original algorithm. Enabled by the broad architectural applicability of LSTM-g, we demonstrate that training recurrent networks engineered for specific tasks can produce better results than single-layer networks. We conclude that LSTM-g has the potential to both improve the performance and broaden the applicability of spatially and temporally local gradient-based training algorithms for recurrent neural networks. {\textcopyright} 2011 Elsevier Ltd.},
author = {Monner, Derek and Reggia, James a.},
xxurl = {10.1016/j.neunet.2011.07.003},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Monner, Reggia - 2012 - A generalized LSTM-like training algorithm for second-order recurrent neural networks.pdf:pdf},
isbn = {18792782},
issn = {08936080},
journal = {Neural Networks},
keywords = {Gradient-based training,Long Short Term Memory (LSTM),Recurrent neural network,Sequential retrieval,Temporal sequence processing},
number = {301},
pages = {70--83},
pmid = {21803542},
title = {{A generalized LSTM-like training algorithm for second-order recurrent neural networks}},
volume = {25},
year = {2012}
}
@article{Mishra2017,
abstract = {Color and strokes are the salient features of text regions in an image. In this work, we use both these fea-tures as cues, and introduce a novel energy function to formulate the text binarization problem. The minimum of this energy function corresponds to the optimal binarization. We minimize the energy function with an iterative graph cut-based algorithm. Our model is robust to variations in foreground and background as we learn Gaussian mixture models for color and strokes in each iteration of the graph cut. We show results on word images from the challenging ICDAR 2003/2011, born-digital image and street view text datasets, as well as full scene images containing text from ICDAR 2013 datasets, and compare our performance with state-of-the-art methods. Our approach shows significant improvements in performance under a variety of perfor-mance measures commonly used to assess text binarization schemes. In addition, our method adapts to diverse document images, like text in videos, handwritten text images.},
author = {Mishra, Anand and Alahari, Karteek and Jawahar, C. V.},
xxurl = {10.1007/s10032-017-0283-9},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mishra, Alahari, Jawahar - 2017 - Unsupervised refinement of color and stroke features for text binarization.pdf:pdf},
issn = {14332825},
journal = {International Journal on Document Analysis and Recognition},
pages = {1--17},
publisher = {Springer Berlin Heidelberg},
title = {{Unsupervised refinement of color and stroke features for text binarization}},
year = {2017}
}
@article{Nguyen2013,
author = {Nguyen, Cuong Tuan and Zhu, Bilan and Nakagawa, Masaki},
xxurl = {10.1109/ICDAR.2013.25},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Zhu, Nakagawa - 2013 - A Semi-incremental Recognition Method for On-Line Handwritten Japanese Text.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {handwriting recognition,incremental recognition,online recognition},
month = {aug},
pages = {84--88},
publisher = {Ieee},
title = {{A Semi-incremental Recognition Method for On-Line Handwritten Japanese Text}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628590},
year = {2013}
}
@article{Kunze2013a,
author = {Kunze, Kai and Kawaichi, Hitoshi and Yoshimura, Kazuyo and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.14},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kunze et al. - 2013 - The Wordometer -- Estimating the Number of Words Read Using Document Image Retrieval and Mobile Eye Tracking.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {25--29},
publisher = {Ieee},
title = {{The Wordometer -- Estimating the Number of Words Read Using Document Image Retrieval and Mobile Eye Tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628579},
year = {2013}
}
@article{Zhu2007,
abstract = {Automatic logo detection and recognition continues to be of great interest to the document retrieval community as it enables effective identification of the source of a document. In this paper, we propose a new approach to logo detection and extraction in document images that robustly classifies and precisely localizes logos using a boosting strategy across multiple image scales. At a coarse scale, a trained Fisher classifier performs initial classification using features from document context and connected components. Each logo candidate region is further classified at successively finer scales by a cascade of simple classifiers, which allows false alarms to be discarded and the detected region to be refined. Our approach is segmentation free and lay-out independent. We define a meaningful evaluation metric to measure the quality of logo detection using labeled groundtruth. We demonstrate the effectiveness of our approach using a large collection of real-world documents.},
archivePrefix = {arXiv},
arxivId = {1202.2368},
author = {Zhu, Guangyu and Doermann, David},
xxurl = {10.1109/ICDAR.2007.4377038},
eprint = {1202.2368},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Doermann - 2007 - Automatic document logo detection.pdf:pdf},
isbn = {0769528228},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {imp-logo-paper},
mendeley-tags = {imp-logo-paper},
pages = {864--868},
pmid = {15376597},
title = {{Automatic document logo detection}},
volume = {2},
year = {2007}
}
@article{Sankaran2013a,
author = {Sankaran, Naveen and Jawahar, C.V.},
xxurl = {10.1109/ICDAR.2013.230},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sankaran, Jawahar - 2013 - Error Detection in Highly Inflectional Languages.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1135--1139},
publisher = {Ieee},
title = {{Error Detection in Highly Inflectional Languages}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628791},
volume = {1},
year = {2013}
}
@article{Ahmed2013,
author = {Ahmed, Sheraz and Kise, Koichi and Iwamura, Masakazu and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/ICDAR.2013.111},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed et al. - 2013 - Automatic Ground Truth Generation of Camera Captured Documents Using Document Image Retrieval.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {528--532},
publisher = {Ieee},
title = {{Automatic Ground Truth Generation of Camera Captured Documents Using Document Image Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628676},
year = {2013}
}
@article{Chakrabarti2002,
abstract = {Similarity search in large time series databases has attracted much research interest recently. It is a difficult problem because of the typically high dimensionality of the data.. The most promising solutions involve performing dimensionality reduction},
author = {Chakrabarti, Kaushik and Keogh, Eamonn and Mehrotra, Sharad and Pazzani, Michael},
xxurl = {10.1145/568518.568520},
issn = {03625915},
journal = {ACM Transactions on Database Systems},
month = {jun},
number = {2},
pages = {188--228},
title = {{Locally adaptive dimensionality reduction for indexing large time series databases}},
url = {http://portal.acm.org/citation.cfm?xxurld=568518.568520},
volume = {27},
year = {2002}
}
@article{Louloudis2009c,
author = {Louloudis, G. and Gatos, B. and Pratikakis, I. and Halatsis, C.},
xxurl = {10.1016/j.patcog.2008.12.016},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Louloudis et al. - 2009 - Text line and word segmentation of handwritten documents.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Gaussian mixture modeling,Hough transform,Text line segmentation,Word segmentation,handwritten document image analysis},
month = {dec},
number = {12},
pages = {3169--3183},
publisher = {Elsevier},
title = {{Text line and word segmentation of handwritten documents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308005335},
volume = {42},
year = {2009}
}
@article{Louloudis2013,
author = {Louloudis, G. and Gatos, B. and Stamatopoulos, N. and Papandreou, a.},
xxurl = {10.1109/ICDAR.2013.282},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Louloudis et al. - 2013 - ICDAR 2013 Competition on Writer Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- writer iden},
month = {aug},
pages = {1397--1401},
publisher = {Ieee},
title = {{ICDAR 2013 Competition on Writer Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628843},
year = {2013}
}
@inproceedings{Howe2011,
author = {Howe, Nicholas R.},
booktitle = {2011 International Conference on Document Analysis and Recognition},
xxurl = {10.1109/ICDAR.2011.11},
isbn = {978-1-4577-1350-7},
month = {sep},
pages = {6--10},
publisher = {IEEE},
title = {{A Laplacian Energy for Document Binarization}},
url = {http://ieeexplore.ieee.org/document/6065266/},
year = {2011}
}
@article{Shieh2008,
abstract = {Current research in indexing and mining time series data has produced many interesting algorithms and representations. However, it has not led to algorithms that can scale to the increasingly massive datasets encountered in science, engineering, and business domains. In this work, we show how a novel multiresolution symbolic representation can be used to index datasets which are several orders of magnitude larger than anything else considered in the literature. Our approach allows both fast exact search and ultra fast approximate search. We show how to exploit the combination of both types of search as sub-routines in data mining algorithms, allowing for the exact mining of truly massive real world datasets, containing millions of time series.},
author = {Shieh, Jin and Keogh, Eamonn},
xxurl = {10.1145/1401890.1401966},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shieh, Keogh - 2008 - i SAX.pdf:pdf},
isbn = {9781605581934},
journal = {Sigkdd},
keywords = {data mining,indexing,representations,time series},
pages = {623},
title = {{i SAX}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.155.4531 http://dl.acm.org/citation.cfm?xxurld=1401890.1401966{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.155.4531{\%}5Cnhttp://dl.acm.org/citation.cfm?xxurld=1401890.1401966},
volume = {KDD '08},
year = {2008}
}
@article{Kirkpatrick1995,
author = {Kirkpatrick, David and Snoeyink, Jack},
xxurl = {10.1007/3-540-60220-8_61},
isbn = {3540602208},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {183--193},
title = {{Computing common tangents without a separating line}},
volume = {955},
year = {1995}
}
@article{Wu1996,
author = {Wu, J. K. and Lam, C. P. and Mehtre, B. M. and Gao, Y. J. and Narasimhalu, A. Desai},
xxurl = {10.1007/BF00393940},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 1996 - Content-based retrieval for trademark registration.pdf:pdf},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
number = {3},
pages = {245--267},
title = {{Content-based retrieval for trademark registration}},
url = {http://link.springer.com/10.1007/BF00393940},
volume = {3},
year = {1996}
}
@article{Roy2009,
abstract = {In this paper, we present a scheme towards the segmentation of English multi-oriented touching strings into individual characters. When two or more characters touch, they generate a big cavity region at the background portion. Using Convex Hull information, we use these background information to find some initial points to segment a touching string into possible primitive segments (a primitive segment consists of a single character or a part of a character). Next these primitive segments are merged to get optimum segmentation and dynamic programming is applied using total likelihood of characters as the objective function. SVM classifier is used to find the likelihood of a character. To consider multi-oriented touching strings the features used in the SVM are invariant to character orientation. Circular ring and convex hull ring based approach has been used along with angular information of the contour pixels of the character to make the feature rotation invariant. From the experiment, we obtained encouraging results.},
author = {Roy, Partha Pratim and Pal, Umapada and Llad{\'{o}}s, Josep and Delalandre, Mathieu},
xxurl = {10.1109/ICDAR.2009.124},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy et al. - 2009 - Multi-oriented and multi-sized touching character segmentation using dynamic programming.pdf:pdf},
isbn = {9780769537252},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
pages = {11--15},
title = {{Multi-oriented and multi-sized touching character segmentation using dynamic programming}},
year = {2009}
}
@article{Khayyat2013,
author = {Khayyat, Muna and Lam, Louisa and Suen, Ching Y.},
xxurl = {10.1109/ICDAR.2013.119},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khayyat, Lam, Suen - 2013 - Verification of Hierarchical Classifier Results for Handwritten Arabic Word Spotting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {572--576},
publisher = {Ieee},
title = {{Verification of Hierarchical Classifier Results for Handwritten Arabic Word Spotting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628684},
year = {2013}
}
@article{Pham2013,
author = {Pham, The Anh and Delalandre, Mathieu and Barrat, Sabine and Ramel, Jean-Yves},
xxurl = {10.1109/ICDAR.2013.216},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pham et al. - 2013 - Robust Symbol Localization Based on Junction Features and Efficient Geometry Consistency Checking.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1083--1087},
publisher = {Ieee},
title = {{Robust Symbol Localization Based on Junction Features and Efficient Geometry Consistency Checking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628781},
year = {2013}
}
@article{Newell2013,
author = {Newell, Andrew J.},
xxurl = {10.1109/ICDAR.2013.91},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newell - 2013 - What Should We Be Comparing for Writer Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {418--422},
publisher = {Ieee},
title = {{What Should We Be Comparing for Writer Identification?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628656},
year = {2013}
}
@article{Zhang2004,
abstract = {More and more images have been generated in digital form around the world. There is a growing interest in finding images in large collections or from remote databases. In order to find an image, the image has to be described or represented by certain features. Shape is an important visual feature of an image. Searching for images using shape features has attracted much attention. There are many shape representation and description techniques in the literature. In this paper, we classify and review these important techniques. We examine implementation procedures for each technique and discuss its advantages and disadvantages. Some recent research results are also included and discussed in this paper. Finally, we identify some promising techniques for image retrieval according to standard principles. ?? 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Zhang, Dengsheng and Lu, Guojun},
xxurl = {10.1016/j.patcog.2003.07.008},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Lu - 2004 - Review of shape representation and description techniques.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {CBIR,Image retrieval,Review,Shape,Shape descriptor},
number = {1},
pages = {1--19},
pmid = {15189822},
title = {{Review of shape representation and description techniques}},
volume = {37},
year = {2004}
}
@article{Sauvola2000,
abstract = {A new method is presented for adaptive document image binarization, where the page is considered as a collection of subcomponents such as text, background and picture. The problems caused by noise, illumination and many source type-related degradations are addressed. Two new algorithms are applied to determine a local threshold for each pixel. The performance evaluation of the algorithm utilizes test images with ground-truth, evaluation metrics for binarization of textual and synthetic images, and a weight-based ranking procedure for the final result presentation. The proposed algorithms were tested with images including different types of document components and degradations. The results were compared with a number of known techniques in the literature. The benchmarking results show that the method adapts and performs well in each case qualitatively and quantitatively. {\textcopyright} 1999 Pattern Recognition Society.},
author = {Sauvola, J. and Pietik{\"{a}}inen, M.},
xxurl = {10.1016/S0031-3203(99)00055-2},
isbn = {0818678984},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Adaptive binarization,Document analysis,Document segmentation,Document understanding,Soft decision},
pmid = {84262800005},
title = {{Adaptive document image binarization}},
year = {2000}
}
@article{Rezende2014,
abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.},
archivePrefix = {arXiv},
arxivId = {1401.4082},
author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
eprint = {1401.4082},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rezende, Mohamed, Wierstra - 2014 - Stochastic Backpropagation and Approximate Inference in Deep Generative Models.pdf:pdf},
month = {jan},
title = {{Stochastic Backpropagation and Approximate Inference in Deep Generative Models}},
year = {2014}
}
@article{Choudhury2013,
author = {Choudhury, Sagnik Ray and Mitra, Prasenjit and Kirk, Andi and Szep, Silvia and Pellegrino, Donald and Jones, Sue and Giles, C. Lee},
xxurl = {10.1109/ICDAR.2013.34},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choudhury et al. - 2013 - Figure Metadata Extraction from Digital Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {135--139},
publisher = {Ieee},
title = {{Figure Metadata Extraction from Digital Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628599},
year = {2013}
}
@article{Patnaik2009,
abstract = {Motivation: Data centers are a critical component of modern IT infrastructure but are also among the worst environmental oenders through their increasing energy usage and the resulting large carbon footprints. Efficient management of data centers, including power management, networking, and cooling infrastructure, is hence crucial to sustainability. In the absence of a "first-principles" approach to manage these complex components and their interactions, data-driven approaches have become attractive and tenable. Results: We present a temporal data mining solution to model and optimize performance of data center chillers, a key component of the cooling infrastructure. It helps bridge raw, numeric, time-series information from sensor streams toward higher level characterizations of chiller behavior, suitable for a data center engineer. To aid in this transduction, temporal data streams are first encoded into a symbolic representation, next run-length encoded segments are mined to form frequent motifs in time series, and finally these metrics are evaluated by their contributions to sustainability. A key innovation in our application is the ability to intersperse "don't care" transitions (e.g., transients) in continuous-valued time series data, an advantage we inherit by the application of frequent episode mining to symbolized representations of numeric time series. Our approach provides both qualitative and quantitative characterizations of the sensor streams to the data center engineer, to aid him in tuning chiller operating characteristics. This system is currently being prototyped for a data center managed by HP and experimental results from this application reveal the promise of our approach. Copyright 2009 ACM.},
author = {Patnaik, Debprakash and Marwah, Manish and Sharma, Ratnesh and Ramakrishnan, Naren},
xxurl = {10.1145/1557019.1557159},
file = {:home/mondal/Downloads/KDD09Chillers.pdf:pdf},
isbn = {9781605584959},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Chillers,Clustering,Data centers,Frequent episodes,Motifs,Sustainability},
pages = {1305--1313},
title = {{Sustainable operation and management of data center chillers using temporal data mining}},
year = {2009}
}
@article{Biller2013,
author = {Biller, Ofer and Asi, Abedelkadir and Kedem, Klara and Dinstein, Itshak},
xxurl = {10.1109/ICDAR.2013.68},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biller et al. - 2013 - WebGT An Interactive Web-Based System for Historical Document Ground Truth Generation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {305--308},
publisher = {Ieee},
title = {{WebGT: An Interactive Web-Based System for Historical Document Ground Truth Generation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628633},
year = {2013}
}
@article{Chi2013,
author = {Chi, Bingyu and Chen, Youbin},
xxurl = {10.1109/ICDAR.2013.159},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chi, Chen - 2013 - Chinese Handwritten Legal Amount Recognition with HMM-Based Approach.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-handwriting recognition,bank check processing,chinese legal amount,hidden markov model},
month = {aug},
pages = {778--782},
publisher = {Ieee},
title = {{Chinese Handwritten Legal Amount Recognition with HMM-Based Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628724},
year = {2013}
}
@article{Mueen2009,
abstract = {Time series motifs are sets of very similar subsequences of a long time series. They are of interest in their own right, and are also used as inputs in several higher-level data mining algorithms including classification, clustering, rule-discovery and summarization. In spite of extensive research in recent years, finding exact time series motifs in massive databases is an open problem. Previous efforts either found approximate motifs or considered relatively small datasets residing in main memory. In this work, we describe for the first time a disk-aware algorithm to find exact time series motifs in multi-gigabyte databases which contain on the order of tens of millions of time series. We have evaluated our algorithm on datasets from diverse areas including medicine, anthropology, computer networking and image processing and show that we can find interesting and meaningful motifs in datasets that are many orders of magnitude larger than anything considered before.},
author = {Mueen, Abdullah and Keogh, Eamonn and Bigdely-Shamlo, Nima},
xxurl = {10.1109/ICDM.2009.15},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mueen, Keogh, Bigdely-Shamlo - 2009 - Finding time series motifs in disk-resident data.pdf:pdf},
isbn = {9780769538952},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Closest pair,Exact method,Time series motif},
pages = {367--376},
title = {{Finding time series motifs in disk-resident data}},
year = {2009}
}
@article{BrianKulis,
annote = {From Duplicate 2 (Kernelized locality-sensitive hashing for scalable image search - Kulis, Brian; Grauman, Kristen)

From Duplicate 1 ( 

Kernelized locality-sensitive hashing for scalable image search

- Kulis, Brian; Grauman, Kristen )

},
author = {Kulis, Brian and Grauman, Kristen and {Brian Kulis}, Kristen Grauman},
xxurl = {10.1109/ICCV.2009.5459466},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulis, Grauman - 2009 - Kernelized locality-sensitive hashing for scalable image search.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulis, Grauman - 2009 - Kernelized locality-sensitive hashing for scalable image search(2).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulis, Grauman, Brian Kulis - 2009 - Kernelized locality-sensitive hashing for scalable image search.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = {sep},
number = {Iccv},
pages = {2130--2137},
publisher = {Ieee},
title = {{Kernelized locality-sensitive hashing for scalable image search}},
url = {http://citeseer.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.167.4414 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459466},
year = {2009}
}
@article{Bataineh2011,
abstract = {Binary image representation is essential format for document analysis. In general, different available binarization techniques are implemented for different types of binarization problems. The majority of binarization techniques are complex and are compounded from filters and existing operations. However, the few simple thresholding methods available cannot be applied to many binarization problems. In this paper, we propose a local binarization method based on a simple, novel thresholding method with dynamic and flexible windows. The proposed method is tested on selected samples called the DIBCO 2009 benchmark dataset using specialized evaluation techniques for binarization processes. To evaluate the performance of our proposed method, we compared it with the Niblack, Sauvola and NICK methods. The results of the experiments show that the proposed method adapts well to all types of binarization challenges, can deal with higher numbers of binarization problems and boosts the overall performance of the binarization. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Bataineh, Bilal and Abdullah, Siti Norul Huda Sheikh and Omar, Khairuddin},
xxurl = {10.1016/j.patrec.2011.08.001},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bataineh, Abdullah, Omar - 2011 - An adaptive local binarization method for document images based on a novel thresholding method and dyn.pdf:pdf},
isbn = {0167-8655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Document image binarization,Local binarization,OCR,Text,Thresholding methods},
number = {14},
pages = {1805--1813},
publisher = {Elsevier B.V.},
title = {{An Adaptive Local Binarization Method for Document Images Based on a Novel Thresholding Method and Dynamic Windows}},
volume = {32},
year = {2011}
}
@article{Jain2012,
author = {Jain, Rajiv and Doermann, David},
xxurl = {10.1109/DAS.2012.54},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Doermann - 2012 - Logo retrieval in document images.pdf:pdf},
isbn = {9780769546612},
journal = {Proceedings - 10th IAPR International Workshop on Document Analysis Systems, DAS 2012},
keywords = {Document Images,Indexing,Logo retrieval,SURF},
pages = {135--139},
title = {{Logo retrieval in document images}},
year = {2012}
}
@misc{PyTorchGAN,
title = {{Understanding and building Generative Adversarial Networks(GANs)- Deep Learning with PyTorch.}},
url = {https://becominghuman.ai/understanding-and-building-generative-adversarial-networks-gans-8de7c1dc0e25},
urldate = {2018-03-28}
}
@article{Delaye2013,
author = {Delaye, Adrien and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.202},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delaye, Liu - 2013 - Graphics Extraction from Heterogeneous Online Documents with Hierarchical Random Fields.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1007--1011},
publisher = {Ieee},
title = {{Graphics Extraction from Heterogeneous Online Documents with Hierarchical Random Fields}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628767},
year = {2013}
}
@article{Stamm2013,
author = {Stamm, Kristin and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/ICDAR.2013.129},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamm, Liwicki, Dengel - 2013 - Continuous Partial-Order Planning for Multichannel Document Analysis A Process-Driven Approach.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {626--630},
publisher = {Ieee},
title = {{Continuous Partial-Order Planning for Multichannel Document Analysis: A Process-Driven Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628694},
year = {2013}
}
@article{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
arxivId = {1701.07875},
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'{e}}on},
eprint = {1701.07875},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arjovsky, Chintala, Bottou - 2017 - Wasserstein GAN.pdf:pdf},
month = {jan},
title = {{Wasserstein GAN}},
year = {2017}
}
@article{Doetsch2013,
author = {Doetsch, Patrick and Ney, Hermann},
xxurl = {10.1109/ICDAR.2013.190},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doetsch, Ney - 2013 - Improvements in RWTH's System for Off-Line Handwriting Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {c},
pages = {935--939},
publisher = {Ieee},
title = {{Improvements in RWTH's System for Off-Line Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628755},
volume = {935},
year = {2013}
}
@article{Yau2003,
abstract = {Graphical representation of DNA sequence provides a simple way of viewing, sorting and comparing various gene structures. A new two-dimensional graphical representation method using a two- quadrant Cartesian coordinates system has been derived for mathematical denotation of DNA sequence. The two-dimensional graphic representation resolves sequences' degeneracy and is mathematically proven to eliminate circuit formation. Given x-projection and y-projection of any point on the graphical representation, the number of A, G, C and T from the beginning of the sequence to that point could be found. Compared with previous methods, this graphical representation is more in-line with the conventional recognition of linear sequences by molecular biologists, and also provides a metaphor in two dimensions for local and global DNA sequence comparison.},
author = {Yau, Stephen S-T and Wang, Jiasong and Niknejad, Amir and Lu, Chaoxiao and Jin, Ning and Ho, Yee-Kin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yau et al. - 2003 - DNA sequence representation without degeneracy.pdf:pdf},
issn = {1362-4962},
journal = {Nucleic acids research},
keywords = {Animals,Base Sequence,Humans,Mice,Models, Theoretical,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = {jun},
number = {12},
pages = {3078--80},
pmid = {12799435},
title = {{DNA sequence representation without degeneracy.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=162336{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {31},
year = {2003}
}
@article{Le2013,
author = {Le, Viet Phuong and Visani, Muriel and Tran, Cao De and Ogier, Jean-Marc},
xxurl = {10.1109/ICDAR.2013.61},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le et al. - 2013 - Improving Logo Spotting and Matching for Document Categorization by a Post-Filter Based on Homography.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {homography,logo spotting,pattern recognition},
month = {aug},
number = {1},
pages = {270--274},
publisher = {Ieee},
title = {{Improving Logo Spotting and Matching for Document Categorization by a Post-Filter Based on Homography}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628626},
year = {2013}
}
@book{Komorowski1997,
address = {Berlin, Heidelberg},
author = {Das, Gautam and Gunopulos, Dimitrios and Mannila, Heikki},
editor = {Komorowski, Jan and Zytkow, Jan},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Principles of Data Mining and Knowledge Discovery}},
volume = {1263},
year = {1997}
}
@article{Rigaud2013a,
author = {Rigaud, Christophe and Karatzas, Dimosthenis and Weijer, Joost Van De and Burie, Jean-christophe and Ogier, Jean-marc},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rigaud et al. - 2013 - Automatic Text Localisation in Scanned Comic Books.pdf:pdf},
isbn = {9789898565471},
journal = {9th International Conference on Computer Vision Theory and Applications},
pages = {814--819},
title = {{Automatic Text Localisation in Scanned Comic Books}},
year = {2013}
}
@article{Material2014,
author = {Material, See Related and Klette, Reinhard and Springer-verlag, Concise Computer Vision},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Material, Klette, Springer-verlag - 2014 - Keypoints and Descriptors 1.pdf:pdf},
title = {{Keypoints and Descriptors 1}},
year = {2014}
}
@article{Kim2013,
author = {Kim, Jongwoo and Le, Daniel X. and Thoma, George R.},
xxurl = {10.1109/ICDAR.2013.35},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Le, Thoma - 2013 - Identification of Investigator Name Zones Using SVM Classifiers and Heuristic Rules.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {bibliographic information,heuristic rules,investigator names,labeling,machine,medline,support vector},
month = {aug},
number = {c},
pages = {140--144},
publisher = {Ieee},
title = {{Identification of Investigator Name Zones Using SVM Classifiers and Heuristic Rules}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628600},
volume = {2},
year = {2013}
}
@article{Mirza2014,
abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
archivePrefix = {arXiv},
arxivId = {1411.1784},
author = {Mirza, Mehdi and Osindero, Simon},
eprint = {1411.1784},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirza, Osindero - 2014 - Conditional Generative Adversarial Nets.pdf:pdf},
isbn = {1406.2661},
issn = {10495258},
pages = {1--7},
title = {{Conditional Generative Adversarial Nets}},
url = {http://arxiv.org/abs/1411.1784},
year = {2014}
}
@article{Nourbakhsh2010,
author = {Nourbakhsh, Farshad and Karatzas, Dimosthenis and Valveny, Ernest},
xxurl = {10.1145/1815330.1815374},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nourbakhsh, Karatzas, Valveny - 2010 - A polar-based logo representation based on topological and colour features.pdf:pdf},
isbn = {9781605587738},
journal = {Proceedings of the 8th IAPR International Workshop on Document Analysis Systems - DAS '10},
pages = {341--348},
title = {{A polar-based logo representation based on topological and colour features}},
url = {http://portal.acm.org/citation.cfm?xxurld=1815330.1815374},
year = {2010}
}
@article{Trifa20071,
author = {Trifa, Vlad and Girod, Lewis and Collier, Travis C. and Blumstein, Daniel and Taylor, C E},
journal = {Center for Embedded Network Sensing},
keywords = {Multiscaled Actuated Sensing},
month = {jan},
title = {{Automated Wildlife Monitoring Using Self-Configuring Sensor Networks Deployed in Natural Habitats}},
url = {https://escholarship.org/uc/item/2059b99k},
year = {2007}
}
@article{Resources2013a,
author = {Resources, Agricultural and Planning, Regional},
xxurl = {10.1007/s00376-012-1252-3.1.Introduction},
file = {:home/mondal/Documents/climate/pdf/Ye2013{\_}Article{\_}Time-seriesModelingAndPredicti.pdf:pdf},
keywords = {arima,climate,fourier method,polynomial trend,statistical model,time series analysis},
number = {2},
pages = {382--396},
title = {{Time-Series Modeling and Prediction of {\~{a}}}},
volume = {30},
year = {2013}
}
@inproceedings{Mondal2011,
abstract = {Template matching is the process for determining the presence and location of a certain reference in the scene sub image. The conventional approach like spatial correlation, cross correlation is computationally expensive and error prone when the object in the image is rotated or translated. The conventional approach gives erroneous result in the presence of variation in illumination of the scene sub image. In this paper, an algorithm for a rotation, scale and illumination invariant template matching approach is proposed, which is based on the combination of multi-resolution wavelet technique, projection method and Zernike moments. It is ideally suited for highlighting local feature points in the decomposed sub images, and the result is computationally saving in the matching process. As demonstrated in the result, the wavelet decomposition along with Zernike moments makes the template matching scheme feasible and efficient for detecting objects in arbitrary orientation and rotations. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {Mondal, Tanmoy and Mourya, Gajendra Kumar},
booktitle = {Communications in Computer and Information Science},
xxurl = {10.1007/978-3-642-19263-0_15},
isbn = {9783642192623},
issn = {18650929},
keywords = {Rotation,Template matching,Wavelet Decomposition,Zernike Moments,scale and illumination invariance},
title = {{An accelerated approach of template matching for rotation, scale and illumination invariance}},
year = {2011}
}
@article{Bruna2015,
author = {Bruna, Joan},
xxurl = {10.1146/annurev.anthro.35.081705.123127},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bruna - 2015 - The Mathematics of Deep Learning.pdf:pdf},
isbn = {978-0-511-25040-8 978-0-511-24936-5 978-0-511-24989-1 978-0-511-24881-8},
issn = {14657333},
journal = {ICCV Tutorial},
title = {{The Mathematics of Deep Learning}},
year = {2015}
}
@article{Moreels2007,
author = {Moreels, Pierre and Perona, Pietro},
xxurl = {10.1007/s11263-006-9967-1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moreels, Perona - 2007 - Evaluation of Features Detectors and Descriptors based on 3D Objects.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = {jul},
number = {3},
pages = {263--284},
publisher = {Kluwer Academic Publishers},
title = {{Evaluation of Features Detectors and Descriptors based on 3D Objects}},
url = {http://link.springer.com/10.1007/s11263-006-9967-1},
volume = {73},
year = {2007}
}
@article{Rothacker2013,
author = {Rothacker, Leonard and Rusinol, Marcal and Fink, Gernot a.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rothacker, Rusinol, Fink - 2013 - Bag-of-Features HMMs for Segmentation-Free Word Spotting in Handwritten Documents.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rothacker, Rusinol, Fink - 2013 - Bag-of-Features HMMs for Segmentation-Free Word Spotting in Handwritten Documents(2).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {ICDAR},
month = {aug},
pages = {1305--1309},
publisher = {Ieee},
title = {{Bag-of-Features HMMs for Segmentation-Free Word Spotting in Handwritten Documents}},
year = {2013}
}
@article{Wan2017,
abstract = {Dynamic time warping (DTW) distance is commonly used in measuring similarity between time series for classification. In order to obtain the minimum cumulative distance, however, DTW distance may map multiple points on one time series to one point on another, and this makes time series over stretched and compressed, resulting in missing important feature information thus influence the classification accuracy. In this paper, we propose a method called adaptive cost dynamic time warping distance (AC-DTW), which adjusts the number of points on one time series mapped to the points on another. AC-DTW records the trajectories of all points and then adaptively allocates the cost rate to each point by calculating cost function at the next step. The results of the experiments implemented on 17 UCR datasets by using nearest neighbor classifier demonstrate that AC-DTW prevails in criterion of higher accuracy rate in comparison with some existing methods.},
author = {Wan, Yuan and Chen, Xiao Li and Shi, Ying},
xxurl = {10.1016/j.cam.2017.01.004},
file = {:home/mondal/Downloads/1-s2.0-S0377042717300080-main.pdf:pdf},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {Adaptive cost,Dynamic time warping,Nearest neighbor classifier,Time series classification},
pages = {514--520},
publisher = {Elsevier B.V.},
title = {{Adaptive cost dynamic time warping distance in time series analysis for classification}},
url = {http://dx.xxurl.org/10.1016/j.cam.2017.01.004},
volume = {319},
year = {2017}
}
@article{Simmons2006,
author = {Simmons, Sabrina and Zachary, Estes},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simmons, Zachary - 2006 - Using latent semantic analysis to estimate similarity.pdf:pdf},
journal = {Proceedings of the Cognitive Science Society},
title = {{Using latent semantic analysis to estimate similarity}},
url = {http://www.researchgate.net/publication/229028527{\_}Using{\_}latent{\_}semantic{\_}analysis{\_}to{\_}estimate{\_}similarity/file/60b7d514316504ead5.pdf},
year = {2006}
}
@article{Gorecki2012,
author = {G{\'{o}}recki, Tomasz and Luczak, Maciej},
xxurl = {10.1007/s10618-012-0251-4},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
month = {feb},
number = {2},
pages = {310--331},
title = {{Using derivatives in time series classification}},
volume = {26},
year = {2012}
}
@article{Karpushin2016,
author = {Karpushin, Maxim and Member, Student and Valenzise, Giuseppe},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karpushin, Member, Valenzise - 2016 - Keypoint Detection in RGBD Images Based on an Anisotropic Scale Space.pdf:pdf},
number = {9},
pages = {1762--1771},
title = {{Keypoint Detection in RGBD Images Based on an Anisotropic Scale Space}},
volume = {18},
year = {2016}
}
@article{Nafchi2013,
author = {Nafchi, Hossein Ziaei and Moghaddam, Reza Farrahi and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.51},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nafchi, Moghaddam, Cheriet - 2013 - Application of Phase-Based Features and Denoising in Postprocessing and Binarization of Historical D.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {binarization,document image processing,document postperocessing,historical document,phase conruency features},
month = {aug},
pages = {220--224},
publisher = {Ieee},
title = {{Application of Phase-Based Features and Denoising in Postprocessing and Binarization of Historical Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628616},
year = {2013}
}
@article{Lu2004,
author = {Lu, Yue and Tan, Chew Lim},
xxurl = {10.1109/TKDE.2004.76},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {65,Digital images,Document image processing,Electronics packaging,Image converters,Image databases,Image retrieval,Index Terms- Document image retrieval,Information retrieval,Internet,Optical character recognition software,Paper technology,character fonts,character sets,document handling,document image database,document image retrieval,document similarity measurement,document similarity measurement.,image retrieval,information retrieval,partial word image matching,primitive string,string matching,visual databases,word searching,word spotting},
language = {English},
month = {nov},
number = {11},
pages = {1398--1410},
publisher = {IEEE},
title = {{Information retrieval in document image databases}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1339266},
volume = {16},
year = {2004}
}
@article{Dutta2014,
author = {Dutta, Shrey and Murthy, Hema a.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dutta, Murthy - 2014 - Discovering Typical Motifs of a Raga From One-Liners of Songs in Carnatic Music.pdf:pdf},
journal = {International Society for Music Information Retrieval},
title = {{Discovering Typical Motifs of a Raga From One-Liners of Songs in Carnatic Music}},
year = {2014}
}
@inproceedings{Gatos:14a,
author = {Gatos, B and Louloudis, G and Causer, T and Grint, K and Romero, V and S{\'{a}}nchez, J A and Toselli, A H and Vidal, E},
booktitle = {11th IAPR International Workshop on Document Analysis Systems (DAS)},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos et al. - 2014 - Ground-Truth production in the tranScriptorium project.pdf:pdf},
title = {{Ground-Truth production in the tranScriptorium project}},
year = {2014}
}
@article{Biswas2012,
abstract = {The information in a document comes in many forms; this includes texts, tables, charts, symbols, maps, logos, stamps, photographs etc. All these forms may be combined in suitable forms to create a document. Paper land maps are useful documents for collection of geographical information. A land map image can be considered as a complex document image as the texts contained there may have a complex background consists of various intensity values and varied orientations. This paper presents two methods for text extraction from scanned land map images. In the first method we have used mathematical morphological operations for making the symbols of text be connected. Then mean and standard deviations are used for text non-text separation. In the second method we have extracted texts based on intensity analysis. The approaches are tested on a collected dataset of map images and experimental results are encouraging. {\textcopyright} 2012 IEEE.},
author = {Biswas, Samit and Das, Amit Kumar},
xxurl = {10.1109/ICIEV.2012.6317410},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biswas, Das - 2012 - Text extraction from scanned land map images.pdf:pdf},
isbn = {9781467311519},
journal = {2012 International Conference on Informatics, Electronics and Vision, ICIEV 2012},
keywords = {Morpholocical operation,Political map image,Text localization,Text segmentation},
pages = {231--236},
title = {{Text extraction from scanned land map images}},
year = {2012}
}
@article{Karatzas2013,
author = {Karatzas, Dimosthenis and Shafait, Faisal and Uchida, Seiichi and Iwamura, Masakazu and Bigorda, Lluis Gomez I and Mestre, Sergi Robles and Mas, Joan and Mota, David Fernandez and Almazan, Jon Almazan and de las Heras, Lluis Pere},
xxurl = {10.1109/ICDAR.2013.221},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karatzas et al. - 2013 - ICDAR 2013 Robust Reading Competition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1484--1493},
publisher = {Ieee},
title = {{ICDAR 2013 Robust Reading Competition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628859},
year = {2013}
}
@phdthesis{Ratanamahatana2005a,
author = {Ratanamahatana, Chotirat},
isbn = {0-542-19472-4},
month = {jan},
publisher = {University of California, Riverside},
school = {UNIVERSITY OF CALIFORNIA RIVERSIDE},
title = {{Improving efficiency and effectiveness of dynamic time warping in large time series databases}},
url = {http://dl.acm.org/citation.cfm?id=1104439},
year = {2005}
}
@article{Pham2003,
abstract = {A fast and effective algorithm is developed for detecting logos in grayscale document images. The computational schemes involve segmentation, and the calculation of the spatial density of the defined foreground pixels. The detection does not require training and is unconstrained in the sense that the presence of a logo in a document image can be detected under scaling, rotation, translation, and noise. Several tests on different electronic document forms such as letters, faxes, and billing statements are carried out to illustrate the performance of the method. ?? 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Pham, Tuan D.},
xxurl = {10.1016/S0031-3203(03)00125-0},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pham - 2003 - Unconstrained logo detection in document images.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Document imaging,Logo detection,Mountain function,Segmentation},
number = {12},
pages = {3023--3025},
title = {{Unconstrained logo detection in document images}},
volume = {36},
year = {2003}
}
@article{Zhu,
abstract = {The discovery of time series motifs has emerged as one of the most useful primitives in time series data mining. Researchers have shown its utility for exploratory data mining, summarization, visualization, segmentation, classification, clustering, and rule discovery. Although there has been more than a decade of extensive research, there is still no technique to allow the discovery of time series motifs in the presence of missing data, despite the well-documented ubiquity of missing data in scientific, industrial, and medical datasets. In this work, we introduce a technique for motif discovery in the presence of missing data. We formally prove that our method is admissible, producing no false negatives. We also show that our method can "piggy-back" off the fastest known motif discovery method with a small constant factor time/space overhead. We will demonstrate our approach on diverse datasets with varying amounts of missing data.},
archivePrefix = {arXiv},
arxivId = {cs.LG/1802.05472v1},
author = {Zhu, Yan and Mueen, Abdullah and Keogh, Eamonn},
eprint = {1802.05472v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Mueen, Keogh - Unknown - Matrix Profile IX Admissible Time Series Motif Discovery with Missing Data.pdf:pdf},
primaryClass = {cs.LG},
title = {{Matrix Profile IX: Admissible Time Series Motif Discovery with Missing Data}},
url = {https://arxiv.org/pdf/1802.05472.pdf}
}
@article{Kingma2018,
abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1 × 1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a flow-based generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow.},
archivePrefix = {arXiv},
arxivId = {1807.03039},
author = {Kingma, Diederik P. and Dhariwal, Prafulla},
eprint = {1807.03039},
file = {:home/mondal/Downloads/5b67b4b117c44aac1c866cea.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {2},
pages = {10215--10224},
title = {{Glow: Generative flow with invertible 1×1 convolutions}},
volume = {2018-Decem},
year = {2018}
}
@misc{LTDL2007,
institution = {University of California, San Francisco},
title = {{The Legacy Tobacco Document Library ({\{}LTDL{\}})}},
url = {http://legacy.library.ucsf.edu/},
year = {2007}
}
@article{Antonacopoulos2013a,
author = {Antonacopoulos, a. and Clausner, C. and Papadopoulos, C. and Pletschacher, S.},
xxurl = {10.1109/ICDAR.2013.293},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antonacopoulos et al. - 2013 - ICDAR 2013 Competition on Historical Newspaper Layout Analysis (HNLA 2013).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- layout analysis,datasets,documents,historical,newspapers,page,performance evaluation,region classification,segmentation},
month = {aug},
pages = {1454--1458},
publisher = {Ieee},
title = {{ICDAR 2013 Competition on Historical Newspaper Layout Analysis (HNLA 2013)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628854},
year = {2013}
}
@article{Rakthanmanon2012a,
address = {New York, New York, USA},
author = {Rakthanmanon, Thanawin and Campana, Bilson and Mueen, Abdullah and Batista, Gustavo and Westover, Brandon and Zhu, Qiang and Zakaria, Jesin and Keogh, Eamonn and Riverside, U C and Hospital, Women and Paulo, S{\~{a}}o},
xxurl = {10.1145/2339530.2339576},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rakthanmanon et al. - 2012 - Searching and mining trillions of time series subsequences under dynamic time warping.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riverside et al. - Unknown - Searching and Mining Trillions of Time Series Subsequences under Dynamic Time Warping.pdf:pdf},
isbn = {9781450314626},
journal = {Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '12},
keywords = {lower bounds,similarity search,time series},
pages = {262},
publisher = {ACM Press},
title = {{Searching and mining trillions of time series subsequences under dynamic time warping}},
url = {http://dl.acm.org/citation.cfm?xxurld=2339530.2339576},
year = {2012}
}
@article{Kieu2013,
author = {Kieu, V.C. and Journet, Nicholas and Visani, Muriel and Mullot, Remy and Domenger, Jean Phillipe},
xxurl = {10.1109/ICDAR.2013.104},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kieu et al. - 2013 - Semi-synthetic Document Image Generation Using Texture Mapping on Scanned 3D Document Shapes.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-distortion model,per-,synthetic document image},
month = {aug},
pages = {489--493},
publisher = {Ieee},
title = {{Semi-synthetic Document Image Generation Using Texture Mapping on Scanned 3D Document Shapes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628669},
year = {2013}
}
@article{Cheng2016,
abstract = {In this paper, we present an Image-to-Class Dynamic Time Warping (I2C-DTW) approach for the recognition of both 3D static hand gestures and 3D hand trajectory gestures. Our contribution is twofold. First, we propose a technique to compute the image-to-class dynamic time warping distance instead of the Image-to-Image distance. By xxurlng so, we obtain better generalization capability using the Image-to-Class distance than the Image-to-Image distance. Second, we propose a compositional model called fingerlets for static gesture representation, and a compositional model called strokelets for trajectory gesture representation. The compositional models make it possible to compute the DTW distance between a data sample and a gesture category. We have evaluated the static gesture recognition performance on several public 3D hand gesture datasets. For better evaluating the performance on trajectory gesture recognition, we collected a 3D hand trajectory gesture dataset, called UESTC-HTG, using a Kinect device. The experiment results show that the proposed I2C-DTW approach significantly improves the recognition accuracy on both static gestures and trajectory gestures.},
author = {Cheng, Hong and Dai, Zhongjun and Liu, Zicheng and Zhao, Yang},
xxurl = {10.1016/j.patcog.2016.01.011},
file = {:home/mondal/Downloads/1-s2.0-S0031320316000157-main.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {3D hand gesture recognition,Dynamic time warping,Fingerlets,Human computer interaction,Image-to-class distance,Strokelets},
pages = {137--147},
publisher = {Elsevier},
title = {{An image-to-class dynamic time warping approach for both 3D static and trajectory hand gesture recognition}},
url = {http://dx.xxurl.org/10.1016/j.patcog.2016.01.011},
volume = {55},
year = {2016}
}
@article{Howbert2012,
author = {Howbert, Jeff},
file = {:home/mondal/Documents/MATHS/02{\_}math{\_}essentials.pdf:pdf},
title = {{Machine Learning Math Essentials}},
year = {2012}
}
@article{Independent,
author = {Independent, Scheduling and Tasks, Multiprocessor and Sud, Universite Paris and Coquibus, Bvd},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Independent et al. - Unknown - Degraded Character Image Restoration.pdf:pdf},
pages = {1--12},
title = {{Degraded Character Image Restoration}}
}
@article{Huang2014,
abstract = {Most of kmeans-type clustering algorithms rely on only intra-cluster compactness, i.e. the dispersions of a cluster. Inter-cluster separation which is widely used in classification algorithms, however, is rarely considered in a clustering process. In this paper, we present a new discriminative subspace kmeans-type clustering algorithm (DSKmeans), which integrates the intra-cluster compactness and the inter-cluster separation simultaneously. Different to traditional weighting kmeans-type algorithms, a 3-order tensor is constructed to evaluate the importance of different features in order to integrate the aforementioned two types of information. First, a new objective function for clustering is designed. To optimize the objective function, the corresponding updating rules for the algorithm are then derived analytically. The properties and performance of DSKmeans are investigated on several numerical and categorical data sets. Experimental results corroborate that our proposed algorithm outperforms the state-of-the-art kmeans-type clustering algorithms with respects to four metrics: Accuracy, RandIndex, Fscore and Normal Mutual Information(NMI).},
author = {Huang, Xiaohui and Ye, Yunming and Guo, Huifeng and Cai, Yi and Zhang, Haijun and Li, Yan},
xxurl = {10.1016/j.knosys.2014.07.009},
file = {:home/mondal/Downloads/1-s2.0-S0950705114002664-main.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {3-Order tensor,Data mining,Feature selection,Kmeans clustering,Subspace clustering},
pages = {293--300},
publisher = {Elsevier B.V.},
title = {{DSKmeans: A new kmeans-type approach to discriminative subspace clustering}},
url = {http://dx.xxurl.org/10.1016/j.knosys.2014.07.009},
volume = {70},
year = {2014}
}
@book{Hassaballah2016,
author = {Hassaballah, M and Abdelmgeid, Aly Amin and Alshazly, Hammam A},
xxurl = {10.1007/978-3-319-28854-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassaballah, Abdelmgeid, Alshazly - 2016 - Image Feature Detectors and Descriptors(2).pdf:pdf},
isbn = {978-3-319-28852-9},
issn = {1860949X},
keywords = {feature descriptor,feature detector,feature extrac-,feature matching,interest points,tion},
pages = {11--46},
title = {{Image Feature Detectors and Descriptors}},
url = {http://link.springer.com/10.1007/978-3-319-28854-3},
volume = {630},
year = {2016}
}
@article{Hassaine2013a,
author = {Hassaine, Abdelaali and {Al Maadeed}, Somaya and Bouridane, Ahmed},
xxurl = {10.1109/ICDAR.2013.285},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassaine, Al Maadeed, Bouridane - 2013 - ICDAR 2013 Competition on Handwriting Stroke Recovery from Offline Data.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1412--1416},
publisher = {Ieee},
title = {{ICDAR 2013 Competition on Handwriting Stroke Recovery from Offline Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628846},
year = {2013}
}
@article{Kingma2013a,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Welling - 2013 - Auto-Encoding Variational Bayes(2).pdf:pdf},
month = {dec},
title = {{Auto-Encoding Variational Bayes}},
year = {2013}
}
@article{Gao2013,
author = {Gao, Hongxing and Rusinol, Marcal and Karatzas, Dimosthenis and Llados, Josep and Sato, Tomokazu and Iwamura, Masakazu and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.53},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao et al. - 2013 - Key-Region Detection for Document Images -- Application to Administrative Document Retrieval.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {230--234},
publisher = {Ieee},
title = {{Key-Region Detection for Document Images -- Application to Administrative Document Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628618},
year = {2013}
}
@article{Rodr2012,
author = {Rodriguez-Serrano, J and Perronnin, F},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodriguez-Serrano, Perronnin - 2012 - A model-based sequence similarity with application to handwritten word-spotting.pdf:pdf},
pages = {1--14},
title = {{A model-based sequence similarity with application to handwritten word-spotting}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6133288},
year = {2012}
}
@article{Roy2008a,
abstract = {Automatic separation of text and symbols from graphics in document image is one of the fundamental aims in graphics recognition. In maps, separation of text and symbols from graphics involves many challenges because the text and symbols frequently touch/overlap with graphical components. Sometimes the colors in a single character are gradually distributed which adds extra difficulty in text and symbol separation from color maps. In this paper we proposed a system to retrieve text and symbol from color map. Here, at first, we separate the map into different foreground layers according to color features and then in each layer, connected component features and skeleton information are used to identify text and symbol from graphics on the basis of their geometrical features. Lastly, segmentation results of the individual layers are combined to get final segmentation results. From the experiment we obtained encouraging results. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
author = {Roy, Partha Pratim and Vazquez, Eduard and Llad{\'{o}}s, Josep and Baldrich, Ramon and Pal, Umapada},
xxurl = {10.1007/978-3-540-88188-9_23},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy et al. - 2008 - A system to segment text and symbols from color maps.pdf:pdf},
isbn = {3540881840},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {245--256},
title = {{A system to segment text and symbols from color maps}},
volume = {5046 LNCS},
year = {2008}
}
@article{Gu2011,
abstract = {To solve the QR code recognition problem caused by ordinary camera collection, the recognition algorithm based on image processing is put forward in this paper. The whole process including image binarization, image tilt correction, image orientation, image geometric correction and image normalization allows images collected on different illumination conditions, different acquisition angles to be quickly identified. Based on other recognition algorithm, some improvements are presented in the image tilt correction, image orientation, image normalization and so on to speed up the image processing and to achieve more simply. Experiments show that the improved method can enhance the recognition speed of two-dimensional code and accuracy.},
author = {Gu, Yunhua and Zhang, Weixiang},
xxurl = {10.1109/ICIST.2011.5765349},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu, Zhang - 2011 - QR code recognition based on image processing.pdf:pdf},
isbn = {978-1-4244-9440-8},
journal = {International Conference on Information Science and Technology},
keywords = {Accuracy,Pixel,QR code recognition,acquisition angle,bar codes,camera collection,cameras,illumination condition,image binarization,image geometric correction,image normalization,image orientation,image processing,image recognition,image segmentation,image tilt correction,lighting},
pages = {733--736},
title = {{QR code recognition based on image processing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5765349},
year = {2011}
}
@article{Chen2003,
abstract = {Logo recognition is of great interest in the document and shape analysis domain. In order to develop a recognition method that is robust to employ under adverse conditions such as different scale/orientation, broken curves, added noise and occlusion, a modified line segment Hausdorff distance is proposed in this paper. The new approach has the advantage to incorporate structural and spatial information to compute dissimilarity between two sets of line segments rather than two sets of points. The proposed technique has been applied on line segments generated from logos with encouraging results. Clear cut distinction between the correct and incorrect matches has been observed. This suggests a strong potential for logo and shape recognition system.},
author = {Chen, Jingying and Leung, Maylor K. and Gao, Yongsheng},
xxurl = {10.1016/S0031-3203(02)00128-0},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Leung, Gao - 2003 - Noisy logo recognition using line segment Hausdorff distance.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {hausdor distance,line,logo matching,shape},
number = {4},
pages = {943--955},
title = {{Noisy logo recognition using line segment Hausdorff distance}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320302001280},
volume = {36},
year = {2003}
}
@article{Baechler2013,
author = {Baechler, Micheal and Liwicki, Marcus and Ingold, Rolf},
xxurl = {10.1109/ICDAR.2013.206},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baechler, Liwicki, Ingold - 2013 - Text Line Extraction Using DMLP Classifiers for Historical Manuscripts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1029--1033},
publisher = {Ieee},
title = {{Text Line Extraction Using DMLP Classifiers for Historical Manuscripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628771},
year = {2013}
}
@inproceedings{Hao2012,
abstract = {The detection of frequently occurring patterns, also called motifs, in data streams has been recognized as an important task. To find these motifs, we use an advanced event encoding and pattern discovery algorithm. As a large time series can contain hundreds of motifs, there is a need to support interactive analysis and exploration. In addition, for certain applications, such as data center resource management, service managers want to be able to predict the next day's power consumption from the previous months' data. For this purpose, we introduce four novel visual analytics methods: (i) motif layout - using colored rectangles for visualizing the occurrences and hierarchical relationships of motifs; (ii) motif distortion - enlarging or shrinking motifs for visualizing them more clearly; (iii) motif merging - combining a number of identical adjacent motif instances to simplify the display; and (iv) pattern preserving prediction - using a pattern-preserving smoothing and prediction algorithm to provide a reliable prediction for seasonal data. We have applied these methods to three real-world datasets: data center chilling utilization, oil well production, and system resource utilization. The results enable service managers to interactively examine motifs and gain new insights into the recurring patterns to analyze system operations. Using the above methods, we have also predicted both power consumption and server utilization in data centers with an accuracy of 70-80{\%}. {\textcopyright} The Author(s) 2011.},
author = {Hao, Ming C. and Marwah, Manish and Janetzko, Halld{\'{o}}r and Dayal, Umeshwar and Keim, Daniel A. and Patnaik, Debprakash and Ramakrishnan, Naren and Sharma, Ratnesh K.},
booktitle = {Information Visualization},
xxurl = {10.1177/1473871611430769},
issn = {14738716},
keywords = {Distortion,Frequent patterns,Merging,Motifs,Multivariate time series,Prediction,Seasonal data},
title = {{Visual exploration of frequent patterns in multivariate time series}},
year = {2012}
}
@article{Lee2010,
abstract = {NIPS 2010 Workshop on Deep Learning and Unsupervised Feature Learning},
author = {Lee, Honglak},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee - 2010 - Tutorial on Deep Learning and Applications.pdf:pdf},
journal = {Talk},
title = {{Tutorial on Deep Learning and Applications}},
year = {2010}
}
@article{Goel2013,
author = {Goel, Vibhor and Mishra, Anand and Alahari, Karteek and Jawahar, C.V.},
xxurl = {10.1109/ICDAR.2013.87},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goel et al. - 2013 - Whole is Greater than Sum of Parts Recognizing Scene Text Words.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {398--402},
publisher = {Ieee},
title = {{Whole is Greater than Sum of Parts: Recognizing Scene Text Words}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628652},
year = {2013}
}
@article{Lopes2018,
abstract = {Climate has complex dynamics due to the plethora of phenomena underlying its evolution. These characteristics pose challenges to conducting solid quantitative analysis and reaching assertive conclusions. In this paper, the global temperature time series (TTS) is viewed as a manifestation of the climate evolution, and its complexity is calculated by means of four different indices, namely the Lempel-Ziv complexity, sample entropy, signal harmonics power ratio, and fractal dimension. In the first phase, the monthly mean TTS is pre-processed by means of empirical mode decomposition, and the TTS trend is calculated. In the second phase, the complexity of the detrended signals is estimated. The four indices capture distinct features of the TTS dynamics in a 4-dim space. Hierarchical clustering is adopted for dimensional reduction and visualization in the 2-dim space. The results show that TTS complexity exhibits space-time variability, suggesting the presence of distinct climate forcing processes in both dimensions. Numerical examples with real-world data demonstrate the effectiveness of the approach.},
author = {Lopes, Ant{\'{o}}nio M. and Machado, J. A.Tenreiro},
xxurl = {10.3390/e20060437},
file = {:home/mondal/Documents/climate/pdf/entropy-20-00437-1.pdf:pdf},
issn = {10994300},
journal = {Entropy},
keywords = {Complexity,Lempel-Ziv complexity,Sample entropy,Temperature time series},
number = {6},
pages = {1--16},
title = {{Complexity analysis of global temperature time series}},
volume = {20},
year = {2018}
}
@article{Kim2005a,
author = {Kim, Chanwoo and Seo, Kwang-deok},
xxurl = {10.1109/TCE.2005.1468022},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Seo - 2005 - Robust DTW-based recognition algorithm for hand-held consumer devices.pdf:pdf},
issn = {0098-3063},
journal = {IEEE Transactions on Consumer Electronics},
month = {may},
number = {2},
pages = {699--709},
title = {{Robust DTW-based recognition algorithm for hand-held consumer devices}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1468022},
volume = {51},
year = {2005}
}
@article{Tak2008,
author = {Tak, Yoon-Sik},
xxurl = {10.3837/tiis.2008.06.001},
issn = {19767277},
journal = {KSII Transactions on Internet and Information Systems},
keywords = {Dynamic time warping,K-NN,Range search,Rotation invariance,Sequence matching,Shape-based image retrieval},
language = {English},
month = {dec},
number = {6},
pages = {280--298},
title = {{Pruning and Matching Scheme for Rotation Invariant Leaf Image Retrieval}},
url = {http://koreauniv.pure.elsevier.com/en/publications/pruning-and-matching-scheme-for-rotation-invariant-leaf-image-retrieval(26a538a8-d26e-4b7b-bea1-bba2fe25f652).html},
volume = {2},
year = {2008}
}
@incollection{Agrawal1993a,
abstract = {We propose an indexing method for time sequences for processing similarity queries. We use the Discrete Fourier Transform (DFT) to map time sequences to the frequency domain, the crucial observation being that, for most sequences of practical interest, only the first few frequencies are strong. Another important observation is Parseval's theorem, which specifies that the Fourier transform preserves the Euclidean distance in the time or frequency domain. Having thus mapped sequences to a lower-dimensionality space by using only the first few Fourier coefficients, we use R*-trees to index the sequences and efficiently answer similarity queries. We provide experimental results which show that our method is superior to search based on sequential scanning. Our experiments show that a few coefficients (1-3) are adequate to provide good performance. The performance gain of our method increases with the number and length of sequences.},
author = {Agrawal, Rakesh and Faloutsos, Christos and Swami, Arun},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
xxurl = {10.1007/3-540-57301-1_5},
isbn = {9783540573012},
issn = {16113349},
pages = {69--84},
title = {{Efficient similarity search in sequence databases}},
url = {http://link.springer.com/10.1007/3-540-57301-1{\_}5},
year = {1993}
}
@article{Summary2014,
author = {Summary, Invoice},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Summary - 2014 - Amazon Web Services Invoice.pdf:pdf},
isbn = {1697552900},
pages = {1--2},
title = {{Amazon Web Services Invoice}},
year = {2014}
}
@article{Bhatia2018,
abstract = {Earthquake is one of the most devastating natural calamities that takes thousands of lives and leaves millions more homeless and deprives them of the basic necessities. Earthquake forecasting can minimize the death count and economic loss encountered by the affected region to a great extent. This study presents an earthquake forecasting system by using Artificial Neural Networks (ANN). Two different techniques are used with the first focusing on the accuracy evaluation of multilayer perceptron using different inputs and different set of hyper-parameters. The limitation of earthquake data in the first experiment led us to explore another technique, known as nowcasting of earthquakes. The nowcasting technique determines the current progression of earthquake cycle of higher magnitude earthquakes by taking into account the number of smaller earthquake events in the same region. To implement the nowcasting method, a Long Short Term Memory (LSTM) neural network architecture is considered because such networks are one of the most recent and promising developments in the time-series analysis. Results of different experiments are discussed along with their consequences.},
author = {Bhatia, Anmol and Pasari, Sumanta and Mehta, Anand},
xxurl = {10.5194/isprs-archives-XLII-5-823-2018},
file = {:home/mondal/Documents/climate/pdf/isprs-archives-XLII-5-823-2018.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Earthquake Forecasting,LSTM Networks,Multilayer Perceptron,Neural Networks,Recurrent Neural Networks},
number = {5},
pages = {823--827},
title = {{Earthquake forecasting using artificial neural networks}},
volume = {42},
year = {2018}
}
@article{Tan2002,
author = {Tan, Chew Lim and Huang, Weihua and Yu, Zhaohui and Xu, Yi},
xxurl = {10.1109/TPAMI.2002.1008389},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Chinese-language text,Computer Society,English-language text,Humans,Image analysis,Image databases,Image retrieval,Image segmentation,Natural languages,Optical character recognition software,Spatial databases,Testing,UW1 database,character objects,document image analysis,document image processing,document segmentation,document vector dot product,feature extraction,horizontal traverse density,image feature extraction,image segmentation,imaged document text retrieval,imaged textual document corpora,information retrieval,n-gram-based document vector,text similarity,vectors,vertical traverse density,visual databases},
language = {English},
month = {jun},
number = {6},
pages = {838--844},
publisher = {IEEE},
title = {{Imaged document text retrieval without OCR}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1008389},
volume = {24},
year = {2002}
}
@article{Howe2013a,
annote = {From Duplicate 1 ( 





















Part-Structured Inkball Models for One-Shot Handwritten Word Spotting





















- Howe, Nicholas R. )







},
author = {Howe, Nicholas R.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Howe - 2013 - Part-Structured Inkball Models for One-Shot Handwritten Word Spotting.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Howe - 2013 - Part-Structured Inkball Models for One-Shot Handwritten Word Spotting(2).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {ICDAR},
month = {aug},
pages = {582--586},
publisher = {Ieee},
title = {{Part-Structured Inkball Models for One-Shot Handwritten Word Spotting}},
year = {2013}
}
@article{Terasawa2009a,
author = {Terasawa, Kengo and Tanaka, Yuzuru},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Terasawa, Tanaka - 2009 - Slit Style HOG Feature for Document Image Word-Spotting.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {ICDAR},
pages = {116--120},
publisher = {Ieee},
title = {{Slit Style HOG Feature for Document Image Word-Spotting}},
year = {2009}
}
@article{Zanibbi2011,
author = {Zanibbi, Richard and Yu, Li},
xxurl = {10.1109/ICDAR.2011.96},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zanibbi, Yu - 2011 - Math Spotting Retrieving Math in Technical Documents Using Handwritten Query Images.pdf:pdf},
isbn = {978-1-4577-1350-7},
journal = {2011 International Conference on Document Analysis and Recognition},
keywords = {-mathematical information retrieval,keyword spotting,math recog-,nition,recognition,segmentation and image-similarity algorithms,similar to keyword,use of optical character,without the},
month = {sep},
pages = {446--451},
publisher = {Ieee},
title = {{Math Spotting: Retrieving Math in Technical Documents Using Handwritten Query Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065351},
year = {2011}
}
@article{Cheng2013,
author = {Cheng, Beibei and Stanley, R. Joe and Antani, Sameer and Thoma, George R.},
xxurl = {10.1109/ICDAR.2013.142},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng et al. - 2013 - Graphical Figure Classification Using Data Fusion for Integrating Text and Image Features.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {binary particle swarm optimization,bpso,data fusion,ea,evolutionary algorithm,feature selection,image processing,layer perceptron neural network,mlp-nn,multi-},
month = {aug},
pages = {693--697},
publisher = {Ieee},
title = {{Graphical Figure Classification Using Data Fusion for Integrating Text and Image Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628707},
year = {2013}
}
@article{Artstein1983,
abstract = { Location: Ref DB 13 Keywords: Control Lyapunov functions (clf) Relaxed$\backslash$ncontrols stabilization dither small control property pulse width$\backslash$nmodulation Comments: This paper is one of the first to discuss the$\backslash$nidea of a control Lyapunov function (clf), although it is not called$\backslash$nthat in the paper. The main result of the paper is that a system$\backslash$nis guaranteed to be stabilizable by relaxed controls iff there is$\backslash$na C{\^{}}1 function V{\textgreater}0 such that $\backslash$inf{\_}u$\backslash$in U V{\_}x$\backslash$cdot f(x,u) {\textless} 0$\backslash$nexcept at x==0. The system is globally stabilizable if V is radially$\backslash$nunbounded. The relaxed control is not necessarily continuous, unless$\backslash$nV also satisifies the small control property (not called this in$\backslash$nthe paper). The author claims that the difference between this paper$\backslash$nand $\backslash$cite{\{}Sontag83{\}} is Sontag does not look for Smooth clf's. Indeed$\backslash$nthis paper guarantees the existence of smooth clf given that a smooth$\backslash$nrelaxed control can asymptotically stabilize the system. $\backslash$cite{\{}Sontag83{\}}$\backslash$ndoes not require the control to be (relaxed) control to be smooth,$\backslash$nand does not guarantee that V will be smooth. },
author = {Artstein, Zvi},
xxurl = {10.1016/0362-546X(83)90049-4},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Artstein - 1983 - Stabilization with relaxed controls.pdf:pdf},
issn = {0362546X},
journal = {Nonlinear Analysis: Theory, Methods {\&} Applications},
keywords = {and phrases,lyapunov functions,relaxed controls,stabilization},
number = {11},
pages = {1163--1173},
title = {{Stabilization with relaxed controls}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0362546X83900494},
volume = {7},
year = {1983}
}
@article{Goto2013,
author = {Goto, Masanori and Ishida, Ryosuke and Feng, Yaokai and Uchida, Seiichi},
xxurl = {10.1109/ICDAR.2013.10},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goto et al. - 2013 - Analyzing the Distribution of a Large-Scale Character Pattern Set Using Relative Neighborhood Graph.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {3--7},
publisher = {Ieee},
title = {{Analyzing the Distribution of a Large-Scale Character Pattern Set Using Relative Neighborhood Graph}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628575},
year = {2013}
}
@article{Senin2008,
abstract = {A flexible, low cost, and portable indoor navigational aid for persons who are blind or have severe visual impairments remains an unmet need and a technical challenge. Whereas devices using global positioning system (GPS) signals hold promise for navigational assistance in the outdoor environment, they do not work where GPS signals are absent or greatly attenuated. Thus a network of navigational beacons is needed for the indoor environment. This paper describes the promise of an indoor navigational aid that relies on a network of custom extended-range RFID tags. RFID (radio-frequency identification) technology has the advantages of being low cost, unobtrusive, and highly flexible in the sense that sight impaired travelers can use personalized RFID tags to mark indoor locations of their particular interest. However, commercially available RFID tags have very short detection ranges. To make them suitable as indoor electronic beacons, their range of detection must be greatly extended. Some of the technical challenges and proposed solutions that can extend the detection range are discussed in this paper following an overview of the proposed RFID based indoor navigational aid.},
author = {Senin, Pavel},
xxurl = {10.1109/IEMBS.2007.4353810},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Senin - 2008 - Dynamic Time Warping Algorithm Review.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Senin - 2008 - Dynamic Time Warping Algorithm Review(2).pdf:pdf},
issn = {1557170X},
journal = {Science},
number = {December},
pages = {1--23},
pmid = {18003476},
title = {{Dynamic Time Warping Algorithm Review}},
url = {http://129.173.35.31/{~}pf/Linguistique/Treillis/ReviewDTW.pdf},
volume = {2007},
year = {2008}
}
@inproceedings{ZZSY+2016,
author = {Zhu, Yan and Zimmerman, Zachary and Senobari, Nader Shakibay and Yeh, Chin-Chia Michael and Funning, Gareth and Mueen, Abdullah and Brisk, Philip and Keogh, Eamonn J},
booktitle = {Proceedings of the International Conference on Data Mining (ICDM)},
pages = {739--748},
title = {{Matrix Profile {\{}II:{\}} Exploiting a Novel Algorithm and GPUs to Break the One Hundred Million Barrier for Time Series Motifs and Joins}},
year = {2016}
}
@article{Kimmel2011,
abstract = {Detection and description of affine-invariant features is a cornerstone component in numerous computer vision applications. In this note, we analyze the notion of maximally stable extremal regions (MSERs) through the prism of the curvature scale space, and conclude that in its original definition, MSER prefers regular (round) regions. Arguing that interesting features in natural images usually have irregular shapes, we propose alternative definitions of MSER which are free of this bias, yet maintain their invariance properties.},
author = {Kimmel, Ron and Zhang, Cuiping and Bronstein, Alex and Bronstein, Michael},
xxurl = {10.1109/TPAMI.2011.133},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {MSER,affine invariance,correspondence,feature detector,stable region},
number = {11},
pages = {2316--2320},
pmid = {21709304},
title = {{Are MSER features really interesting?}},
volume = {33},
year = {2011}
}
@article{Rama2013,
abstract = {The ASJP (Automated Similarity Judgment Program) described an automated, lexical similarity-based method for dating the world's language groups using 52 archaeological, epigraphic and historical calibration date points. The present paper describes a new automated dating method, based on phonotactic diversity. Unlike ASJP, our method does not require any information on the internal classification of a language group. Also, the method can use all the available word lists for a language and its dialects eschewing the debate on 'language' vs. 'dialect'. We further combine these dates and provide a new baseline which, to our knowledge, is the best one. We make a systematic comparison of our method, ASJP's dating procedure, and combined dates. We predict time depths for world's language families and sub-families using this new baseline. Finally, we explain our results in the model of language change given by Nettle.},
author = {Rama, Taraka},
xxurl = {10.1371/journal.pone.0063238},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rama - 2013 - Phonotactic diversity predicts the time depth of the world's language families.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Algorithms,Cultural Evolution,History, Ancient,Humans,Language,Language: history,Linguistics,Linguistics: methods,Models, Theoretical,Phonation,Time Factors},
month = {jan},
number = {5},
pages = {e63238},
pmid = {23691003},
publisher = {Public Library of Science},
title = {{Phonotactic diversity predicts the time depth of the world's language families.}},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0063238},
volume = {8},
year = {2013}
}
@article{Felzenszwalb2010,
author = {Felzenszwalb, P F and Girshick, R B and McAllester, D and Ramanan, D},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb et al. - 2010 - Object Detection with Discriminative Trained Part Based Models.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Object Detection; Object Localization; Part-based},
number = {9},
pages = {1627--1645},
title = {{Object Detection with Discriminative Trained Part Based Models}},
volume = {32},
year = {2010}
}
@article{Wang2013f,
author = {Wang, Xiaobing and Song, Yonghong and Zhang, Yuanlin},
xxurl = {10.1109/ICDAR.2013.278},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Song, Zhang - 2013 - Natural Scene Text Detection with Multi-channel Connected Component Segmentation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1375--1379},
publisher = {Ieee},
title = {{Natural Scene Text Detection with Multi-channel Connected Component Segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628839},
year = {2013}
}
@article{Kessi2016,
author = {Kessi, Louisa and Bourgeois, Frank Le and Garcia, Christophe and Kessi, Louisa and Bourgeois, Frank Le and Garcia, Christophe and Efficient, An and Characters, New Pde-based and Kessi, Louisa and Lebourgeois, Frank and Garcia, Christophe},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kessi et al. - 2016 - An Efficient New PDE-based Characters Reconstruction After Graphics Removal.pdf:pdf},
title = {{An Efficient New PDE-based Characters Reconstruction After Graphics Removal}},
year = {2016}
}
@article{Goutte1999,
abstract = {Analysis of fMRI time series is often performed by extracting one or more parameters for the individual voxels. Methods based, e.g., on various statistical tests are then used to yield parameters corresponding to probability of activation or activation strength. However, these methods do not indicate whether sets of voxels are activated in a similar way or in different ways. Typically, delays between two activated signals are not identified. In this article, we use clustering methods to detect similarities in activation between voxels. We employ a novel metric that measures the similarity between the activation stimulus and the fMRI signal. We present two different clustering algorithms and use them to identify regions of similar activations in an fMRI experiment involving a visual stimulus.},
author = {Goutte, Cyril and Toft, Peter and Rostrup, Egill and Nielsen, Finn {\AA} and Hansen, Lars Kai},
xxurl = {10.1006/nimg.1998.0391},
issn = {10538119},
journal = {NeuroImage},
month = {mar},
number = {3},
pages = {298--310},
title = {{On Clustering fMRI Time Series}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811998903913},
volume = {9},
year = {1999}
}
@article{Suk2017a,
abstract = {Artificial neural networks, conceptually and structurally inspired by neural systems, are of great interest along with deep learning, thanks to their great successes in various fields including medical imaging analysis. In this chapter, we describe the fundamental concepts and ideas of (deep) neural networks and explain algorithmic advances to learn network parameters efficiently by avoiding overfitting. Specifically, this chapter focuses on introducing (i) feed-forward neural networks, (ii) gradient descent-based parameter optimization algorithms, (iii) different types of deep models, (iv) technical tricks for fast and robust training of deep models, and (v) open source deep learning frameworks for quick practice.},
author = {Suk, Heung Il},
xxurl = {10.1016/B978-0-12-810408-8.00002-X},
file = {:home/mondal/Documents/MATHS/appendix{\_}b{\_}algebra.pdf:pdf},
isbn = {9780128104095},
journal = {Deep Learning for Medical Image Analysis},
keywords = {Convolutional neural network,Deep Boltzmann machine,Deep belief network,Deep learning,Neural networks},
pages = {3--24},
title = {{An Introduction to Neural Networks and Deep Learning}},
year = {2017}
}
@article{Wang2015,
abstract = {As font is one of the core design concepts, automatic font identification and similar font suggestion from an image or photo has been on the wish list of many designers. We study the Visual Font Recognition (VFR) problem [4], and advance the state-of-The-Art remarkably by developing the DeepFont system. First of all, we build up the first avail-able large-scale VFR dataset, named AdobeVFR, consisting of both labeled synthetic data and partially labeled real-world data. Next, to combat the domain mismatch between available training and testing data, we introduce a Convo-lutional Neural Network (CNN) decomposition approach, using a domain adaptation technique based on a Stacked Convolutional Auto-Encoder (SCAE) that exploits a large corpus of unlabeled real-world text images combined with synthetic data preprocessed in a specific way. Moreover, we study a novel learning-based model compression approach, in order to reduce the DeepFont model size without sacrific-ing its performance. The DeepFont system achieves an ac-curacy of higher than 80{\%} (top-5) on our collected dataset, and also produces a good font similarity measure for font selection and suggestion. We also achieve around 6 times compression of the model without any visible loss of recog-nition accuracy.},
archivePrefix = {arXiv},
arxivId = {1507.03196},
author = {Wang, Zhangyang and Yang, Jianchao and Jin, Hailin and Shechtman, Eli and Agarwala, Aseem and Brandt, Jonathan and Huang, Thomas S.},
xxurl = {10.1145/2733373.2806219},
eprint = {1507.03196},
file = {:home/mondal/Downloads/1507.03196v1.pdf:pdf},
isbn = {9781450334594},
journal = {MM 2015 - Proceedings of the 2015 ACM Multimedia Conference},
keywords = {Deep Learning,Domain Adaptation,Model Compression,Visual Font Recognition},
pages = {451--459},
title = {{DeepFont: Identify your font from an image}},
year = {2015}
}
@article{Amaral2013,
author = {Amaral, Aline Maria M.M. and Freitas, Cinthia Obladen De Almendra and Bortolozzi, Flavio},
xxurl = {10.1109/ICDAR.2013.188},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amaral, Freitas, Bortolozzi - 2013 - Feature Selection for Forensic Handwriting Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-feature selection,forensic,forensic letter,graphometric feature,handwriting analysis,writer identification},
month = {aug},
pages = {922--926},
publisher = {Ieee},
title = {{Feature Selection for Forensic Handwriting Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628753},
year = {2013}
}
@article{Roy2013,
author = {Roy, Ankush and Garain, Utpal},
xxurl = {10.1109/ICDAR.2013.105},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy, Garain - 2013 - A Probabilistic Model for Reconstruction of Torn Forensic Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {abilistic reconstruction,colour cue,computational,document reconstruction,prob-,shape prior,torn documents},
month = {aug},
pages = {494--498},
publisher = {Ieee},
title = {{A Probabilistic Model for Reconstruction of Torn Forensic Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628670},
year = {2013}
}
@article{Al-HajjMohamad2009,
abstract = {The problem addressed in this study is the offline recognition of handwritten Arabic city names. The names are assumed to belong to a fixed lexicon of about 1,000 entries. A state-of-the-art classical right-left hidden Markov model (HMM)-based recognizer (reference system) using the sliding window approach is developed. The feature set includes both baseline-independent and baseline-dependent features. The analysis of the errors made by the recognizer shows that the inclination, overlap, and shifted positions of diacritical marks are major sources of errors. In this paper, we propose coping with these problems. Our approach relies on the combination of three homogeneous HMM-based classifiers. All classifiers have the same topology as the reference system and differ only in the orientation of the sliding window. We compare three combination schemes of these classifiers at the decision level. Our reported results on the benchmark IFN/ENIT database of Arabic Tunisian city names give a recognition rate higher than 90 percent accuracy and demonstrate the superiority of the neural network-based combination. Our results also show that the combination of classifiers performs better than a single classifier dealing with slant-corrected images and that the approach is robust for a wide range of orientation angles.},
author = {{Al-Hajj Mohamad}, Ramy and Likforman-Sulem, Laurence and Mokbel, Chafic},
xxurl = {10.1109/TPAMI.2008.136},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Hajj Mohamad, Likforman-Sulem, Mokbel - 2009 - Combining slanted-frame classifiers for improved HMM-based Arabic handwriting recognit.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Markov Chains,Middle East,Models, Statistical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reading,Subtraction Technique},
month = {jul},
number = {7},
pages = {1165--77},
pmid = {19443916},
title = {{Combining slanted-frame classifiers for improved HMM-based Arabic handwriting recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19443916},
volume = {31},
year = {2009}
}
@article{Mondal2011a,
abstract = {Anatomical structure tracing on cephalograms is a significant way to obtain cephalometric analysis. Cephalometric analysis is divided in two categories, manual and automatic approaches. The manual approach is limited in accuracy and repeatability due to differences in inter- and intra-personal marking. In this paper, we have attempted to develop and test a novel method for automatic localization of craniofacial structures based on the detected edges in the region of interest. Before edge detection of the particular region, the region was filtered by adaptive non local filter for noise removal by keeping the edge information undisturbed. According to the gray-scale feature at the different regions of the cephalograms, modified Canny edge detection algorithm for obtaining tissue contour was proposed. With the application of morphological opening and edge linking approaches, an improved bidirectional contour tracing methodology was proposed by an interactive selection of the starting edge pixels, the tracking process searches repetitively for an edge pixel at the neighborhood of previously searched edge pixel to segment images, and then craniofacial structures are obtained. The effectiveness of the algorithm is demonstrated by the preliminary experimental results obtained with the proposed method.},
author = {Mondal, Tanmoy and Jain, Ashish and Sardana, H. K.},
xxurl = {10.1109/TIP.2011.2131662},
issn = {19410042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
title = {{Automatic craniofacial structure detection on cephalometric images.}},
year = {2011}
}
@article{Higa2013,
author = {Higa, Keisuke and Hotta, Seiji},
xxurl = {10.1109/ICDAR.2013.112},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Higa, Hotta - 2013 - Local Subspace Classifier with Transformation Invariance for Appearance-Based Character Recognition in Natural Imag.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {533--537},
publisher = {Ieee},
title = {{Local Subspace Classifier with Transformation Invariance for Appearance-Based Character Recognition in Natural Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628677},
year = {2013}
}
@article{He2013,
author = {He, Yuan and Pan, Pan and Xie, Shufu and Sun, Jun and Naoi, Satoshi},
xxurl = {10.1109/ICDAR.2013.88},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2013 - A Book Dewarping System by Boundary-Based 3D Surface Reconstruction.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {3d surface reconstruction,document image rectification,document image restoration,image dewarping,the classification is illustrated,without additional information},
month = {aug},
pages = {403--407},
publisher = {Ieee},
title = {{A Book Dewarping System by Boundary-Based 3D Surface Reconstruction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628653},
year = {2013}
}
@article{Aach2001,
abstract = {Motivation: Increasingly, biological processes are being studied through time series of RNA expression data collected for large numbers of genes. Because common processes may unfold at varying rates in different experiments or individuals, methods are needed that will allow corresponding expression states in different time series to be mapped to one another. Results: We present implementations of time warping algorithms applicable to RNA and protein expression data and demonstrate their application to published yeast RNA expression time series. Programs executing two warping algorithms are described, a simple warping algorithm and an interpolative algorithm, along with programs that generate graphics that visually present alignment information. We show time warping to be superior to simple clustering at mapping corresponding time states. We document the impact of statistical measurement noise and sample size on the quality of time alignments, and present issues related to statistical assessment of alignment quality through alignment scores. We also discuss directions for algorithm improvement including development of multiple time series alignments and possible applications to causality searches and non-temporal processes ( concentration warping'). Availability: Academic implementations of alignment programs genewarp and genewarpi and the graphics generation programs grphwarp and grphwarpi are available as Win32 system DOS box executables on our web site along with documentation on their use. The publicly available data on which they were demonstrated may be found at http://genome-www.stanford.edu/cellcycle/. Postscript files generated by grphwarp and grphwarpi may be directly printed or viewed using GhostView software available at http://www.cs.wisc.edu/{\~{}}ghost/. Contact: church@arep.med.harvard.edu Supplementary information: http://arep.med.harvard.edu/timewarp/supplement.htm.},
author = {Aach, J. and Church, G. M.},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jun},
number = {6},
pages = {495--508},
title = {{Aligning gene expression time series with time warping algorithms}},
volume = {17},
year = {2001}
}
@article{Yan2013,
author = {Yan, Yan and Yin, Xu-Cheng and Wang, Zhi-Bin and Yin, Xuwang and Yang, Chun and Hao, Hong-Wei},
xxurl = {10.1109/ICDAR.2013.138},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan et al. - 2013 - Sorting-Based Dynamic Classifier Ensemble Selection.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {3,4,can achieve better performance,classifier sorting,classifiers instead,diversity measurement,dynamic,ensemble learning,ensemble selection,of using them all,selecting part of the,studies have shown that},
month = {aug},
pages = {673--677},
publisher = {Ieee},
title = {{Sorting-Based Dynamic Classifier Ensemble Selection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628703},
year = {2013}
}
@article{Rodr2008,
author = {Rodriguez, JA and Perronnin, F},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodriguez, Perronnin - 2008 - Unsupervised writer style adaptation for handwritten word spotting.pdf:pdf},
isbn = {9781424421756},
journal = {ICPR},
pages = {1--4},
title = {{Unsupervised writer style adaptation for handwritten word spotting}},
year = {2008}
}
@article{Stern2013,
abstract = {In this work, we consider the recognition of dynamic gestures based on representative sub-segments of a gesture, which are denoted as most discriminating segments (MDSs). The automatic extraction and recognition of such small representative segments, rather than extracting and recognizing the full gestures themselves, allows for a more discriminative classifier. A MDS is a sub-segment of a gesture that is most dissimilar to all other gesture sub-segments. Gestures are classified using a MDSLCS algorithm, which recognizes the MDSs using a modified longest common subsequence (LCS) measure. The extraction of MDSs from a data stream uses adaptive window parameters, which are driven by the successive results of multiple calls to the LCS classifier. In a preprocessing stage, gestures that have large motion variations are replaced by several forms of lesser variation. We learn these forms by adaptive clustering of a training set of gestures, where we reemploy the LCS to determine similarity between gesture trajectories. The MDSLCS classifier achieved a gesture recognition rate of 92.6{\%} when tested using a set of pre-cut free hand digit (0-9) gestures, while hidden Markov models (HMMs) achieved an accuracy of 89.5{\%}. When the MDSLCS was tested against a set of streamed digit gestures, an accuracy of 89.6{\%} was obtained. At present the HMMs method is considered the state-of-the-art method for classifying motion trajectories. The MDSLCS algorithm had a higher accuracy rate for pre-cut gestures, and is also more suitable for streamed gestures. MDSLCS provides a significant advantage over HMMs by not requiring data re-sampling during run-time and performing well with small training sets. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Stern, Helman and Shmueli, Merav and Berman, Sigal},
xxurl = {10.1016/j.patrec.2013.02.007},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stern, Shmueli, Berman - 2013 - Most discriminating segment - Longest common subsequence (MDSLCS) algorithm for dynamic hand gesture cla.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classification,Digits,Gesture recognition,Longest common subsequence},
number = {15},
pages = {1980--1989},
publisher = {Elsevier B.V.},
title = {{Most discriminating segment - Longest common subsequence (MDSLCS) algorithm for dynamic hand gesture classification}},
url = {http://dx.xxurl.org/10.1016/j.patrec.2013.02.007},
volume = {34},
year = {2013}
}
@article{Han2015,
author = {Han, Richard},
file = {:home/mondal/Documents/MATHS/Math-for-Machine-Learning-Book-Preview.pdf:pdf},
title = {{Math for Machine Learning Open Doors to Data Science and Artificial Intelligence}},
year = {2015}
}
@article{Meng2010,
abstract = {This paper proposes a general-purpose method for estimating the skew angles of document images. Rather than to derive a skew angle merely from text lines, the proposed method exploits various types of visual cues of image skew available in local image regions. The visual cues are extracted by Radon transform and then outliers of them are iteratively rejected through a floating cascade. A bagging (bootstrap aggregating) estimator is finally employed to combine the estimations on the local image blocks. Our experimental results show significant improvements against the state-of-the-art methods, in terms of execution speed and estimation accuracy, as well as the robustness to short and sparse text lines, multiple different skews and the presence of nontextual objects of various types and quantities.},
author = {Meng, Gaofeng and Pan, Chunhong and Zheng, Nanning and Sun, Chen},
xxurl = {10.1109/TIP.2010.2045677},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meng et al. - 2010 - Skew estimation of document images using bagging.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Bagging estimator,Document image analysis,Floating cascade,Radon transform,Skew estimation},
number = {7},
pages = {1837--1846},
pmid = {20236898},
title = {{Skew estimation of document images using bagging}},
volume = {19},
year = {2010}
}
@article{Ye2013a,
author = {Ye, Peng and Doermann, David},
xxurl = {10.1109/ICDAR.2013.148},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ye, Doermann - 2013 - Document Image Quality Assessment A Brief Survey.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {723--727},
publisher = {Ieee},
title = {{Document Image Quality Assessment: A Brief Survey}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628713},
year = {2013}
}
@article{Vo2018,
abstract = {The binarization of degraded document images is a challenging problem in terms of document analysis. Binarization is a classification process in which intra-image pixels are assigned to either of the two following classes: foreground text and background. Most of the algorithms are constructed on low-level features in an unsupervised manner, and the consequent disenabling of full utilization of input-domain knowledge considerably limits distinguishing of background noises from the foreground. In this paper, a novel supervised-binarization method is proposed, in which a hierarchical deep supervised network (DSN) architecture is learned for the prediction of the text pixels at different feature levels. With higher-level features, the network can differentiate text pixels from background noises, whereby severe degradations that occur in document images can be managed. Alternatively, foreground maps that are predicted at lower-level features present a higher visual quality at the boundary area. Compared with those of traditional algorithms, binary images generated by our architecture have cleaner background and better-preserved strokes. The proposed approach achieves state-of-the-art results over widely used DIBCO datasets, revealing the robustness of the presented method.},
author = {Vo, Quang Nhat and Kim, Soo Hyung and Yang, Hyung Jeong and Lee, Gueesang},
xxurl = {10.1016/j.patcog.2017.08.025},
isbn = {0031320317},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Convolutional neural network,Document analysis,Document image binarization},
pages = {568--586},
publisher = {Elsevier Ltd},
title = {{Binarization of degraded document images based on hierarchical deep supervised network}},
volume = {74},
year = {2018}
}
@article{Wang2015a,
abstract = {As font is one of the core design concepts, automatic font identification and similar font suggestion from an image or photo has been on the wish list of many designers. We study the Visual Font Recognition (VFR) problem [4], and advance the state-of-The-Art remarkably by developing the DeepFont system. First of all, we build up the first avail-able large-scale VFR dataset, named AdobeVFR, consisting of both labeled synthetic data and partially labeled real-world data. Next, to combat the domain mismatch between available training and testing data, we introduce a Convo-lutional Neural Network (CNN) decomposition approach, using a domain adaptation technique based on a Stacked Convolutional Auto-Encoder (SCAE) that exploits a large corpus of unlabeled real-world text images combined with synthetic data preprocessed in a specific way. Moreover, we study a novel learning-based model compression approach, in order to reduce the DeepFont model size without sacrific-ing its performance. The DeepFont system achieves an ac-curacy of higher than 80{\%} (top-5) on our collected dataset, and also produces a good font similarity measure for font selection and suggestion. We also achieve around 6 times compression of the model without any visible loss of recog-nition accuracy.},
archivePrefix = {arXiv},
arxivId = {1507.03196},
author = {Wang, Zhangyang and Yang, Jianchao and Jin, Hailin and Shechtman, Eli and Agarwala, Aseem and Brandt, Jonathan and Huang, Thomas S.},
xxurl = {10.1145/2733373.2806219},
eprint = {1507.03196},
file = {:home/mondal/Downloads/sig-alternate.pdf:pdf},
isbn = {9781450334594},
journal = {MM 2015 - Proceedings of the 2015 ACM Multimedia Conference},
keywords = {Deep Learning,Domain Adaptation,Model Compression,Visual Font Recognition},
number = {May 2018},
pages = {451--459},
title = {{DeepFont: Identify your font from an image}},
year = {2015}
}
@article{Salakhutdinov2015,
abstract = {Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many artificial intelligence–related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. In this article, we review several popular deep learning models, including deep belief networks and deep Boltzmann machines. We show that (a) these deep generative models, which contain many layers of latent variables and millions of parameters, can be learned efficiently, and (b) the learned high-level feature representations can be successfully applied in many application domains, including visual object recognition, information retrieval, classification, and regression tasks.},
author = {Salakhutdinov, Ruslan},
xxurl = {10.1146/annurev-statistics-010814-020120},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salakhutdinov - 2015 - Learning Deep Generative Models.pdf:pdf},
isbn = {978-0-494-61080-0},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
keywords = {deep belief networks,deep boltzmann machines,deep learning,graphical},
number = {1},
pages = {361--385},
title = {{Learning Deep Generative Models}},
url = {http://www.annualreviews.org/xxurl/10.1146/annurev-statistics-010814-020120},
volume = {2},
year = {2015}
}
@article{Ahmed2012,
abstract = {In this paper we propose a novel method for the extraction of signatures from document images. Instead of using a human defined set of features a part-based feature extraction method is used. In particular, we use the Speeded Up Robust Features (SURF) to distinguish the machine printed text from signatures. Using SURF features makes the approach generally more useful and reliable for different resolution documents. We have evaluated our system on the publicly available Tobacco-800 dataset in order to compare it to previous work. Finally, all signatures were found in the images and less than half of the found signatures are false positives. Therefore, our system can be applied for practical use.},
author = {Ahmed, Sheraz and Malik, Muhammad Imran and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/ICFHR.2012.271},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed et al. - 2012 - Signature segmentation from document images.pdf:pdf},
isbn = {9780769547749},
issn = {15505235},
journal = {Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR},
keywords = {Extraction,Local features,Logos,Machine printed text,SURF,Signature segmentation},
pages = {425--429},
title = {{Signature segmentation from document images}},
year = {2012}
}
@article{Iga2004,
abstract = {Objective. - To examine total migraine freedom (TMF), defined as pain freedom and absence of associated symptoms, using rizatriptan clinical trial data and to explore advantages of TMF as a single primary composite efficacy endpoint. Background. - The FDA has set a higher regulatory hurdle for registration of new migraine agents requiring both pain freedom (or relief) and absence of each associated symptom (phonophobia, photophobia, and nausea). Methods. - Twelve studies representing phase III + efficacy/safety studies of rizatriptan 10 mg in adults treating migraine were included in the meta-analysis. The percentage of patients achieving TMF at 2 hours by study and combined by treatment group was summarized by treatment paradigm (early/mild pain, moderate/severe, menstrual migraine). To demonstrate the impact of the strict migraine regulatory hurdle on clinical trial design and to compare it to TMF, simulation via bootstrap sampling was used. Results. - Odds ratios (rizatriptan vs placebo, all P {\textless} .001) for TMF were 6.2 (95{\%} CI: [4.9, 7.7]) for moderate/severe, 2.7 (95{\%} CI: [1.8, 4.0]) for menstrual, and 3.1 (95{\%} CI: [2.4, 4.0]) for early/mild. Most with moderate/severe migraine reported photophobia and/or phonophobia at baseline, but only half had nausea. Simulation results showed a substantial loss of power analyzing absence of pain and each symptom compared with the composite TMF endpoint across all treatment paradigms. Conclusion. - Rizatriptan 10 mg was superior to placebo in achieving TMF at 2 hours post-dose across all treatment paradigms. Given that the majority of patients with migraine do not exhibit all 3 associated symptoms, the TMF endpoint has significant advantages vs establishing efficacy on pain and each symptom individually. {\textcopyright} 2010 American Headache Society Published by Wiley Periodicals, Inc.},
author = {Iga, Chihiro and Wakahara, Toru},
xxurl = {10.1109/IWFHR.2004.25},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iga, Wakahara - 2004 - Character image reconstruction from a feature space using shape morphing and genetic algorithms.pdf:pdf},
isbn = {0769521878},
issn = {15505235},
journal = {Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR},
pages = {341--346},
title = {{Character image reconstruction from a feature space using shape morphing and genetic algorithms}},
year = {2004}
}
@inproceedings{Sehad2014,
author = {Sehad, Abdenour and Chibani, Youcef and Cheriet, Mohamed},
booktitle = {2014 14th International Conference on Frontiers in Handwriting Recognition},
xxurl = {10.1109/ICFHR.2014.123},
isbn = {978-1-4799-4334-0},
month = {sep},
pages = {702--707},
publisher = {IEEE},
title = {{Gabor Filters for Degraded Document Image Binarization}},
url = {http://ieeexplore.ieee.org/document/6981102/},
year = {2014}
}
@article{Cozzolino2018,
abstract = {Distinguishing manipulated from real images is becoming increasingly difficult as new sophisticated image forgery approaches come out by the day. Naive classification approaches based on Convolutional Neural Networks (CNNs) show excellent performance in detecting image manipulations when they are trained on a specific forgery method. However, on examples from unseen manipulation approaches, their performance drops significantly. To address this limitation in transferability, we introduce Forensic-Transfer (FT). We devise a learning-based forensic detector which adapts well to new domains, i.e., novel manipulation methods and can handle scenarios where only a handful of fake examples are available during training. To this end, we learn a forensic embedding based on a novel autoencoder-based architecture that can be used to distinguish between real and fake imagery. The learned embedding acts as a form of anomaly detector; namely, an image manipulated from an unseen method will be detected as fake provided it maps sufficiently far away from the cluster of real images. Comparing to prior works, FT shows significant improvements in transferability, which we demonstrate in a series of experiments on cutting-edge benchmarks. For instance, on unseen examples, we achieve up to 85{\%} in terms of accuracy, and with only a handful of seen examples, our performance already reaches around 95{\%}.},
archivePrefix = {arXiv},
arxivId = {1812.02510},
author = {Cozzolino, Davide and Thies, Justus and R{\"{o}}ssler, Andreas and Riess, Christian and Nie{\ss}ner, Matthias and Verdoliva, Luisa},
eprint = {1812.02510},
file = {:home/mondal/Downloads/1812.02510.pdf:pdf},
title = {{ForensicTransfer: Weakly-supervised Domain Adaptation for Forgery Detection}},
url = {http://arxiv.org/abs/1812.02510},
year = {2018}
}
@inproceedings{MueenKZCW09,
author = {Mueen, Abdullah and Keogh, Eamonn J and Zhu, Qiang and Cash, Sydney and Westover, M Brandon},
booktitle = {Proceedings of the {\{}SIAM{\}} International Conference on Data Mining, {\{}SDM{\}} 2009, April 30 - May 2, 2009, Sparks, Nevada, {\{}USA{\}}},
pages = {473--484},
title = {{Exact Discovery of Time Series Motifs}},
year = {2009}
}
@incollection{year,
title = {{No Title}}
}
@article{Jiang2006,
abstract = {Motivated by the studies in Gestalt principle, this paper describes a novel approach on the adaptive selection of visual features for trademark retrieval. We consider five kinds of visual saliencies: symmetry, continuity, proximity, parallelism and closure property. The first saliency is based on Zernike moments, while the others are modeled by geometric elements extracted illusively as a whole from a trademark. Given a query trademark, we adaptively determine the features appropriate for retrieval by investigating its visual saliencies. We show that in most cases, either geometric or symmetric features can give us good enough accuracy. To measure the similarity of geometric elements, we propose a maximum weighted bipartite graph (WBG) matching algorithm under transformation sets which is found to be both effective and efficient for retrieval. ?? 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Jiang, Hui and Ngo, Chong Wah and Tan, Hung Khoon},
xxurl = {10.1016/j.patcog.2005.08.012},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Ngo, Tan - 2006 - Gestalt-based feature similarity measure in trademark database.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Bipartite graph matching under transformation sets,Gestalt principle,Trademark image retrieval},
number = {5},
pages = {988--1001},
title = {{Gestalt-based feature similarity measure in trademark database}},
volume = {39},
year = {2006}
}
@article{Hegland2001,
abstract = {In order to detect massive compact halo objects (MACHOs) using microlensing, nightly images of the Large and Small Magellanic Clouds and the Galactic Bulge were taken between 1992 and 2000 with a 1.27 meter telescope. The resulting data contains 8{\textperiodcentered}1010 photometric measurements of star light intensity magnitudes in the red and blue bands for 60 million stars. It has been suggested that the wealth of data may be used to discover new types of variable stars. We briefly outline some methods which may assist the astronomer in classifying variable stars which occur in the MACHO data. First, the almost periodic behavior of many long-period variable stars is used to obtain estimates of the magnitudes on a regular grid and also in regions of missing values. Then some simple features are suggested which characterize the star time series. A classifier based on additive models using these features has been implemented and is part of a tool which can be used in the search for new time series classes. {\textcopyright} 2001 Elsevier Science B.V. All rights reserved.},
author = {Hegland, Markus and Clarke, William and Kahn, Margaret},
xxurl = {10.1016/S0010-4655(01)00307-1},
issn = {00104655},
journal = {Computer Physics Communications},
keywords = {Data mining,MACHO project,Variable stars},
month = {dec},
number = {1-3},
pages = {22--28},
title = {{Mining the MACHO dataset}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0010465501003071},
volume = {142},
year = {2001}
}
@article{Zhong2013,
author = {Zhong, Guoqiang and Chherawala, Youssouf and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.266},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong, Chherawala, Cheriet - 2013 - An Empirical Evaluation of Supervised Dimensionality Reduction for Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {10,ancient document understanding,as far as we,handwritten digits recognition,however,know,learning,manifold,network analysis,relational learning,supervised dimensionality reduction,this is},
month = {aug},
pages = {1315--1319},
publisher = {Ieee},
title = {{An Empirical Evaluation of Supervised Dimensionality Reduction for Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628827},
year = {2013}
}
@article{Santosh2013e,
author = {Santosh, K.C. and Wendling, Laurent and Lamiroy, Bart},
xxurl = {10.1109/ICDAR.2013.157},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santosh, Wendling, Lamiroy - 2013 - Relation Bag-of-Features for Symbol Retrieval.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {768--772},
publisher = {Ieee},
title = {{Relation Bag-of-Features for Symbol Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628722},
year = {2013}
}
@article{Nafchi2013a,
author = {Nafchi, Hossein Ziaei and Ayatollahi, Seyed Morteza and Moghaddam, Reza Farrahi and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.165},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nafchi et al. - 2013 - An Efficient Ground Truthing Tool for Binarization of Historical Manuscripts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {807--811},
publisher = {Ieee},
title = {{An Efficient Ground Truthing Tool for Binarization of Historical Manuscripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628730},
year = {2013}
}
@article{Ntirogiannis2009,
annote = {From Duplicate 1 ( 

A Modified Adaptive Logical Level Binarization Technique for Historical Document Images

- Ntirogiannis, Konstantinos; Gatos, Basilis; Pratikakis, Ioannis )

},
author = {Ntirogiannis, Konstantinos and Gatos, Basilis and Pratikakis, Ioannis},
xxurl = {10.1109/ICDAR.2009.225},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ntirogiannis, Gatos, Pratikakis - 2009 - A Modified Adaptive Logical Level Binarization Technique for Historical Document Images.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
pages = {1171--1175},
publisher = {Ieee},
title = {{A Modified Adaptive Logical Level Binarization Technique for Historical Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277601},
year = {2009}
}
@article{Rusinol2012,
author = {Rusinol, M and Llados, Josep},
xxurl = {10.1109/ICFHR.2012.282},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusinol, Llados - 2012 - The role of the users in handwritten word spotting applications query fusion and relevance feedback.pdf:pdf},
isbn = {978-1-4673-2262-1},
journal = {2012 International Conference on Frontiers in Handwriting Recognition},
keywords = {-handwritten word spotting,relevance feedback},
month = {sep},
pages = {55--60},
publisher = {Ieee},
title = {{The role of the users in handwritten word spotting applications: query fusion and relevance feedback}},
year = {2012}
}
@inproceedings{Hoppner2001,
abstract = {{\textcopyright} Springer-Verlag Berlin Heidelberg 2001. Recently, association rule mining has been generalized to the discovery of episodes in event sequences. In this paper, we additionally take durations into account and thus present a generalization to time intervals. We discover frequent temporal patterns in a single series of such labeled intervals, which we call a state sequence. A temporal pattern is defined as a set of states together with their interval relationships described in terms of Allen's interval logic, for instance “A before B, A overlaps C, C overlaps B” or equivalently “state A ends before state B starts, the gap is covered by state C”. As an example we consider the problem of deriving local weather forecasting rules that allow us to conclude from the qualitative behaviour of the air-pressure curve to the wind-strength. Here, the states have been extracted automatically from (multivariate) time series and characterize the trend of the time series locally within the assigned time interval.},
author = {H{\"{o}}ppner, Frank},
booktitle = {PKDD '01 Proceedings of the 5th European Conference on Principles of Data Mining and Knowledge Discovery},
title = {{Discovery of Temporal Patterns. Learning Rules about the Qualitative Behaviour of Time Series}},
year = {2001}
}
@article{Kleber2013,
author = {Kleber, Florian and Fiel, Stefan and Diem, Markus and Sablatnig, Robert},
xxurl = {10.1109/ICDAR.2013.117},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kleber et al. - 2013 - CVL-DataBase An Off-Line Database for Writer Retrieval, Writer Identification and Word Spotting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {560--564},
publisher = {Ieee},
title = {{CVL-DataBase: An Off-Line Database for Writer Retrieval, Writer Identification and Word Spotting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628682},
year = {2013}
}
@article{Halatsis,
author = {Halatsis, Constantin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Halatsis - Unknown - Line and Word Segmentation of Handwritten Documents Menu Next Line and Word Segmentation of Handwritten Documents P.pdf:pdf},
keywords = {document analysis,handwritten documents,hough transform,text line segmentation,word},
pages = {2--7},
title = {{Line and Word Segmentation of Handwritten Documents Menu Next Line and Word Segmentation of Handwritten Documents Prev Menu}}
}
@article{Zhu2013,
author = {Zhu, Yuanping and Sun, Jun and Naoi, Satoshi},
xxurl = {10.1109/ICDAR.2013.66},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Sun, Naoi - 2013 - Sub-structure Learning Based Handwritten Chinese Text Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-handwritten chinese text recognition,clustering,structure learning,sub-},
month = {aug},
pages = {295--299},
publisher = {Ieee},
title = {{Sub-structure Learning Based Handwritten Chinese Text Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628631},
year = {2013}
}
@article{Mishra2014,
author = {Mishra, Anand},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mishra - 2014 - Understanding Text in Scene Images.pdf:pdf},
number = {May},
title = {{Understanding Text in Scene Images}},
volume = {200907004},
year = {2014}
}
@book{Smolinski2008,
address = {Berlin, Heidelberg},
xxurl = {10.1007/978-3-540-78534-7},
editor = {Smolinski, Tomasz G. and Milanova, Mariofanna G. and Hassanien, Aboul-Ella},
isbn = {978-3-540-78533-0},
publisher = {Springer Berlin Heidelberg},
series = {Studies in Computational Intelligence},
title = {{Applications of Computational Intelligence in Biology}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-78534-7},
volume = {122},
year = {2008}
}
@inproceedings{Bukhari2012b,
abstract = {Major challenges in camera-base document analysis$\backslash$nare dealing with uneven shadows, high degree of curl and$\backslash$nperspective distortions. In CBDAR 2007, we introduced the$\backslash$nfirst dataset (DFKI-I) of camera-captured document images in$\backslash$nconjunction with a page dewarping contest. One of the main$\backslash$nlimitations of this dataset is that it contains images only from$\backslash$ntechnical books with simple layouts and moderate curl/skew.$\backslash$nMoreover, it does not contain information about cameras$\backslash$nspecifications and settings, imaging environment, and document$\backslash$ncontents. This kind of information would be more helpful for$\backslash$nunderstanding the results of the experimental evaluation of$\backslash$ncamera-based document image processing (binarization, page$\backslash$nsegmentation, dewarping, etc.). In this paper, we introduce a$\backslash$nnew dataset (the IUPR dataset) of camera-captured document$\backslash$nimages. As compared to the previous dataset, the new dataset$\backslash$ncontains images from different varieties of technical and nontechnical$\backslash$nbooks with more challenging problems, like different$\backslash$ntypes of layouts, large variety of curl, wide range of perspective$\backslash$ndistortions, and high to low resolutions. Additionally, the$\backslash$ndocument images in the new dataset are provided with detailed$\backslash$ninformation about thickness of books, imaging environment$\backslash$nand cameras viewing angle and its internal settings. The new$\backslash$ndataset will help research community to develop robust cameracaptured$\backslash$ndocument processing algorithms in order to solve the$\backslash$nchallenging problems in the dataset and to compare different$\backslash$nmethods on a common ground.},
author = {Bukhari, Syed Saqib and Shafait, Faisal and Breuel, Thomas M.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
xxurl = {10.1007/978-3-642-29364-1_13},
isbn = {9783642293634},
issn = {03029743},
keywords = {Camera-Captured Document Processing,Dataset,Performance Evaluation},
pages = {164--171},
title = {{The IUPR dataset of camera-captured document images}},
volume = {7139 LNCS},
year = {2012}
}
@article{BolanSu2013,
abstract = {-Improvement in a degraded document images is one of the salient and challenging research now days. Image get degraded due to unbalance illumination spread over document including smearing of text, bleeding of ink to the other side of page, degradation of paper ink due to aging, manuscript characters from background side appear as noise on the lead side and get blend with the lead side characters etc. Image document binarization technique is used to perform in the pre-processing level for document analysis, to extract and segment out the fore text from the document flipside. In the previous year's numerous binarization techniques are proposed, none of them is suitable for all types of degradation. The previous studies revels that there is no automatic and robust system, competent of choosing the most useful method of binarization for various types of inputs. Whereas various binarization approaches are used to enhance the degraded image with pros and cons. This paper accomplishes a comprising survey of better binarization techniques. Also focus on the problems being encountered and the related issues in the area of document image binarization.},
author = {{Bolan Su} and {Shijian Lu} and {Chew Lim Tan}},
xxurl = {10.1109/TIP.2012.2231089},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bolan Su, Shijian Lu, Chew Lim Tan - 2013 - A Robust Document Image Binarization Technique for Degraded Document Images.pdf:pdf},
isbn = {9781509014897},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
keywords = {binarization,degraded document image,degraded document image examples,document analysis,fig -1,from dibco,image processing,post processing,segmentation},
number = {4},
pages = {1408--1417},
pmid = {1998042074},
title = {{A Robust Document Image Binarization Technique for Degraded Document Images}},
volume = {22},
year = {2013}
}
@article{Material2014a,
author = {Material, See Related and Klette, Reinhard and Springer-verlag, Concise Computer Vision},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Material, Klette, Springer-verlag - 2014 - Keypoints and Descriptors 1(2).pdf:pdf},
pages = {1--32},
title = {{Keypoints and Descriptors 1}},
year = {2014}
}
@article{Bui2013,
author = {Bui, Quang Anh and Visani, Muriel and Mullot, Remy},
xxurl = {10.1109/ICDAR.2013.268},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bui, Visani, Mullot - 2013 - Invariants Extraction Method Applied in an Omni-language Old Document Navigating System.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {a coding which is,ambiguous zones detection,characters,clustering,etc,extraction,ideograms,invariant extraction,one drawback of most,pictograms,stroke,that it relies on,word retrieval,word retrieval systems is},
month = {aug},
pages = {1325--1329},
publisher = {Ieee},
title = {{Invariants Extraction Method Applied in an Omni-language Old Document Navigating System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628829},
year = {2013}
}
@article{Huang2018,
abstract = {Background elimination for noisy character images or character images from real scene is still a challenging problem, due to the bewildering backgrounds, uneven illumination, low resolution and different distortions. We propose a stroke-based character reconstruction(SCR) method that use a weighted quadratic Bezier curve(WQBC) to represent strokes of a character. Only training on our synthetic data, our stroke extractor can achieve excellent reconstruction effect in real scenes. Meanwhile. It can also help achieve great ability in defending adversarial attacks of character recognizers.},
archivePrefix = {arXiv},
arxivId = {1806.08990},
author = {Huang, Zhewei and Heng, Wen and Tao, Yuanzheng and Zhou, Shuchang},
eprint = {1806.08990},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2018 - Stroke-based Character Reconstruction.pdf:pdf},
title = {{Stroke-based Character Reconstruction}},
url = {http://arxiv.org/abs/1806.08990},
year = {2018}
}
@article{Diem2013a,
author = {Diem, Markus and Fiel, Stefan and Garz, Angelika and Keglevic, Manuel and Kleber, Florian and Sablatnig, Robert},
xxurl = {10.1109/ICDAR.2013.287},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diem et al. - 2013 - ICDAR 2013 Competition on Handwritten Digit Recognition (HDRC 2013).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {Hdrc},
pages = {1422--1427},
publisher = {Ieee},
title = {{ICDAR 2013 Competition on Handwritten Digit Recognition (HDRC 2013)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628848},
year = {2013}
}
@article{Lu2008a,
abstract = {This paper presents a document retrieval technique that is capable of searching document images without OCR (optical character recognition). The proposed technique retrieves document images by a new word shape coding scheme, which captures the document content through annotating each word image by a word shape code. In particular, we annotate word images by using a set of topological shape features including character ascenders/descenders, character holes, and character water reservoirs. With the annotated word shape codes, document images can be retrieved by either query keywords or a query document image. Experimental results show that the proposed document image retrieval technique is fast, efficient, and tolerant to various types of document degradation.},
annote = {From Duplicate 2 (Document image retrieval through word shape coding. - Lu, Shijian; Li, Linlin; Tan, Chew Lim)

From Duplicate 1 ( 







Document image retrieval through word shape coding.







- Lu, Shijian; Li, Linlin; Tan, Chew Lim )



},
author = {Lu, Shijian and Li, Linlin and Tan, Chew Lim},
xxurl = {10.1109/TPAMI.2008.89},
isbn = {01628828 (ISSN)},
issn = {01628828},
journal = {TPAMI},
keywords = {Artificial Intelligence,Automated,Automated: methods,Automatic Data Processing,Automatic Data Processing: methods,Computer-Assisted,Computer-Assisted: methods,Database Management Systems,Databases,Document image analysis,Document image retrieval,Documentation,Documentation: methods,Factual,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Language,Pattern Recognition,Reading,Word shape coding},
month = {nov},
number = {11},
pages = {1913--8},
pmid = {18787240},
title = {{Document image retrieval through word shape coding.}},
volume = {30},
year = {2008}
}
@inproceedings{Vasilopoulos2013,
author = {Vasilopoulos, Nikos and Kavallieratou, Ergina},
booktitle = {SPIE},
issn = {0277-786X},
language = {en},
month = {feb},
pages = {86580F},
title = {{A classification-free word-spotting system}},
volume = {8658},
year = {2013}
}
@article{Hsiao-LinPeng1997,
abstract = {In this paper, a new trademark recognition method using closed contours is proposed. The developed method can be used to retrieve similar trademarks, even those with irregular shapes, so as to simplify and speed up the manual trademark examination process. Trademarks are first decomposed into complete sets of elementary closed contours, each of which is then encoded as an angle-code string according to chain-code information. A two-step string-matching algorithm can then be employed to compute similarities between closed contours. Finally, the maximum and average terms of the similarities between contours are integrated into the whole trademark similarity measure. After that, the similarity measure can be the criterion for retrieving similar trademarks. More specifically, since the proposed method to encode closed contours is insensitive to translation, rotation and size variations, our method has the ability to detect infringement cases in which trademarks are changed in translation, rotation, or size. Moreover, our method can cope with the special resemblances such as inclusion, mirror and partial resemblances. Experimental results are presented to show the feasibility and practicability of the proposed approach.},
author = {{Hsiao-Lin Peng} and {Shu-Yuan Chen}},
xxurl = {10.1016/S0167-8655(97)00050-0},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hsiao-Lin Peng, Shu-Yuan Chen - 1997 - Trademark shape recognition using closed contours.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Chain codes,Closed contours,Partial matching,Similarity measure,Trademark recognition},
number = {8},
pages = {791--803},
title = {{Trademark shape recognition using closed contours}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865597000500},
volume = {18},
year = {1997}
}
@article{LiLiu2012,
author = {{Li Liu} and Fieguth, Paul},
xxurl = {10.1109/TPAMI.2011.145},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {mar},
number = {3},
pages = {574--586},
title = {{Texture Classification from Random Features}},
url = {http://ieeexplore.ieee.org/document/6136524/},
volume = {34},
year = {2012}
}
@article{AntonioCardone,
author = {{Antonio Cardone, Ra K. Gupta}, Mukul Karnik},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antonio Cardone, Ra K. Gupta - 2003 - A survey of shape similarity assessment algorithms for product design and manufacturing applicatio.pdf:pdf},
journal = {Journal of Computing and Information Science in Engineering},
pages = {109--118},
title = {{A survey of shape similarity assessment algorithms for product design and manufacturing applications}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.138.7453},
volume = {3},
year = {2003}
}
@article{Khayyat2014,
author = {Khayyat, Muna and Lam, Louisa and Suen, Ching Y.},
xxurl = {10.1016/j.patcog.2013.08.014},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khayyat, Lam, Suen - 2014 - Learning-based word spotting system for Arabic handwritten documents.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Language models,Partial segmentation,Word spotting,arabic handwriting recognition},
month = {mar},
number = {3},
pages = {1021--1030},
publisher = {Elsevier},
title = {{Learning-based word spotting system for Arabic handwritten documents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003132031300335X},
volume = {47},
year = {2014}
}
@article{Furukawa2013,
author = {Furukawa, Takeshi},
xxurl = {10.1109/ICDAR.2013.226},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Furukawa - 2013 - A New Method for Discriminating Printers Based on Contours Qualities of Printed Characters Using Wavelet Decomposition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {as bit map and,as pro-,at first how to,contours,font,fonts are,in computers or,mainly two types such,methods of description of,printers were described,store and express fonts,vector outline,wavelet decomposition},
month = {aug},
pages = {1115--1119},
publisher = {Ieee},
title = {{A New Method for Discriminating Printers Based on Contours Qualities of Printed Characters Using Wavelet Decomposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628787},
year = {2013}
}
@article{Louloudis2012a,
author = {Louloudis, G. and a.L. Kesidis and Gatos, B.},
xxurl = {10.1109/DAS.2012.34},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Louloudis, Kesidis, Gatos - 2012 - Efficient Word Retrieval Using a Multiple Ranking Combination Scheme.pdf:pdf},
isbn = {978-0-7695-4661-2},
journal = {2012 10th IAPR International Workshop on Document Analysis Systems},
keywords = {- word retrieval,appear in the collection,combination,data fusion,multiple rankings,ranking,the top ranking,will be placed on,word matching,word retrieval, multiple rankings, ranking combina},
month = {mar},
pages = {379--383},
publisher = {Ieee},
title = {{Efficient Word Retrieval Using a Multiple Ranking Combination Scheme}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6195398},
year = {2012}
}
@article{DBLP:journals/tip/MondalJS11,
author = {Mondal, Tanmoy and Jain, Ashish and Sardana, H K},
xxurl = {10.1109/TIP.2011.2131662},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal, Jain, Sardana - 2011 - Automatic Craniofacial Structure Detection on Cephalometric Images.pdf:pdf},
journal = {{\{}IEEE{\}} Trans. Image Processing},
number = {9},
pages = {2606--2614},
title = {{Automatic Craniofacial Structure Detection on Cephalometric Images}},
url = {https://xxurl.org/10.1109/TIP.2011.2131662},
volume = {20},
year = {2011}
}
@article{Marteau2009,
abstract = {In a way similar to the string-to-string correction problem, we address discrete time series similarity in light of a time-series-to-time-series-correction problem for which the similarity between two time series is measured as the minimum cost sequence of edit operations needed to transform one time series into another. To define the edit operations, we use the paradigm of a graphical editing process and end up with a dynamic programming algorithm that we call Time Warp Edit Distance (TWED). TWED is slightly different in form from Dynamic Time Warping (DTW), Longest Common Subsequence (LCSS), or Edit Distance with Real Penalty (ERP) algorithms. In particular, it highlights a parameter that controls a kind of stiffness of the elastic measure along the time axis. We show that the similarity provided by TWED is a potentially useful metric in time series retrieval applications since it could benefit from the triangular inequality property to speed up the retrieval process while tuning the parameters of the elastic measure. In that context, a lower bound is derived to link the matching of time series into downsampled representation spaces to the matching into the original space. The empiric quality of the TWED distance is evaluated on a simple classification task. Compared to Edit Distance, DTW, LCSS, and ERP, TWED has proved to be quite effective on the considered experimental task.},
annote = {From Duplicate 1 ( 

Time warp edit distance with stiffness adjustment for time series matching.

- Marteau, Pierre-Fran{\c{c}}ois )

},
author = {Marteau, Pierre-Fran{\c{c}}ois},
xxurl = {10.1109/TPAMI.2008.76},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marteau - 2009 - Time warp edit distance with stiffness adjustment for time series matching.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer Simulation,Computer-Assisted,Models,Pattern Recognition,Signal Processing,Subtraction Technique,Theoretical,Time Factors},
month = {feb},
number = {2},
pages = {306--318},
pmid = {19110495},
title = {{Time warp edit distance with stiffness adjustment for time series matching.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19110495},
volume = {31},
year = {2009}
}
@book{Shi2007,
address = {Berlin, Heidelberg},
xxurl = {10.1007/978-3-540-72588-6},
editor = {Shi, Yong and van Albada, Geert Dick and Dongarra, Jack and Sloot, Peter M. A.},
isbn = {978-3-540-72587-9},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Computational Science – ICCS 2007}},
url = {http://link.springer.com/10.1007/978-3-540-72588-6},
volume = {4489},
year = {2007}
}
@article{Lebourgeois2013,
author = {Lebourgeois, Frank and Drira, Fadoua and Gaceb, Djamel and Duong, Jean},
xxurl = {10.1109/ICDAR.2013.19},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lebourgeois et al. - 2013 - Fast Integral MeanShift Application to Color Segmentation of Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {challenge,clusters,image segmentation,inevitably compromised by two,integral volume,main parameters related to,meanshift,moreover,segmentation process is,the,the accuracy of the,the prior knowledge of,their number and the},
month = {aug},
pages = {52--56},
publisher = {Ieee},
title = {{Fast Integral MeanShift: Application to Color Segmentation of Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628584},
year = {2013}
}
@article{Hassanzadeh2011,
author = {Hassanzadeh, Sina and Pourghassem, Hossein},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassanzadeh, Pourghassem - 2011 - A Novel Logo Detection and Recognition Framework for Separated Part Logos in Document Images.pdf:pdf},
issn = {19918178},
journal = {Australian Journal of Basic and Applied Sciences},
keywords = {black pixel,boundary extraction,decision tree classifier,feature extraction,histogram,horizontal dilation,knn classification,logo detection,logo image normalization,logo recognition,spatial density},
number = {9},
pages = {936--946},
title = {{A Novel Logo Detection and Recognition Framework for Separated Part Logos in Document Images}},
volume = {5},
year = {2011}
}
@article{Zhu2018c,
abstract = {Recent work has shown that deep neural networks are highly sensitive to tiny perturbations of input images, giving rise to adversarial examples. Though this property is usually considered a weakness of learned models, we explore whether it can be beneficial. We find that neural networks can learn to use invisible perturbations to encode a rich amount of useful information. In fact, one can exploit this capability for the task of data hiding. We jointly train encoder and decoder networks, where given an input message and cover image, the encoder produces a visually indistinguishable encoded image, from which the decoder can recover the original message. We show that these encodings are competitive with existing data hiding algorithms, and further that they can be made robust to noise: our models learn to reconstruct hidden information in an encoded image despite the presence of Gaussian blurring, pixel-wise dropout, cropping, and JPEG compression. Even though JPEG is non-differentiable, we show that a robust model can be trained using differentiable approximations. Finally, we demonstrate that adversarial training improves the visual quality of encoded images.},
archivePrefix = {arXiv},
arxivId = {1807.09937},
author = {Zhu, Jiren and Kaplan, Russell and Johnson, Justin and Fei-Fei, Li},
xxurl = {10.1007/978-3-030-01267-0_40},
eprint = {1807.09937},
file = {:home/mondal/Downloads/HiDDEN{\_}InfoHiding.pdf:pdf},
isbn = {9783030012663},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Adversarial networks,Convolutional networks,Deep learning,Robust blind watermarking,Steganography},
pages = {682--697},
title = {{HiDDeN: Hiding data with deep networks}},
volume = {11219 LNCS},
year = {2018}
}
@article{Liu2006,
abstract = {The automatic recognition algorithm of quick response code is discussed in this paper. An image processing system based on embedded system is described to be able to binarization, location, segment, and decoding the QR code. In order to adapting various sizes, various gray-level values, and under various lighting conditions of real bar code image, a high-speed, high-accuracy binarization method is developed, which can locate the finder pattern accurately and integrate the local thresholding method with global thresholding. Experiments have shown that over 99{\%} barcode can be optimally recognized with the proposed algorithm. It can achieve higher recognition rate of high density bar code, and is applicable to real world scene image},
author = {Liu, Yue and Liu, Mingjun},
xxurl = {10.1109/ISDA.2006.253712},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Liu - 2006 - Automatic Recognition Algorithm of Quick Response Code Based on Embedded System.pdf:pdf},
isbn = {0-7695-2528-8},
journal = {Sixth International Conference on Intelligent Systems Design and Applications},
keywords = {Cameras,Code standards,Embedded system,Encoding,Error correction codes,Gray codes,ISO standards,Image coding,Image recognition,Information science,Mobile handsets,automatic recognition algorithm,bar code image,bar codes,binarization,decoding,embedded system,embedded systems,global thresholding,gray-level values,image processing system,image recognition,local thresholding method,quick response code,real world scene image},
pages = {783--788},
title = {{Automatic Recognition Algorithm of Quick Response Code Based on Embedded System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4021764},
volume = {2},
year = {2006}
}
@article{Ahmed2012a,
abstract = {In this paper we propose a novel part-based method for the extraction of text touching graphic components. The Speeded Up Robust Features (SURF) are used to localize the text components and distinguish them from graphics. We introduce several post-processing steps to finally detect the text. We have tested our method on a publicly available data set of architectural floor plans and on real geographical maps. On floor plans we have located more than 95{\%}ofthe text components which were not identified as text beforehand because they were touching graphic components.},
author = {Ahmed, Sheraz and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/DAS.2012.39},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Liwicki, Dengel - 2012 - Extraction of text touching graphics using SURF.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Liwicki, Dengel - 2012 - Extraction of text touching graphics using SURF(2).pdf:pdf},
isbn = {9780769546612},
journal = {DAS 2012},
keywords = {SURF,Text extraction,Text/graphics segmentation},
number = {March},
pages = {349--353},
title = {{Extraction of text touching graphics using SURF}},
year = {2012}
}
@article{Saykol2004,
abstract = {There is an accelerating demand to access the visual content of documents stored in historical and cultural archives. Availability of electronic imaging tools and effective image processing techniques makes it feasible to process the multimedia data in large databases. In this paper, a framework for content-based retrieval of historical documents in the Ottoman Empire archives is presented. The documents are stored as textual images, which are compressed by constructing a library of symbols occurring in a document, and the symbols in the original image are then replaced with pointers into the codebook to obtain a compressed representation of the image. The features in wavelet and spatial domain based on angular and distance span of shapes are used to extract the symbols. In order to make content-based retrieval in historical archives, a query is specified as a rectangular region in an input image and the same symbol-extraction process is applied to the query region. The queries are processed on the codebook of documents and the query images are identified in the resulting documents using the pointers in textual images. The querying process does not require decompression of images. The new content-based retrieval framework is also applicable to many other document archives using different scripts.},
author = {Saykol, Ediz and Sinop, Ali Kemal and G{\"{u}}d{\"{u}}kbay, Ugur and Ulusoy, Ozg{\"{u}}r and Cetin, a Enis},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saykol et al. - 2004 - Content-based retrieval of historical Ottoman documents stored as textual images.pdf:pdf},
issn = {1057-7149},
journal = {TIP},
keywords = {Abstracting and Indexing as Topic,Abstracting and Indexing as Topic: methods,Algorithms,Archaeology,Archaeology: methods,Archives,Art,Automated,Automatic Data Processing,Automatic Data Processing: methods,Computer Graphics,Computer-Assisted,Computer-Assisted: methods,Culture,Data Compression,Data Compression: methods,Database Management Systems,Databases,Factual,Hypermedia,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Dissemination,Information Dissemination: methods,Internet,Natural Language Processing,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Software,User-Computer Interface},
month = {mar},
number = {3},
pages = {314--25},
pmid = {15376924},
title = {{Content-based retrieval of historical Ottoman documents stored as textual images.}},
volume = {13},
year = {2004}
}
@article{Tarafdar2013,
author = {Tarafdar, Arundhati and Pal, Umapada and Roy, Partha Pratim and Ragot, Nicolas and Ramel, Jean-Yves},
xxurl = {10.1109/ICDAR.2013.71},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarafdar et al. - 2013 - A Two-Stage Approach for Word Spotting in Graphical Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {document image analysis,graphical documents,information retrieval,sift,word},
month = {aug},
pages = {319--323},
publisher = {Ieee},
title = {{A Two-Stage Approach for Word Spotting in Graphical Documents}},
year = {2013}
}
@article{Dumoulin2016,
abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
archivePrefix = {arXiv},
arxivId = {1603.07285},
author = {Dumoulin, Vincent and Visin, Francesco},
xxurl = {10.1051/0004-6361/201527329},
eprint = {1603.07285},
isbn = {9783319105895},
issn = {16113349},
pages = {1--28},
pmid = {26353135},
title = {{A guide to convolution arithmetic for deep learning}},
url = {http://arxiv.org/abs/1603.07285},
year = {2016}
}
@article{Kalantidis2014,
abstract = {We present a simple vector quantizer that combines low distortion with fast search and apply it to approximate near- est neighbor (ANN) search in high dimensional spaces. Leveraging the very same data structure that is used to pro- vide non-exhaustive search, i.e., inverted lists or a multi- index, the idea is to locally optimize an individual product quantizer (PQ) per cell and use it to encode residuals. Lo- cal optimization is over rotation and space decomposition; interestingly, we apply a parametric solution that assumes a normal distribution and is extremely fast to train. With a reasonable space and time overhead that is constant in the data size, we set a new state-of-the-art on several public datasets, including a billion-scale one. 1.},
author = {Kalantidis, Yannis and Avrithis, Yannis},
xxurl = {10.1109/CVPR.2014.298},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalantidis, Avrithis - 2014 - Locally Optimized Product Quantization for Approximate Nearest Neighbor Search.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)},
number = {c},
title = {{Locally Optimized Product Quantization for Approximate Nearest Neighbor Search}},
url = {http://image.ntua.gr/iva/files/lopq.pdf},
volume = {1},
year = {2014}
}
@article{Shih2001,
abstract = {With the increase in the number of trademarks, trademark imitation has become a serious problem. Thus, building an efficient trademark retrieval system is imperative. In this paper, such a system is presented. First, a semi-automatic segmentation method is proposed to extract the shapes of those representative objects, called 'masks', in each trademark. Next, some features are selected to describe a mask. These include invariant moments, the histogram of edge directions, and two kinds of transform coefficients that are robust to geometric deformation. Then, based on the rank of the feature distance, a similarity measure is provided to do the similar trademark retrieval. Finally, a feedback algorithm is also proposed to automatically determine the weight of each feature according to the user's response. Furthermore, in order to show the effectiveness of the proposed system, two databases from MPEG-7 test database are used to compare the performances of the proposed system and those methods using chain code, Zernike moments or MPLV as features. The experimental results show that the proposed system is superior to others. ?? 2001 Elsevier Science B.V. All rights reserved.},
author = {Shih, Jau Ling and Chen, Ling Hwei},
xxurl = {10.1016/S0262-8856(01)00063-4},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shih, Chen - 2001 - A new system for trademark segmentation and retrieval.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Feedback algorithm,Trademark retrieval,Trademark segmentation},
number = {13},
pages = {1011--1018},
title = {{A new system for trademark segmentation and retrieval}},
volume = {19},
year = {2001}
}
@article{Afchar2019,
abstract = {This paper presents a method to automatically and efficiently detect face tampering in videos, and particularly focuses on two recent techniques used to generate hyper-realistic forged videos: Deepfake and Face2Face. Traditional image forensics techniques are usually not well suited to videos due to the compression that strongly degrades the data. Thus, this paper follows a deep learning approach and presents two networks, both with a low number of layers to focus on the mesoscopic properties of images. We evaluate those fast networks on both an existing dataset and a dataset we have constituted from online videos. The tests demonstrate a very successful detection rate with more than 98{\%} for Deepfake and 95{\%} for Face2Face.},
archivePrefix = {arXiv},
arxivId = {1809.00888},
author = {Afchar, Darius and Nozick, Vincent and Yamagishi, Junichi and Echizen, Isao},
xxurl = {10.1109/WIFS.2018.8630761},
eprint = {1809.00888},
file = {:home/mondal/Downloads/1809.00888v1.pdf:pdf},
isbn = {9781538665367},
journal = {10th IEEE International Workshop on Information Forensics and Security, WIFS 2018},
title = {{MesoNet: A compact facial video forgery detection network}},
year = {2019}
}
@inproceedings{Rathb,
abstract = {Many museum and library archives are digitizing their large collections of handwritten historical manuscripts to enable public access to them. These collections are only available in image formats and require expensive manual annotation work for access to them. Current handwriting recognizers have word error rates in excess of 50{\%} and therefore cannot be used for such material. We describe two statistical models for retrieval in large collections of handwritten manuscripts given a text query. Both use a set of transcribed page images to learn a joint probability distribution between features computed from word images and their transcriptions. The models can then be used to retrieve unlabeled images of handwritten documents given a text query. We show experiments with a training set of 100 transcribed pages and a test set of 987 handwritten page images from the George Washington collection. Experiments show that the precision at 20 documents is about 0.4 to 0.5 depending on the model. To the best of our knowledge, this is the first automatic retrieval system for historical manuscripts using text queries, without manual transcription of the original corpus.},
author = {Rath, Toni M and Manmatha, R and Lavrenko, Victor},
booktitle = {ACM SIGIR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rath, Manmatha, Lavrenko - 2004 - A Search Engine for Historical Manuscript Images.pdf:pdf},
isbn = {1581138814},
keywords = {handwriting retrieval,historical manuscripts,relevance models},
pages = {369--376},
title = {{A Search Engine for Historical Manuscript Images}},
year = {2004}
}
@article{Wemhoener2013b,
author = {Wemhoener, David and Yalniz, Ismet Zeki and Manmatha, R.},
xxurl = {10.1109/ICDAR.2013.39},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wemhoener, Yalniz, Manmatha - 2013 - Creating an Improved Version Using Noisy OCR from Multiple Editions.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-ocr error correction,scanned,sequence alignment},
month = {aug},
pages = {160--164},
publisher = {Ieee},
title = {{Creating an Improved Version Using Noisy OCR from Multiple Editions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628604},
year = {2013}
}
@article{Huang1997,
author = {Huang, R W},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang - 1997 - Pergamon INDEXING PICTURES BY KEY OBJECTS FOR LARGE-SCALE IMAGE DATABASES.pdf:pdf},
issn = {00313203},
number = {7},
pages = {1229--1237},
title = {{Pergamon INDEXING PICTURES BY KEY OBJECTS FOR LARGE-SCALE IMAGE DATABASES *}},
volume = {30},
year = {1997}
}
@article{Malik2013b,
author = {Malik, Muhammad Imran and Ahmed, Sheraz and Liwicki, Marcus and Dengel, Andreas},
xxurl = {10.1109/ICDAR.2013.196},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malik et al. - 2013 - FREAK for Real Time Forensic Signature Verification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {971--975},
publisher = {Ieee},
title = {{FREAK for Real Time Forensic Signature Verification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628761},
volume = {2010},
year = {2013}
}
@article{Germain2015,
abstract = {There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder's parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with state-of-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators.},
archivePrefix = {arXiv},
arxivId = {1502.03509},
author = {Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
xxurl = {10.1103/PhysRevB.91.195316},
eprint = {1502.03509},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Germain et al. - 2015 - MADE Masked Autoencoder for Distribution Estimation.pdf:pdf},
isbn = {1502.03509},
issn = {1098-0121},
title = {{MADE: Masked Autoencoder for Distribution Estimation}},
url = {http://arxiv.org/abs/1502.03509},
volume = {37},
year = {2015}
}
@article{Metz2016,
abstract = {We introduce a method to stabilize Generative Adversarial Networks (GANs) by defining the generator objective with respect to an unrolled optimization of the discriminator. This allows training to be adjusted between using the optimal discriminator in the generator's objective, which is ideal but infeasible in practice, and using the current value of the discriminator, which is often unstable and leads to poor solutions. We show how this technique solves the common problem of mode collapse, stabilizes training of GANs with complex recurrent generators, and increases diversity and coverage of the data distribution by the generator.},
archivePrefix = {arXiv},
arxivId = {1611.02163},
author = {Metz, Luke and Poole, Ben and Pfau, David and Sohl-Dickstein, Jascha},
eprint = {1611.02163},
pages = {1--25},
pmid = {202927},
title = {{Unrolled Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1611.02163},
year = {2016}
}
@article{Kimura2013,
author = {Kimura, Takashi and Huang, Rong and Uchida, Seiichi and Iwamura, Masakazu and Omachi, Shinichiro and Kise, Koichi},
xxurl = {10.1109/ICDAR.2013.26},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kimura et al. - 2013 - The Reading-Life Log -- Technologies to Recognize Texts That We Read.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {91--95},
publisher = {Ieee},
title = {{The Reading-Life Log -- Technologies to Recognize Texts That We Read}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628591},
year = {2013}
}
@article{Flow2002a,
author = {Flow, Measuring Fluid and Spinners, Continuous and Bore, Full and Meters, Flow and Meters, Diverting Flow and Format, Log and Speed, Cable and Conventions, Sign and Principles, Fluid Flow and Tools, Radioactive Tracer and Logging, Oxygen Activation and Activation, Oxygen and Example, Log and Water, Schlumberger and Log, Flow and Principles, Operating and Oxygen, Stationary and Example, Activation and Oxygen, Stationary and Example, Activation},
file = {:home/mondal/Documents/MATHS/CalcI{\_}Complete.pdf:pdf},
number = {July},
pages = {1--12},
title = {{Table of Contents Table of Contents ی ﺮ ﺘ ﮐ د ﻪ ﺒ ﺣ ﺎ ﺼ ﻣ ر د ﺎ ﻫ ز ﺎ ﯿ ﺘ ﻣ ا ﻪ ﺴ ﯾ ﺎ ﻘ ﻣ ) ؟ ﻢ ﻨ ﮐ پ ﺎ ﭼ ب ﺎ ﺘ ﮐ ﺪ ﯾ ﺎ ﺑ ا ﺮ ﭼ )}},
year = {2002}
}
@article{Zhang2015a,
abstract = {Similarity measures are of fundamental importance in time series data mining. Dynamic Time Warping (DTW) is a quite popular measure because it handles time distortions well. However, DTW has an inherent shortcoming in that DTW can lead to pathological alignments between time series where a single point maps onto a large subsection of another time series. To overcome this problem, we propose a novel variant of DTW named SC-DTW. SC-DTW employs shape context, a rich local shape descriptor, to replace the raw observed values considered by conventional DTW. The main novelties of SC-DTW are (1) it deeply explores both the numerical nature and shape nature of time series; and (2) neighborhood information for each point is taken into account. SC-DTW can generate a more feature-to-feature alignment between time series and thus serves as a robust similarity measure. We test the performance of SC-DTW on UCR time series datasets using the one nearest neighbor (1NN) classifier. Compared with other well-established methods, SC-DTW provides better accuracy on 24 of 34 datasets.},
author = {Zhang, Zheng and Tang, Ping and Duan, Rubing},
xxurl = {10.1016/j.ins.2015.04.007},
file = {:home/mondal/Downloads/1-s2.0-S0020025515002753-main.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Classification,Dynamic time warping,Shape context,Similarity measure,Time series},
pages = {88--101},
publisher = {Elsevier Inc.},
title = {{Dynamic time warping under pointwise shape context}},
url = {http://dx.xxurl.org/10.1016/j.ins.2015.04.007},
volume = {315},
year = {2015}
}
@article{Yagoubi2020,
abstract = {Indexing is crucial for many data mining tasks that rely on efficient and effective similarity query processing. Consequently, indexing large volumes of time series, along with high performance similarity query processing, have became topics of high interest. For many applications across diverse domains though, the amount of data to be processed might be intractable for a single machine, making existing centralized indexing solutions inefficient. We propose a parallel indexing solution that gracefully scales to billions of time series, and a parallel query processing strategy that, given a batch of queries, efficiently exploits the index. Our experiments, on both synthetic and real world data, illustrate that our index creation algorithm works on four billion time series in less than five hours, while the state of the art centralized algorithms do not scale and have their limit on 1 billion time series, where they need more than five days. Also, our distributed querying algorithm is able to efficiently process millions of queries over collections of billions of time series, thanks to an effective load balancing mechanism.},
author = {Yagoubi, Djamel Edine and Akbarinia, Reza and Masseglia, Florent and Palpanas, Themis},
xxurl = {10.1109/TKDE.2018.2880215},
issn = {15582191},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Time series,distributed querying,parallel indexing},
title = {{Massively Distributed Time Series Indexing and Querying}},
year = {2020}
}
@article{Barachant2013,
abstract = {The use of spatial covariance matrix as a feature is investigated for motor imagery EEG-based classification in brain-computer interface applications. A new kernel is derived by establishing a connection with the Riemannian geometry of symmetric positive definite matrices. Different kernels are tested, in combination with support vector machines, on a past BCI competition dataset. We demonstrate that this new approach outperforms significantly state of the art results, effectively replacing the traditional spatial filtering approach. {\textcopyright} 2013 Elsevier B.V.},
author = {Barachant, Alexandre and Bonnet, St{\'{e}}phane and Congedo, Marco and Jutten, Christian},
xxurl = {10.1016/j.neucom.2012.12.039},
isbn = {0925-2312},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Brain-computer interfaces,Covariance matrix,Kernel,Riemannian geometry,Support vector machine},
pages = {172--178},
title = {{Classification of covariance matrices using a Riemannian-based kernel for BCI applications}},
volume = {112},
year = {2013}
}
@inproceedings{DBLP:conf/icdar/2013,
isbn = {978-0-7695-4999-6},
publisher = {{\{}IEEE{\}} Computer Society},
title = {{12th International Conference on Document Analysis and Recognition, {\{}ICDAR{\}} 2013, Washington, DC, USA, August 25-28, 2013}},
url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6627713},
year = {2013}
}
@article{Baker2005,
abstract = {Most tutorials on complex topics are apparently written by very smart people whose goal is to use as little space as possible and who assume that their readers already know almost as much as the author does. This tutorial's not like that. It's more a manifestivus for the rest of us. It's about the mechanics of singular value decomposition, especially as it relates to some techniques in natural language processing. It's written by someone who knew zilch about singular value decomposition or any of the underlying math before he started writing it, and knows barely more than that now. Accordingly, it's a bit long on the background part, and a bit short on the truly explanatory part, but hopefully it contains all the information necessary for someone who's never heard of singular value decomposition before to be able to do it.},
author = {Baker, Kirk},
xxurl = {10.1021/jo0008901},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker - 2005 - Singular value decomposition tutorial.pdf:pdf},
issn = {00223263},
journal = {The Ohio State University},
pages = {24},
title = {{Singular value decomposition tutorial}},
url = {http://www.ling.ohio-state.edu/{~}kbaker/pubs/Singular{\_}Value{\_}Decomposition{\_}Tutorial.pdf{\%}5Cnhttp://www.ams.org/samplings/feature-column/fcarc-svd},
volume = {2005},
year = {2005}
}
@article{Gharghabi,
abstract = {At their core, many time series data mining algorithms reduce to reasoning about the shapes of time series subsequences. This requires an effective distance measure, and for last two decades most algorithms use Euclidean Distance or DTW as their core subroutine. We argue that these distance measures are not as robust as the community seems to believe. The undue faith in these measures perhaps derives from an overreliance on the benchmark datasets and self-selection bias. The community is simply reluctant to address more difficult domains, for which current distance measures are ill-suited. In this work, we introduce a novel distance measure MPdist. We show that our proposed distance measure is much more robust than current distance measures. For example, it can handle data with missing values or spurious regions. Furthermore, it allows us to successfully mine datasets that would defeat any Euclidean or DTW distance-based algorithm. Additionally, we show that our distance measure can be computed so efficiently as to allow analytics on very fast arriving streams.},
author = {Gharghabi, Shaghayegh and Imani, Shima and Bagnall, Anthony and Darvishzadeh, Amirali and Keogh, Eamonn},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gharghabi et al. - Unknown - An Ultra-Fast Time Series Distance Measure to allow Data Mining in more Complex Real-World Deployments.pdf:pdf},
keywords = {Distance Measure,Matrix Profile,Time Series},
title = {{An Ultra-Fast Time Series Distance Measure to allow Data Mining in more Complex Real-World Deployments}}
}
@article{Coppi2010,
author = {Coppi, Renato and D'Urso, Pierpaolo and Giordani, Paolo},
xxurl = {10.1007/s00357-010-9043-y},
issn = {0176-4268},
journal = {Journal of Classification},
month = {apr},
number = {1},
pages = {54--88},
title = {{A Fuzzy Clustering Model for Multivariate Spatial Time Series}},
url = {http://link.springer.com/10.1007/s00357-010-9043-y},
volume = {27},
year = {2010}
}
@inproceedings{YHK2016,
author = {Yeh, Chin-Chia Michael and Herle, Helga Van and Keogh, Eamonn J},
booktitle = {Proceedings of the International Conference on Data Mining (ICDM)},
pages = {579--588},
title = {{Matrix Profile {\{}III:{\}} The Matrix Profile Allows Visualization of Salient Subsequences in Massive Time Series}},
year = {2016}
}
@article{Im2016,
abstract = {Gatys et al. (2015) showed that optimizing pixels to match features in a convolutional network with respect reference image features is a way to render images of high visual quality. We show that unrolling this gradient-based optimization yields a recurrent computation that creates images by incrementally adding onto a visual "canvas". We propose a recurrent generative model inspired by this view, and show that it can be trained using adversarial training to generate very good image samples. We also propose a way to quantitatively compare adversarial networks by having the generators and discriminators of these networks compete against each other.},
archivePrefix = {arXiv},
arxivId = {1602.05110},
author = {Im, Daniel Jiwoong and Kim, Chris Dongjoo and Jiang, Hui and Memisevic, Roland},
xxurl = {10.1007/s10909-016-1606-9},
eprint = {1602.05110},
issn = {15737357},
title = {{Generating images with recurrent adversarial networks}},
url = {http://arxiv.org/abs/1602.05110},
year = {2016}
}
@article{Meng2014,
abstract = {Document images captured by a digital camera often suffer from serious geometric distortions. In this paper, we propose an active method to correct geometric distortions in a camera-captured document image. Unlike many passive rectification methods that rely on text-lines or features extracted from images, our method uses two structured beams illuminating upon the document page to recover two spatial curves. A developable surface is then interpolated to the curves by finding the correspondence between them. The developable surface is finally flattened onto a plane by solving a system of ordinary differential equations. Our method is a content independent approach and can restore a corrected document image of high accuracy with undistorted contents. Experimental results on a variety of real-captured document images demonstrate the effectiveness and efficiency of the proposed method.},
author = {Meng, Gaofeng and Wang, Ying and Qu, Shenquan and Xiang, Shiming and Pan, Chunhong},
xxurl = {10.1109/CVPR.2014.497},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meng et al. - 2014 - Active flattening of curved document images via two structured beams.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {developable surface interpolation,document image processing,geometric rectification,structured beams},
number = {95},
pages = {3890--3897},
title = {{Active flattening of curved document images via two structured beams}},
year = {2014}
}
@article{Cecotti2013,
author = {Cecotti, Hubert and Vajda, Szilard},
xxurl = {10.1109/ICDAR.2013.96},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cecotti, Vajda - 2013 - Rejection Schemes in Multi-class Classification -- Application to Handwritten Character Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {445--449},
publisher = {Ieee},
title = {{Rejection Schemes in Multi-class Classification -- Application to Handwritten Character Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628661},
year = {2013}
}
@article{RamosTerrades2007,
abstract = {Shape descriptors play an important role in many document analysis application. In this paper we review some of the shape descriptors proposed in the last years from a new point of view. We propose the definitions of descriptor and primitive and introduce the notion of feature extraction method. With these definitions, we propose a new classification of shape descriptors that permits to classify according to their properties pointing out their strengths and weaknesses.},
author = {{Ramos Terrades}, O. and Tabbone, S. and Valveny, E.},
xxurl = {10.1109/ICDAR.2007.4378709},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramos Terrades, Tabbone, Valveny - 2007 - A review of shape descriptors for document analysis.pdf:pdf},
isbn = {0769528228},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
number = {Icdar},
pages = {227--231},
title = {{A review of shape descriptors for document analysis}},
volume = {1},
year = {2007}
}
@article{Algorithms,
author = {Algorithms, Basic},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Algorithms - Unknown - Terminology and Basic Algorithms.pdf:pdf},
title = {{Terminology and Basic Algorithms}}
}
@inproceedings{Hu2013c,
abstract = {Extensive research on time series classification in the last decade has produced fast and accurate algorithms for the single-dimensional case. However, the increasing prevalence of inexpensive sensors has reinforced the need for algorithms to handle multi-dimensional time series. For example, modern smartphones have at least a dozen sensors capable of producing streaming time series, and hospital-based (and increasingly, home-based) medical devices can produce time series streams from more than twenty sensors. The two most common ways to generalize from single to multi-dimensional data are to use all the streams or just the single best stream as determined at training time. However, as we show here, both approaches can be very brittle. Moreover, neither approach exploits the observation that different sensors may be considered "experts" on different classes. In this work, we introduce a novel framework for multi-dimensional time series classification that weights the class prediction from each time series stream. These weights are based not only on each stream's previous track record on the class it is currently predicting, but also on the distance from the unlabeled object. As we demonstrate with extensive experiments on real data, our method is more accurate than current approaches and particularly robust in the face of concept drift or sensor noise. {\textcopyright} 2013 IEEE.},
author = {Hu, Bing and Chen, Yanping and Zakaria, Jesin and Ulanova, Liudmila and Keogh, Eamonn},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
xxurl = {10.1109/ICDM.2013.33},
issn = {15504786},
keywords = {classification,multi-dimensional time series},
title = {{Classification of multi-dimensional streaming time series by weighting each classifier's track record}},
year = {2013}
}
@article{Oord2016,
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.},
archivePrefix = {arXiv},
arxivId = {1601.06759},
author = {van den Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
eprint = {1601.06759},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oord, Kalchbrenner, Kavukcuoglu - 2016 - Pixel Recurrent Neural Networks.pdf:pdf},
isbn = {9781510829008},
title = {{Pixel Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1601.06759},
volume = {48},
year = {2016}
}
@inproceedings{Jain2010,
abstract = {Cephalometric analysis has an important role in diagnosis and treatment planning for malocclusions. Most analysis steps are computable and underlying structure may be generated provided landmarks are correctly localized. Due to the complexity of human anatomy sensed in a cephalometric x-ray, the landmarks are localized by human experts. In the last few years, efforts have been made to automate this process. This work contributes into a novel approach by first making a generic template search to make a coarse localization of the landmarks. A finer search further combines the best suitable edge or region based final localization. In both the steps of searching, small search area is allocated for each landmark. Films were digitized at three hundred dpi(dots per inch) and the experiments were conducted by recording fourteen landmarks on a number of patients by three dentists. Ground truth of the coordinates was obtained by averaging and the results of the algorithm were compared with these reference values. The result indicates that most of the landmarks lie in the specified limits. In this manner, both speed and accuracy is achieved with performance comparable to humans. {\textcopyright} 2010 IEEE.},
author = {Jain, Ashish and Mondal, Tanmoy and Sardana, H. K.},
booktitle = {ICCET 2010 - 2010 International Conference on Computer Engineering and Technology, Proceedings},
xxurl = {10.1109/ICCET.2010.5485871},
isbn = {9781424463503},
keywords = {Cephalograms,Cephalometric analysis,Template matching},
title = {{A novel strategy for automatic localization of cephalometric landmarks}},
year = {2010}
}
@article{Soffer1997,
author = {Soffer, Aya and Samet, Hanan},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soffer, Samet - 1997 - Negative shape features for image databases consisting of geographic symbols.pdf:pdf},
journal = {Proc. 3rd International Workshop on Visual Form},
pages = {1--13},
title = {{Negative shape features for image databases consisting of geographic symbols}},
year = {1997}
}
@article{Tuytelaars2007,
abstract = {Local Invariant Feature Detectors: A Survey},
author = {Tuytelaars, Tinne and Mikolajczyk, Krystian},
xxurl = {10.1561/0600000017},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuytelaars, Mikolajczyk - 2007 - Local Invariant Feature Detectors A Survey.pdf:pdf},
issn = {1572-2740},
journal = {Foundations and Trends{\textregistered} in Computer Graphics and Vision},
keywords = {Computer Vision,Feature detection and selection,Object and scene recognition,Segmentation and grouping},
number = {3},
pages = {177--280},
publisher = {Now Publishers, Inc.},
title = {{Local Invariant Feature Detectors: A Survey}},
url = {http://www.nowpublishers.com/article/Details/CGV-017},
volume = {3},
year = {2007}
}
@article{Etal.Ash2012,
author = {et al. Ash, Robert},
file = {:home/mondal/Documents/MATHS/math4ml.pdf:pdf},
pages = {1--47},
title = {{VNR0: Mathematics for Machine Learning}},
year = {2012}
}
@article{Feild2013a,
author = {Feild, Jacqueline L. and Learned-Miller, Erik G. and Smith, David a.},
xxurl = {10.1109/ICDAR.2013.183},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feild, Learned-Miller, Smith - 2013 - Using a Probabilistic Syllable Model to Improve Scene Text Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {897--901},
publisher = {Ieee},
title = {{Using a Probabilistic Syllable Model to Improve Scene Text Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628748},
year = {2013}
}
@article{Khan2013,
author = {Khan, Zohaib and Shafait, Faisal and Mian, Ajmal},
xxurl = {10.1109/ICDAR.2013.179},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan, Shafait, Mian - 2013 - Hyperspectral Imaging for Ink Mismatch Detection.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {877--881},
publisher = {Ieee},
title = {{Hyperspectral Imaging for Ink Mismatch Detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628744},
year = {2013}
}
@article{Gomez2013,
author = {Gomez, Lluis and Karatzas, Dimosthenis},
xxurl = {10.1109/ICDAR.2013.100},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomez, Karatzas - 2013 - Multi-script Text Extraction from Natural Scenes.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {467--471},
publisher = {Ieee},
title = {{Multi-script Text Extraction from Natural Scenes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628665},
year = {2013}
}
@inproceedings{DBLP:conf/das/2016,
isbn = {978-1-5090-1792-8},
publisher = {{\{}IEEE{\}} Computer Society},
title = {{12th {\{}IAPR{\}} Workshop on Document Analysis Systems, {\{}DAS{\}} 2016, Santorini, Greece, April 11-14, 2016}},
url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7485953},
year = {2016}
}
@article{Radford2015,
abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
archivePrefix = {arXiv},
arxivId = {1511.06434},
author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
xxurl = {10.1051/0004-6361/201527329},
eprint = {1511.06434},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radford, Metz, Chintala - 2015 - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.pdf:pdf},
isbn = {2004012439},
issn = {0004-6361},
pages = {1--16},
pmid = {23459267},
title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1511.06434},
year = {2015}
}
@article{Wang2016a,
abstract = {For any two one-dimensional time series of equal or non-equal length, we propose a new method to determine their shape distance. Each of the original time series is represented by a sequence of linear segments which are produced by l1 trend filtering. As the dimensionality of this representation ranges between time series, dynamic time warping (DTW) method is used to calculate the distance between time series. In contrast to the standard dynamic time warping method, here the element of the new distance matrix concerns the distance between two linear segments instead of two elements of the original time series. More specifically, the distance between the two linear segments is calculated as the area of a triangle which is formed by the two linear segments after their translation and connection. In brief, the new measure can be regarded as the dynamic time warping distance computed in a piecewise linear space. Furthermore, we show that new distance measure quantitatively reflects the shape's difference between two one-dimensional time series. The simulation experiments presented in this paper illustrate the performance of the proposed method.},
author = {Wang, Xiao and Yu, Fusheng and Pedrycz, Witold},
xxurl = {10.1016/j.asoc.2016.06.033},
file = {:home/mondal/Downloads/1-s2.0-S1568494616303131-main.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Area-based shape distance,Dynamic time warping,One-dimensional time series,l1 trend filtering},
pages = {650--659},
publisher = {Elsevier B.V.},
title = {{An area-based shape distance measure of time series}},
url = {http://dx.xxurl.org/10.1016/j.asoc.2016.06.033},
volume = {48},
year = {2016}
}
@article{Abe2002,
author = {Abe, Shigeo and Inoue, Takuya},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abe, Inoue - 2002 - Fuzzy Support Vector Machines for Multiclass Problems.pdf:pdf},
isbn = {2930307021},
journal = {European Symposium on Artificial Neural Networks (ESANN2002)},
number = {April},
pages = {113--118},
title = {{Fuzzy Support Vector Machines for Multiclass Problems}},
year = {2002}
}
@article{Pratikakis2018,
abstract = {{\textcopyright} 2017 IEEE. DIBCO 2017 is the international Competition on Document Image Binarization organized in conjunction with the ICDAR 2017 conference. The general objective of the contest is to identify current advances in document image binarization of machine-printed and handwritten document images using performance evaluation measures that are motivated by document image analysis and recognition requirements. This paper describes the competition details including the evaluation measures used as well as the performance of the 26 submitted methods along with a brief description of each method.},
author = {Pratikakis, Ioannis and Zagoris, Konstantinos and Barlas, George and Gatos, Basilis},
xxurl = {10.1109/ICDAR.2017.228},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratikakis et al. - 2018 - ICDAR2017 Competition on Document Image Binarization (DIBCO 2017).pdf:pdf},
isbn = {9781538635865},
issn = {15205363},
journal = {ICDAR},
keywords = {Binarization,Handwritten document image,Machine-printed,Performance evaluation},
number = {Dibco},
pages = {1395--1403},
title = {{ICDAR2017 Competition on Document Image Binarization (DIBCO 2017)}},
volume = {1},
year = {2018}
}
@article{Ziaratban2008,
abstract = {This paper presents a new two-stage method for estimating and correcting the baseline of handwritten subwords in Farsi and Arabic text lines. Based on the template matching algorithm, the candidate baseline pixels are detected. The writing path and the baseline of the subwords are estimated in the first and second stages of the proposed algorithm, respectively. After the estimation in each stage, the baseline is adjusted in the correction phase. Experimental results show the effectiveness of this approach in adjusting the baseline close to the correct position.},
author = {Ziaratban, M. and Faez, K.},
xxurl = {10.1109/ICPR.2008.4761822},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ziaratban, Faez - 2008 - A novel two-stage algorithm for baseline estimation and correction in Farsi and Arabic handwritten text line.pdf:pdf},
isbn = {978-1-4244-2174-9},
issn = {1051-4651},
journal = {2008 19th International Conference on Pattern Recognition},
pages = {2--6},
title = {{A novel two-stage algorithm for baseline estimation and correction in Farsi and Arabic handwritten text line}},
year = {2008}
}
@article{Rusinol2013,
author = {Rusinol, Marcal and Benkhelfallah, Tayeb and DAndecy, Vincent Poulain},
xxurl = {10.1109/ICDAR.2013.223},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusinol, Benkhelfallah, dAndecy - 2013 - Field Extraction from Administrative Documents by Incremental Structural Templates.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1100--1104},
publisher = {Ieee},
title = {{Field Extraction from Administrative Documents by Incremental Structural Templates}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628784},
year = {2013}
}
@inproceedings{Chen1995,
author = {Chen, Francine R. and Bloomberg, Dan S. and Wilcox, Lynn D.},
booktitle = {IS{\&}T/SPIE's Symposium on Electronic Imaging: Science {\&} Technology},
xxurl = {10.1117/12.205828},
editor = {Vincent, Luc M. and Baird, Henry S.},
month = {mar},
pages = {256--269},
publisher = {International Society for Optics and Photonics},
title = {{Spotting phrases in lines of imaged text}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=992269},
year = {1995}
}
@article{Oliveira2013,
author = {Oliveira, Daniel and Lins, Rafael and Torreao, Gabriel and Fan, Jian and Thielo, Marcelo},
xxurl = {10.1109/ICDAR.2013.57},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliveira et al. - 2013 - An Efficient Algorithm for Segmenting Warped Text-Lines in Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {camera documents,document image processing,page segmentation,text-line segmentation},
month = {aug},
pages = {250--254},
publisher = {Ieee},
title = {{An Efficient Algorithm for Segmenting Warped Text-Lines in Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628622},
year = {2013}
}
@inproceedings{MichailVlachos,
abstract = {Although most time-series data mining research has concentrated on providing solutions for a single distance function, in this work we motivate the need for a single index structure that can support multiple distance measures. Our specific area of interest is the efficient retrieval and analysis of trajectory similarities. Trajectory datasets are very common in environmental applications, mobility experiments, video surveillance and are especially important for the discovery of certain biological patterns. Our primary similarity measure is based on the Longest Common Subsequence (LCSS) model, that offers enhanced robustness, particularly for noisy data, which are encountered very often in real world applications. However, our index is able to accommodate other distance measures as well, including the ubiquitous Euclidean distance, and the increasingly popular Dynamic Time Warping (DTW). While other researchers have advocated one or other of these similarity measures, a major contribution of our work is the ability to support all these measures without the need to restructure the index. Our framework guarantees no false dismissals and can also be tailored to provide much faster response time at the expense of slightly reduced precision/recall. The experimental results demonstrate that our index can help speed-up the computation of expensive similarity measures such as the LCSS and the DTW.},
address = {New York, USA},
author = {Vlachos, Michail and Hadjieleftheriou, Marios and Gunopulos, Dimitrios and Keogh, Eamonn J.},
booktitle = {KDD},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vlachos et al. - 2003 - Indexing multi-dimensional time-series with support for multiple distance measures.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michail Vlachos - Unknown - Indexing multi-dimensional time-series with support for multiple distance measures.pdf:pdf},
keywords = {clustering,distance measure,distances,dynamic time warping,handwriting,longest common subsequence,time series,toread,trajectories},
mendeley-tags = {clustering,distances,dynamic time warping,handwriting,time series,toread},
month = {aug},
pages = {216--225},
publisher = {ACM Press},
title = {{Indexing multi-dimensional time-series with support for multiple distance measures}},
year = {2003}
}
@article{Lei2017,
abstract = {As fuzzy c-means clustering (FCM) algorithm is sensitive to noise, local spatial information is often introduced to an objective function to improve the robustness of the FCM algorithm for image segmentation. However, the introduction of local spatial information often leads to a high computational complexity, arising out of an iterative calculation of the distance between pixels within local spatial neighbors and clustering centers. To address this issue, an improved FCM algorithm based on morphological reconstruction and membership filtering (FRFCM) that is significantly faster and more robust than FCM, is proposed in this paper. Firstly, the local spatial information of images is incorporated into FRFCM by introducing morphological reconstruction operation to guarantee noise-immunity and image detail-preservation. Secondly, the modification of membership partition, based on the distance between pixels within local spatial neighbors and clustering centers, is replaced by local membership filtering that depends only on the spatial neighbors of membership partition. Compared to state-of-the-art algorithms, the proposed FRFCM algorithm is simpler and significantly faster, since it is unnecessary to compute the distance between pixels within local spatial neighbors and clustering centers. In addition, it is efficient for noisy image segmentation because membership filtering are able to improve membership partition matrix efficiently. Experiments performed on synthetic and real-world images demonstrate that the proposed algorithm not only achieves better results, but also requires less time than state-of-the-art algorithms for image segmentation.},
author = {He, Lifeng and Nandi, Asoke K. and Jia, Xiaohong and Zhang, Yanning and Meng, Hongying and Lei, Tao},
xxurl = {10.1109/tfuzz.2018.2796074},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2018 - Significantly Fast and Robust Fuzzy C-Means Clustering Algorithm Based on Morphological Reconstruction and Membership.pdf:pdf},
issn = {1063-6706},
journal = {IEEE Transactions on Fuzzy Systems},
number = {5},
pages = {3027--3041},
title = {{Significantly Fast and Robust Fuzzy C-Means Clustering Algorithm Based on Morphological Reconstruction and Membership Filtering}},
volume = {26},
year = {2018}
}
@article{R.Manmatha,
author = {{R. Manmatha}, Toni M. Rath},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/R. Manmatha - 2003 - Indexing of Handwritten Historical Documents - Recent Progress.pdf:pdf},
journal = {Proceedings of Symposium on Document Image Understanding Technology (SDIUT)},
pages = {77--85},
title = {{Indexing of Handwritten Historical Documents - Recent Progress}},
year = {2003}
}
@article{Thinkuser2008,
author = {Thinkuser, By and Group, H C I},
file = {:home/mondal/Documents/MATHS/CalcIII{\_}Complete.pdf:pdf},
isbn = {0302543287},
journal = {Group},
number = {766},
pages = {0--108},
title = {{Calculus III course}},
volume = {2008},
year = {2008}
}
@article{Baranauskas2013,
author = {Baranauskas, Edgaras and Hills, Jon and Bagnall, Anthony and Lines, Jason and Mapp, James},
xxurl = {10.1007/s10618-013-0322-1},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
number = {4},
pages = {851--881},
title = {{Classification of time series by shapelet transformation}},
volume = {28},
year = {2013}
}
@article{Kato2011,
abstract = {This paper proposes a method for low resolution QR-code recognition. A QR-code is a two-dimensional binary symbol that can embed various information such as characters and numbers. To recognize a QR-code correctly and stably, the resolution of an input image should be high. In practice, however, recognition of a QR-code is usually difficult due to low resolution when it is captured from a distance. In this paper, we propose a method to improve the performance of low resolution QR-code recognition by using the super-resolution technique that generates a high resolution image from multiple low-resolution images. Although a QR-code is a binary pattern, it is observed as a grayscale image due to the degradation through the capturing process. Especially the pixels around the borders between white and black regions become ambiguous. To overcome this problem, the proposed method introduces a binary pattern constraint to generate super-resolved images appropriate for recognition. Experimental results showed that a recognition rate of 98{\%} can be achieved by the proposed method, which is a 15.7{\%} improvement in comparison with a method using a conventional super-resolution method. {\textcopyright} 2011 IEEE.},
author = {Kato, Yuji and Deguchi, Daisuke and Takahashi, Tomokazu and Ide, Ichiro and Murase, Hiroshi},
xxurl = {10.1109/ICDAR.2011.201},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kato et al. - 2011 - Low resolution QR-code recognition by applying super-resolution using the property of QR-codes.pdf:pdf},
isbn = {9780769545202},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {QR-code recognition,Super-resolution,binary constraint},
pages = {992--996},
title = {{Low resolution QR-code recognition by applying super-resolution using the property of QR-codes}},
year = {2011}
}
@article{Zifan2007,
author = {Zifan, Ali and Saberi, Sohrab and Moradi, Mohammad Hassan and Towhidkhah, Farzad},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zifan et al. - 2007 - Automated ECG Segmentation Using Piecewise Derivative Dynamic Time Warping.pdf:pdf},
journal = {International Journal of Medical, Health, Pharmaceutical and Biomedical Engineering},
keywords = {-tion,1,adaptive piecewise constant approximation,and piecewise derivative dynamic,derivative dynamic time warping,dynamic programming,ecg segmentation,piecewise,time warping},
number = {3},
pages = {764--768},
title = {{Automated ECG Segmentation Using Piecewise Derivative Dynamic Time Warping}},
volume = {1},
year = {2007}
}
@article{Rahmani2008,
author = {Rahmani, R. and Goldman, S.A. and {Hui Zhang} and Cholleti, S.R. and Fritts, J.E.},
xxurl = {10.1109/TPAMI.2008.112},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {nov},
number = {11},
pages = {1902--1912},
title = {{Localized Content-Based Image Retrieval}},
url = {http://ieeexplore.ieee.org/document/4509439/},
volume = {30},
year = {2008}
}
@article{Stamatopoulos2009,
author = {Stamatopoulos, Nikolaos and Gatos, Basilis and Perantonis, Stavros J.},
xxurl = {10.1016/j.patcog.2008.10.020},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamatopoulos, Gatos, Perantonis - 2009 - A method for combining complementary techniques for document image segmentation.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Combination method,Document image analysis,Segmentation,document image segmentation},
month = {dec},
number = {12},
pages = {3158--3168},
publisher = {Elsevier},
title = {{A method for combining complementary techniques for document image segmentation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003132030800441X},
volume = {42},
year = {2009}
}
@inproceedings{SiamakKhoubyari,
author = {{Siamak Khoubyari}, Jonathan J. Hull},
booktitle = {In 2nd Annual Symposium on Document Analysis and Information Retrieval},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siamak Khoubyari - 1993 - Keyword location in noisy document image.pdf:pdf},
pages = {217----231},
title = {{Keyword location in noisy document image}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.300.7573},
year = {1993}
}
@article{Seth2013,
author = {Seth, Sharad and Nagy, George},
xxurl = {10.1109/ICDAR.2013.181},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seth, Nagy - 2013 - Segmenting Tables via Indexing of Value Cells by Table Headers.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {1,14,data flow of tango,fig,indexing by header strings,minimum indexing,point,table segmentation},
month = {aug},
pages = {887--891},
publisher = {Ieee},
title = {{Segmenting Tables via Indexing of Value Cells by Table Headers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628746},
year = {2013}
}
@article{Lu2013,
author = {Lu, Xiaoqing and Tang, Zhi and Liu, Yan and Gao, Liangcai and Wang, Ting and Wang, Zhipeng},
xxurl = {10.1109/ICDAR.2013.55},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2013 - Stroke-Based Character Segmentation of Low-Quality Images on Ancient Chinese Tablet.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {character localization,character segmentation,chinese tablet image,enhanced stroke filter,stroke detection},
month = {aug},
pages = {240--244},
publisher = {Ieee},
title = {{Stroke-Based Character Segmentation of Low-Quality Images on Ancient Chinese Tablet}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628620},
year = {2013}
}
@article{Campana2012,
abstract = {Most time series data mining algorithms use similarity search as a core subroutine, and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms. The difficulty of scaling search to large datasets largely explains why most academic work on time series data mining has plateaued at considering a few millions of time series objects, while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine truly massive time series for the first time. We demonstrate the following extremely unintuitive fact; in large datasets we can exactly search under DTW much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. In particular, the largest dataset we consider is larger than the combined size of all of the time series datasets considered in all data mining papers ever published. We show that our ideas allow us to solve higher-level time series data mining problem such as motif discovery and clustering at scales that would otherwise be untenable. In addition to mining massive datasets, we will show that our ideas also have implications for real-time monitoring of data streams, allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible.},
author = {Campana, Bilson and Rakthanmanon, Thanawin and Batista, Gustavo and Mueen, Abdullah and Zhu, Qiang and Keogh, Eamonn and Westover, Brandon and Zakaria, Jesin},
xxurl = {10.1145/2339530.2339576},
file = {:home/mondal/Downloads/Searching{\_}and{\_}Mining{\_}Trillions{\_}of{\_}Time{\_}Series{\_}Subs.pdf:pdf},
isbn = {9781577356332},
issn = {10450823},
keywords = {lower bounds,similarity search,time series},
pages = {262},
pmid = {18225950},
title = {{Searching and mining trillions of time series subsequences under dynamic time warping}},
year = {2012}
}
@article{Rani2013,
author = {Rani, Rajneesh and Dhir, Renu and Lehal, Gurpreet Singh},
xxurl = {10.1109/ICDAR.2013.233},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rani, Dhir, Lehal - 2013 - Script Identification of Pre-segmented Multi-font Characters and Digits.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1150--1154},
publisher = {Ieee},
title = {{Script Identification of Pre-segmented Multi-font Characters and Digits}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628794},
year = {2013}
}
@article{Herzog2013,
author = {Herzog, Rainer and Solth, Arved and Neumann, Bernd},
xxurl = {10.1109/ICDAR.2013.262},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Herzog, Solth, Neumann - 2013 - Using Harris Corners for the Retrieval of Graphs in Historical Manuscripts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-retrieval,graph,interest point,manuscript},
month = {aug},
pages = {1295--1299},
publisher = {Ieee},
title = {{Using Harris Corners for the Retrieval of Graphs in Historical Manuscripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628823},
year = {2013}
}
@article{Goodfellow2016,
author = {Goodfellow, Ian},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow - 2016 - Introduction to Generative Adversarial Networks.pdf:pdf},
title = {{Introduction to Generative Adversarial Networks}},
year = {2016}
}
@inproceedings{DBLP:conf/acpr/2015,
isbn = {978-1-4799-6100-9},
publisher = {IEEE},
title = {{3rd {\{}IAPR{\}} Asian Conference on Pattern Recognition, {\{}ACPR{\}} 2015, Kuala Lumpur, Malaysia, November 3-6, 2015}},
url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7484414},
year = {2015}
}
@article{Bertrand2013b,
author = {Bertrand, Romain and Gomez-Kramer, Petra and Terrades, Oriol Ramos and Franco, Patrick and Ogier, Jean-Marc},
xxurl = {10.1109/ICDAR.2013.29},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertrand et al. - 2013 - A System Based on Intrinsic Features for Fraudulent Document Detection.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {document analysis,fake,forgery,fraudulent doc-,paper document,ument},
month = {aug},
pages = {106--110},
publisher = {Ieee},
title = {{A System Based on Intrinsic Features for Fraudulent Document Detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628594},
year = {2013}
}
@inproceedings{Zhu2009,
abstract = {Graphics detection and recognition are fundamental research problems in document image analysis and retrieval. As one of the most pervasive graphical elements in business and government documents, logos may enable immediate identification of organizational entities and serve extensively as a declaration of a document's source and ownership. In this work, we developed an automatic logo-based document image retrieval system that handles: (1) Logo detection and segmentation by boosting a cascade of classifiers across multiple image scales; and (2) Logo matching using translation, scale, and rotation invariant shape descriptors and matching algorithms. Our approach is segmentation free and layout independent and we address logo retrieval in an unconstrained setting of 2D feature point matching. Finally, we quantitatively evaluate the effectiveness of our approach using large collections of real-world complex document images.},
author = {Zhu, Guangyu and Doermann, David},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
xxurl = {10.1109/ICDAR.2009.60},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Doermann - 2009 - Logo matching for document image retrieval.pdf:pdf},
isbn = {9780769537252},
issn = {15205363},
keywords = {imp-logo-paper},
mendeley-tags = {imp-logo-paper},
pages = {606--610},
pmid = {19762928},
title = {{Logo matching for document image retrieval}},
year = {2009}
}
@inproceedings{Manmatha,
author = {{Manmatha, R. Chengfeng}, H. and Riseman, E.M.},
booktitle = {CVPR},
isbn = {0-8186-7258-7},
issn = {1063-6919},
language = {English},
pages = {631--637},
publisher = {IEEE Comput. Soc. Press},
title = {{Word spotting: a new approach to indexing handwriting}},
year = {1996}
}
@article{Yeh2017a,
abstract = {Multidimensional Scaling (MDS) is one of the most versatile tools used for exploratory data mining. It allows a first glimpse of possible structure in the data, which can inform the choice of analyses used. Its uses are multiple. It can give the user an idea as to the clusterability or linear separability of the data. It can help spot outliers, or can hint at the intrinsic dimensionality of the data. Moreover, it can sometimes reveal unexpected latent dimensions in the data. With all these uses, MDS is increasingly used in areas as diverse as marketing, medicine, genetics, music and linguistics. One of the strengths of MDS is that it is essentially agnostic to data type, as we can use any distance measure to create the distance matrix, which is the only required input to the MDS algorithm. In spite of this generality, we make the following claim. MDS is not (well) defined for an increasingly important data type, time series subsequences. In this work we explain why this is the case, and we propose a scalable solution. We demonstrate the utility of our ideas on several diverse real-world datasets. At the core of our approach is a novel Minimum Description Length (MDL) subsequence extraction algorithm. Beyond MDS visualization, this subsequence extraction subroutine may be a useful tool in its own right.},
author = {Yeh, Chin Chia Michael and {Van Herle}, Helga and Keogh, Eamonn},
xxurl = {10.1109/ICDM.2016.92},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh, Van Herle, Keogh - 2017 - Matrix profile III The matrix profile allows visualization of salient subsequences in massive time series.pdf:pdf},
isbn = {9781509054725},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Feature Extraction,Multidimensional Scaling,Time Series,Visualization},
pages = {579--588},
pmid = {28447870},
title = {{Matrix profile III: The matrix profile allows visualization of salient subsequences in massive time series}},
year = {2017}
}
@article{Mehri2015,
author = {Mehri, Maroua and Pierre, H and Sliti, Nabil and Gomez-kr, Petra and Essoukri, Najoua and Amara, Ben},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehri et al. - 2015 - Extraction of Homogeneous Regions in Historical Document Images.pdf:pdf},
isbn = {0005265500470},
journal = {Visigrapp},
pages = {47--54},
title = {{Extraction of Homogeneous Regions in Historical Document Images}},
year = {2015}
}
@inproceedings{Pratikakis2019,
abstract = {DIBCO 2019 is the international Competition on Document Image Binarization organized in conjunction with the ICDAR 2019 conference. The general objective of the contest is to identify current advances in document image binarization of machine-printed and handwritten document images using performance evaluation measures that are motivated by document image analysis and recognition requirements. This paper describes the competition details including the evaluation measures used as well as the performance of the 24 submitted methods along with a brief description of each method.},
author = {Pratikakis, Ioannis and Zagoris, Konstantinos and Karagiannis, Xenofon and Tsochatzidis, Lazaros and Mondal, Tanmoy and Marthot-Santaniello, Isabelle},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
xxurl = {10.1109/ICDAR.2019.00249},
isbn = {9781728128610},
issn = {15205363},
keywords = {Binarization,Handwritten document image,Machine-printed,Performance evaluation},
title = {{ICDAR 2019 competition on document image binarization (DIBCO 2019)}},
year = {2019}
}
@article{Croll,
author = {Croll, Paul R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Croll - Unknown - IEEE Computer Society Technical {\&} Conference Activities Board.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Croll - Unknown - IEEE Computer Society Technical {\&} Conference Activities Board(2).pdf:pdf},
isbn = {1714821838},
pages = {1504},
title = {{IEEE Computer Society Technical {\&} Conference Activities Board}}
}
@article{Flow2002c,
author = {Flow, Measuring Fluid and Spinners, Continuous and Bore, Full and Meters, Flow and Meters, Diverting Flow and Format, Log and Speed, Cable and Conventions, Sign and Principles, Fluid Flow and Tools, Radioactive Tracer and Logging, Oxygen Activation and Activation, Oxygen and Example, Log and Water, Schlumberger and Log, Flow and Principles, Operating and Oxygen, Stationary and Example, Activation and Oxygen, Stationary and Example, Activation},
file = {:home/mondal/Documents/MATHS/DE{\_}Complete.pdf:pdf},
number = {July},
pages = {1--12},
title = {{Table of Contents Table of Contents ی ﺮ ﺘ ﮐ د ﻪ ﺒ ﺣ ﺎ ﺼ ﻣ ر د ﺎ ﻫ ز ﺎ ﯿ ﺘ ﻣ ا ﻪ ﺴ ﯾ ﺎ ﻘ ﻣ ) ؟ ﻢ ﻨ ﮐ پ ﺎ ﭼ ب ﺎ ﺘ ﮐ ﺪ ﯾ ﺎ ﺑ ا ﺮ ﭼ )}},
year = {2002}
}
@article{Krinidis2010,
author = {Krinidis, Stelios and Chatzis, Vassilios},
xxurl = {10.1109/TIP.2010.2040763},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krinidis, Chatzis - 2010 - A Robust Fuzzy Local Information C-means Clustering Algorithm.pdf:pdf},
number = {May},
title = {{A Robust Fuzzy Local Information C-means Clustering Algorithm}},
year = {2010}
}
@inproceedings{YKK2017,
author = {Yeh, Chin-Chia Michael and Kavantzas, Nickolas and Keogh, Eamonn J},
booktitle = {Proceedings of the International Conference on Data Mining (ICDM)},
pages = {565--574},
title = {{Matrix Profile {\{}VI:{\}} Meaningful Multidimensional Motif Discovery}},
year = {2017}
}
@article{Rolnick2019,
abstract = {Climate change is one of the greatest challenges facing humanity, and we, as machine learning experts, may wonder how we can help. Here we describe how machine learning can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by machine learning, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the machine learning community to join the global effort against climate change.},
archivePrefix = {arXiv},
arxivId = {1906.05433},
author = {Rolnick, David and Donti, Priya L. and Kaack, Lynn H. and Kochanski, Kelly and Lacoste, Alexandre and Sankaran, Kris and Ross, Andrew Slavin and Milojevic-Dupont, Nikola and Jaques, Natasha and Waldman-Brown, Anna and Luccioni, Alexandra and Maharaj, Tegan and Sherwin, Evan D. and Mukkavilli, S. Karthik and Kording, Konrad P. and Gomes, Carla and Ng, Andrew Y. and Hassabis, Demis and Platt, John C. and Creutzig, Felix and Chayes, Jennifer and Bengio, Yoshua},
eprint = {1906.05433},
file = {:home/mondal/Downloads/1906.05433(1).pdf:pdf},
title = {{Tackling Climate Change with Machine Learning}},
url = {http://arxiv.org/abs/1906.05433},
year = {2019}
}
@article{Agarwal2013,
author = {Agarwal, Arpit and Garg, Ritu and Chaudhury, Santanu},
xxurl = {10.1109/ICDAR.2013.171},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agarwal, Garg, Chaudhury - 2013 - Greedy Search for Active Learning of OCR.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {837--841},
publisher = {Ieee},
title = {{Greedy Search for Active Learning of OCR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628736},
year = {2013}
}
@inproceedings{Uchida2017,
abstract = {Significant progress has been made with deep neural networks recently. Sharing trained models of deep neural networks has been a very important in the rapid progress of research and development of these systems. At the same time, it is necessary to protect the rights to shared trained models. To this end, we propose to use digital watermarking technology to protect intellectual property and detect intellectual property infringement in the use of trained models. First, we formulate a new problem: embedding watermarks into deep neural networks. Second, we propose a general framework for embedding a watermark in model parameters, using a parameter regularizer. Our approach does not impair the performance of networks into which a watermark is placed because the watermark is embedded while training the host network. Finally, we perform comprehensive experiments to reveal the potential of watermarking deep neural networks as the basis of this new research effort. We show that our framework can embed a watermark during the training of a deep neural network from scratch, and during fine-tuning and distilling, without impairing its performance. The embedded watermark does not disappear even after fine-tuning or parameter pruning; the watermark remains complete even after 65{\%} of parameters are pruned.},
archivePrefix = {arXiv},
arxivId = {1701.04082},
author = {Uchida, Yusuke and Nagai, Yuki and Sakazawa, Shigeyuki and Satoh, Shin'Ichi},
booktitle = {ICMR 2017 - Proceedings of the 2017 ACM International Conference on Multimedia Retrieval},
xxurl = {10.1145/3078971.3078974},
eprint = {1701.04082},
isbn = {9781450347013},
keywords = {Deep neural networks,Regularizer,Watermarking},
title = {{Embedding watermarks into deep neural networks}},
year = {2017}
}
@inproceedings{Smeaton,
author = {Smeaton, A.F. and Spitz, A.L.},
booktitle = {Proceedings of the Fourth International Conference on Document Analysis and Recognition},
xxurl = {10.1109/ICDAR.1997.620655},
isbn = {0-8186-7898-4},
keywords = {Character recognition,Computer applications,Computer interfaces,Humans,Image retrieval,Information retrieval,Knowledge representation,Natural languages,OCR,Optical character recognition software,Shape,character shape coding,classification,document image processing,document images,document texts,image classification,image coding,information retrieval,machine readable format,optical character recognition,performance,queries,relevance assessments,search terms,software performance evaluation,word tokens},
language = {English},
pages = {974--978},
publisher = {IEEE Comput. Soc},
title = {{Using character shape coding for information retrieval}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=620655},
volume = {2},
year = {1997}
}
@article{Ayyalasomayajula2018,
abstract = {Binarization of digital documents is the task of classifying each pixel in an image of the document as belonging to the background (parchment/paper) or foreground (text/ink). Historical documents are often subjected to degradations, that make the task challenging. In the current work a deep neural network architecture is proposed that combines a fully convolutional network with an unrolled primal-dual network that can be trained end-to-end to achieve state of the art binarization on four out of seven datasets. Document binarization is formulated as an energy minimization problem. A fully convolutional neural network is trained for semantic segmentation of pixels that provides labeling cost associated with each pixel. This cost estimate is refined along the edges to compensate for any over or under estimation of the foreground class using a primal-dual approach. We provide necessary overview on proximal operator that facilitates theoretical underpinning required to train a primal-dual network using a gradient descent algorithm. Numerical instabilities encountered due to the recurrent nature of primal-dual approach are handled. We provide experimental results on document binarization competition dataset along with network changes and hyperparameter tuning required for stability and performance of the network. The network when pre-trained on synthetic dataset performs better as per the competition metrics.},
archivePrefix = {arXiv},
arxivId = {1801.08694},
author = {Ayyalasomayajula, Kalyan Ram and Malmberg, Filip and Brun, Anders},
xxurl = {10.1016/j.patrec.2018.05.011},
eprint = {1801.08694},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayyalasomayajula, Malmberg, Brun - 2018 - PDNet Semantic segmentation integrated with a primal-dual network for document binarization.pdf:pdf},
isbn = {01678655 (ISSN)},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Binarization,Convolutional neural networks,Energy minimization,Primal-dual scheme,Semantic segmentation},
pages = {1--9},
publisher = {Elsevier B.V.},
title = {{PDNet: Semantic segmentation integrated with a primal-dual network for document binarization}},
url = {https://xxurl.org/10.1016/j.patrec.2018.05.011},
volume = {0},
year = {2018}
}
@article{Gorecki2014,
abstract = {Over recent years the popularity of time series has soared. Given the widespread use of modern information technology, a large number of time series may be collected. As a consequence there has been a dramatic increase in the amount of interest in querying and mining such data. A vital component in many types of time series analyses is the choice of an appropriate dissimilarity measure. Numerous measures have been proposed to date, with the most successful ones based on dynamic programming. One of such measures is longest common subsequence (LCSS). In this paper, we propose a parametrical extension of LCSS based on derivatives. In contrast to well-known measures from the literature, our approach considers the general shape of a time series rather than point-to-point function comparison. The new dissimilarity measure is used in classification with the nearest neighbor rule. In order to provide a comprehensive comparison, we conducted a set of experiments, testing effectiveness on 47 real time series. Experiments show that our method provides a higher quality of classification compared with LCSS on examined data sets.},
author = {G{\'{o}}recki, Tomasz},
xxurl = {10.1016/j.patrec.2014.03.009},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}recki - 2014 - Using derivatives in a longest common subsequence dissimilarity measure for time series classification.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Data mining,Derivative longest common subsequence,Longest common subsequence,Time series},
month = {aug},
pages = {99--105},
title = {{Using derivatives in a longest common subsequence dissimilarity measure for time series classification}},
volume = {45},
year = {2014}
}
@article{Tuarob2013,
author = {Tuarob, Suppawong and Bhatia, Sumit and Mitra, Prasenjit and Giles, C. Lee},
xxurl = {10.1109/ICDAR.2013.151},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuarob et al. - 2013 - Automatic Detection of Pseudocodes in Scholarly Documents Using Machine Learning.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {738--742},
publisher = {Ieee},
title = {{Automatic Detection of Pseudocodes in Scholarly Documents Using Machine Learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628716},
year = {2013}
}
@article{Mehri2013,
author = {Mehri, Maroua and Heroux, Pierre and Gomez-Kramer, Petra and Boucher, Alain and Mullot, Remy},
xxurl = {10.1109/ICDAR.2013.167},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehri et al. - 2013 - A Pixel Labeling Approach for Historical Digitized Books.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {autocorrelation,cluster-,consensus clustering,historical books,homogeneity,ing accuracy metrics,multires-,olution,pixel labeling,texture},
month = {aug},
pages = {817--821},
publisher = {Ieee},
title = {{A Pixel Labeling Approach for Historical Digitized Books}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628732},
year = {2013}
}
@article{Obdrzalek2005,
abstract = {Realistic approaches to large scale object recognition, i.e. for detection and localisation of hundreds or more objects, must support sub-linear time indexing. In the paper, we propose a method capable of recognising one of N objects in log(N) time. The ”visual memory” is organised as a binary decision tree that is built to minimise average time to decision. Leaves of the tree represent a few local image areas, and each non-terminal node is associated with a 'weak classiﬁer'. In the recognition phase, a single invariant measurement decides in which subtree a corresponding image area is sought. The method preserves all the strengths of local afﬁne region methods –robustness to background clutter, occlusion, and large changes of viewpoints. Experimentally we show that it supports near real-time recognition of hundreds of objects with state-of-the-art recognition rates. After the test image is processed (in a second on a current PCs), the recognition via indexing into the visual memory requires milliseconds.},
author = {Obdrzalek, Stepan and Matas, Jiri},
xxurl = {10.5244/C.19.3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Obdrzalek, Matas - 2005 - Sub-linear Indexing for Large Scale Object Recognition.pdf:pdf},
isbn = {1-901725-29-4},
journal = {British Machine Vision Conferece},
pages = {1--10},
title = {{Sub-linear Indexing for Large Scale Object Recognition.}},
url = {http://www.cs.utexas.edu/{~}grauman/courses/spring2007/395T/papers/obdrzalek-tree-bmvc05.pdf},
year = {2005}
}
@article{Seki2013a,
author = {Seki, Minenobu and Asano, Eisuke and Yasue, Tsukasa and Nagayoshi, Hiroto and Shinjo, Hiroshi and Nagasaki, Takeshi},
xxurl = {10.1109/ICDAR.2013.32},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seki et al. - 2013 - Color Drop-Out Binarization Method for Document Images with Color Shift.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {a color shift,advance,binarization,color shift,colors that are not,determined in,even if there is,form,is proposed,morphology,with several formats and},
month = {aug},
pages = {123--127},
publisher = {Ieee},
title = {{Color Drop-Out Binarization Method for Document Images with Color Shift}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628597},
year = {2013}
}
@article{Doersch2016,
abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, in-cluding handwritten digits [1, 2], faces [1, 3, 4], house numbers [5, 6], CIFAR images [6], physical models of scenes [4], segmentation [7], and predicting the future from static images [8]. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
author = {Doersch, Carl},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doersch - 2016 - Tutorial on Variational Autoencoders.pdf:pdf},
keywords = {neural networks,structured prediction,unsupervised learning,variational autoencoders},
title = {{Tutorial on Variational Autoencoders}},
year = {2016}
}
@article{Lipton2015,
abstract = {Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translat-ing natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connec-tionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have tradition-ally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and paral-lel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research.},
archivePrefix = {arXiv},
arxivId = {1506.00019v2},
author = {Lipton, Zachary Chase},
xxurl = {10.1145/2647868.2654889},
eprint = {1506.00019v2},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lipton - 2015 - A Critical Review of Recurrent Neural Networks for Sequence Learning.pdf:pdf},
isbn = {9781450330633},
issn = {9781450330633},
journal = {CoRR},
pages = {1--38},
pmid = {18267787},
title = {{A Critical Review of Recurrent Neural Networks for Sequence Learning}},
url = {http://arxiv.org/abs/1506.00019},
volume = {abs/1506.0},
year = {2015}
}
@article{R.Manmathaa,
author = {{R. Manmatha}, W. B. Croft},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/R. Manmatha - Unknown - Word Spotting Indexing Handwritten Archives.pdf:pdf},
title = {{Word Spotting: Indexing Handwritten Archives}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.48.9433}
}
@article{Karami2015,
abstract = {-Fast and robust image matching is a very important task with various applications in computer vision and robotics. In this paper, we compare the performance of three different image matching techniques, i.e., SIFT, SURF, and ORB, against different kinds of transformations and deformations such as scaling, rotation, noise, fish eye distortion, and shearing. For this purpose, we manually apply different types of transformations on original images and compute the matching evaluation parameters such as the number of key points in images, the matching rate, and the execution time required for each algorithm and we will show that which algorithm is the best more robust against each kind of distortion.},
archivePrefix = {arXiv},
arxivId = {1710.02726},
author = {Karami, Ebrahim and Prasad, Siva and Shehata, Mohamed},
xxurl = {10.13140/RG.2.1.1558.3762},
eprint = {1710.02726},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karami, Prasad, Shehata - 2015 - Image Matching Using SIFT, SURF, BRIEF and ORB Performance Comparison for Distorted Images.pdf:pdf},
journal = {Newfoundland Electrical and Computer Engineering Conference},
title = {{Image Matching Using SIFT, SURF, BRIEF and ORB: Performance Comparison for Distorted Images}},
url = {https://www.researchgate.net/publication/290436456{\_}Image{\_}Identification{\_}Using{\_}SIFT{\_}Algorithm{\_}Performance{\_}Analysis{\_}against{\_}Different{\_}Image{\_}Deformations},
year = {2015}
}
@article{Peng2013,
author = {Peng, Xujun and Cao, Huaigu and Subramanian, Krishna and Prasad, Rohit and Natarajan, Prem},
xxurl = {10.1109/ICDAR.2013.207},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng et al. - 2013 - Exploiting Stroke Orientation for CRF Based Binarization of Historical Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1034--1038},
publisher = {Ieee},
title = {{Exploiting Stroke Orientation for CRF Based Binarization of Historical Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628772},
year = {2013}
}
@article{Dinh2014,
abstract = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
archivePrefix = {arXiv},
arxivId = {1410.8516},
author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
xxurl = {1410.8516},
eprint = {1410.8516},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Krueger, Bengio - 2014 - NICE Non-linear Independent Components Estimation.pdf:pdf},
isbn = {1410.8516},
issn = {1410.8516},
number = {2},
pages = {1--13},
title = {{NICE: Non-linear Independent Components Estimation}},
url = {http://arxiv.org/abs/1410.8516},
volume = {1},
year = {2014}
}
@inproceedings{Jagadish,
author = {Jagadish, H.V. and Faloutsos, C.},
booktitle = {ICDE},
keywords = {Acceleration,Application software,Computer science,Databases,Discrete Fourier transforms,Educational institutions,Euclidean distance,FastMap,Indexing,Pattern matching,Speech recognition,Testing,decelerations,dissimilarity metric,fast linear test,fast similarity searching,field tested dissimilarity metric,indexing viewpoint,large time sequence databases,local accelerations,query processing,sequence length,sequential scanning,signal processing,similar time sequence retrieval,synthetic datasets,temporal databases,time warping},
language = {English},
pages = {201--208},
publisher = {IEEE Comput. Soc},
title = {{Efficient retrieval of similar time sequences under time warping}},
year = {1998}
}
@article{Hao2013,
author = {Hao, Shudong and Gao, Zongtian and Zhang, Mingqing and Xu, Yanyan and Peng, Hengli and Su, Kaile and Ke, Dengfeng},
xxurl = {10.1109/ICDAR.2013.156},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hao et al. - 2013 - Automated Error Detection and Correction of Chinese Characters in Written Essays Based on Weighted Finite-State Tran.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {error correction,error detection,n-gram language model,transducer,weighted finite-state,wfst},
month = {aug},
pages = {763--767},
publisher = {Ieee},
title = {{Automated Error Detection and Correction of Chinese Characters in Written Essays Based on Weighted Finite-State Transducer}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628721},
year = {2013}
}
@article{Philbin2010,
author = {Philbin, James and Isard, Michael and Sivic, Josef and Zisserman, Andrew},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Philbin et al. - 2010 - Descriptor Learning for Eﬃcient Retrieval.pdf:pdf},
journal = {Eccv},
pages = {677--691},
title = {{Descriptor Learning for Eﬃcient Retrieval}},
year = {2010}
}
@article{Wan2005,
author = {Wan, Vincent and Carmichael, James},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wan, Carmichael - 2005 - Polynomial dynamic time warping kernel support vector machines for dysarthric speech recognition with sparse tr.pdf:pdf},
journal = {Interspeech},
pages = {3321--3324},
title = {{Polynomial dynamic time warping kernel support vector machines for dysarthric speech recognition with sparse training data.}},
url = {http://www.researchgate.net/publication/221478420{\_}Polynomial{\_}dynamic{\_}time{\_}warping{\_}kernel{\_}support{\_}vector{\_}machines{\_}for{\_}dysarthric{\_}speech{\_}recognition{\_}with{\_}sparse{\_}training{\_}data/file/79e4150b7256b621ac.pdf},
year = {2005}
}
@article{Zinke2006,
abstract = {$\backslash$nDynamic Time Warping (DTW) is a frequently used technique for the optimal alignment of sequences with respect$\backslash$nto given constraints. The main disadvantage of DTW are both its$\backslash$ntime and memory complexity. We present a novel iterative scheme$\backslash$nwhich can significantly improve the DTW performance with respect$\backslash$nto computation time and memory requirements in case of very large$\backslash$nsequences. In contrast to previous iterative approaches which were$\backslash$ndesigned for clustering time series with respect to shape, our$\backslash$nmethod is suitable for precise alignments for a wide range of$\backslash$ndifferent features and similarity measures.},
author = {Mayer, Dessislava and Zinke, A},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mayer, Zinke, Mayer - 2006 - Iterative Multi Scale Dynamic Time Warping.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mayer, Zinke - 2006 - Iterative multi scale dynamic time warping.pdf:pdf},
journal = {Universit{\"{a}}t Bonn, CG-2006/1},
keywords = {dynamic time warping,multi scale dtw},
title = {{Iterative multi scale dynamic time warping}},
year = {2006}
}
@article{Mondal2013a,
annote = {From Duplicate 1 ( 







A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing







- Mondal, Tanmoy; Ragot, Nicolas; Ramel, Jean-Yves; Pal, Umapada )



},
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean-Yves and Pal, Umapada},
xxurl = {10.1109/ICDAR.2013.242},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2013 - A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2013 - A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing(2).pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {fast word spotting,gabor kernel,gabor wavelet,hashing,kernelised loaclity sensitive hashing,kernelized locality sensitive,klsh,word,word recognition,word spotting},
month = {aug},
pages = {1195--1199},
publisher = {Ieee},
title = {{A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing}},
year = {2013}
}
@techreport{RathT.andManmatha,
author = {Rath, Toni M. and Manmatha, R.},
booktitle = {Tech Report MM-40, University of Massachusetts Amherst.},
title = {{Lower-Bounding of Dynamic Time Warping Distances for Multivariate Time}},
url = {http://works.bepress.com/r{\_}manmatha/19/},
year = {2002}
}
@article{Al-Naymat2009,
abstract = {We present a new space-efficient approach, (SparseDTW), to compute the Dynamic Time Warping (DTW) distance between two time series that always yields the optimal result. This is in contrast to other known approaches which typically sacrifice optimality to attain space efficiency. The main idea behind our approach is to dynamically exploit the existence of similarity and/or correlation between the time series. The more the similarity between the time series the less space required to compute the DTW between them. To the best of our knowledge, all other techniques to speedup DTW, impose apriori constraints and do not exploit similarity characteristics that may be present in the data. We conduct experiments and demonstrate that SparseDTW outperforms previous approaches.},
archivePrefix = {arXiv},
arxivId = {1201.2969},
author = {Al-Naymat, Ghazi and Chawla, Sanjay and Taheri, Javid},
eprint = {1201.2969},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Naymat, Chawla, Taheri - 2009 - SparseDTW A novel approach to speed up dynamic time warping.pdf:pdf},
isbn = {9781920682828},
issn = {14451336},
journal = {Conferences in Research and Practice in Information Technology Series},
keywords = {Data mining,Dynamic time warping,Similarity measures,Time series},
number = {2007},
pages = {117--127},
title = {{SparseDTW: A novel approach to speed up dynamic time warping}},
volume = {101},
year = {2009}
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
xxurl = {10.1038/nature14539},
eprint = {arXiv:1312.6184v5},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeCun, Bengio, Hinton - 2015 - Deep learning.pdf:pdf},
isbn = {9780521835688},
issn = {0028-0836},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {10463930},
title = {{Deep learning}},
url = {http://dx.xxurl.org/10.1038/nature14539},
volume = {521},
year = {2015}
}
@article{Zhang2013b,
author = {Zhang, Xin and Lin, Zhouchen and Sun, Fuchun and Ma, Yi},
xxurl = {10.1109/ICDAR.2013.86},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2013 - Rectification of Optical Characters as Transform Invariant Low-Rank Textures.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {393--397},
publisher = {Ieee},
title = {{Rectification of Optical Characters as Transform Invariant Low-Rank Textures}},
year = {2013}
}
@inproceedings{YZUB+2016,
author = {Yeh, Chin-Chia Michael and Zhu, Yan and Ulanova, Liudmila and Begum, Nurjahan and Ding, Yifei and Dau, Hoang Anh and Silva, Diego Furtado and Mueen, Abdullah and Keogh, Eamonn J},
booktitle = {Proceedings of the International Conference on Data Mining (ICDM)},
pages = {1317--1322},
title = {{Matrix Profile {\{}I:{\}} All Pairs Similarity Joins for Time Series: {\{}A{\}} Unifying View That Includes Motifs, Discords and Shapelets}},
year = {2016}
}
@inproceedings{Wang2002,
author = {Wang, Xuewen and Ding, Xiaoqing and Liu, Changsong},
booktitle = {Object recognition supported by user interaction for service robots},
xxurl = {10.1109/ICPR.2002.1047437},
isbn = {0-7695-1695-X},
issn = {1051-4651},
keywords = {Character recognition,Chinese character images,Chinese character recognition,Design methodology,Feature extraction,Gabor filters,Histograms,Image recognition,Image sampling,Intelligent systems,Laboratories,Nonlinear distortion,backgrounds,binary images,character recognition,feature extraction,feature extraction method,filtering theory,greyscale images,handwritten character recognition,noise,noises,nonlinear function,optical character recognition,optimisation,optimized Gabor filter based feature extraction,printed character recognition,statistical information,stroke distortions},
language = {English},
pages = {223--226},
publisher = {IEEE Comput. Soc},
title = {{Optimized Gabor filter based feature extraction for character recognition}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1047437},
volume = {4},
year = {2002}
}
@article{Do2013,
author = {Do, Thanh Ha and Tabbone, Salvatore and Terrades, Oriol Ramos},
xxurl = {10.1109/ICDAR.2013.60},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Do, Tabbone, Terrades - 2013 - New Approach for Symbol Recognition Combining Shape Context of Interest Points with Sparse Representation.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {265--269},
publisher = {Ieee},
title = {{New Approach for Symbol Recognition Combining Shape Context of Interest Points with Sparse Representation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628625},
year = {2013}
}
@article{Hesson2008a,
author = {Hesson, Ali and Androutsos, Dimitrios},
xxurl = {10.1117/12.785076},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hesson, Androutsos - 2008 - Logo detection using wavelet co-occurrence histograms.pdf:pdf},
number = {July},
pages = {682006--682006--11},
title = {{Logo detection using wavelet co-occurrence histograms}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=812781},
year = {2008}
}
@phdthesis{Borgwardt.2007,
author = {Borgwardt., Karsten M.},
school = {udwig-Maximilians- University},
title = {{Graph Kernels}},
year = {2007}
}
@article{Liu2013,
author = {Liu, Li and Lu, Yue and Suen, Ching Y. and Xu, Jinhua},
xxurl = {10.1109/ICDAR.2013.54},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2013 - Modeling Local Word Spatial Configurations for Near Duplicate Document Image Retrieval.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {235--239},
publisher = {Ieee},
title = {{Modeling Local Word Spatial Configurations for Near Duplicate Document Image Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628619},
year = {2013}
}
@article{Puri2013,
author = {Puri, Mukta and Srihari, Sargur N. and Tang, Yi},
xxurl = {10.1109/ICDAR.2013.267},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puri, Srihari, Tang - 2013 - Bayesian Network Structure Learning and Inference Methods for Handwriting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-bayesian networks,forensics,full multivariate multinomial,is a multinomial,needed to characterize the,probabilistic formulation each characteristic,probabilities,random variable,structure learning,the number of parameters},
month = {aug},
pages = {1320--1324},
publisher = {Ieee},
title = {{Bayesian Network Structure Learning and Inference Methods for Handwriting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628828},
year = {2013}
}
@article{Xia2012a,
address = {New York, New York, USA},
author = {Xia, Hao and Wu, Pengcheng and Hoi, Steven C.H. and Jin, Rong},
xxurl = {10.1145/2348283.2348294},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia et al. - 2012 - Boosting multi-kernel locality-sensitive hashing for scalable image retrieval.pdf:pdf},
isbn = {9781450314725},
journal = {Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval - SIGIR '12},
keywords = {high-dimensional indexing,image retrieval,locality-sensitive hash-},
pages = {55},
publisher = {ACM Press},
title = {{Boosting multi-kernel locality-sensitive hashing for scalable image retrieval}},
url = {http://dl.acm.org/citation.cfm?xxurld=2348283.2348294},
year = {2012}
}
@article{Cai,
author = {Cai, Weiling and Zhang, Daoqiang},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Zhang - Unknown - Fast and Robust Fuzzy C-Means Clustering Algorithms Incorporating Local Information for Image Segmentation.pdf:pdf},
pages = {1--27},
title = {{Fast and Robust Fuzzy C-Means Clustering Algorithms Incorporating Local Information for Image Segmentation}},
volume = {2}
}
@article{Mondal2013,
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean-Yves and Pal, Umapada},
xxurl = {10.1109/ICDAR.2013.242},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2013 - A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {gabor kernel,gabor wavelet,kernelised loaclity sensitive hashing,word,word recognition,word spotting},
month = {aug},
pages = {1195--1199},
publisher = {Ieee},
title = {{A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628803},
year = {2013}
}
@article{Siriteerakul2013,
author = {Siriteerakul, Teera},
xxurl = {10.1109/ICDAR.2013.173},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siriteerakul - 2013 - Mixed Thai-English Character Classification Based on Histogram of Oriented Gradient Feature.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-character classification,histogram of,thai ocr},
month = {aug},
pages = {847--851},
publisher = {Ieee},
title = {{Mixed Thai-English Character Classification Based on Histogram of Oriented Gradient Feature}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628738},
year = {2013}
}
@article{Su2013b,
author = {Su, Feng and Lu, Tong},
xxurl = {10.1109/ICDAR.2013.217},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su, Lu - 2013 - Discriminative Weighting and Subspace Learning for Ensemble Symbol Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1088--1092},
publisher = {Ieee},
title = {{Discriminative Weighting and Subspace Learning for Ensemble Symbol Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628782},
year = {2013}
}
@inproceedings{Pastor-Pellicer2015,
abstract = {Convolutional Neural Networks have systematically shown good performance in Computer Vision and in Handwritten Text Recog-nition tasks. This paper proposes the use of these models for docu-ment image binarization. The main idea is to classify each pixel of the image into foreground and background from a sliding window centered at the pixel to be classified. An experimental analysis on the effect of sensitive parameters and some working topologies are proposed using two different corpora, of very different properties: DIBCO and Santgall.},
author = {Pastor-Pellicer, J. and Espa{\~{n}}a-Boquera, S. and Zamora-Mart{\'{i}}nez, F. and {Zeshan Afzal}, M. and Castro-Bleda, Maria Jose and Afzal, M. Zeshan and Castro-Bleda, Maria Jose and {Zeshan Afzal}, M. and Castro-Bleda, Maria Jose},
booktitle = {Lecture Notes in Computer Science},
xxurl = {10.1007/978-3-319-19222-2_10},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pastor-Pellicer et al. - 2015 - Insights on the use of convolutional neural networks for document image binarization.pdf:pdf},
isbn = {9783319192215},
issn = {16113349},
pages = {115--126},
publisher = {Springer},
title = {{Insights on the Use of Convolutional Neural Networks for Document Image Binarization}},
volume = {9095},
year = {2015}
}
@article{Kumar2013a,
author = {Kumar, Jayant and Doermann, David},
xxurl = {10.1109/ICDAR.2013.248},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Doermann - 2013 - Unsupervised Classification of Structurally Similar Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1225--1229},
publisher = {Ieee},
title = {{Unsupervised Classification of Structurally Similar Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628809},
year = {2013}
}
@article{Fiel2013b,
author = {Fiel, Stefan and Sablatnig, Robert},
xxurl = {10.1109/ICDAR.2013.114},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fiel, Sablatnig - 2013 - Writer Identification and Writer Retrieval Using the Fisher Vector on Visual Vocabularies.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {545--549},
publisher = {Ieee},
title = {{Writer Identification and Writer Retrieval Using the Fisher Vector on Visual Vocabularies}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628679},
year = {2013}
}
@article{Agazzi1994,
abstract = {An algorithm for robust machine recognition of keywords embedded in a poorly printed document is presented. For each keyword, two statistical models, called pseudo 2-D hidden Markov models, are created for representing the actual keyword and all the other extraneous words, respectively. Dynamic programming is then used for matching an unknown input word with the two models and for making a maximum likelihood decision. Although the models are pseudo 2-D in the sense that they are not fully connected 2-D networks, they are shown to be general enough in characterizing printed words efficiently. These models facilitate a nice {\&}ldquo;elastic matching{\&}rdquo; property in both horizontal and vertical directions, which makes the recognizer not only independent of size and slant but also tolerant of highly deformed and noisy words. The system is evaluated on a synthetically created database that contains about 26000 words. Currently, the authors achieve a recognition accuracy of 99{\%} when words in testing and training sets are of the same font size, and 96{\%} when they are in different sizes. In the latter case, the conventional 1-D HMM achieves only a 70{\%} accuracy rate},
author = {Agazzi, O.E. and Kuo, Shyh-Shiaw Kuo Shyh-Shiaw},
issn = {01628828},
journal = {TPAMI},
keywords = {corner{\_}flow{\_}regularization},
language = {English},
mendeley-tags = {corner{\_}flow{\_}regularization},
number = {8},
pages = {842--848},
publisher = {IEEE},
title = {{Keyword spotting in poorly printed documents using pseudo 2-D hidden Markov models}},
volume = {16},
year = {1994}
}
@article{Dinformatique2001,
author = {D'informatique, De and Ese, N and Esent, P and Au, E},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D'informatique et al. - 2001 - Long Short-Term Memory in Recurrent Neural Networks.pdf:pdf},
journal = {Ukpmc.Ac.Uk},
pages = {94},
title = {{Long Short-Term Memory in Recurrent Neural Networks}},
url = {http://ukpmc.ac.uk/abstract/CIT/442484},
volume = {2366},
year = {2001}
}
@article{Cai2007,
author = {Cai, Weiling and Chen, Songcan and Zhang, Daoqiang},
xxurl = {10.1016/j.patcog.2006.07.011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Chen, Zhang - 2007 - Fast and robust fuzzy c -means clustering algorithms incorporating local information for image segmentation.pdf:pdf},
keywords = {clustering,enhanced fuzzy c -means,fcm,fuzzy c -means clustering,gray constraints,image segmentation,robustness,spatial constraints},
pages = {825--838},
title = {{Fast and robust fuzzy c -means clustering algorithms incorporating local information for image segmentation}},
volume = {40},
year = {2007}
}
@inproceedings{Roy12013,
abstract = {In this paper, we present a solution towards building a retrieval system over handwritten document images that i) is recognition-free, ii) allows text-querying, iii) can retrieve at sub-word level, iv) can search for out-of-vocabulary words. Unlike previous approaches that operate at either character or word levels, we use character n-gram images (CNG-img) as the retrieval primitive. CNG-img are sequences of character segments, that are represented and matched in the image-space. The word-images are now treated as a bag-of-CNG-img, that can be indexed and matched in the feature space. This allows for recognition-free search (query-by-example), which can retrieve morphologically similar words that have matching sub-words. Further, to enable query-by-keyword, we build an automated scheme to generate labeled exemplars for characters and character n-grams, from unconstrained handwritten documents. We pose this problem as one of weakly-supervised learning, where character/n-gram labeling is obtained automatically from the word labels. The resulting retrieval system can answer queries from an unlimited. vocabulary. The approach is demonstrated on the George Washington collection, results show major improvement in retrieval performance as compared to word-recognition and word-spotting methods.},
author = {Roy, Udit and Sankaran, Naveen and Sankar, K. Pramod and Jawahar, C.V.},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy et al. - 2013 - Character N-Gram Spotting on Handwritten Documents Using Weakly-Supervised Segmentation.pdf:pdf},
keywords = {CNG-img retrieval primitive,Character recognition,George Washington collection,Handwriting recognition,Hidden Markov models,Image segmentation,Indexes,Labeling,Training,character N-gram spotting,handwritten character recognition,handwritten document image,handwritten documents,image matching,image representation,image retrieval,image retrieval system,image-space matching,image-space representation,out-of-vocabulary words,query-by-example,query-by-keyword,recognition-free system,sub-word level retrieval,text-querying,weakly-supervised segmentation,word-recognition method,word-spotting method},
month = {aug},
pages = {577--581},
publisher = {IEEE},
shorttitle = {Document Analysis and Recognition (ICDAR), 2013 12},
title = {{Character N-Gram Spotting on Handwritten Documents Using Weakly-Supervised Segmentation}},
year = {2013}
}
@article{Li2018,
abstract = {In this work, we describe a new deep learning based method that can effectively distinguish AI-generated fake videos (referred to as {\{}$\backslash$em DeepFake{\}} videos hereafter) from real videos. Our method is based on the observations that current DeepFake algorithm can only generate images of limited resolutions, which need to be further warped to match the original faces in the source video. Such transforms leave distinctive artifacts in the resulting DeepFake videos, and we show that they can be effectively captured by convolutional neural networks (CNNs). Compared to previous methods which use a large amount of real and DeepFake generated images to train CNN classifier, our method does not need DeepFake generated images as negative training examples since we target the artifacts in affine face warping as the distinctive feature to distinguish real and fake images. The advantages of our method are two-fold: (1) Such artifacts can be simulated directly using simple image processing operations on a image to make it as negative example. Since training a DeepFake model to generate negative examples is time-consuming and resource-demanding, our method saves a plenty of time and resources in training data collection; (2) Since such artifacts are general existed in DeepFake videos from different sources, our method is more robust compared to others. Our method is evaluated on two sets of DeepFake video datasets for its effectiveness in practice.},
archivePrefix = {arXiv},
arxivId = {1811.00656},
author = {Li, Yuezun and Lyu, Siwei},
eprint = {1811.00656},
file = {:home/mondal/Downloads/Li{\_}Exposing{\_}DeepFake{\_}Videos{\_}By{\_}Detecting{\_}Face{\_}Warping{\_}Artifacts{\_}CVPRW{\_}2019{\_}paper.pdf:pdf},
title = {{Exposing DeepFake Videos By Detecting Face Warping Artifacts}},
url = {http://arxiv.org/abs/1811.00656},
year = {2018}
}
@article{Yeh2017,
abstract = {—Time series motifs are approximately repeating patterns in real-valued time series data. They are useful for exploratory data mining and are often used as inputs for various time series clustering, classification, segmentation, rule discovery, and visualization algorithms. Since the introduction of the first motif discovery algorithm for univariate time series in 2002, multiple efforts have been made to generalize motifs to the multidimensional case. In this work, we show that these efforts, which typically attempt to find motifs on all dimensions, will not produce meaningful motifs except in the most contrived situations. We explain this finding and introduce mSTAMP, an algorithm that allows meaningful discovery of multidimensional motifs. Beyond producing objectively and subjectively meaningful results, our algorithm has a host of additional advantages, including being much faster, requiring fewer parameters and supporting streaming data. We demonstrate the utility of our mSTAMP-based motif discovery framework on domains as diverse as audio processing, industry, and sports analytics.},
author = {Yeh, Chin-Chia Michael and Kavantzas, Nickolas and Keogh, Eamonn},
xxurl = {10.1109/ICDM.2017.66},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh, Kavantzas, Keogh - 2017 - Matrix Profile VI Meaningful Multidimensional Motif Discovery.pdf:pdf},
isbn = {978-1-5386-3835-4},
issn = {15504786},
journal = {2017 IEEE International Conference on Data Mining (ICDM)},
keywords = {behaviors are almost identical,however,if we focus solely,if we look that,limbs,motif discovery,multidimensional data,on all of the,on the boxer,s dominant hand,set of mo-cap markers,the differences in the,the full,the two,time series},
pages = {565--574},
title = {{Matrix Profile VI: Meaningful Multidimensional Motif Discovery}},
url = {http://ieeexplore.ieee.org/document/8215529/},
year = {2017}
}
@article{Latecki2007,
author = {Latecki, Longin Jan and Wang, Qiang and Koknar-Tezel, Suzan and Megalooikonomou, Vasileios},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Latecki et al. - 2007 - Optimal Subsequence Bijection.pdf:pdf},
isbn = {0-7695-3018-4},
journal = {ICDM},
month = {oct},
pages = {565--570},
publisher = {Ieee},
title = {{Optimal Subsequence Bijection}},
year = {2007}
}
@article{Gunter2005,
abstract = {Unconstrained handwritten text recognition is one of the most difficult problems in the field of pattern recognition. Recently, a number of classifier creation and combination methods, known as ensemble methods, have been proposed in the field of machine learning. They have shown improved recognition performance over single classifiers. In this paper, we examine the influence of the vocabulary size, the number of training samples, and the number of classifiers on the performance of three ensemble methods in the context of cursive handwriting recognition. All experiments were conducted using an off-line handwritten word recognizer based on hidden Markov models (HMMs).},
author = {G{\"{u}}nter, Simon and Bunke, Horst},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}nter, Bunke - 2005 - Off-line cursive handwriting recognition using multiple classifier systems on the influence of vocabulary, ensem.pdf:pdf},
issn = {01438166},
journal = {Optics and Lasers in Engineering},
month = {mar},
number = {3-5},
pages = {437--454},
title = {{Off-line cursive handwriting recognition using multiple classifier systems on the influence of vocabulary, ensemble, and training set size}},
volume = {43},
year = {2005}
}
@article{Rossler2020,
abstract = {The rapid progress in synthetic image generation and manipulation has now come to a point where it raises significant concerns for the implications towards society. At best, this leads to a loss of trust in digital content, but could potentially cause further harm by spreading false information or fake news. This paper examines the realism of state-of-the-art image manipulations, and how difficult it is to detect them, either automatically or by humans. To standardize the evaluation of detection methods, we propose an automated benchmark for facial manipulation detection. In particular, the benchmark is based on DeepFakes, Face2Face, FaceSwap and NeuralTextures as prominent representatives for facial manipulations at random compression level and size. The benchmark is publicly available and contains a hidden test set as well as a database of over 1.8 million manipulated images. This dataset is over an order of magnitude larger than comparable, publicly available, forgery datasets. Based on this data, we performed a thorough analysis of data-driven forgery detectors. We show that the use of additional domainspecific knowledge improves forgery detection to unprecedented accuracy, even in the presence of strong compression, and clearly outperforms human observers.},
archivePrefix = {arXiv},
arxivId = {1901.08971},
author = {Rossler, Andreas and Cozzolino, Davide and Verdoliva, Luisa and Riess, Christian and Thies, Justus and Niessner, Matthias},
xxurl = {10.1109/iccv.2019.00009},
eprint = {1901.08971},
file = {:home/mondal/Downloads/1901.08971v3.pdf:pdf},
pages = {1--11},
title = {{FaceForensics++: Learning to Detect Manipulated Facial Images}},
year = {2020}
}
@article{Gobel2013,
author = {Gobel, Max and Hassan, Tamir and Oro, Ermelinda and Orsi, Giorgio},
xxurl = {10.1109/ICDAR.2013.292},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gobel et al. - 2013 - ICDAR 2013 Table Competition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1449--1453},
publisher = {Ieee},
title = {{ICDAR 2013 Table Competition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628853},
year = {2013}
}
@article{StamatopoulosBorder,
annote = {From Duplicate 1 ( 

Automatic borders detection of camera document images

- Stamatopoulos, N )

},
author = {Stamatopoulos, N},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stamatopoulos - 2007 - Automatic borders detection of camera document images.pdf:pdf},
journal = {CBDAR},
pages = {71--78},
title = {{Automatic borders detection of camera document images}},
year = {2007}
}
@inproceedings{Tarafdar2010,
abstract = {In the current scenario retrieving information from document images is a challenging problem. In this paper we propose a shape code based word-image matching (word-spotting) technique for retrieval of multilingual documents written in Indian languages. Here, each query word image to be searched is represented by a primitive shape code using (i) zonal information of extreme points (ii) vertical shape based feature (iii) crossing count (with respect to vertical bar position) (iv) loop shape and position (v) background information etc. Each candidate word (a word having similar aspect ratio and topological feature to the query word) of the document is also coded accordingly. Then, an inexact string matching technique is used to measure the similarity between the primitive codes generated from the query word image and each candidate word of the document with which the query image is to be searched. Based on the similarity score, we retrieve the document where the query image is found. Experimental results on Bangla, Devnagari and Gurumukhi scripts document image databases confirm the feasibility and efficiency of our proposed approach.},
author = {Tarafdar, Arundhati and Mondal, Ranju and Pal, Srikanta and Pal, Umapada and Kimura, Fumitaka},
booktitle = {ICPR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarafdar et al. - 2010 - Shape Code Based Word-Image Matching for Retrieval of Indian Multi-lingual Documents.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarafdar et al. - 2010 - Shape Code Based Word-Image Matching for Retrieval of Indian Multi-lingual Documents(2).pdf:pdf},
keywords = {Computer vision,Document image processing,Document image retrieval,Encoding,Feature extraction,Image coding,Image segmentation,Indian multilingual documents,Indian script document image,Pattern recognition,Shape,Shape code,Word spotting,background information,crossing count,document image retrieval,image matching,image retrieval,inexact string matching technique,loop position,loop shape,query word image,shape code,shape code based word-image matching,string matching,vertical shape based feature,word spotting,word-spotting technique,zonal information},
language = {English},
month = {aug},
pages = {1989--1992},
publisher = {IEEE},
title = {{Shape Code Based Word-Image Matching for Retrieval of Indian Multi-lingual Documents}},
year = {2010}
}
@article{Goodfellow,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {arXiv:1406.2661v1},
author = {Goodfellow, Ij and Pouget-Abadie, Jean and Mirza, Mehdi},
xxurl = {10.1017/CBO9781139058452},
eprint = {arXiv:1406.2661v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow, Pouget-Abadie, Mirza - 2014 - Generative Adversarial Networks.pdf:pdf},
isbn = {1406.2661},
issn = {10495258},
journal = {arXiv preprint arXiv: {\ldots}},
pages = {1--9},
pmid = {1000183096},
title = {{Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1406.2661},
year = {2014}
}
@article{Liang2005,
abstract = { Compared to scanned images, document pictures captured by camera can suffer from distortions due to perspective and page warping. It is necessary to restore a frontal planar view of the page before other OCR techniques can be applied. In this paper we describe a novel approach for flattening a curved document in a single picture captured by an uncalibrated camera. To our knowledge this is the first reported method able to process general curved documents in images without camera calibration. We propose to model the page surface by a developable surface, and exploit the properties (parallelism and equal line spacing) of the printed textual content on the page to recover the surface shape. Experiments show that the output images are much more OCR friendly than the original ones. While our method is designed to work with any general developable surfaces, it can be adapted for typical special cases including planar pages, scans of thick books, and opened books.},
author = {Liang, Jian and DeMenthon, Daniel and Doermann, David},
xxurl = {10.1109/CVPR.2005.163},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, DeMenthon, Doermann - 2005 - Flattening curved documents in images.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, DeMenthon, Doermann - 2005 - Flattening curved documents in images(2).pdf:pdf},
isbn = {0769523722},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {338--345},
title = {{Flattening curved documents in images}},
volume = {2},
year = {2005}
}
@article{Perronnin2009,
author = {Perronnin, Florent and Rodriguez-Serrano, Jose a.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perronnin, Rodriguez-Serrano - 2009 - Fisher Kernels for Handwritten Word-spotting.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {ICDAR},
keywords = {a match is declared,approaches,character,hypothesis,identified,if the score of,in query-by-string,keyword model exceeds a,qbs,the,threshold,two main types of,word image on the,word-spotting approaches can be},
pages = {106--110},
publisher = {Ieee},
title = {{Fisher Kernels for Handwritten Word-spotting}},
year = {2009}
}
@article{Kesidis2011,
annote = {From Duplicate 1 ( 







Efficient Cut-Off Threshold Estimation for Word Spotting Applications







- Kesidis, a. L.; Gatos, B. )



},
author = {Kesidis, a. L. and Gatos, B.},
xxurl = {10.1109/ICDAR.2011.64},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kesidis, Gatos - 2011 - Efficient Cut-Off Threshold Estimation for Word Spotting Applications.pdf:pdf},
isbn = {978-1-4577-1350-7},
journal = {2011 International Conference on Document Analysis and Recognition},
keywords = {cut-off threshold,document,word spotting},
month = {sep},
pages = {279--283},
publisher = {Ieee},
title = {{Efficient Cut-Off Threshold Estimation for Word Spotting Applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065319},
year = {2011}
}
@article{Muja2014,
abstract = {For many computer vision and machine learning problems, large training sets are key for good performance. However, the most computationally expensive part of many computer vision and machine learning algorithms consists of finding nearest neighbor matches to high dimensional vectors that represent the training data. We propose new algorithms for approximate nearest neighbor matching and evaluate and compare them with previous algorithms. For matching high dimensional features, we find two algorithms to be the most efficient: the randomized k-d forest and a new algorithm proposed in this paper, the priority search k-means tree. We also propose a new algorithm for matching binary features by searching multiple hierarchical clustering trees and show it outperforms methods typically used in the literature. We show that the optimal nearest neighbor algorithm and its parameters depend on the data set characteristics and describe an automated configuration procedure for finding the best algorithm to search a particular data set. In order to scale to very large data sets that would otherwise not fit in the memory of a single machine, we propose a distributed nearest neighbor matching framework that can be used with any of the algorithms described in the paper. All this research has been released as an open source library called fast library for approximate nearest neighbors (FLANN), which has been incorporated into OpenCV and is now one of the most popular libraries for nearest neighbor matching.},
author = {Muja, Marius and Lowe, David G.},
xxurl = {10.1109/TPAMI.2014.2321376},
isbn = {0162-8828 VO  - 36},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Nearest neighbor search,algorithm configuration,approximate search,big data},
number = {11},
pages = {2227--2240},
pmid = {26353063},
title = {{Scalable nearest neighbor algorithms for high dimensional data}},
volume = {36},
year = {2014}
}
@article{Bagdanov2007,
abstract = {In this paper we describe a system for detection and retrieval of trademarks appearing in sports videos. We propose a compact representation of trademarks and video frame content based on SIFT feature points. This representation can be used to robustly detect, localize, and retrieve trademarks as they appear in a variety of different sports video types. Classification of trademarks is performed by matching a set of SIFT feature descriptors for each trademark instance against the set of SIFT features detected in each frame of the video. Localization is performed through robust clustering of matched feature points in the video frame. Experimental results are provided, along with an analysis of the precision and recall. Results show that the our proposed technique is efficient and effectively detects and classifies trademarks},
author = {Bagdanov, Andrew D. and Ballan, Lamberto and Bertini, Marco and {Del Bimbo}, Alberto},
xxurl = {10.1145/1290082.1290096},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bagdanov et al. - 2007 - Trademark matching and retrieval in sports video databases.pdf:pdf},
isbn = {9781595937780},
journal = {Proceedings of the international workshop on Workshop on multimedia information retrieval  - MIR '07},
keywords = {multimedia,trademark matching,video retrieval},
pages = {79},
title = {{Trademark matching and retrieval in sports video databases}},
url = {http://portal.acm.org/citation.cfm?xxurld=1290082.1290096},
year = {2007}
}
@article{Rath,
annote = {From Duplicate 1 ( 


Features for word spotting in historical manuscripts


- Rath, T M; Manmatha, R )

},
author = {Rath, T M and Manmatha, R},
xxurl = {10.1109/ICDAR.2003.1227662},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rath, Manmatha - Unknown - Features for word spotting in historical manuscripts.pdf:pdf},
isbn = {0-7695-1960-1},
journal = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
pages = {218--222},
publisher = {IEEE Comput. Soc},
title = {{Features for word spotting in historical manuscripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227662},
volume = {1}
}
@article{Visin2015,
abstract = {In this paper, we propose a deep neural network architecture for object recognition based on recurrent neural networks. The proposed network, called ReNet, replaces the ubiquitous convolution+pooling layer of the deep convolutional neural network with four recurrent neural networks that sweep horizontally and vertically in both directions across the image. We evaluate the proposed ReNet on three widely-used benchmark datasets; MNIST, CIFAR-10 and SVHN. The result suggests that ReNet is a viable alternative to the deep convolutional neural network, and that further investigation is needed.},
archivePrefix = {arXiv},
arxivId = {1505.00393},
author = {Visin, Francesco and Kastner, Kyle and Cho, Kyunghyun and Matteucci, Matteo and Courville, Aaron and Bengio, Yoshua},
eprint = {1505.00393},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Visin et al. - 2015 - ReNet A Recurrent Neural Network Based Alternative to Convolutional Networks.pdf:pdf},
isbn = {9781577357384},
issn = {10450823},
pages = {1--9},
title = {{ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks}},
url = {http://arxiv.org/abs/1505.00393},
year = {2015}
}
@article{KumarBoyat2015,
abstract = {Noise is always presents in digital images during image acquisition, coding, transmission, and processing steps. Noise is very difficult to remove it from the digital images without the prior knowledge of noise model. That is why, review of noise models are essential in the study of image denoising techniques. In this paper, we express a brief overview of various noise models. These noise models can be selected by analysis of their origin. In this way, we present a complete and quantitative analysis of noise models available in digital images.},
author = {{Kumar Boyat}, Ajay and Joshi, Brijendra Kumar},
xxurl = {10.5121/sipij.2015.6206},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar Boyat, Joshi - 2015 - A Review Paper Noise Models in Digital Image Processing.pdf:pdf},
issn = {22293922},
journal = {An International Journal (SIPIJ)},
keywords = {Digital images,Noise model,Power spectral density (PDF),Probability density function},
number = {2},
pages = {63--75},
title = {{A Review Paper: Noise Models in Digital Image Processing}},
volume = {6},
year = {2015}
}
@article{Eickeler2010,
author = {Eickeler, Stefan and Seibert, Christoph and Birlinghoven, Schloss and Augustin, Sankt and Konya, Iuliu and Eickeler, Stefan and Seibert, Christoph},
xxurl = {10.1109/ICPR.2010.474},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eickeler et al. - 2010 - Fast Seamless Skew and Orientation Detection in Document Images.pdf:pdf},
isbn = {978-1-4244-7542-1},
number = {March},
title = {{Fast Seamless Skew and Orientation Detection in Document Images}},
year = {2010}
}
@article{Ratanamahatana2004b,
abstract = {The Dynamic Time Warping (DTW) distance measure is a technique that has long been known in speech recognition community. It allows a non-linear mapping of one signal to another by minimizing the distance between the two. A decade ago, DTW was introduced into Data Mining community as a utility for various tasks for time series problems including classification, clustering, and anomaly detection. The technique has flourished, particularly in the last three years, and has been applied to a variety of problems in various disciplines. In spite of DTW's great success, there are still several persistent “myths” about it. These myths have caused confusion and led to much wasted research effort. In this work, we will dispel these myths with the most comprehensive set of time series experiments ever conducted},
author = {Ratanamahatana, Ca and Keogh, E},
xxurl = {10.1097/01.CCM.0000279204.24648.44},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratanamahatana, Keogh - 2004 - Everything you know about dynamic time warping is wrong.pdf:pdf},
isbn = {978-0-89871-593-4},
issn = {00903493},
journal = {Third Workshop on Mining Temporal and Sequential Data},
keywords = {data mining,dynamic time warping,experimentation},
pages = {22--25},
pmid = {15513920},
title = {{Everything you know about dynamic time warping is wrong}},
year = {2004}
}
@article{Griechisch2013,
author = {Griechisch, Erika and Malk, Muhammad Imran and Liwicki, Marcus},
xxurl = {10.1109/ICDAR.2013.82},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Griechisch, Malk, Liwicki - 2013 - Online Signature Analysis Based on Accelerometric and Gyroscopic Pens and Legendre Series.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {374--378},
publisher = {Ieee},
title = {{Online Signature Analysis Based on Accelerometric and Gyroscopic Pens and Legendre Series}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628647},
year = {2013}
}
@article{Fu2007,
author = {Fu, Bin and Wu, Minghui and Li, R and Li, Wenxin and Xu, Zhuoqun and Yang, Chunxu},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu et al. - 2007 - A model-based book dewarping method using text line detection.pdf:pdf},
journal = {Proc. 2nd Int. Workshop on Camera {\ldots}},
pages = {63--70},
title = {{A model-based book dewarping method using text line detection}},
url = {http://www.imlab.jp/cbdar2007/proceedings/papers/P1.pdf},
year = {2007}
}
@inproceedings{Szegedy2014,
abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extent. We can cause the network to misclassify an image by applying a certain hardly perceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.},
archivePrefix = {arXiv},
arxivId = {1312.6199},
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
booktitle = {2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings},
eprint = {1312.6199},
title = {{Intriguing properties of neural networks}},
year = {2014}
}
@article{Wei2013a,
author = {Wei, Hongxi and Gao, Guanglai},
xxurl = {10.1007/s10032-013-0203-6},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
month = {feb},
number = {1},
pages = {33--45},
title = {{A keyword retrieval system for historical Mongolian document images}},
volume = {17},
year = {2013}
}
@article{Breuel2013,
author = {Breuel, Thomas M. and Ul-Hasan, Adnan and Al-Azawi, Mayce Ali and Shafait, Faisal},
xxurl = {10.1109/ICDAR.2013.140},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breuel et al. - 2013 - High-Performance OCR for Printed English and Fraktur Using LSTM Networks.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {683--687},
publisher = {Ieee},
title = {{High-Performance OCR for Printed English and Fraktur Using LSTM Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628705},
year = {2013}
}
@inproceedings{Ge2004,
abstract = {This paper addresses the problem of automatically detecting specific patterns or shapes in time-series data. A novel and flexible approach is proposed based on segmental semi-Markov models. Unlike dynamic time-warping or template-matching, the proposed framework provides a systematic and coherent framework for leveraging both prior knowledge and training data. The pattern of interest is modeled as a K-state segmental hidden Markov model where each state is responsible for the generation of a component of the overall shape using a state-based regression function. The distance (in time) between segments is modeled as a semi-Markov process, allowing flexible deformation of time. The model can be constructed from a single training example. Recognition of a pattern in a new time series is achieved by a recursive Viterbi-like algorithm which scales linearly in the length of the sequence. The method is successfully demonstrated on real data sets, including an application to end-point detection in semiconductor manufacturing.},
address = {New York, New York, USA},
author = {Ge, Xianping and Smyth, Padhraic},
booktitle = {Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '00},
xxurl = {10.1145/347090.347109},
isbn = {1581132336},
pages = {81--90},
publisher = {ACM Press},
title = {{Deformable Markov model templates for time-series pattern matching}},
url = {http://portal.acm.org/citation.cfm?xxurld=347090.347109},
year = {2000}
}
@article{Density2011,
author = {Density, Zone and Directional, Background},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Density, Directional - 2011 - Devanagari Isolated Character Recognition by using Statistical features.pdf:pdf},
keywords = {- davanagari character recognition,background directional,distribution,forground pixel,support vector machine,zone density},
number = {6},
pages = {2400--2407},
title = {{Devanagari Isolated Character Recognition by using Statistical features}},
volume = {3},
year = {2011}
}
@article{Lew2006,
author = {Lew, Michael S. and Sebe, Nicu and Djeraba, Chabane and Jain, Ramesh},
xxurl = {10.1145/1126004.1126005},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
keywords = {Multimedia information retrieval,audio retrieval,human-computer interaction,image databases,image search,multimedia indexing,video retrieval},
month = {feb},
number = {1},
pages = {1--19},
publisher = {ACM},
title = {{Content-based multimedia information retrieval}},
url = {http://dl.acm.org/citation.cfm?id=1126004.1126005},
volume = {2},
year = {2006}
}
@article{Mikolajczyk2010,
author = {Mikolajczyk, Krystian and Schmid, Cordelia and Mikolajczyk, Krystian and Schmid, Cordelia and Sparr, Gunnar and Nielsen, Mads and European, Peter Johansen},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolajczyk et al. - 2010 - An affine invariant interest point detector To cite this version.pdf:pdf},
isbn = {3540479694},
title = {{An affine invariant interest point detector To cite this version :}},
year = {2010}
}
@article{Wang2010,
author = {Wang, Da Han and Ketterlin, Alain and Ganc, Pierre},
xxurl = {10.1016/j.patcog.2010.09.013},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang - 2010 - A global averaging method for dynamic time warping , with applications to clustering.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ketterlin, Ganc - 2010 - A global averaging method for dynamic time warping , with applications to clustering.pdf:pdf},
keywords = {distance-based clustering,dtw barycenter averaging,dynamic time warping,global averaging,satellite image time series,sequence analysis,time series averaging,time series clustering},
title = {{A global averaging method for dynamic time warping , with applications to clustering}},
year = {2010}
}
@article{Indermuhle2012a,
author = {Indermuhle, Emanuel and Frinken, Volkmar and Bunke, Horst},
xxurl = {10.1109/ICFHR.2012.232},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Indermuhle, Frinken, Bunke - 2012 - Mode Detection in Online Handwritten Documents Using BLSTM Neural Networks.pdf:pdf},
isbn = {978-1-4673-2262-1},
journal = {2012 International Conference on Frontiers in Handwriting Recognition},
month = {sep},
pages = {302--307},
publisher = {Ieee},
title = {{Mode Detection in Online Handwritten Documents Using BLSTM Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6424410},
year = {2012}
}
@article{Yankov2008,
abstract = {The problem of finding unusual time series has recently attracted much attention, and several promising methods are now in the literature. However, virtually all proposed methods assume that the data reside in main memory. For many real-world problems this is not be the case. For example, in astronomy, multi-terabyte time series datasets are the norm. Most current algorithms faced with data which cannot fit in main memory resort to multiple scans of the disk/tape and are thus intractable. In this work we show how one particular definition of unusual time series, the time series discord, can be discovered with a disk aware algorithm. The proposed algorithm is exact and requires only two linear scans of the disk with a tiny buffer of main memory. Furthermore, it is very simple to implement. We use the algorithm to provide further evidence of the effectiveness of the discord definition in areas as diverse as astronomy, Web query mining, video surveillance, etc., and show the efficiency of our method on datasets which are many orders of magnitude larger than anything else attempted in the literature.},
author = {Yankov, Dragomir and Keogh, Eamonn and Rebbapragada, Umaa},
xxurl = {10.1007/s10115-008-0131-9},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {Discords,Disk aware algorithms,Distance outliers,Time series},
month = {nov},
number = {2},
pages = {241--262},
title = {{Disk aware discord discovery: finding unusual time series in terabyte sized datasets}},
url = {http://link.springer.com/10.1007/s10115-008-0131-9},
volume = {17},
year = {2008}
}
@article{Jain2008b,
author = {Jain, Prateek and Kulis, Brian and Grauman, Kristen},
xxurl = {10.1109/CVPR.2008.4587841},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Kulis, Grauman - 2008 - Fast image search for learned metrics.pdf:pdf},
isbn = {978-1-4244-2242-5},
journal = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
month = {jun},
pages = {1--8},
publisher = {Ieee},
title = {{Fast image search for learned metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587841},
year = {2008}
}
@article{Mueen2013,
abstract = {Time series motifs are pairs of individual time series, or subsequences of a longer time series, which are very similar to each other. As with their discrete analogues in computational biology, this similarity hints at structure which has been conserved for some reason and may therefore be of interest. Since the formalism of time series motifs in 2002, dozens of researchers have used them for diverse applications in many different domains. Because the obvious algorithm for computing motifs is quadratic in the number of items, more than a dozen approximate algorithms to discover motifs have been proposed in the literature. In this work, for the first time, we show a tractable exact algorithm to find time series motifs. As we shall show through extensive experiments, our algorithm is up to three orders of magnitude faster than brute-force search in large datasets. We further show that our algorithm is fast enough to be used as a subroutine in higher level data mining algorithms for anytime classification, near-duplicate detection and summarization, and we consider detailed case studies in domains as diverse as electroencephalograph interpretation and entomological telemetry data mining.},
author = {Mueen, Abdullah and Keogh, Eamonn and Zhu, Qiang and Cash, Sydney and Westover, Brandon},
xxurl = {10.1137/1.9781611972795.41},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mueen et al. - 2013 - Exact Discovery of Time Series Motifs.pdf:pdf},
pages = {473--484},
title = {{Exact Discovery of Time Series Motifs}},
year = {2013}
}
@article{Wu2016,
abstract = {In this paper we present a fully trainable binarization solution for degraded document images. Unlike previous attempts that often used simple features with a series of pre- and post-processing, our solution encodes all heuristics about whether or not a pixel is foreground text into a high-dimensional feature vector and learns a more complicated decision function. In particular, we prepare features of three types: 1) existing features for binarization such as intensity [1], contrast [2], [3], and Laplacian [4], [5]; 2) reformulated features from existing binarization decision functions such those in [6] and [7]; and 3) our newly developed features, namely the Logarithm Intensity Percentile (LIP) and the Relative Darkness Index (RDI). Our initial experimental results show that using only selected samples (about 1.5{\%} of all available training data), we can achieve a binarization performance comparable to those fine-tuned (typically by hand), state-of-the-art methods. Additionally, the trained document binarization classifier shows good generalization capabilities on out-of-domain data.},
archivePrefix = {arXiv},
arxivId = {1505.00529},
author = {Wu, Yue and Natarajan, Premkumar and Rawls, Stephen and Abdalmageed, Wael},
xxurl = {10.1109/ICIP.2016.7533063},
eprint = {1505.00529},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2016 - Learning document image binarization from data.pdf:pdf},
isbn = {9781467399616},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
number = {1},
pages = {3763--3767},
title = {{Learning document image binarization from data}},
volume = {2016-Augus},
year = {2016}
}
@article{Hollaus2013,
author = {Hollaus, Fabian and Gau, Melanie and Sablatnig, Robert},
xxurl = {10.1109/ICDAR.2013.36},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hollaus, Gau, Sablatnig - 2013 - Enhancement of Multispectral Images of Degraded Documents by Employing Spatial Information.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {145--149},
publisher = {Ieee},
title = {{Enhancement of Multispectral Images of Degraded Documents by Employing Spatial Information}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628601},
year = {2013}
}
@article{Balogh2008,
author = {Balogh, J{\'{o}}zsef and Martin, Ryan},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balogh, Martin - 2008 - Edit distance and its computation.pdf:pdf},
issn = {10778926},
journal = {Electronic Journal of Combinatorics},
number = {1 R},
pages = {1--27},
title = {{Edit distance and its computation}},
volume = {15},
year = {2008}
}
@article{Ahmed2008,
abstract = {Logos detection on textual images is a decisive stage in documents recognition and classification system. The over or the sub-detection of logos strongly penalizes the system capacities and corrupts the subsequent stages result. We developed here an effective and robust logo extraction algorithm while considering the two principals proprieties of logos: spatial compactness and colorimetric uniformity. First, the image content is reduced and transformed using mathematical morphology operators to decrease the distance between the identical logo parts. Afterwards the logo regions of height spatial and chromatic densities are detected. The results demonstrate the robustness of the proposed method over a range of representative text images.},
author = {Ahmed, Zeggari and Fella, Hachouf},
xxurl = {10.1109/ISIE.2008.4677020},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Fella - 2008 - Logos extraction on picture documents using shape and color density.pdf:pdf},
isbn = {1424416655},
journal = {IEEE International Symposium on Industrial Electronics},
keywords = {Color density,Histogram,Logo,Mountain function,Page segmentation,Spatial density},
pages = {2492--2496},
title = {{Logos extraction on picture documents using shape and color density}},
year = {2008}
}
@article{Zhang2017,
abstract = {Dynamic Time Warping (DTW) is probably the most popular distance measure for time series data, because it captures flexible similarities under time distortions. However, DTW has long been suffering from the pathological alignment problem, and most existing solutions, which essentially impose rigid constraints on the warping path, are likely to miss the correct alignments. A crucial observation on pathological alignment is that it always leads to an abnormally large number of links between two sequences. Based on this new observation, we propose a novel variant of DTW called LDTW, which limits the total number of links during the optimization process of DTW. LDTW not only oppresses the pathological alignment effectively, but also allows more flexibilities when measuring similarities. It is a softer constraint because we still let the optimization process of DTW decide how many links to allocate to each data point and where to put these links. In this paper, we introduce the motivation and algorithm of LDTW and we conduct a nearest neighbor classification experiment on UCR time series archive to show its performance.},
author = {Zhang, Zheng and Tavenard, Romain and Bailly, Adeline and Tang, Xiaotong and Tang, Ping and Corpetti, Thomas},
xxurl = {10.1016/j.ins.2017.02.018},
file = {:home/mondal/Downloads/1-s2.0-S0020025517304176-main.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Classification,Distance measure,Dynamic Time Warping (DTW),Time series,Warping path},
pages = {91--107},
publisher = {Elsevier Inc.},
title = {{Dynamic Time Warping under limited warping path length}},
url = {http://dx.xxurl.org/10.1016/j.ins.2017.02.018},
volume = {393},
year = {2017}
}
@article{Nguyen2019,
abstract = {The revolution in computer hardware, especially in graphics processing units and tensor processing units, has enabled significant advances in computer graphics and artificial intelligence algorithms. In addition to their many beneficial applications in daily life and business, computer-generated/manipulated images and videos can be used for malicious purposes that violate security systems, privacy, and social trust. The deepfake phenomenon and its variations enable a normal user to use his or her personal computer to easily create fake videos of anybody from a short real online video. Several countermeasures have been introduced to deal with attacks using such videos. However, most of them are targeted at certain domains and are ineffective when applied to other domains or new attacks. In this paper, we introduce a capsule network that can detect various kinds of attacks, from presentation attacks using printed images and replayed videos to attacks using fake videos created using deep learning. It uses many fewer parameters than traditional convolutional neural networks with similar performance. Moreover, we explain, for the first time ever in the literature, the theory behind the application of capsule networks to the forensics problem through detailed analysis and visualization.},
archivePrefix = {arXiv},
arxivId = {1910.12467},
author = {Nguyen, Huy H. and Yamagishi, Junichi and Echizen, Isao},
eprint = {1910.12467},
file = {:home/mondal/Downloads/1910.12467.pdf:pdf},
title = {{Use of a Capsule Network to Detect Fake Images and Videos}},
url = {http://arxiv.org/abs/1910.12467},
year = {2019}
}
@inproceedings{Yao2015,
author = {Yao, Shunyi and Wen, Ying and Lu, Yue},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao, Wen, Lu - 2015 - HoG based Two-Directional Dynamic Time Warping for Handwritten Word Spotting.pdf:pdf},
isbn = {9781479918058},
keywords = {features,handwritten documents,two-directional dynamic time warping,word spotting},
title = {{HoG based Two-Directional Dynamic Time Warping for Handwritten Word Spotting}},
year = {2015}
}
@article{Dinges2013a,
author = {Dinges, Laslo and Al-Hamadi, Ayoub and Elzobi, Moftah},
xxurl = {10.1109/ICDAR.2013.255},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinges, Al-Hamadi, Elzobi - 2013 - An Approach for Arabic Handwriting Synthesis Based on Active Shape Models.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1260--1264},
publisher = {Ieee},
title = {{An Approach for Arabic Handwriting Synthesis Based on Active Shape Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628816},
year = {2013}
}
@inproceedings{Lu2002,
abstract = {An approach to searching user-specified words/phases in Chinese document images, without the requirements of layout analysis, is proposed in this paper. Bounding boxes of Chinese character images are first determined using the connected component analysis. Next, a suitable character from the user-specified word/phrase is chosen as the initial character to search for a matching candidate in the document. Once a matched candidate is found, its adjacent characters in the horizontal and vertical directions are examined for matching with other corresponding characters in the user-specified word/phrase, subject to the constraints of positional relation and size similarity. The character matching is done in two stages. The coarse matching is carried out based on the stroke density features. A weighted Hausdorff distance is proposed for the second matching phase. Experimental results show that the proposed method can effectively search the user-specified Chinese word/phrase from horizontal or vertical text lines of document images.},
author = {Lu, Yue and Tan, Chew Lim},
booktitle = {International Conference on Pattern Recognition},
isbn = {0-7695-1695-X},
issn = {1051-4651},
keywords = {Character recognition,Chinese document image processing,Computer science,Content based retrieval,Costs,Image analysis,Image retrieval,Image storage,Indexing,Information retrieval,Optical character recognition software,bounding boxes,character matching,character recognition,coarse matching,connected component analysis,document image processing,feature extraction,pattern matching,positional relation,size similarity,stroke density features,weighted Hausdorff distance,word spotting},
language = {English},
pages = {57--60},
publisher = {IEEE Comput. Soc},
title = {{Word spotting in Chinese document images without layout analysis}},
volume = {3},
year = {2002}
}
@article{Diem2009,
abstract = {The main problems of Optical Character Recognition (OCR) systems are solved if printed latin text is considered. Since OCR systems are based upon binary images, their results are poor if the text is degraded. In this paper a codex consisting of ancient manuscripts is investigated. Due to environmental effects the characters of the analyzed codex are washed out which leads to poor results gained by state of the art binarization methods. Hence, a segmentation free approach based on local descriptors is being developed. Regarding local information allows for recognizing characters that are only partially visible. In order to recognize a character the local descriptors are initially classified with a Support Vector Machine (SVM) and then identified by a voting scheme of neighboring local descriptors. State of the art local descriptor systems are evaluated in this paper in order to compare their performance for the recognition of degraded characters.},
author = {Diem, Markus and Sablatnig, Robert},
xxurl = {10.1109/ICDAR.2009.158},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diem, Sablatnig - 2009 - Recognition of degraded handwritten characters using local features.pdf:pdf},
isbn = {9780769537252},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
pages = {221--225},
title = {{Recognition of degraded handwritten characters using local features}},
year = {2009}
}
@article{Fornes2013,
author = {Fornes, Alicia and Otazu, Xavier and Llados, Josep},
xxurl = {10.1109/ICDAR.2013.47},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fornes, Otazu, Llados - 2013 - Show-Through Cancellation and Image Enhancement by Multiresolution Contrast Processing.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {200--204},
publisher = {Ieee},
title = {{Show-Through Cancellation and Image Enhancement by Multiresolution Contrast Processing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628612},
year = {2013}
}
@article{Kolcz2000,
author = {Kolcz, A and Alspector, J and Augusteijn, M},
xxurl = {10.1007/s100440070020},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolcz, Alspector, Augusteijn - 2000 - A line-oriented approach to word spotting in handwritten documents.pdf:pdf},
issn = {1433-7541},
journal = {Pattern Analysis {\&} Applications},
keywords = {dynamic time warping,handwriting recognition,holistic features,template matching,word recognition,word spotting},
number = {2},
pages = {153--168},
title = {{A line-oriented approach to word spotting in handwritten documents}},
url = {http://link.springer.com/article/10.1007/s100440070020},
volume = {3},
year = {2000}
}
@article{Federal2011,
author = {Federal, Universidade and Rio, D O and Do, Grande},
file = {:home/mondal/Downloads/tkde18-dpisax-extended.pdf:pdf},
number = {May},
pages = {1--14},
title = {{Indexing and Querying Dataspaces}},
year = {2011}
}
@article{Gordo2013,
author = {Gordo, Albert and Rusinol, Marcal and Karatzas, Dimosthenis and Bagdanov, Andrew D.},
xxurl = {10.1109/ICDAR.2013.128},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gordo et al. - 2013 - Document Classification and Page Stream Segmentation for Digital Mailroom Applications.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {621--625},
publisher = {Ieee},
title = {{Document Classification and Page Stream Segmentation for Digital Mailroom Applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628693},
year = {2013}
}
@article{Samadiani2015,
abstract = {In this paper, we propose a method for recognizing English characters in different fonts. The proposed method based on neural network is resistant to font variant. When the samples in new fonts are added to the database, the accuracy of existing methods rapidly decreases and they are not resistant to font variant but to the accuracy of proposed method that almost stays constant and does not much decrease. A similarity measure neural network is used to identify characters and similarity measure compares the features of characters and the features of the indicators associated with the characters from A to Z obtained in the training stage. We use similarity measure instead of distance measure in SOM neural network because a person learns font-independent and a literate can read without knowing the font of the written note. In fact he/she measures similarity between the notes in new fonts and learned notes in his/her mind. Therefore, we use two samples for training the network as representative of all fonts such as default notes in man's mind. We could obtain 98.56{\%} accuracy of recognizing a database that includes 24 different fonts in 11 different sizes.},
author = {Samadiani, Najmeh and Hassanpour, Hamid},
xxurl = {10.1016/j.jesit.2015.06.003},
file = {:home/mondal/Downloads/1-s2.0-S2314717215000355-main.pdf:pdf},
issn = {23147172},
journal = {Journal of Electrical Systems and Information Technology},
keywords = {character recognition,feature extraction,similarity measure,som neural network},
number = {2},
pages = {207--218},
publisher = {Electronics Research Institute (ERI)},
title = {{A neural network-based approach for recognizing multi-font printed English characters}},
url = {http://dx.xxurl.org/10.1016/j.jesit.2015.06.003},
volume = {2},
year = {2015}
}
@article{Su2013c,
author = {Su, Bing and Ding, Xiaoqing and Peng, Liangrui and Liu, Changsong},
xxurl = {10.1109/ICDAR.2013.253},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su et al. - 2013 - A Novel Baseline-independent Feature Set for Arabic Handwriting Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-baseline-independent,arabic handwriting recognition,feature extraction,log-,space distribution},
month = {aug},
pages = {1250--1254},
publisher = {Ieee},
title = {{A Novel Baseline-independent Feature Set for Arabic Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628814},
year = {2013}
}
@article{Tensmeyer2017,
abstract = {Classifying pages or text lines into font categories aids transcription because single font Optical Character Recognition (OCR) is generally more accurate than omni-font OCR. We present a simple framework based on Convolutional Neural Networks (CNNs), where a CNN is trained to classify small patches of text into predefined font classes. To classify page or line images, we average the CNN predictions over densely extracted patches. We show that this method achieves state-of-The-art performance on a challenging dataset of 40 Arabic computer fonts with 98.8{\%} line level accuracy. This same method also achieves the highest reported accuracy of 86.6{\%} in predicting paleographic scribal script classes at the page level on medieval Latin manuscripts. Finally, we analyze what features are learned by the CNN on Latin manuscripts and find evidence that the CNN is learning both the defining morphological differences between scribal script classes as well as overfitting to class-correlated nuisance factors. We propose a novel form of data augmentation that improves robustness to text darkness, further increasing classification performance.},
archivePrefix = {arXiv},
arxivId = {1708.03669},
author = {Tensmeyer, Chris and Saunders, Daniel and Martinez, Tony},
xxurl = {10.1109/ICDAR.2017.164},
eprint = {1708.03669},
file = {:home/mondal/Downloads/1708.03669.pdf:pdf},
isbn = {9781538635865},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {Convolutional Neural Networks,Data Augmentation,Deep Learning,Document Image Classification,Network Architecture,Preprocessing},
pages = {985--990},
title = {{Convolutional Neural Networks for Font Classification}},
volume = {1},
year = {2017}
}
@article{Gattal2017,
abstract = {{\textcopyright} 2017 Association for Computing Machinery. Several approaches for handwritten digits recognition are proposed an appearance feature-based approach. In this paper we process handwritten digit image without deskewing using oriented Basic Image Features (oBIF) Column scheme extracted from the complete image as well as from different regions of the image by applying a uniform grid sampling to the image. oBIF Column scheme is a very efficient feature descriptor for handwritten digits which is arise from variations in size, shape and slant. Moreover, 4th Nearest Neighbor (4-NN) has been employed as classifier which has better responses. The experimental study is conducted on MNIST dataset and 98.32{\%} recognition rate has been achieved which is comparable with the state of the art.},
author = {Gattal, Abdeljalil and Djeddi, Chawki and Chibani, Youcef and Siddiqi, Imran},
xxurl = {10.1145/3129186.3129189},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gattal et al. - 2017 - Oriented Basic Image Features Column for isolated handwritten digit.pdf:pdf},
isbn = {9781450353090},
journal = {Proceedings of the International Conference on Computing for Engineering and Sciences  - ICCES '17},
number = {October},
pages = {13--18},
title = {{Oriented Basic Image Features Column for isolated handwritten digit}},
url = {http://dl.acm.org/citation.cfm?xxurld=3129186.3129189},
year = {2017}
}
@article{Chen2013,
author = {Chen, Jin and Lopresti, Daniel},
xxurl = {10.1109/ICDAR.2013.189},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Lopresti - 2013 - Alternatives for Page Skew Compensation in Writer Identification.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {927--931},
publisher = {Ieee},
title = {{Alternatives for Page Skew Compensation in Writer Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628754},
year = {2013}
}
@article{Moghaddam2013,
author = {Moghaddam, Reza Farrahi and Moghaddam, Fereydoun Farrahi and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.144},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moghaddam, Moghaddam, Cheriet - 2013 - Unsupervised Ensemble of Experts (EoE) Framework for Automatic Binarization of Document Images.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {703--707},
publisher = {Ieee},
title = {{Unsupervised Ensemble of Experts (EoE) Framework for Automatic Binarization of Document Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628709},
year = {2013}
}
@article{Khurshid2012,
annote = {From Duplicate 1 ( 





















Word spotting in historical printed documents using shape and sequence comparisons





















- Khurshid, Khurram; Faure, Claudie; Vincent, Nicole )







},
author = {Khurshid, Khurram and Faure, Claudie and Vincent, Nicole},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khurshid, Faure, Vincent - 2012 - Word spotting in historical printed documents using shape and sequence comparisons.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khurshid, Faure, Vincent - 2012 - Word spotting in historical printed documents using shape and sequence comparisons(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Digital libraries,Dynamic Time Warping,Historical documents,Information retrieval,Segmentation-driven string matching,Word spotting},
number = {7},
pages = {2598--2609},
publisher = {Elsevier},
title = {{Word spotting in historical printed documents using shape and sequence comparisons}},
volume = {45},
year = {2012}
}
@article{Initiative2005,
abstract = {7 things you should know about..blogs. (2005). Educause Learning Initiative, Retrieved from www.educause.edu/eli},
author = {Initiative, Educause Learning},
journal = {Scenario},
keywords = {blog,weblog},
title = {{7 things you should know about... Blogs}},
year = {2005}
}
@article{Zhang2013d,
author = {Zhang, Heng and Zhou, Xiang-Dong and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.118},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhou, Liu - 2013 - Keyword Spotting in Online Chinese Handwritten Documents with Candidate Scoring Based on Semi-CRF Model.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {based on,documents with candidate scoring,handwritten,spotting in online chinese},
month = {aug},
pages = {567--571},
publisher = {Ieee},
title = {{Keyword Spotting in Online Chinese Handwritten Documents with Candidate Scoring Based on Semi-CRF Model}},
year = {2013}
}
@article{Langer2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1102.3828v1},
author = {Langer, J.},
eprint = {arXiv:1102.3828v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Langer - 2011 - Searching in One Billion Vectors Re-Rankwith Source Coding.pdf:pdf},
journal = {Annals of Physics},
number = {2},
title = {{Searching in One Billion Vectors: Re-Rankwith Source Coding}},
url = {http://www.mendeley.com/research/no-title-avail/},
volume = {54},
year = {2011}
}
@book{Rusinol2009a,
author = {Rusinol, M},
booktitle = {Ddd.Uab.Cat},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusinol - 2009 - Geometric and Structural-based Symbol Spotting. Application to Focused Retrieval in Graphic Document Collections.pdf:pdf},
isbn = {9788493652975},
title = {{Geometric and Structural-based Symbol Spotting. Application to Focused Retrieval in Graphic Document Collections}},
url = {http://ddd.uab.cat/pub/tesis/2001/tdx-0218102-103941/arp1de1.pdf{\%}5Cnhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Geometric+and+Structural-based+Symbol+Spotting.+Application+to+Focused+Retrieval+in+Graphic+Document+Collections{\#}0},
year = {2009}
}
@article{Bluche2013,
author = {Bluche, Theodore and Ney, Hermann and Kermorvant, Christopher},
xxurl = {10.1109/ICDAR.2013.64},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bluche, Ney, Kermorvant - 2013 - Feature Extraction with Convolutional Neural Networks for Handwritten Word Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {285--289},
publisher = {Ieee},
title = {{Feature Extraction with Convolutional Neural Networks for Handwritten Word Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628629},
year = {2013}
}
@article{Zhang2012,
abstract = {Text detection and extraction in images with complex background can provide useful information for video annotation and indexing. More attention is paid to text detection for its importance, but text extraction is necessary for the text recognition, and it can test the validity of text detection. In this paper, we conclude text extraction is to segment the image and to remove noises, and then a robust text extraction method incorporating local information is proposed. First, we get the gray image from the original image and reprocess the gray image with edge enhancement. Then a binarization method incorporating local information is used to segment the gray image, by which the textnoises are removed and a binary image is obtained. Finally, the connected component analysis based on the character's density and geometric feature is performed on the binary image, by which background-noises are removed. The preliminary experiments show some promising results. {\textcopyright} 2012 IEEE.},
author = {Zhang, Yang and Wang, Chunheng and Xiao, Baihua and Shi, Cunzhao},
xxurl = {10.1109/ICFHR.2012.164},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2012 - A new text extraction method incorporating local information.pdf:pdf},
isbn = {9780769547749},
issn = {15505235},
journal = {Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR},
keywords = {Binarization,CCA,Local information,Text extraction,Text segmentation},
pages = {252--255},
title = {{A new text extraction method incorporating local information}},
year = {2012}
}
@article{Adamek2006,
author = {Adamek, Tomasz and O'Connor, Noel E. and Smeaton, Alan F.},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adamek, O'Connor, Smeaton - 2006 - Word matching using single closed contours for indexing handwritten historical documents.pdf:pdf},
issn = {1433-2833},
journal = {IJDAR},
month = {jul},
number = {2-4},
pages = {153--165},
title = {{Word matching using single closed contours for indexing handwritten historical documents}},
volume = {9},
year = {2006}
}
@article{Bai2007,
abstract = {In this paper, we introduce a new skeleton pruning method based on contour partitioning. Any contour partition can be used, but the partitions obtained by Discrete Curve Evolution (DCE) yield excellent results. The theoretical properties and the experiments presented demonstrate that obtained skeletons are in accord with human visual perception and stable, even in the presence of significant noise and shape variations, and have the same topology as the original skeletons. In particular, we have proven that the proposed approach never produces spurious branches, which are common when using the known skeleton pruning methods. Moreover, the proposed pruning method does not displace the skeleton points. Consequently, all skeleton points are centers of maximal disks. Again, many existing methods displace skeleton points in order to produces pruned skeletons.},
author = {Bai, Xiang and Latecki, Longin Jan and Liu, Wen-Yu},
xxurl = {10.1109/TPAMI.2007.59},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai, Latecki, Liu - 2007 - Skeleton pruning by contour partitioning with discrete curve evolution.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Numerical Analysis, Computer-Assisted,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Signal Processing, Computer-Assisted},
month = {mar},
number = {3},
pages = {449--62},
pmid = {17224615},
title = {{Skeleton pruning by contour partitioning with discrete curve evolution.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17224615},
volume = {29},
year = {2007}
}
@article{Li2013f,
abstract = {Time series visualization is one of the most fundamental tasks, which is often used to discover patterns by a user interface. Many increasing interests in time series visualization in the last decade have resulted in the development of various state-of-the-art visualization techniques. In most cases, time series visualization is based on one of the representation frameworks which not only reduce the dimensionality, but sufficiently reflect the shapes of the raw time series as well. In this paper, a new time series visualization based on shape features is proposed to discover surprising patterns and mine frequent trends (motifs discovery). Since the shape features validly summarize both the global and local structures of time series and often use the slopes (or the angles) of the changeable values over time to describe the trends of time series, part of the work is to extract the important shape features and transform them into symbol string. After dimensionality reduction and symbol representation, a circle plotted by the visualization technique is split into many small sectors which simultaneously represent substring patterns of unequal length by multi-resolution function. Since the overall shape features of time series are based on data point importance, the surprising patterns and frequent trends can be accurately discovered even under a high compress ratio. The refined results of patterns discovery and frequent trends mining on financial and other time series datasets indicate that the proposed approach is an effective visualization tool for time series mining. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Li, Hailin and Yang, Libin},
xxurl = {10.1016/j.knosys.2012.12.011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Yang - 2013 - Time series visualization based on shape features.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Frequent trends mining,Patterns discovery,Shape feature,Symbol representation,Time series visualization},
pages = {43--53},
title = {{Time series visualization based on shape features}},
url = {http://dx.xxurl.org/10.1016/j.knosys.2012.12.011},
volume = {41},
year = {2013}
}
@article{Bukhari2012,
author = {Bukhari, Syed Saqib and Shafait, Faisal and Breuel, Thomas M.},
xxurl = {10.1007/978-3-642-29364-1_10},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bukhari, Shafait, Breuel - 2012 - Border noise removal of camera-captured document images using page frame detection.pdf:pdf},
isbn = {9783642293634},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Border Noise Removal,Camera-Captured Document Images,Page Frame Detection},
pages = {126--137},
title = {{Border noise removal of camera-captured document images using page frame detection}},
volume = {7139 LNCS},
year = {2012}
}
@article{Gattal2016,
abstract = {A facile synthesis of sulfonyl amidines via carbon-nitrogen bond formation mediated by FeCl(3) was developed and an interesting major product of cyclic tertiary amine was observed, which showed the good selectivity of FeCl(3)-mediated activation of cyclic alpha-C-H bonds of cyclic tertiary amines.},
author = {Gattal, Abdeljalil and Djeddi, Chawki and Chibani, Youcef and Siddiqi, Imran},
xxurl = {10.1109/DAS.2016.10},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gattal et al. - 2016 - Isolated Handwritten Digit Recognition Using oBIFs and Background Features.pdf:pdf},
isbn = {9781509017928},
issn = {1359-7345},
journal = {Proceedings - 12th IAPR International Workshop on Document Analysis Systems, DAS 2016},
keywords = {Background Features,Isolated handwritten digits,Support Vector Machine,oBIFs},
number = {April},
pages = {305--310},
pmid = {20024232},
title = {{Isolated Handwritten Digit Recognition Using oBIFs and Background Features}},
year = {2016}
}
@article{Cutter2012,
author = {Cutter, Michael P. and Chiu, Patrick},
xxurl = {10.1109/DAS.2012.24},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cutter, Chiu - 2012 - Capture and dewarping of page spreads with a handheld compact 3D camera.pdf:pdf},
isbn = {9780769546612},
journal = {Proceedings - 10th IAPR International Workshop on Document Analysis Systems, DAS 2012},
keywords = {3D camera,dewarping,document analysis,document capture,stereo camera},
pages = {205--209},
title = {{Capture and dewarping of page spreads with a handheld compact 3D camera}},
year = {2012}
}
@inproceedings{Fang2017,
abstract = {Motivated by concerns for user privacy, we design a steganographic system (“stegosystem”) that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. We propose a new linguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1705.10742},
author = {Fang, Tina and Jaggi, Martin and Argyraki, Katerina},
booktitle = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Student Research Workshop},
xxurl = {10.18653/v1/P17-3017},
eprint = {1705.10742},
isbn = {9781945626562},
title = {{Generating steganographic text with LSTMs}},
year = {2017}
}
@article{Jain2013f,
author = {Jain, Rajiv and Doermann, David},
xxurl = {10.1109/ICDAR.2013.115},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Doermann - 2013 - Writer Identification Using an Alphabet of Contour Gradient Descriptors.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {as follows,describes related work,handwriting,paper,paper is set up,schemes explored in the,section 2,section 3 presents the,section 4 introduces the,segmentation,the rest of the,writer identification},
month = {aug},
pages = {550--554},
publisher = {Ieee},
title = {{Writer Identification Using an Alphabet of Contour Gradient Descriptors}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628680},
year = {2013}
}
@article{Okamoto2013,
author = {Okamoto, Akihiro and Yoshida, Hiromi and Tanaka, Naoki},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Okamoto, Yoshida, Tanaka - 2013 - A Binarization Method for Degraded Document Images with.pdf:pdf},
isbn = {9781538642252},
keywords = {Feature Extraction,Segmentation},
number = {5},
pages = {18--22},
title = {{A Binarization Method for Degraded Document Images with}},
year = {2013}
}
@inproceedings{Mueen2010b,
abstract = {We consider the problem of computing all-pair correlations in a warehouse containing a large number (e.g., tens of thousands) of time-series (or, signals). The problem arises in automatic discovery of patterns and anomalies in data intensive applications such as data center management, environmental monitoring, and scientific experiments. However, with existing techniques, solving the problem for a large stream warehouse is extremely expensive, due to the problem's inherent quadratic I/O and CPU complexities. We propose novel algorithms, based on Discrete Fourier Transformation (DFT) and graph partitioning, to reduce the end-to-end response time of an all-pair correlation query. To minimize I/O cost, we partition a massive set of input signals into smaller batches such that caching the signals one batch at a time maximizes data reuse and minimizes disk I/O. To reduce CPU cost, we propose two approximation algorithms. Our first algorithm efficiently computes approximate correlation coefficients of similar signal pairs within a given error bound. The second algorithm efficiently identifies, without any false positives or negatives, all signal pairs with correlations above a given threshold. For many real applications, our approximate solutions are as useful as corresponding exact solutions, due to our strict error guarantees. However, compared to the state-of-the-art exact algorithms, our algorithms are up to 17x faster for several real datasets. {\textcopyright} 2010 ACM.},
author = {Mueen, Abdullah and Nath, Suman and Liu, Jie},
booktitle = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
xxurl = {10.1145/1807167.1807188},
isbn = {9781450300322},
issn = {07308078},
keywords = {correlation matrix,discrete fourier transform},
title = {{Fast approximate correlation for massive time-series data}},
year = {2010}
}
@article{Yadav2013,
author = {Yadav, Nivedita and Chaudhury, Santanu and Kalra, Prem},
xxurl = {10.1109/ICDAR.2013.281},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yadav, Chaudhury, Kalra - 2013 - Most Discriminative Primitive Selection for Identity Determination Using Handwritten Devanagari Script.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {a forensic document examiner,always looks for peculiar,characteristic of handwriting while,classification,devanagri,fde,feature selection,for writer recognition,selection,sequential forward,writer identification},
month = {aug},
pages = {1390--1394},
publisher = {Ieee},
title = {{Most Discriminative Primitive Selection for Identity Determination Using Handwritten Devanagari Script}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628842},
year = {2013}
}
@article{Shivram2013b,
author = {Shivram, Arti and Ramaiah, Chetan and Setlur, Srirangaraj and Govindaraju, Venu},
xxurl = {10.1109/ICDAR.2013.12},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shivram et al. - 2013 - IBM{\_}UB{\_}1 A Dual Mode Unconstrained English Handwriting Dataset.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {- and their relevance,central,characteristics of the dataset,document search and retrieval,dual,indexing and various forms,modality,of handwritten,offline,online,spotting,the twin-folio structure and,to current research,we first describe two},
month = {aug},
pages = {13--17},
publisher = {Ieee},
title = {{IBM{\_}UB{\_}1: A Dual Mode Unconstrained English Handwriting Dataset}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628577},
year = {2013}
}
@article{JAIN1998,
abstract = {Retrieval efficiency and accuracy are two important issues in designing a content-based database retrieval system. We propose a method for trademark image database retrieval based on object shape information that would supplement traditional text-based retrieval systems. This system achieves both the desired efficiency and accuracy using a two-stage hierarchy: in the first stage, simple and easily computable shape features are used to quickly browse through the database to generate a moderate number of plausible retrievals when a query is presented; in the second stage, the candidates from the first stage are screened using a deformable template matching process to discard spurious matches. We have tested the algorithm using hand drawn queries on a trademark database containing 1100 images. Each retrieval takes a reasonable amount of computation time (∼4–5s on a Sun Space 20 workstation). The topmost image retrieved by the system agrees with that obtained by human subjects, but there are significant differences between the ranking of the top-10 images retrieved by our system and the ranking of those selected by the human subjects. This demonstrates the need for developing shape features that are better able to capture human perceptual similarity of shapes. An improved heuristic has been suggested for more accurate retrievals. The proposed scheme matches filled-in query images against filled-in images from the database, thus using only the gross details in the image. Experiments with database images used as query images have shown that matching on the filled-in database extracts more images within the top-20 retrievals that have similar content. We believe that developing an automatic retrieval algorithm which matches human performance is an extremely difficult and challenging task. However, considering the substantial amount of time and effort needed for a manual retrieval from a large image database, an automatic shape-based retrieval technique can significantly simplify the retrieval task.},
author = {JAIN, ANIL K. and VAILAYA, ADITYA},
xxurl = {10.1016/S0031-3203(97)00131-3},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/JAIN, VAILAYA - 1998 - Shape-Based Retrieval a Case Study With Trademark Image Databases.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Deformable template,Image database,Logos,Moment invariants,Shape similarity,Trademarks},
number = {9},
pages = {1369--1390},
title = {{Shape-Based Retrieval: a Case Study With Trademark Image Databases}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320397001313{\%}5Cnhttp://linkinghub.elsevier.com/retrieve/pii/S0031320397001313},
volume = {31},
year = {1998}
}
@article{Fellow2013a,
author = {Fellow, R Kimmel and Zhang, C and Member, A Bronstein and Member, M Bronstein},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fellow et al. - 2013 - Are MSER Features Really Interesting.pdf:pdf},
number = {August 2011},
pages = {2316},
title = {{Are MSER Features Really Interesting ?}},
year = {2013}
}
@article{Turner2017,
abstract = {Although recent advances in regional Convolutional Neural Networks (CNNs) enable them to outperform conventional techniques on standard object detection and classification tasks, their response time is still slow for real-time performance. To address this issue, we propose a method for region proposal as an alternative to selective search, which is used in current state-of-the art object detection algorithms. We evaluate our Keypoint Density-based Region Proposal (KDRP) approach and show that it speeds up detection and classification on fine-grained tasks by 100{\%} versus the existing selective search region proposal technique without compromising classification accuracy. KDRP makes the application of CNNs to real-time detection and classification feasible.},
archivePrefix = {arXiv},
arxivId = {1603.00502},
author = {Turner, J. T. and Gupta, Kalyan Moy and Aha, David},
xxurl = {10.1109/AIPR.2016.8010582},
eprint = {1603.00502},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Turner, Gupta, Aha - 2017 - Keypoint density-based region proposal for fine-grained object detection using regions with convolutional ne.pdf:pdf},
isbn = {9781509032846},
issn = {21642516},
journal = {Proceedings - Applied Imagery Pattern Recognition Workshop},
keywords = {Deep Learning,Keypoint Density Region Proposal (KDRP),Object Detection,Regional Convolutional Neural Networks (rCNN)},
title = {{Keypoint density-based region proposal for fine-grained object detection using regions with convolutional neural network features}},
year = {2017}
}
@article{Kulis2009d,
abstract = {We introduce a method that enables scalable similarity search for learned metrics. Given pairwise similarity and dissimilarity constraints between some examples, we learn a Mahalanobis distance function that captures the examples' underlying relationships well. To allow sublinear time similarity search under the learned metric, we show how to encode the learned metric parameterization into randomized locality-sensitive hash functions. We further formulate an indirect solution that enables metric learning and hashing for vector spaces whose high dimensionality makes it infeasible to learn an explicit transformation over the feature dimensions. We demonstrate the approach applied to a variety of image data sets, as well as a systems data set. The learned metrics improve accuracy relative to commonly used metric baselines, while our hashing construction enables efficient indexing with learned distances and very large databases.},
author = {Kulis, Brian and Jain, Prateek and Grauman, Kristen},
xxurl = {10.1109/TPAMI.2009.151},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulis, Jain, Grauman - 2009 - Fast similarity search for learned metrics.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Databases, Factual,Humans,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Pattern Recognition, Automated,Posture},
month = {dec},
number = {12},
pages = {2143--57},
pmid = {19834137},
title = {{Fast similarity search for learned metrics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19834137},
volume = {31},
year = {2009}
}
@article{Keogh2004a,
abstract = {The problem of indexing time series has attracted much interest. Most algorithms used to index time series utilize the Euclidean distance or some variation thereof. However, it has been forcefully shown that the Euclidean distance is a very brittle distance measure. Dy- namic time warping (DTW) is a much more robust distance measure for time series, allowing similar shapes to match even if they are out of phase in the time axis. Because of this flexi- bility, DTW is widely used in science, medicine, industry and finance. Unfortunately, however, DTW does not obey the triangular inequality and thus has resisted attempts at exact indexing. Instead, many researchers have introduced approximate indexing techniques or abandoned the idea of indexing and concentrated on speeding up sequential searches. In this work, we intro- duce a novel technique for the exact indexing of DTW. We prove that our method guarantees no false dismissals and we demonstrate its vast superiority over all competing approaches in the largest and most comprehensive set of time series indexing experiments ever undertaken.},
annote = {From Duplicate 2 ( 

Exact indexing of dynamic time warping

- Keogh, Eamonn; Ratanamahatana, Chotirat Ann )

},
author = {Keogh, Eamonn and Ratanamahatana, Chotirat Ann},
xxurl = {10.1007/s10115-004-0154-9},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keogh, Ratanamahatana - 2005 - Exact indexing of dynamic time warping.pdf:pdf},
isbn = {9781558608696},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {dynamic time warping,indexing,lower bounding,time series},
month = {may},
number = {3},
pages = {358--386},
title = {{Exact indexing of dynamic time warping}},
volume = {7},
year = {2005}
}
@article{Aggarwal2010,
author = {Aggarwal, Charu C},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal - 2010 - The Generalized Dimensionality Reduction Problem.pdf:pdf},
journal = {Proceedings of the 10th SIAM International Conference on Data Mining},
number = {3},
pages = {607--618},
title = {{The Generalized Dimensionality Reduction Problem}},
volume = {2},
year = {2010}
}
@article{Schmid2000,
abstract = {Many different low-level feature detectors exist and it is widely agreed that the evaluation of detectors is important. In this paper we introduce two evaluation criteria for interest points' repeatability rate and information content. Repeatability rate evaluates the geometric stability under different transformations. Information content measures the distinctiveness of features. Different interest point detectors are compared using these two criteria. We determine which detector gives the best results and show that it satisfies the criteria well.},
author = {Schmid, Cordelia and Mohr, Roger and Bauckhage, Christian},
xxurl = {10.1023/A:1008199403446},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmid, Mohr, Bauckhage - 2000 - Evaluation of interest point detectors.pdf:pdf},
isbn = {0920-5691},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {comparison of detectors,information content,interest points,quantitative evaluation,repeatability},
number = {2},
pages = {151--172},
title = {{Evaluation of interest point detectors}},
volume = {37},
year = {2000}
}
@article{Biswas2012a,
author = {Biswas, Samit},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biswas - 2012 - Fuzzy Graph Modeling for Text segmentation from Land Map Images.pdf:pdf},
isbn = {9781450316606},
journal = {Proceedings of the Eighth Indian Conference on Computer Vision, Graphics and Image Processing},
keywords = {extracted,fuzzy graph,kind of document containing,like ocr from the,map is a special,political land map,processing and applications,similarity relation,text portion},
title = {{Fuzzy Graph Modeling for Text segmentation from Land Map Images}},
year = {2012}
}
@article{Seok2013,
author = {Seok, Jae-Hyun and Kim, Jin Hyung},
xxurl = {10.1109/ICDAR.2013.124},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seok, Kim - 2013 - Scene Text Recognition with a Hough Forest Implicit Shape Model.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {599--603},
publisher = {Ieee},
title = {{Scene Text Recognition with a Hough Forest Implicit Shape Model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628689},
year = {2013}
}
@article{Wang2016,
abstract = {Breast cancer is the leading type of malignant tumor observed in women and the effective treatment depends on its early diagnosis. Diagnosis from histopathological images remains the «gold standard» for breast cancer. The complexity of breast cell histopathology (BCH) images makes reliable segmentation and classification hard. In this paper, an automatic quantitative image analysis technique of BCH images is proposed. For the nuclei segmentation, top-bottom hat transform is applied to enhance image quality. Wavelet decomposition and multi-scale region-growing (WDMR) are combined to obtain regions of interest (ROIs) thereby realizing precise location. A double-strategy splitting model (DSSM) containing adaptive mathematical morphology and Curvature Scale Space (CSS) corner detection method is applied to split overlapped cells for better accuracy and robustness. For the classification of cell nuclei, 4 shape-based features and 138 textural features based on color spaces are extracted. Optimal feature set is obtained by support vector machine (SVM) with chain-like agent genetic algorithm (CAGA). The proposed method was tested on 68 BCH images containing more than 3600 cells. Experimental results show that the mean segmentation sensitivity was 91.53{\%} (±4.05{\%}) and specificity was 91.64{\%} (±4.07{\%}). The classification performance of normal and malignant cell images can achieve 96.19{\%} (±0.31{\%}) for accuracy, 99.05{\%} (±0.27{\%}) for sensitivity and 93.33{\%} (±0.81{\%}) for specificity.},
author = {Wang, Pin and Hu, Xianling and Li, Yongming and Liu, Qianqian and Zhu, Xinjian},
xxurl = {10.1016/j.sigpro.2015.11.011},
file = {:home/mondal/Downloads/1-s2.0-S0165168415003916-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Breast cancer,Chain-like agent genetic algorithm,Curvature scale space corner detection,Nuclei segmentation,Support vector machine classification,Wavelet decomposition},
pages = {1--13},
publisher = {Elsevier},
title = {{Automatic cell nuclei segmentation and classification of breast cancer histopathology images}},
url = {http://dx.xxurl.org/10.1016/j.sigpro.2015.11.011},
volume = {122},
year = {2016}
}
@inproceedings{Dollar2013,
abstract = {Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets.},
archivePrefix = {arXiv},
arxivId = {arXiv:1406.5549v1},
author = {Dollar, Piotr and Zitnick, C. Lawrence},
booktitle = {ICCV},
xxurl = {10.1109/ICCV.2013.231},
eprint = {arXiv:1406.5549v1},
isbn = {9781479928392},
issn = {1550-5499},
keywords = {edge detection,realtime vision,structure learning},
pmid = {26352995},
title = {{Structured Forests for Fast Edge Detection}},
year = {2013}
}
@article{Zhu2018b,
abstract = {Time series motifs have been in the literature for about fifteen years, but have only recently begun to receive significant attention in the research community. This is perhaps due to the growing realization that they implicitly offer solutions to a host of time series problems, including rule discovery, anomaly detection, density estimation, semantic segmentation, etc. Recent work has improved the scalability to the point where exact motifs can be computed on datasets with up to a million data points in tenable time. However, in some domains, for example seismology, there is an insatiable need to address even larger datasets. In this work we show that a combination of a novel algorithm and a high-performance GPU allows us to significantly improve the scalability of motif discovery. We demonstrate the scalability of our ideas by finding the full set of exact motifs on a dataset with one hundred million subsequences, by far the largest dataset ever mined for time series motifs. Furthermore, we demonstrate that our algorithm can produce actionable insights in seismology and other domains.},
author = {Zhu, Yan and Zimmerman, Zachary and {Shakibay Senobari}, Nader and Yeh, Chin Chia Michael and Funning, Gareth and Mueen, Abdullah and Brisk, Philip and Keogh, Eamonn},
xxurl = {10.1007/s10115-017-1138-x},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2018 - Exploiting a novel algorithm and GPUs to break the ten quadrillion pairwise comparisons barrier for time series moti.pdf:pdf},
isbn = {9781509054725},
issn = {02193116},
journal = {Knowledge and Information Systems},
keywords = {GPUs,Joins,Motifs,Time series},
number = {1},
pages = {203--236},
title = {{Exploiting a novel algorithm and GPUs to break the ten quadrillion pairwise comparisons barrier for time series motifs and joins}},
volume = {54},
year = {2018}
}
@inproceedings{Rao2017,
abstract = {In this paper, we present a new image forgery detection method based on deep learning technique, which utilizes a convolutional neural network (CNN) to automatically learn hierarchical representations from the input RGB color images. The proposed CNN is specifically designed for image splicing and copy-move detection applications. Rather than a random strategy, the weights at the first layer of our network are initialized with the basic high-pass filter set used in calculation of residual maps in spatial rich model (SRM), which serves as a regularizer to efficiently suppress the effect of image contents and capture the subtle artifacts introduced by the tampering operations. The pre-Trained CNN is used as patch descriptor to extract dense features from the test images, and a feature fusion technique is then explored to obtain the final discriminative features for SVM classification. The experimental results on several public datasets show that the proposed CNN based model outperforms some state-of-The-Art methods.},
author = {Rao, Yuan and Ni, Jiangqun},
booktitle = {8th IEEE International Workshop on Information Forensics and Security, WIFS 2016},
xxurl = {10.1109/WIFS.2016.7823911},
isbn = {9781509011384},
title = {{A deep learning approach to detection of splicing and copy-move forgeries in images}},
year = {2017}
}
@article{Gerdjikov2013,
author = {Gerdjikov, Stefan and Mihov, Stoyan and Nenchev, Vladislav},
xxurl = {10.1109/ICDAR.2013.72},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gerdjikov, Mihov, Nenchev - 2013 - Extraction of Spelling Variations from Language Structure for Noisy Text Correction.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {269973},
pages = {324--328},
publisher = {Ieee},
title = {{Extraction of Spelling Variations from Language Structure for Noisy Text Correction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628637},
year = {2013}
}
@article{Tensmeyer2018,
abstract = {Binarization of degraded historical manuscript images is an important pre-processing step for many document processing tasks. We formulate binarization as a pixel classification learning task and apply a novel Fully Convolutional Network (FCN) architecture that operates at multiple image scales, including full resolution. The FCN is trained to optimize a continuous version of the Pseudo F-measure metric and an ensemble of FCNs outperform the competition winners on 4 of 7 DIBCO competitions. This same binarization technique can also be applied to different domains such as Palm Leaf Manuscripts with good performance. We analyze the performance of the proposed model w.r.t. the architectural hyperparameters, size and diversity of training data, and the input features chosen.},
archivePrefix = {arXiv},
arxivId = {1708.03276},
author = {Tensmeyer, Chris and Martinez, Tony},
xxurl = {10.1109/ICDAR.2017.25},
eprint = {1708.03276},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tensmeyer, Martinez - 2018 - Document Image Binarization with Fully Convolutional Neural Networks.pdf:pdf},
isbn = {9781538635865},
issn = {15205363},
journal = {ICDAR},
keywords = {Binarization,Convolutional Neural Networks,Deep Learning,Historical Document Analysis,Preprocessing},
pages = {99--104},
title = {{Document Image Binarization with Fully Convolutional Neural Networks}},
volume = {1},
year = {2018}
}
@article{Frinken2014,
author = {Frinken, Volkmar and Fischer, Andreas and Baumgartner, Markus and Bunke, Horst},
xxurl = {10.1016/j.patcog.2013.06.030},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frinken et al. - 2014 - Keyword spotting for self-training of BLSTM NN based handwriting recognition systems.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Document retrieval,Handwriting recognition,Keyword spotting,Neural networks,Semi-supervised learning,blstm nn based handwriting,spotting for self-training of},
month = {mar},
number = {3},
pages = {1073--1082},
publisher = {Elsevier},
title = {{Keyword spotting for self-training of BLSTM NN based handwriting recognition systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320313002823},
volume = {47},
year = {2014}
}
@article{Sivic2003,
abstract = {We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recog-nition can proceed successfully despite changes in view-point, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vec-tor quantization), and inverted file systems and document rankings are used. The result is that retrieval is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching on two full length feature films.},
archivePrefix = {arXiv},
arxivId = {1504.06897},
author = {Sivic, Josef and Zisserman, Andrew},
xxurl = {10.1109/ICCV.2003.1238663},
eprint = {1504.06897},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sivic, Zisserman - 2003 - Video Google A text retrieval approach to object matching in videos.pdf:pdf},
isbn = {0769519504},
issn = {00189219},
journal = {Toward Category-Level Object Recognition},
number = {Iccv},
pages = {1470--1477},
pmid = {25052830},
title = {{Video Google: A text retrieval approach to object matching in videos}},
url = {http://www.robots.ox.ac.uk/{~}vgg/publications/papers/sivic03.pdf{\%}5Cnhttp://www.cse.unr.edu/{~}bebis/CS773C/ObjectRecognition/Papers/VideoGoogle.pdf},
year = {2003}
}
@article{Filho2013,
author = {Filho, a.N.G. Lopes and Mello, C.a.B.},
xxurl = {10.1109/ICDAR.2013.46},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filho, Mello - 2013 - Degraded Digit Restoration Based on Physical Forces.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {approach,centripetal force,degraded digits,detail,inertial force,paper,physical forces,restoration,results of the new,section 4 shows the,section 5 concludes the,while},
month = {aug},
pages = {195--199},
publisher = {Ieee},
title = {{Degraded Digit Restoration Based on Physical Forces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628611},
year = {2013}
}
@article{Noise2007,
author = {Noise, Fixed Pattern},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noise - 2007 - Topic 5 Noise in Images.pdf:pdf},
number = {August},
title = {{Topic 5 : Noise in Images}},
year = {2007}
}
@article{Toselli2013a,
annote = {From Duplicate 2 ( 





















Fast HMM-Filler Approach for Key Word Spotting in Handwritten Documents





















- Toselli, Alejandro Hector; Vidal, Enrique )







},
author = {Toselli, Alejandro Hector and Vidal, Enrique},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Toselli, Vidal - 2013 - Fast HMM-Filler Approach for Key Word Spotting in Handwritten Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
issn = {1520-5363},
journal = {ICDAR},
keywords = {Character Lattice,Computational modeling,Decoding,HMM Viterbi decoding process,HMM-Filler Model,Handwriting recognition,Hidden Markov models,Indexing,Spotting,Training,Viterbi algorithm,Viterbi decoding,be spotted,character lattices,computing time of word-specific,document image processing,even for small collections,fast HMM-filler approach,for all the,garbage Hidden Markov Models,handwritten documents,handwritten text recognition,however,information retrieval,line images and all,of,on-the-fly,practice,query computing time,renders,searching,single Viterbi decoding process,speech recognition,string key word spotting,the query words to,the very large,this idea unfeasible in,viterbi decoding},
language = {English},
month = {aug},
pages = {501--505},
publisher = {Ieee},
title = {{Fast HMM-Filler Approach for Key Word Spotting in Handwritten Documents}},
year = {2013}
}
@inproceedings{Zhua,
abstract = {Time series motif discovery is an important primitive for time series analytics, and is used in domains as diverse as neuroscience, music and sports analytics. In recent years, algorithmic advances (coupled with hardware improvements) have greatly expanded the purview of motif discovery. Nevertheless, we argue that there is an insatiable need for further scalability. This is because more than most types of analytics, motif discovery benefits from interactivity. The two state-of-the-art algorithms to find motifs are STOMP, which requires O(n 2) time, and STAMP, which, despite being an O(logn) factor slower, is the preferred solution for most applications, as it is a fast converging anytime algorithm. In favorable scenarios STAMP needs only to be run to a small fraction of completion to provide a very accurate approximation of the top-k motifs. In this work we introduce SCRIMP++, an O(n 2) time algorithm that is also an anytime algorithm, combining the best features of STOMP and STAMP. As we shall show, SCRIMP++ maintains all the desirable properties of the original algorithms, but converges much faster, in almost all scenarios producing the correct output after spending a tiny fraction of the full computation time. We argue that for many end-users, this allows motif discovery to be performed in interactive sessions. Moreover, this interactivity can be game changing in terms of the analytics that can be performed.},
author = {Zhu, Yan and Yeh, Chin-Chia Michael and Zimmerman, Zachary and Kamgar, Kaveh and Keogh, Eamonn},
booktitle = {2018 IEEE International Conference on Data Mining (ICDM)},
xxurl = {10.1109/ICDM.2018.00099},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - Unknown - Matrix Profile XI SCRIMP Motif Discovery at Interactive Speeds.pdf:pdf},
isbn = {978-1-5386-9159-5},
keywords = {anytime algorithms,as gpus,demonstrate that scrimp,further expands the purview,larger datasets,matrix profile and allows,motif discovery,of the,performance computing platforms such,time series,us to consider even,we will},
month = {nov},
pages = {837--846},
publisher = {IEEE},
title = {{Matrix Profile XI: SCRIMP++: Time Series Motif Discovery at Interactive Speeds}},
url = {http://www.cs.ucr.edu/{~}eamonn/SCRIMP{\_}ICDM{\_}camera{\_}ready{\_}updated.pdf https://ieeexplore.ieee.org/document/8594908/},
year = {2018}
}
@article{Yong-SungKim1997,
abstract = {An ever increasing number of registered trademarks has created$\backslash$ngreater demand for an automatic trademark retrieval system. We present a$\backslash$nmethod for such a system based on the image content using shape$\backslash$nfeatures. Zernike or pseudo-Zernike moments of the image are employed as$\backslash$na feature set. To retrieve similar shapes, we take into account visually$\backslash$nsalient features that dominantly affect the global shape of the$\backslash$ntrademarks and ignore their minor detail. Experimental results on a$\backslash$ndatabase of 3,000 trademark images demonstrate that the proposed method$\backslash$nretrieves visually similar trademarks which agree well with human$\backslash$nperception},
author = {{Yong-Sung Kim} and {Whoi-Yul Kim}},
xxurl = {10.1109/CVPR.1997.609340},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yong-Sung Kim, Whoi-Yul Kim - 1997 - Content-based trademark retrieval system using visually salient features.pdf:pdf},
isbn = {0-8186-7822-4},
issn = {1063-6919},
journal = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {content-based,image database,image retrieval,trademark,zernike moment},
pages = {307--312},
title = {{Content-based trademark retrieval system using visually salient features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=609340},
volume = {16},
year = {1997}
}
@article{Hertz1999,
abstract = {Motivation: Molecular biologists frequently can obtain interesting insight by aligning a set of related DNA, RNA or protein sequences. Such alignments can be used to determine either evolutionary or functional relationships. Our interest is in identifying functional relationships. Unless the sequences are very similar, it is necessary to have a specific strategy for measuring - or scoring - the relatedness of the aligned sequences. If the alignment is not known, one can be determined by finding an alignment that optimizes the scoring scheme. Results: We describe four components to our approach for determining alignments of multiple sequences. First, we review a log-likelihood scoring scheme we call information content. Second, we describe two methods for estimating the P value of an individual information content score: (i) a method that combines a technique from large-deviation statistics with numerical calculations; (ii) a method that is exclusively numerical. Third, we describe how we count the number of possible alignments given the overall amount of sequence data. This count is multiplied by the P value to determine the expected frequency of an information content score and, thus, the statistical significance of the corresponding alignment. Statistical significance can be used to compare alignments having differing widths and containing differing numbers of sequences. Fourth, we describe a greedy algorithm for determining alignments of functionally related sequences. Finally, we test the accuracy of our P value calculations, and give an example of using our algorithm to identify binding sites for Escherichia coli CRP protein. Availability: Programs were developed under the UNIX operating system and are available by anonymous ftp from ftp://beagle.colorado.edu/pub/consensus.},
author = {Hertz, Gerald Z. and Stormo, Gary D.},
xxurl = {10.1093/bioinformatics/15.7.563},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jul},
number = {7},
pages = {563--577},
title = {{Identifying DNA and protein patterns with statistically significant alignments of multiple sequences}},
url = {https://academic.oup.com/bioinformatics/article-lookup/xxurl/10.1093/bioinformatics/15.7.563},
volume = {15},
year = {1999}
}
@article{Frinken2010a,
author = {Frinken, Volkmar and Fischer, Andreas and Bunke, Horst and Manmatha, R.},
xxurl = {10.1109/ICFHR.2010.61},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frinken et al. - 2010 - Adapting BLSTM Neural Network Based Keyword Spotting Trained on Modern Data to Historical Documents.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frinken et al. - 2010 - Adapting BLSTM Neural Network Based Keyword Spotting Trained on Modern Data to Historical Documents(2).pdf:pdf},
isbn = {978-1-4244-8353-2},
journal = {2010 12th International Conference on Frontiers in Handwriting Recognition},
keywords = {-keyword spotting,adaptation,handwriting,historical data,neural networks,recognition},
month = {nov},
pages = {352--357},
publisher = {Ieee},
title = {{Adapting BLSTM Neural Network Based Keyword Spotting Trained on Modern Data to Historical Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5693548},
year = {2010}
}
@book{DeAntoni1986,
address = {Heidelberg},
author = {A, Carlier},
xxurl = {10.1007/978-3-642-46890-2},
editor = {{De Antoni}, F. and Lauro, N. and Rizzi, A.},
isbn = {978-3-7908-0355-6},
publisher = {Physica-Verlag HD},
title = {{Factor Analysis of Evolution and Cluster Methods on Trajectories}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-46890-2},
year = {1986}
}
@article{Furukori2013,
author = {Furukori, F. and Yamazaki, S. and Miyagishi, T. and Shirai, K. and Okamoto, M.},
xxurl = {10.1109/ICDAR.2013.238},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Furukori et al. - 2013 - An OCR System with OCRopus for Scientific Documents Containing Mathematical Formulas.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1175--1179},
publisher = {Ieee},
title = {{An OCR System with OCRopus for Scientific Documents Containing Mathematical Formulas}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628799},
year = {2013}
}
@article{Gao2013b,
author = {Gao, Yan and Jin, Lianwen and Yang, Weixin},
xxurl = {10.1109/ICDAR.2013.176},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao, Jin, Yang - 2013 - An Empirical Comparative Study of Online Handwriting Chinese Character Recognition Simplified vs. Traditional.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-handwriting},
month = {aug},
pages = {862--866},
publisher = {Ieee},
title = {{An Empirical Comparative Study of Online Handwriting Chinese Character Recognition: Simplified vs. Traditional}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628741},
year = {2013}
}
@article{Konidaris2007a,
author = {Konidaris, T. and Gatos, B. and Ntzios, K. and Pratikakis, I. and Theodoridis, S. and Perantonis, S. J.},
xxurl = {10.1007/s10032-007-0042-4},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konidaris et al. - 2007 - Keyword-guided word spotting in historical printed documents using synthetic data and user feedback.pdf:pdf},
issn = {1433-2833},
journal = {International Journal of Document Analysis and Recognition (IJDAR)},
keywords = {-guided word spotting in,b,gatos,historical printed documents,i,j,k,konidaris,ntzios,perantonis,pratikakis,s,t,theodoridis,user feedback,using synthetic data and},
month = {mar},
number = {2-4},
pages = {167--177},
title = {{Keyword-guided word spotting in historical printed documents using synthetic data and user feedback}},
url = {http://link.springer.com/10.1007/s10032-007-0042-4},
volume = {9},
year = {2007}
}
@article{Gorecki2014b,
abstract = {Over recent years the popularity of time series has soared. As a consequence there has been a dramatic increase in the amount of interest in querying and mining such data. In particular, many new distance measures between time series have been introduced. In this paper we propose a new distance function based on derivatives and transforms of time series. In contrast to well-known measures from the literature, our approach combines three distances: DTW distance between time series, DTW distance between derivatives of time series, and DTW distance between transforms of time series. The new distance is used in classification with the nearest neighbor rule. In order to provide a comprehensive comparison, we conducted a set of experiments, testing effectiveness on 47 time series data sets from a wide variety of application domains. Our experiments show that this new method provides a significantly more accurate classification on the examined data sets. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
author = {G{\'{o}}recki, Tomasz and Luczak, Maciej},
xxurl = {10.1016/j.knosys.2014.02.011},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}recki, Luczak - 2014 - Non-isometric transforms in time series classification using DTW.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Cosine transform,Derivative dynamic time warping,Dynamic time warping,Hilbert transform,Sine transform,Time series},
pages = {98--108},
title = {{Non-isometric transforms in time series classification using DTW}},
volume = {61},
year = {2014}
}
@article{Dau2017,
abstract = {Time series motif discovery has emerged as perhaps the most used primitive for time series data mining, and has seen applications to domains as diverse as robotics, medicine and climatology. There has been recent significant progress on the scalability of motif discovery. However, we believe that the current definitions of motif discovery are limited, and can create a mismatch between the user's intent/expectations, and the motif discovery search outcomes. In this work, we explain the reasons behind these issues, and introduce a novel and general framework to address them. Our ideas can be used with current state-of-the-art algorithms with virtually no time or space overhead, and are fast enough to allow real-time interaction and hypotheses testing on massive datasets. We demonstrate the utility of our ideas on domains as diverse as seismology and epileptic seizure monitoring.},
author = {Dau, Hoang Anh and Keogh, Eamonn},
xxurl = {10.1145/3097983.3097993},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dau, Keogh - 2017 - Matrix Profile V A Generic Technique to Incorporate Domain Knowledge into Motif Discovery.pdf:pdf},
isbn = {9781450348874},
issn = {0277-2116},
journal = {KDD '17 Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {interactive data mining,matrix profile,motif discovery,time series},
pages = {125--134},
title = {{Matrix Profile V : A Generic Technique to Incorporate Domain Knowledge into Motif Discovery}},
url = {http://dl.acm.org/citation.cfm?id=3097993},
year = {2017}
}
@article{World1998,
author = {Oka, R},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oka - 1998 - Spotting method for classification of real world data.pdf:pdf},
journal = {The Computer Journal},
keywords = {and some hmm models,applicable to the category,both an extension of,connected word recognition using,for silence and garbage,like units of recognition,of word-,the third approach includes,this approach is only},
number = {8},
pages = {1--6},
title = {{Spotting method for classification of real world data}},
volume = {41},
year = {1998}
}
@article{Marti2001a,
abstract = {In this paper, a system for the reading of totally unconstrained handwritten text is presented. The kernel of the system is a hidden Markov model (HMM) for handwriting recognition. This HMM is enhanced by a statistical language model. Thus linguistic knowledge beyond the lexicon level is incorporated in the recognition process. Another novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided. A number of experiments with various language models and large vocabularies have been conducted. The language models used in the system were also analytically compared based on their perplexity. Keywords: Cursive handwriting recognition; offline handwriting recognition; uncon- strained sentence recognition; hidden Markov model; statistical language model; bigram statistics.},
author = {Marti, U.V. and Bunke, H.},
journal = {IJPRAI},
keywords = {bigram,bigram staistics,cursive handwriting recognition,hidden Markov model,hidden markov model,offline handwriting recognition,offline hardwriting recognition,statistical language model,strained sentence recognition,uncon-,unconstrained sentence recognition},
month = {jun},
pages = {65--90},
publisher = {World Scientific Publishing Co., Inc.},
title = {{Using a statistical language model to improve the performance of an HMM-based cursive handwriting recognition system}},
volume = {15},
year = {2001}
}
@article{Yanping2015a,
abstract = {The options for treatment of the young patient with late-stage avascular necrosis of the femoral head are limited. The authors performed a conservative type of femoral hemiarthroplasty on a select group of patients. They chose for the series only patients with Ficat stage III and IV avascular necrosis, particularly those who had an intact acetabulum and femoral-head involvement only. Of 19 procedures followed for an average of 36 months, there were 84{\%} good and excellent results. The authors feel that this operative procedure may have a role in the treatment of this specific group of young patients.},
author = {Yanping, Chen and Keogh, Eamonn and Hu, Bing and Begum, Nurjahan and Bagnall, Anthony and Mueen, Abdullah and Batista, Gustavo},
journal = {URL:www.cs.ucr.edu/{\~{}}eamonn/time{\_}series{\_}data/},
title = {{UCR Time Series Classification Archive}},
year = {2015}
}
@book{Havranek1984,
address = {Heidelberg},
author = {K, Ka{\v{s}}melj},
xxurl = {10.1007/978-3-642-51883-6},
editor = {Havr{\'{a}}nek, T. and {\v{S}}id{\'{a}}k, Z. and Nov{\'{a}}k, M.},
isbn = {978-3-7051-0007-7},
pages = {99--105},
publisher = {Physica-Verlag HD},
title = {{Means for Analysis of Space — Time Relationship}},
url = {http://link.springer.com/10.1007/978-3-642-51883-6},
year = {1984}
}
@article{Itani2013a,
author = {Itani, Yusuke and Hirano, Takashi and Ishii, Jun},
xxurl = {10.1109/ICDAR.2013.249},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Itani, Hirano, Ishii - 2013 - Text Line Extraction Method Using Domain-Based Active Contour Model.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {8,active contour model,classifiers,document image analysis,h,height and a,however,in a character group,it assumes bounding box,ratio of block length,takahashi et al,text line extraction},
month = {aug},
pages = {1230--1234},
publisher = {Ieee},
title = {{Text Line Extraction Method Using Domain-Based Active Contour Model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628810},
year = {2013}
}
@article{Gorecki2014d,
author = {G{\'{o}}recki, Tomasz and Krzy{\'{s}}ko, Miros{\l}aw},
xxurl = {10.7151/dmps.1163},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}recki, Krzy{\'{s}}ko - 2014 - A learning algorithm combining functional discriminant coordinates and functional principal components.pdf:pdf},
issn = {1509-9423},
journal = {Discussiones Mathematicae Probability and Statistics},
keywords = {functional discriminant coor-,functional principal components},
number = {1-2},
pages = {127},
title = {{A learning algorithm combining functional discriminant coordinates and functional principal components}},
url = {http://www.discuss.wmie.uz.zgora.pl/ps/index.php?xxurl=10.7151/dmps.1163},
volume = {34},
year = {2014}
}
@article{Smith1997,
abstract = {バイラテラルファイタの提案1998よりも先に同じアイデアを提案した論文 This paper describes a new approach to low level image processing; in particular, edge and corner detection and structure preserving noise reduction. Non-linear ﬁltering is used to deﬁne which parts of the image are closely related to each individual pixel; each pixel has associated with it a local image region which is of similar brightness to that pixel. The new feature detectors are based on the minimization of this local image region, and the noise reduction method uses this region as the smoothing neighbourhood. The resulting methods are accurate, noise resistant and fast. Details of the new feature detectors and of the new noise reduction method are described, along with test results.},
author = {Smith, Stephen M and Brady, J Michael},
xxurl = {10.1023/A:1007963824710},
isbn = {0920-5691},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {c crown copyright 1995,defence research agency,edge detection,farnborough,feature detection,gu14 6td,hampshire,noise reduction,smoothing,uk,univalue areas},
number = {1},
pages = {45--78},
title = {{SUSAN — A New Approach to Low Level Image Processing}},
volume = {23},
year = {1997}
}
@article{Win2018,
abstract = {Automated cell nuclei segmentation is the most crucial step toward the implementation of a computer-aided diagnosis system for cancer cells. Studies on the automated analysis of cytology pleural effusion images are few because of the lack of reliable cell nuclei segmentation methods.Therefore, this paper presents a comparative study of twelve nuclei segmentation methods for cytology pleural effusion images.Each method involves three main steps: preprocessing,segmentation, and postprocessing.The preprocessing and segmentation stages help enhancing the image quality and extracting the nuclei regions from the rest of the image, respectively.The postprocessing stage helps in refining the segmented nuclei and removing false findings.The segmentation methods are quantitatively evaluated for 35 cytology images of pleural effusion by computing five performance metrics. The evaluation results show that the segmentation performances of the Otsu, k-means, mean shift, Chan-Vese,and graph cut methods are 94,94,95,94,and 93{\%},respectively, with high abnormal nuclei detection rates.The average computational times per image are 1.08,36.62,50.18,330, and 44.03 seconds,respectively.The findings of this study will be useful for current and potential future studies on cytology images of pleural effusion.},
author = {Win, Khin Yadanar and Choomchuay, Somsak and Hamamoto, Kazuhiko and Raveesunthornkiat, Manasanan},
xxurl = {10.1155/2018/9240389},
file = {:home/mondal/Downloads/9240389.pdf:pdf},
issn = {20402309},
journal = {Journal of Healthcare Engineering},
title = {{Comparative study on automated cell nuclei segmentation methods for cytology pleural effusion images}},
volume = {2018},
year = {2018}
}
@article{Bukhari2012a,
abstract = {Dewarping of camera-captured document images$\backslash$nis one the important preprocessing steps before feeding them$\backslash$nto a document analysis system. Over the last few years, many$\backslash$napproaches have been proposed for document image dewarping.$\backslash$nUsually optical character recognition (OCR) based and/or$\backslash$nfeature based approaches are used for the evaluation of dewarping$\backslash$nalgorithms. OCR based evaluation is a good measure$\backslash$nfor the performance of a dewarping method on text regions, but$\backslash$nit does not measure how well the dewarping algorithm works$\backslash$non the non-text regions like mathematical equations, graphics,$\backslash$nor tables. Feature based evaluation methods, on the other$\backslash$nhand, do not have this problem, however, they have following$\backslash$nlimitations: i) a lot of manual assistance is required for groundtruth$\backslash$ngeneration, and ii) evaluation metrics are not sufficient$\backslash$nto get meaningful information about dewarping quality. In$\backslash$nthis paper, we present an image based methodology for the$\backslash$nperformance evaluation of dewarping algorithms using SIFT$\backslash$nfeatures. For ground-truths, our method only requires scanned$\backslash$nimages of pages which have been captured by a camera.$\backslash$nThis paper introduces a vectorial performance evaluation score$\backslash$nwhich gives comprehensive information for determining the$\backslash$nperformance of different dewarping methods. We have tested$\backslash$nour performance evaluation methodology on the participating$\backslash$nmethods of CBDAR 2007 document image dewarping contest$\backslash$nand illustrated the correctness of our method.},
author = {Bukhari, Syed Saqib and Shafait, Faisal and Breuel, Thomas M.},
xxurl = {10.1007/978-3-642-29364-1_11},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bukhari, Shafait, Breuel - 2012 - An image based performance evaluation method for page dewarping algorithms using SIFT features.pdf:pdf},
isbn = {9783642293634},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Camera-Captured Document Images,Dewarping,Performance Evaluation,SIFT},
pages = {138--149},
title = {{An image based performance evaluation method for page dewarping algorithms using SIFT features}},
volume = {7139 LNCS},
year = {2012}
}
@article{Hebert2013,
author = {Hebert, David and Nicolas, Stephane and Paquet, Thierry},
xxurl = {10.1109/ICDAR.2013.236},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hebert, Nicolas, Paquet - 2013 - Discrete CRF Based Combination Framework for Document Image Binarization.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1165--1169},
publisher = {Ieee},
title = {{Discrete CRF Based Combination Framework for Document Image Binarization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628797},
year = {2013}
}
@article{Makhzani2013,
abstract = {Recently, it has been observed that when representations are learnt in a way that encourages sparsity, improved performance is obtained on classification tasks. These methods involve combinations of activation functions, sampling steps and different kinds of penalties. To investigate the effectiveness of sparsity by itself, we propose the k-sparse autoencoder, which is an autoencoder with linear activation function, where in hidden layers only the k highest activities are kept. When applied to the MNIST and NORB datasets, we find that this method achieves better classification results than denoising autoencoders, networks trained with dropout, and RBMs. k-sparse autoencoders are simple to train and the encoding stage is very fast, making them well-suited to large problem sizes, where conventional sparse coding algorithms cannot be applied.},
archivePrefix = {arXiv},
arxivId = {1312.5663},
author = {Makhzani, Alireza and Frey, Brendan},
eprint = {1312.5663},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makhzani, Frey - 2013 - k-Sparse Autoencoders.pdf:pdf},
month = {dec},
title = {{k-Sparse Autoencoders}},
year = {2013}
}
@article{Giorgino2009,
annote = {From Duplicate 2 ( 

Computing and Visualizing Dynamic Time Warping Alignments in R : The dtw Package

- Giorgino, Toni )

},
author = {Giorgino, Toni},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giorgino - 1996 - Computing and Visualizing Dynamic Time Warping Alignments in R The dtw Package.pdf:pdf},
journal = {Journal of Statistical Software},
keywords = {alignment,dynamic programming,dynamic time warping,timeseries},
title = {{Computing and visualizing dynamic time warping alignments in R: the dtw package}},
url = {ftp://ftp.up.ac.za/pub/windows/CRAN/web/packages/dtw/vignettes/dtw.pdf},
year = {2009}
}
@article{Chen2013b,
author = {Chen, Jinying and Prasad, Rohit and Cao, Huaigu and Natarajan, Premkumar},
xxurl = {10.1109/ICDAR.2013.200},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2013 - Detecting OOV Names in Arabic Handwritten Data.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {consensus network,handwritten,keyword spotting,oov,reranking},
month = {aug},
pages = {994--998},
publisher = {Ieee},
title = {{Detecting OOV Names in Arabic Handwritten Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628765},
year = {2013}
}
@article{Ghosh2018,
abstract = {This paper proposes a region based convolutional neural network for segmentation-free word spotting. Our net- work takes as input an image and a set of word candidate bound- ing boxes and embeds all bounding boxes into an embedding space, where word spotting can be casted as a simple nearest neighbour search between the query representation and each of the candidate bounding boxes. We make use of PHOC embedding as it has previously achieved significant success in segmentation- based word spotting. Word candidates are generated using a simple procedure based on grouping connected components using some spatial constraints. Experiments show that R-PHOC which operates on images directly can improve the current state-of- the-art in the standard GW dataset and performs as good as PHOCNET in some cases designed for segmentation based word spotting.},
archivePrefix = {arXiv},
arxivId = {1707.01294},
author = {Ghosh, Suman K. and Valveny, Ernest},
xxurl = {10.1109/ICDAR.2017.136},
eprint = {1707.01294},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosh, Valveny - 2018 - R-PHOC Segmentation-Free Word Spotting Using CNN.pdf:pdf},
isbn = {9781538635865},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {Bounding box,Connected component,Phoc embedding,Qbe word spotting,R phoc network,Region based cnn,Segmentation free,Segmentation free word spotting,Word spotting},
pages = {801--806},
title = {{R-PHOC: Segmentation-Free Word Spotting Using CNN}},
volume = {1},
year = {2018}
}
@incollection{Tombre2008,
author = {Tombre, Karl and Lamiroy, Bart},
xxurl = {10.1007/978-3-540-85920-8_62},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tombre, Lamiroy - 2008 - Pattern Recognition Methods for Querying and Browsing Technical Documentation.pdf:pdf},
pages = {504--518},
publisher = {Springer, Berlin, Heidelberg},
title = {{Pattern Recognition Methods for Querying and Browsing Technical Documentation}},
url = {http://link.springer.com/10.1007/978-3-540-85920-8{\_}62},
year = {2008}
}
@article{Dollar2012,
author = {Dollar, P. and Wojek, C. and Schiele, B. and Perona, P.},
xxurl = {10.1109/TPAMI.2011.155},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {apr},
number = {4},
pages = {743--761},
title = {{Pedestrian Detection: An Evaluation of the State of the Art}},
url = {http://ieeexplore.ieee.org/document/5975165/},
volume = {34},
year = {2012}
}
@article{Krayem2013,
author = {Krayem, Abdulwahab and Sherkat, Nasser and Evett, Lindsay and Osman, Taha},
xxurl = {10.1109/ICDAR.2013.227},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krayem et al. - 2013 - Holistic Arabic Whole Word Recognition Using HMM and Block-Based DCT.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {analogy,arabic fonts,arabic ocr,asr,block-based dct,holistic approach,htk toolkit,markov models,ocr,recognition,they have applied hidden,to the automatic speech,vector quantizer},
month = {aug},
pages = {1120--1124},
publisher = {Ieee},
title = {{Holistic Arabic Whole Word Recognition Using HMM and Block-Based DCT}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628788},
year = {2013}
}
@article{Banko2012,
abstract = {In recent years, dynamic time warping (DTW) has begun to become the most widely used technique for comparison of time series data where extensive a priori knowledge is not available. However, it is often expected a multivariate comparison method to consider the correlation between the variables as this correlation carries the real information in many cases. Thus, principal component analysis (PCA) based similarity measures, such as PCA similarity factor (SPCA), are used in many industrial applications. In this paper, we present a novel algorithm called correlation based dynamic time warping (CBDTW) which combines DTW and PCA based similarity measures. To preserve correlation, multivariate time series are segmented and the local dissimilarity function of DTW originated from SPCA. The segments are obtained by bottom-up segmentation using special, PCA related costs. Our novel technique qualified on two databases, the database of signature verification competition 2004 and the commonly used AUSLAN dataset. We show that CBDTW outperforms the standard SPCA and the most commonly used, Euclidean distance based multivariate DTW in case of datasets with complex correlation structure. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Bank{\'{o}}, Zolt{\'{a}}n and Abonyi, J{\'{a}}nos},
xxurl = {10.1016/j.eswa.2012.05.012},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bank{\'{o}}, Abonyi - 2012 - Correlation based dynamic time warping of multivariate time series.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Dynamic time warping,Multivariate time series,Principal component analysis,Segmentation,Similarity},
number = {17},
pages = {12814--12823},
title = {{Correlation based dynamic time warping of multivariate time series}},
volume = {39},
year = {2012}
}
@article{Mueen2014,
abstract = {We consider the problem of joining two long time series based on their most correlated segments. Two time series can be joined at any locations and for arbitrary length. Such join locations and length provide useful knowledge about the synchrony of the two time series and have applications in many domains including environmental monitoring, patient monitoring and power monitoring. However, join on correlation is a computationally expensive task, specially when the time series are large. The naive algorithm requires O (n4) computation where n is the length of the time series. We propose an algorithm, named Jocor, that uses two algorithmic techniques to tackle the complexity. First, the algorithm reuses the computation by caching sufficient statistics and second, the algorithm prunes unnecessary correlation computation by admissible heuristics. The algorithm runs orders of magnitude faster than the naive algorithm and enables us to join long time series as well as many small time series. We propose a variant of Jocor for fast approximation and an extension to a GPU-based parallel method to bring down the running-time to interactive level for analytics applications. We show three independent uses of time series join on correlation which are made possible by our algorithm.},
author = {Mueen, Abdullah and Hamooni, Hossein and Estrada, Trilce},
xxurl = {10.1109/ICDM.2014.52},
file = {:home/mondal/Downloads/joinICDM.pdf:pdf},
isbn = {9781479943029},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Alignment,Correlation,Matching,Similarity,Time Series},
number = {January},
pages = {450--459},
title = {{Time Series Join on Subsequence Correlation}},
volume = {2015-Janua},
year = {2014}
}
@article{Wienert2012,
abstract = {Automated image analysis of cells and tissues has been an active research field in medical informatics for decades but has recently attracted increased attention due to developments in computer and microscopy hardware and the awareness that scientific and diagnostic pathology require novel approaches to perform objective quantitative analyses of cellular and tissue specimens. Model-based approaches use a priori information on cell shape features to obtain the segmentation, which may introduce a bias favouring the detection of cell nuclei only with certain properties. In this study we present a novel contour-based minimum-modelg cell detection and segmentation approach that uses minimal a priori information and detects contours independent of their shape. This approach avoids a segmentation bias with respect to shape features and allows for an accurate segmentation (precision = 0.908; recall = 0.859; validation based on ∼8000 manually-labeled cells) of a broad spectrum of normal and disease-related morphological features without the requirement of prior training.},
author = {Wienert, Stephan and Heim, Daniel and Saeger, Kai and Stenzinger, Albrecht and Beil, Michael and Hufnagl, Peter and Dietel, Manfred and Denkert, Carsten and Klauschen, Frederick},
xxurl = {10.1038/srep00503},
file = {:home/mondal/Downloads/srep00503.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
pages = {1--7},
title = {{Detection and segmentation of cell nuclei in virtual microscopy images: A minimum-model approach}},
volume = {2},
year = {2012}
}
@inproceedings{Rakthanmanon2013,
abstract = {Time series shapelets are a recent promising concept in time series data mining. Shapelets are time series snippets that can be used to classify unlabeled time series. Shapelets not only provide interpretable results, which are useful for domain experts and developers alike, but shapelet-based classifiers have been shown by several independent research groups to have superior accuracy on many datasets. Moreover, shapelets can be seen as generalizing the lazy nearest neighbor classifier to an eager classifier. Thus, as a deployed classification tool, shapelets can be many orders of magnitude faster than any rival with comparable accuracy. Although shapelets are a useful concept, the current literature bemoans the fact that shapelet discovery is a time-consuming task. In spite of several efforts to speed up shapelet discovery algorithms, including the use of specialist hardware, the current state-of-the-art algorithms are still intractable on large datasets. In this work, we propose a fast shapelet discovery algorithm that outperforms the current state-of-the-art by two or three orders of magnitude, while producing models with accuracy that is not perceptibly different.},
author = {Rakthanmanon, Thanawin and Keogh, Eamonn},
booktitle = {Proceedings of the 2013 SIAM International Conference on Data Mining, SDM 2013},
xxurl = {10.1137/1.9781611972832.74},
isbn = {9781611972627},
title = {{Fast shapelets: A scalable algorithm for discovering time series shapelets}},
year = {2013}
}
@article{Surinta2013b,
author = {Surinta, Olarik and Schomaker, Lambert and Wiering, Marco},
xxurl = {10.1109/ICDAR.2013.40},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Surinta, Schomaker, Wiering - 2013 - A Comparison of Feature and Pixel-Based Methods for Recognizing Handwritten Bangla Digits.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-handwritten bangla digit recognition,character,classification,feature extraction technique,pixel-based method,recognition,support vector machines},
month = {aug},
pages = {165--169},
publisher = {Ieee},
title = {{A Comparison of Feature and Pixel-Based Methods for Recognizing Handwritten Bangla Digits}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628605},
volume = {165},
year = {2013}
}
@article{Li2017,
abstract = {Lower bound function is one of the important techniques used to fast search and index time series data. Multivariate time series has two aspects of high dimensionality including the time-based dimension and the variable-based dimension. Due to the influence of variable-based dimension, a novel method is proposed to deal with the lower bound distance computation for multivariate time series. The proposed method like the traditional ones also reduces the dimensionality of time series in its first step and thus does not directly apply the lower bound function on the multivariate time series. The dimensionality reduction is that multivariate time series is reduced to univariate time series denoted as center sequences according to the principle of piecewise aggregate approximation. In addition, an extended lower bound function is designed to obtain good tightness and fast measure the distance between any two center sequences. The experimental results demonstrate that the proposed lower bound function has better tightness and improves the performance of similarity search in multivariate time series datasets.},
author = {Li, Hailin},
xxurl = {10.1016/j.physa.2016.10.062},
file = {:home/mondal/Downloads/1-s2.0-S037843711630749X-main.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Center sequence,Data mining,Lower bound function,Multivariate time series,Piecewise aggregate approximation},
pages = {622--637},
publisher = {Elsevier B.V.},
title = {{Distance measure with improved lower bound for multivariate time series}},
url = {http://dx.xxurl.org/10.1016/j.physa.2016.10.062},
volume = {468},
year = {2017}
}
@misc{Chen,
author = {Chen, Yanping and Keogh, Eamonn and Hu, Bing and Begum, Nurjahan and Bagnall, Anthony and Mueen, Abdullah and Batista, Gustavo},
title = {{The UCR Time Series Classification Archive}},
url = {http://www.cs.ucr.edu/{~}eamonn/time{\_}series{\_}data/},
urldate = {2015-09-03},
year = {2105}
}
@article{Ulges2005,
abstract = { Digital cameras have become almost ubiquitous and their use for fast and casual capturing of natural images is unchallenged. For making images of documents, however, they have not caught up to flatbed scanners yet, mainly because camera images tend to suffer from distortion due to the perspective and are therefore limited in their further use for archival or OCR. For images of non-planar paper surfaces like books, page curl causes additional distortion, which poses an even greater problem due to its nonlinearity. This paper presents a new algorithm for removing both perspective and page curl distortion. It requires only a single camera image as input and relies on a priori layout information instead of additional hardware. Therefore, it is much more user friendly than most previous approaches, and allows for flexible ad hoc document capture. Results are presented showing that the algorithm produces visually pleasing output and increases OCR accuracy, thus having the potential to become a general purpose preprocessing tool for camera based document capture.},
author = {Ulges, Adrian and Lamport, Christoph H. and Breuel, Thomas M.},
xxurl = {10.1109/ICDAR.2005.90},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ulges, Lamport, Breuel - 2005 - Document image dewarping using robust estimation of curled text lines.pdf:pdf},
isbn = {0769524206},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
pages = {1001--1005},
title = {{Document image dewarping using robust estimation of curled text lines}},
volume = {2005},
year = {2005}
}
@article{Pew-ThianYap2010,
author = {{Pew-Thian Yap} and {Xudong Jiang} and Kot, Alex Chichung},
xxurl = {10.1109/TPAMI.2009.119},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {jul},
number = {7},
pages = {1259--1270},
title = {{Two-Dimensional Polar Harmonic Transforms for Invariant Image Representation}},
url = {http://ieeexplore.ieee.org/document/4967611/},
volume = {32},
year = {2010}
}
@inproceedings{Jeong2011,
abstract = {Dynamic time warping (DTW), which finds the minimum path by providing non-linear alignments between two time series, has been widely used as a distance measure for time series classification and clustering. However, DTW does not account for the relative importance regarding the phase difference between a reference point and a testing point. This may lead to misclassification especially in applications where the shape similarity between two sequences is a major consideration for an accurate recognition. Therefore, we propose a novel distance measure, called a weighted DTW (WDTW), which is a penalty-based DTW. Our approach penalizes points with higher phase difference between a reference point and a testing point in order to prevent minimum distance distortion caused by outliers. The rationale underlying the proposed distance measure is demonstrated with some illustrative examples. A new weight function, called the modified logistic weight function (MLWF), is also proposed to systematically assign weights as a function of the phase difference between a reference point and a testing point. By applying different weights to adjacent points, the proposed algorithm can enhance the detection of similarity between two time series. We show that some popular distance measures such as DTW and Euclidean distance are special cases of our proposed WDTW measure. We extend the proposed idea to other variants of DTW such as derivative dynamic time warping (DDTW) and propose the weighted version of DDTW. We have compared the performances of our proposed procedures with other popular approaches using public data sets available through the UCR Time Series Data Mining Archive for both time series classification and clustering problems. The experimental results indicate that the proposed approaches can achieve improved accuracy for time series classification and clustering problems. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Jeong, Young Seon and Jeong, Myong K and Omitaomu, Olufemi A},
booktitle = {Pattern Recognition},
isbn = {0031-3203},
keywords = {Adaptive weights,Dynamic time warping,Modified logistic weight function,Time series classification,Time series clustering,Weighted dynamic time warping},
number = {9},
pages = {2231--2240},
publisher = {Elsevier},
title = {{Weighted dynamic time warping for time series classification}},
volume = {44},
year = {2011}
}
@inproceedings{JianboShi1994,
abstract = {Abstract No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. W e propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world.},
author = {{Jianbo Shi} and Tomasi},
booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition CVPR-94},
xxurl = {10.1109/CVPR.1994.323794},
isbn = {0-8186-5825-8},
issn = {1063-6919},
pages = {593--600},
pmid = {11968495},
title = {{Good features to track}},
url = {http://ieeexplore.ieee.org/document/323794/},
year = {1994}
}
@article{Banerjee2008,
author = {Banerjee, Jyotirmoy and Jawahar, C V},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banerjee, Jawahar - 2008 - Restoration of Document Images using Bayesian Inference.pdf:pdf},
title = {{Restoration of Document Images using Bayesian Inference}},
year = {2008}
}
@article{Gaceb2013b,
author = {Gaceb, Djamel and Lebourgeois, Frank and Duong, Jean},
xxurl = {10.1109/ICDAR.2013.31},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gaceb, Lebourgeois, Duong - 2013 - Adaptative Smart-Binarization Method For Images of Business Documents.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {document image,industrial application,processin,realaxation,smart-binarization},
month = {aug},
pages = {118--122},
publisher = {Ieee},
title = {{Adaptative Smart-Binarization Method: For Images of Business Documents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628596},
year = {2013}
}
@inproceedings{Niennattrakul2007,
author = {Niennattrakul, Vit and Ratanamahatana, Chotirat Ann},
booktitle = {2007 International Conference on Multimedia and Ubiquitous Engineering (MUE'07)},
xxurl = {10.1109/MUE.2007.165},
isbn = {0-7695-2777-9},
language = {English},
pages = {733--738},
publisher = {IEEE},
title = {{On Clustering Multimedia Time Series Data Using K-Means and Dynamic Time Warping}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4197360},
year = {2007}
}
@article{Naylor2019,
abstract = {The advent of digital pathology provides us with the challenging opportunity to automatically analyze whole slides of diseased tissue in order to derive quantitative profiles that can be used for diagnosis and prognosis tasks. In particular, for the development of interpretable models, the detection and segmentation of cell nuclei is of the utmost importance. In this paper, we describe a new method to automatically segment nuclei from Haematoxylin and Eosin (HE) stained histopathology data with fully convolutional networks. In particular, we address the problem of segmenting touching nuclei by formulating the segmentation problem as a regression task of the distance map. We demonstrate superior performance of this approach as compared to other approaches using Convolutional Neural Networks.},
author = {Naylor, Peter and La{\'{e}}, Marick and Reyal, Fabien and Walter, Thomas},
xxurl = {10.1109/TMI.2018.2865709},
file = {:home/mondal/Downloads/08438559.pdf:pdf},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Cancer research,deep learning,digital pathology,histopathology,nuclei segmentation},
number = {2},
pages = {448--459},
title = {{Segmentation of Nuclei in Histopathology Images by Deep Regression of the Distance Map}},
volume = {38},
year = {2019}
}
@article{Socher2013,
abstract = {Machine learning is everywhere in today's NLP, but by and large machine learning amounts to numerical optimization of weights for human designed representations and features. The goal of deep learning is to explore how computers can take advantage of data to develop features and representations appropriate for complex interpretation tasks. This tutorial aims to cover the basic motivation, ideas, models and learning algorithms in deep learning for natural language processing. Recently, these methods have been shown to perform very well on various NLP tasks such as language modeling, POS tagging, named entity recognition, sentiment analysis and paraphrase detection, among others. The most attractive quality of these techniques is that they can perform well without any external hand-designed resources or time-intensive feature engineering. Despite these advantages, many researchers in NLP are not familiar with these methods. Our focus is on insight and understanding, using graphical illustrations and simple, intuitive derivations. The goal of the tutorial is to make the inner workings of these techniques transparent, intuitive and their results interpretable, rather than black boxes labeled "magic here". The first part of the tutorial presents the basics of neural networks, neural word vectors, several simple models based on local windows and the math and algorithms of training via backpropagation. In this section applications include language modeling and POS tagging. In the second section we present recursive neural networks which can learn structured tree outputs as well as vector representations for phrases and sentences. We cover both equations as well as applications. We show how training can be achieved by a modified version of the backpropagation algorithm introduced before. These modifications allow the algorithm to work on tree structures. Applications include sentiment analysis and paraphrase detection. We also draw connections to recent work in semantic compositionality in vector spaces. The principle goal, again, is to make these methods appear intuitive and interpretable rather than mathematically confusing. By this point in the tutorial, the audience members should have a clear understanding of how to build a deep learning system for word-, sentence- and document-level tasks. The last part of the tutorial gives a general overview of the different applications of deep learning in NLP, including bag of words models. We will provide a discussion of NLP-oriented issues in modeling, interpretation, representational power, and optimization.},
archivePrefix = {arXiv},
arxivId = {1206.5533},
author = {Socher, Richard and Manning, Christopher},
xxurl = {10.1007/978-3-642-35289-8-26},
eprint = {1206.5533},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Socher, Manning - 2013 - Deep Learning for NLP (without magic).pdf:pdf},
isbn = {9783642352881},
issn = {03029743},
journal = {Naacl 2013},
pages = {1--204},
pmid = {25497547},
title = {{Deep Learning for NLP (without magic)}},
url = {http://nlp.stanford.edu/courses/NAACL2013/},
year = {2013}
}
@article{Ramage2007,
abstract = {How can we apply machine learning to data that is represented as a sequence of observations over time? For instance, we migth be interested in discovering the sequence of words that someone spoke based on an audio recording of their speech. Or we might be interested in annotating a sequence of words with their part-of-speech-tags. These notes provides a thorough mathematical introduction to the concept of Markov Models -a formalism for reasoning about states over time- and Hidden Markov Models - where we wish to recover a series of states from a series of observations. The final section includes some pointers to resources that preset this material from other perspectives.},
author = {Ramage, Daniel},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramage - 2007 - Hidden Markov models fundamentals.pdf:pdf},
journal = {Lecture Notes. http://cs229. stanford. edu/section/ {\ldots}},
pages = {1--13},
title = {{Hidden Markov models fundamentals}},
url = {http://see.stanford.edu/materials/aimlcs229/cs229-hmm.pdf},
year = {2007}
}
@article{DBLP:journals/tip/MondalJS11,
author = {Mondal, Tanmoy and Jain, Ashish and Sardana, H K},
xxurl = {10.1109/TIP.2011.2131662},
journal = {{\{}IEEE{\}} Trans. Image Processing},
number = {9},
pages = {2606--2614},
title = {{Automatic Craniofacial Structure Detection on Cephalometric Images}},
url = {https://xxurl.org/10.1109/TIP.2011.2131662},
volume = {20},
year = {2011}
}
@article{Almazan,
abstract = {—This article addresses the problems of word spotting and word recognition on images. In word spotting, the goal is to find all instances of a query word in a dataset of images. In recognition, the goal is to recognize the content of the word image, usually aided by a dictionary or lexicon. We describe an approach in which both word images and text strings are embedded in a common vectorial subspace. This is achieved by a combination of label embedding and attributes learning, and a common subspace regression. In this subspace, images and strings that represent the same word are close together, allowing one to cast recognition and retrieval tasks as a nearest neighbor problem. Contrary to most other existing methods, our representation has a fixed length, is low dimensional, and is very fast to compute and, especially, to compare. We test our approach on four public datasets of both handwritten documents and natural images showing results comparable or better than the state-of-the-art on spotting and recognition tasks.},
author = {Almaz{\'{a}}n, Jon and Almaz{\'{a}}n, Almaz´ and Gordo, Albert and Forn{\'{e}}s, Alicia and Forn{\'{e}}s, Forn´ and Valveny, Ernest},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almaz{\'{a}}n et al. - Unknown - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Word Spotting and Recognition with Embedded.pdf:pdf},
keywords = {Attribute-based representation,Handwritten Text,Index Terms-Word image representation,Scene Text,Word Recognition !,Word Spotting},
pages = {1--17},
title = {{IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Word Spotting and Recognition with Embedded Attributes}}
}
@inproceedings{Alcantarilla2012,
abstract = {In this paper, we introduce KAZE features, a novelmultiscale 2D fea- ture detection and description algorithm in nonlinear scale spaces. Previous ap- proaches detect and describe features at different scale levels by building or ap- proximating the Gaussian scale space of an image. However, Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same de- gree both details and noise, reducing localization accuracy and distinctiveness. In contrast, we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering. In thisway, we can make blurring locally adaptive to the image data, reducing noise but retaining object boundaries, obtaining su- perior localization accuracy and distinctiviness. The nonlinear scale space is built using efficient Additive Operator Splitting (AOS) techniques and variable con- ductance diffusion. We present an extensive evaluation on benchmark datasets and a practical matching application on deformable surfaces. Even though our features are somewhat more expensive to compute than SURF due to the con- struction of the nonlinear scale space, but comparable to SIFT, our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods.},
author = {Alcantarilla, Pablo Fern{\'{a}}ndez and Bartoli, Adrien and Davison, Andrew J.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
xxurl = {10.1007/978-3-642-33783-3_16},
isbn = {9783642337826},
issn = {03029743},
number = {PART 6},
pages = {214--227},
title = {{KAZE features}},
volume = {7577 LNCS},
year = {2012}
}
@article{Mauro2013,
author = {Mauro, Nicola Di and Esposito, Floriana and Ferilli, Stefano},
xxurl = {10.1109/ICDAR.2013.180},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mauro, Esposito, Ferilli - 2013 - Finding Critical Cells in Web Tables with SRL Trying to Uncover the Devil's Tease.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {882--886},
publisher = {Ieee},
title = {{Finding Critical Cells in Web Tables with SRL: Trying to Uncover the Devil's Tease}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628745},
year = {2013}
}
@article{Jalba2005,
abstract = {A method for automatic identification of diatoms (single-celled algae with silica shells) based on extraction of features on the contour of the cells by multi-scale mathematical morphology is presented. After extracting the contour of the cell, it is smoothed adaptively, encoded using Freeman chain code, and converted into a curvature representation which is invariant under translation and scale change. A curvature scale space is built from these data, and the most important features are extracted from it by unsupervised cluster analysis. The resulting pattern vectors, which are also rotation-invariant, provide the input for automatic identification of diatoms by decision trees and k-nearest neighbor classifiers. The method is tested on two large sets of diatom images. The techniques used are applicable to other shapes besides diatoms.},
author = {Jalba, Andrei C. and Wilkinson, Michael H. F. and Roerdink, Jos B. T. M. and Bayer, Micha M. and Juggins, Stephen},
xxurl = {10.1007/s00138-005-0175-8},
isbn = {0932-8092},
issn = {0932-8092},
journal = {Machine Vision and Applications},
month = {jun},
number = {4},
pages = {217--228},
title = {{Automatic diatom identification using contour analysis by morphological curvature scale spaces}},
url = {http://link.springer.com/10.1007/s00138-005-0175-8},
volume = {16},
year = {2005}
}
@article{Li2013,
author = {Li, Liang and Panichkriangkrai, Chulapong and Hachimura, Kozaburo},
xxurl = {10.1109/ICDAR.2013.37},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Panichkriangkrai, Hachimura - 2013 - Ukiyo-e Rakkan Retrieval System.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {150--154},
publisher = {Ieee},
title = {{Ukiyo-e Rakkan Retrieval System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628602},
year = {2013}
}
@article{Mirza2014a,
abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
archivePrefix = {arXiv},
arxivId = {1411.1784},
author = {Mirza, Mehdi and Osindero, Simon},
eprint = {1411.1784},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirza, Osindero - 2014 - Conditional Generative Adversarial Nets.pdf:pdf},
month = {nov},
title = {{Conditional Generative Adversarial Nets}},
year = {2014}
}
@article{Paramanandam2016,
abstract = {The process of Nuclei detection in high-grade breast cancer images is quite challenging in the case of image processing techniques due to certainheterogeneous characteristics of cancer nuclei such as enlarged and irregularlyshaped nuclei, highly coarse chromatin marginalized to the nuclei peripheryand visible nucleoli. Recent reviews state that existing techniques show appreciable segmentation accuracy on breast histopathology images whose nuclei are dispersed and regular in texture and shape; however, typical cancer nuclei are often clustered and have irregular texture and shape properties.This paper proposes a novel segmentation algorithm for detecting individual nuclei from Hematoxylin and Eosin (H{\&}E) stained breast histopathology images. This detection framework estimates a nuclei saliency map using tensor voting followed by boundary extraction of the nuclei on the saliency map using a Loopy Back Propagation (LBP) algorithmon a Markov Random Field (MRF). The method was tested on both whole-slide images and frames of breast cancer histopathology images. Experimentalresults demonstrate high segmentation performance with efficient precision, recall and dice-coefficient rates, upon testing high-grade breast cancer images containing several thousand nuclei. In addition to the optimal performance on the highly complex images presented in this paper, this method also gave appreciable results in comparison with two recently published methods-Wienert et al. (2012) and Veta et al. (2013), which were tested using their own datasets.},
author = {Paramanandam, Maqlin and O'Byrne, Michael and Ghosh, Bidisha and Mammen, Joy John and Manipadam, Marie Therese and Thamburaj, Robinson and Pakrashi, Vikram},
xxurl = {10.1371/journal.pone.0162053},
file = {:home/mondal/Downloads/journal.pone.0162053.PDF:PDF},
issn = {19326203},
journal = {PLoS ONE},
number = {9},
pages = {1--15},
title = {{Automated segmentation of nuclei in breast cancer histopathology images}},
volume = {11},
year = {2016}
}
@article{Presentation2001,
author = {Presentation, Mser},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Presentation - 2001 - MSER Operator Maximally Stable Extremal Regions Examples of MSER Regions.pdf:pdf},
title = {{MSER Operator : Maximally Stable Extremal Regions Examples of MSER Regions}},
year = {2001}
}
@article{Khan2013a,
author = {Khan, Salman H. and Khan, Zeashan and Shafait, Faisal},
xxurl = {10.1109/ICDAR.2013.198},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan, Khan, Shafait - 2013 - Can Signature Biometrics Address Both Identification and Verification Problems.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {2,3,can tackle,canonical correlation,compressed sensing,distance matching,face recognition based systems,focused on identity verification,handwritten signatures,in contrast,problem,sparse representation,that they are solely},
month = {aug},
pages = {981--985},
publisher = {Ieee},
title = {{Can Signature Biometrics Address Both Identification and Verification Problems?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628763},
year = {2013}
}
@article{Kalantidis2011,
abstract = {We propose a scalable logo recognition approach that extends the common bag-of-words model and incorporates local geometry in the indexing process. Given a query image and a large logo database, the goal is to recognize the logo contained in the query, if any. We locally group features in triples using multi-scale Delaunay triangulation and represent triangles by signatures capturing both visual appearance and local geometry. Each class is represented by the union of such signatures over all instances in the class. We see large scale recognition as a sub-linear search problem where signatures of the query image are looked up in an inverted index structure of the class models. We evaluate our approach on a large-scale logo recognition dataset with more than four thousand classes.},
author = {Kalantidis, Yannis and Pueyo, Lluis Garcia and Trevisiol, Michele and van Zwol, Roelof and Avrithis, Yannis},
xxurl = {10.1145/1991996.1992016},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalantidis et al. - 2011 - Scalable triangulation-based logo recognition.pdf:pdf},
isbn = {9781450303361},
journal = {Proceedings of the 1st ACM International Conference on Multimedia Retrieval - ICMR '11},
pages = {1--7},
title = {{Scalable triangulation-based logo recognition}},
url = {http://portal.acm.org/citation.cfm?xxurld=1991996.1992016},
year = {2011}
}
@article{Lv2013,
author = {Lv, Yan-Fei and Huang, Lin-Lin and Wang, Da-Han and Liu, Cheng-Lin},
xxurl = {10.1109/ICDAR.2013.23},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lv et al. - 2013 - Learning-Based Candidate Segmentation Scoring for Real-Time Recognition of Online Overlaid Chinese Handwriting.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {geometric scores,online overlaid chinese,segmentation,stroke cut},
month = {aug},
pages = {74--78},
publisher = {Ieee},
title = {{Learning-Based Candidate Segmentation Scoring for Real-Time Recognition of Online Overlaid Chinese Handwriting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628588},
volume = {1},
year = {2013}
}
@article{Teja2013,
author = {Teja, S. Prabhu and Namboodiri, Anoop M.},
xxurl = {10.1109/ICDAR.2013.175},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Teja, Namboodiri - 2013 - A Ballistic Stroke Representation of Online Handwriting for Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {857--861},
publisher = {Ieee},
title = {{A Ballistic Stroke Representation of Online Handwriting for Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628740},
year = {2013}
}
@inproceedings{LZPK2018,
author = {Linardi, Michele and Zhu, Yan and Palpanas, Themis and Keogh, Eamonn J},
booktitle = {Proceedings of the International Conference on Management of Data (SIGMOD)},
pages = {1053--1066},
title = {{Matrix Profile {\{}X:{\}} {\{}VALMOD{\}} - Scalable Discovery of Variable-Length Motifs in Data Series}},
year = {2018}
}
@article{Roy2011,
author = {Roy, Partha Pratim and Ramel, Jean-Yves and Ragot, Nicolas},
xxurl = {10.1109/ICDAR.2011.142},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy, Ramel, Ragot - 2011 - Word Retrieval in Historical Document Using Character-Primitives.pdf:pdf},
isbn = {978-1-4577-1350-7},
journal = {2011 International Conference on Document Analysis and Recognition},
month = {sep},
pages = {678--682},
publisher = {Ieee},
title = {{Word Retrieval in Historical Document Using Character-Primitives}},
year = {2011}
}
@inproceedings{Mair2010,
abstract = {The efficient detection of interesting features is a crucial step for various tasks in Computer Vision. Corners are favored cues due to their two dimensional constraint and fast algorithms to detect them. Recently, a novel corner detection approach, FAST, has been presented which outperforms previous algorithms in both computational performance and repeatability. We will show how the accelerated segment test, which underlies FAST, can be significantly improved by making it more generic while increasing its performance.We do so by finding the optimal decision tree in an extended configuration space, and demonstrating how specialized trees can be combined to yield an adaptive and generic accelerated segment test. The resulting method provides high performance for arbitrary environments and so unlike FAST does not have to be adapted to a specific scene structure. We will also discuss how different test patterns affect the corner response of the accelerated segment test.},
author = {Mair, Elmar and Hager, Gregory D. and Burschka, Darius and Suppa, Michael and Hirzinger, Gerhard},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
xxurl = {10.1007/978-3-642-15552-9_14},
isbn = {3642155510},
issn = {03029743},
keywords = {AGAST,AST,adaptive,corner detector,effcient,generic},
number = {PART 2},
pages = {183--196},
title = {{Adaptive and generic corner detection based on the accelerated segment test}},
volume = {6312 LNCS},
year = {2010}
}
@article{Attalla2005,
abstract = {In this paper, we are going to present a novel shape similarity retrieval algorithm that can be used to match and recognize 2D objects. The match process uses a new multi-resolution polygonal shape descriptor that is invariant to scale, rotation and translation. The shape descriptor equally segments the contour of any shape, regardless of its complexity, and captures three features around its center including the distance and slope relative to the center. All parameters are normalized relative to the max values. The novel shape matching algorithm uses the shape descriptor and applies it by linearly scanning a stored set of shapes and measuring the similarity using elastic comparisons of shape segments. Similarity measurement is achieved by the sum of differences distance measure. The multi-resolution segmentation provides flexibility for applications that have different time and space requirements while maintaining high accuracy results and the elastic matching adds an advantage when matching partially occluded shapes. We applied our algorithms on many test databases including the MPEG-7 shape core experiment and achieved the highest result reported with a score of 84.33{\%} for the MPEG-7 Part B similarity test.},
author = {Attalla, Emad and Siy, Pepe},
xxurl = {10.1016/j.patcog.2005.02.009},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Attalla, Siy - 2005 - Robust shape similarity retrieval based on contour segmentation polygonal multiresolution and elastic matching.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Shape polygonal approximation,Shape representation and matching,Shape similarity retrieval},
month = {dec},
number = {12},
pages = {2229--2241},
title = {{Robust shape similarity retrieval based on contour segmentation polygonal multiresolution and elastic matching}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320305000919},
volume = {38},
year = {2005}
}
@article{GuHCSCH17,
author = {Gu, Zhuoer and He, Ligang and Chang, Cheng and Sun, Jianhua and Chen, Hao and Huang, Chenlin},
xxurl = {10.1007/s10766-016-0439-0},
journal = {International Journal of Parallel Programming},
number = {4},
pages = {853--878},
title = {{Developing an Efficient Pattern Discovery Method for {\{}CPU{\}} Utilizations of Computers}},
url = {https://xxurl.org/10.1007/s10766-016-0439-0},
volume = {45},
year = {2017}
}
@article{Santosh2013d,
author = {Santosh, K.C. and Belaid, Abdel},
xxurl = {10.1109/ICDAR.2013.16},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santosh, Belaid - 2013 - Document Information Extraction and Its Evaluation Based on Client's Relevance.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {1},
pages = {35--39},
publisher = {Ieee},
title = {{Document Information Extraction and Its Evaluation Based on Client's Relevance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628581},
year = {2013}
}
@article{Million2006123,
annote = {From Duplicate 1 ( 

Matching word images for content-based retrieval from printed document images

- Meshesha, Million; Jawahar, C V )






From Duplicate 1 ( 















































































































































































































































Matching word images for content-based retrieval from printed document images















































































































































































































































- Meshesha, Million; Jawahar, C V )































































},
author = {Meshesha, Million and Jawahar, CV V},
issn = {1433-2833},
journal = {IJDAR},
keywords = {degradation models,feature extraction,matching word images,partial matching},
month = {aug},
number = {1},
pages = {29--38},
title = {{Matching word images for content-based retrieval from printed document images}},
volume = {11},
year = {2008}
}
@article{Keogh1998,
abstract = {We introduce an extended representation of time series that allows fast, accurate classification and clustering in addition to the ability to explore time series data in a relevance feedback framework. The representation consists of piece- wise linear segments to represent shape and a weight vector that contains the relative importance of each individual linear segment. In the classification context, the weights are learned automatically as part of the training cycle. In the relevance feedback context, the weights are determined by an interactive and iterative process in which users rate various choices presented to them. Our representation allows a user to define a variety of similarity measures that can be tailored to specific domains. We demonstrate our approach on space telemetry, medical and synthetic data. 1.0},
author = {Keogh, Eamonn and Pazzani, M},
journal = {In: 4th International Conference on Knowledge Discovery and Data Mining.},
title = {{An enhanced representation of time series which allows fast and accurate classification, clustering and relevance feedback}},
year = {1998}
}
@article{Hassan2013a,
author = {Hassan, Ehtesham and Chaudhury, Santanu and Gopal, M.},
xxurl = {10.1109/ICDAR.2013.243},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassan, Chaudhury, Gopal - 2013 - Multi-modal Information Integration for Document Retrieval.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-document indexing,multi-,multi-modal retrieval,ple kernel learning},
month = {aug},
pages = {1200--1204},
publisher = {Ieee},
title = {{Multi-modal Information Integration for Document Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628804},
year = {2013}
}
@article{Ntirogiannis2014b,
abstract = {— Document image binarization is an important step in the document image analysis and recognition pipeline. H-DIBCO 2014 is the International Document Image Binarization Competition which is dedicated to handwritten document images organized in conjunction with ICFHR 2014 conference. The objective of the contest is to identify current advances in handwritten document image binarization using meaningful evaluation performance measures. This paper reports on the contest details including the evaluation measures used as well as the performance of the 8 submitted methods along with a short description of each method.},
author = {Ntirogiannis, Konstantinos and Gatos, Basilis and Pratikakis, Ioannis},
xxurl = {10.1109/ICFHR.2014.141},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ntirogiannis, Gatos, Pratikakis - 2014 - ICFHR2014 Competition on Handwritten Document Image Binarization (H-DIBCO 2014).pdf:pdf},
isbn = {9781479943340},
issn = {21676453},
journal = {Proceedings of International Conference on Frontiers in Handwriting Recognition, ICFHR},
keywords = {binarization,handwritten document image processing,performance evaluation},
pages = {809--813},
title = {{ICFHR2014 Competition on Handwritten Document Image Binarization (H-DIBCO 2014)}},
volume = {2014-Decem},
year = {2014}
}
@article{Azad2009,
abstract = {In the recent past, the recognition and localization of objects based on local point features has become a widely accepted and utilized method. Among the most popular features are currently the SIFT features, the more recent SURF features, and region-based features such as the MSER. For time-critical application of object recognition and localization systems operating on such features, the SIFT features are too slow (500600ms for images of size 640480 on a 3GHz CPU). The faster SURF achieve a computation time of 150240 ms, which is still too slow for active tracking of objects or visual servoing applications. In this paper, we present a combination of the Harris corner detector and the SIFT descriptor, which computes features with a high repeatability and very good matching properties within approx. 20 ms. While just computing the SIFT descriptors for computed Harris interest points would lead to an approach that is not scale-invariant, we will show how scale-invariance can be achieved without a time-consuming scale space analysis. Furthermore, we will present results of successful application of the proposed features within our system for recognition and localization of textured objects. An extensive experimental evaluation proves the practical applicability of our approach.},
author = {Azad, Pedram and Asfour, Tamim and Dillmann, R{\"{u}}diger},
xxurl = {10.1109/IROS.2009.5354611},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Azad, Asfour, Dillmann - 2009 - Combining Harris interest points and the SIFT descriptor for fast scale-invariant object recognition.pdf:pdf},
isbn = {9781424438044},
journal = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009},
pages = {4275--4280},
title = {{Combining Harris interest points and the SIFT descriptor for fast scale-invariant object recognition}},
year = {2009}
}
@article{Joly2009,
abstract = {This paper presents a new content-based retrieval framework applied to logo retrieval in large natural image collections 1. The first contribution is a new challenging dataset, called BelgaLogos, which was created in collaboration with pro- fessionals of a press agency, in order to evaluate logo retrieval technologies in real-world scenarios. The second and main contribution is a new visual query expansion method us- ing an a contrario thresholding strategy in order to improve the accuracy of expanded query images. Whereas previous methods based on the same paradigm used a purely hand tuned fixed threshold, we provide a fully adaptive method enhancing both genericity and effectiveness. This new tech- nique is evaluated on both OxfordBuilding dataset and our new BelgaLogos dataset.},
author = {Joly, Alexis and Buisson, Olivier},
xxurl = {10.1145/1631272.1631361},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joly, Buisson - 2009 - Logo retrieval with a contrario visual query expansion.pdf:pdf},
isbn = {9781605586083},
journal = {Proceedings of the seventeen ACM international conference on Multimedia - MM '09},
pages = {581},
title = {{Logo retrieval with a contrario visual query expansion}},
url = {http://portal.acm.org/citation.cfm?xxurld=1631272.1631361},
year = {2009}
}
@article{Abdolhoseini2019,
abstract = {Automated cell nucleus segmentation is the key to gain further insight into cell features and functionality which support computer-aided pathology in early diagnosis of diseases such as breast cancer and brain tumour. Despite considerable advances in automated segmentation, it still remains a challenging task to split heavily clustered nuclei due to intensity variations caused by noise and uneven absorption of stains. To address this problem, we propose a novel method applicable to variety of histopathological images stained for different proteins, with high speed, accuracy and level of automation. Our algorithm is initiated by applying a new locally adaptive thresholding method on watershed regions. Followed by a new splitting technique based on multilevel thresholding and the watershed algorithm to separate clustered nuclei. Finalized by a model-based merging step to eliminate oversegmentation and a model-based correction step to improve segmentation results and eliminate small objects. We have applied our method to three image datasets: breast cancer stained for hematoxylin and eosin (H{\&}E), Drosophila Kc167 cells stained for DNA to label nuclei, and mature neurons stained for NeuN. Evaluated results show our method outperforms the state-of-the-art methods in terms of accuracy, precision, F1-measure, and computational time.},
author = {Abdolhoseini, Mahmoud and Kluge, Murielle G. and Walker, Frederick R. and Johnson, Sarah J.},
xxurl = {10.1038/s41598-019-38813-2},
file = {:home/mondal/Downloads/s41598-019-38813-2.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--13},
title = {{Segmentation of Heavily Clustered Nuclei from Histopathological Images}},
volume = {9},
year = {2019}
}
@article{Wilson2017,
abstract = {Adaptive optimization methods, which perform local optimization with a metric constructed from the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We show that for simple overparameterized problems, adaptive methods often find drastically different solutions than gradient descent (GD) or stochastic gradient descent (SGD). We construct an illustrative binary classification problem where the data is linearly separable, GD and SGD achieve zero test error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of adaptive methods on several state-of-the-art deep learning models. We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.},
archivePrefix = {arXiv},
arxivId = {1705.08292},
author = {Wilson, Ashia C. and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nathan and Recht, Benjamin},
eprint = {1705.08292},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson et al. - 2017 - The Marginal Value of Adaptive Gradient Methods in Machine Learning.pdf:pdf},
pages = {1--14},
title = {{The Marginal Value of Adaptive Gradient Methods in Machine Learning}},
url = {http://arxiv.org/abs/1705.08292},
year = {2017}
}
@article{Hoang2012,
abstract = {A pattern descriptor invariant to rotation, scaling, translation (RST), and robust to additive noise is proposed by using the Radon, Fourier, and Mellin transforms. The Radon transform converts the RST transformations applied on a pattern image into transformations in the radial and angular coordinates of the patterns Radon image. These beneficial properties of the Radon transform make it an useful intermediate representation for the extraction of invariant features from pattern images for the purpose of indexing/matching. In this paper, invariance to RST is obtained by applying the 1D FourierMellin and discrete Fourier transforms on the radial and angular coordinates of the patterns Radon image respectively. The implementation of the proposed descriptor is reasonably fast and correct, based mainly on the fusion of the Radon and Fourier transforms and on a modification of the Mellin transform. Theoretical arguments validate the robustness of the proposed descriptor to additive noise and empirical evidence on both occlusion/deformation and noisy datasets shows its effectiveness. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
author = {Hoang, Thai V. and Tabbone, Salvatore},
xxurl = {10.1016/j.patcog.2011.06.020},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoang, Tabbone - 2012 - Invariant pattern recognition using the RFM descriptor.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Feature extraction,FourierMellin transform,Invariant pattern representation,Noise robustness,Radon transform},
number = {1},
pages = {271--284},
publisher = {Elsevier},
title = {{Invariant pattern recognition using the RFM descriptor}},
url = {http://dx.xxurl.org/10.1016/j.patcog.2011.06.020},
volume = {45},
year = {2012}
}
@misc{GaleoneAutoencoder,
title = {{Introduction to Autoencoders – P. Galeone's blog}},
url = {https://pgaleone.eu/neural-networks/2016/11/18/introduction-to-autoencoders/},
urldate = {2018-03-28}
}
@article{Ul-Hasan2013,
author = {Ul-Hasan, Adnan and Ahmed, Saad Bin and Rashid, Faisal and Shafait, Faisal and Breuel, Thomas M.},
xxurl = {10.1109/ICDAR.2013.212},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ul-Hasan et al. - 2013 - Offline Printed Urdu Nastaleeq Script Recognition with Bidirectional LSTM Networks.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {1061--1065},
publisher = {Ieee},
title = {{Offline Printed Urdu Nastaleeq Script Recognition with Bidirectional LSTM Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628777},
year = {2013}
}
@article{Zhou2013,
author = {Zhou, Yahan and Feild, Jacqueline and Learned-Miller, Erik and Wang, Rui},
xxurl = {10.1109/ICDAR.2013.98},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2013 - Scene Text Segmentation via Inverse Rendering.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {457--461},
publisher = {Ieee},
title = {{Scene Text Segmentation via Inverse Rendering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628663},
year = {2013}
}
@article{Easton2013,
author = {Easton, Roger},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013.pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(2).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(3).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(4).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(5).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(6).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(7).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(8).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(9).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(10).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(11).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(12).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(13).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(14).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(15).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(16).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(17).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(18).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(19).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(20).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(21).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(22).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(23).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(24).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(25).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(26).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(27).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Icdar 2013(28).pdf:pdf;:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Easton - 2013 - Icdar 2013.pdf:pdf},
pages = {2013},
title = {{Icdar 2013}},
year = {2013}
}
@article{Ziaratban2010,
abstract = {In this paper, a novel script-independent block-based text line extraction technique is proposed for multi-skewed document images. Three parameters are defined to adopt the method with various writings. Extensive experiments on different datasets demonstrate that the proposed algorithm outperforms previous methods.},
author = {Ziaratban, Majid and Faez, Karim},
xxurl = {10.1109/ICPR.2010.70},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ziaratban, Faez - 2010 - An adaptive script-independent block-based text line extraction.pdf:pdf},
isbn = {9780769541099},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
keywords = {Block-Based,Script-Independent,Text line extraction},
number = {2},
pages = {249--252},
pmid = {5597585},
title = {{An adaptive script-independent block-based text line extraction}},
volume = {1},
year = {2010}
}
@article{Yang2015,
author = {Yang, Lian and Lu, Zhangping},
xxurl = {10.1155/2015/310704},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Lu - 2015 - A New Scheme for Keypoint Detection and Description.pdf:pdf},
issn = {15635147},
journal = {Mathematical Problems in Engineering},
title = {{A New Scheme for Keypoint Detection and Description}},
volume = {2015},
year = {2015}
}
@article{Neumann2013,
author = {Neumann, Luka and Matas, Jiri},
xxurl = {10.1109/ICDAR.2013.110},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neumann, Matas - 2013 - On Combining Multiple Segmentations in Scene Text Recognition.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {523--527},
publisher = {Ieee},
title = {{On Combining Multiple Segmentations in Scene Text Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628675},
year = {2013}
}
@article{Verma2019,
abstract = {Information retrieval (IR) models often employ complex variations in term weights to compute an aggregated similarity score of a query-document pair. Treating IR models as black-boxes makes it difficult to understand or explain why certain documents are retrieved at top-ranks for a given query. Local explanation models have emerged as a popular means to understand individual predictions of classification models. However, there is no systematic investigation that learns to interpret IR models, which is in fact the core contribution of our work in this paper. We explore three sampling methods to train an explanation model and propose two metrics to evaluate explanations generated for an IR model. Our experiments reveal some interesting observations, namely that a) diversity in samples is important for training local explanation models, and b) the stability of a model is inversely proportional to the number of parameters used to explain the model.},
archivePrefix = {arXiv},
arxivId = {arXiv:1707.09418v1},
author = {Verma, Manisha and Ganguly, Debasis},
xxurl = {10.1145/nnnnnnn.nnnnnnn},
eprint = {arXiv:1707.09418v1},
file = {:home/mondal/Downloads/1707.09418.pdf:pdf},
isbn = {9781450361729},
journal = {SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
keywords = {Interpretability,Point-wise explanations,Ranking},
number = {1},
pages = {1281--1284},
title = {{LiRME: Locally interpretable ranking model explanation}},
volume = {1},
year = {2019}
}
@article{Gatos2011a,
author = {Gatos, B. and Kesidis, a. L. and Papandreou, a.},
xxurl = {10.1109/ICDAR.2011.234},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos, Kesidis, Papandreou - 2011 - Adaptive Zoning Features for Character and Word Recognition.pdf:pdf},
isbn = {978-1-4577-1350-7},
journal = {2011 International Conference on Document Analysis and Recognition},
month = {sep},
pages = {1160--1164},
publisher = {Ieee},
title = {{Adaptive Zoning Features for Character and Word Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065492},
year = {2011}
}
@article{Saidani2013,
author = {Saidani, a. and Echi, a. Kacem and Belaid, a.},
xxurl = {10.1109/ICDAR.2013.163},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saidani, Echi, Belaid - 2013 - Identification of Machine-Printed and Handwritten Words in Arabic and Latin Scripts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {classification,extraction,script and nature,word level},
month = {aug},
pages = {798--802},
publisher = {Ieee},
title = {{Identification of Machine-Printed and Handwritten Words in Arabic and Latin Scripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628728},
year = {2013}
}
@article{Gevrekci2009,
abstract = {Most interest point detection algorithms are highly sensitive to illumination variations. This paper presents a method to find interest points robustly even under large non-uniform photometric changes. The method, which we call illumination robust feature extraction transform (IRFET), determines salient interest points in an image by calculating and analyzing contrast signatures. A contrast signature shows the response of an interest point detector with respect to a set of contrast stretching functions. The IRFET is generic and can be used with most interest point detectors. In this paper, we demonstrate that the IRFET improves the repeatability rate of the Harris corner detector significantly (by around 25{\%} on average in the experiments). ?? 2008 Elsevier Inc. All rights reserved.},
author = {Gevrekci, Murat and Gunturk, Bahadir K.},
xxurl = {10.1016/j.cviu.2008.11.006},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gevrekci, Gunturk - 2009 - Illumination robust interest point detection.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Corner detection,Harris corner detector,Illumination invariance,Interest point detection},
number = {4},
pages = {565--571},
publisher = {Elsevier Inc.},
title = {{Illumination robust interest point detection}},
url = {http://dx.xxurl.org/10.1016/j.cviu.2008.11.006},
volume = {113},
year = {2009}
}
@article{Wang2013b,
author = {Wang, Song and Uchida, Seiichi and Liwicki, Marcus},
xxurl = {10.1109/ICDAR.2013.41},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Uchida, Liwicki - 2013 - Part-Based Recognition of Arbitrary Fonts.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {font recognition,local fea-,part-based recognition},
month = {aug},
pages = {170--174},
publisher = {Ieee},
title = {{Part-Based Recognition of Arbitrary Fonts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628606},
year = {2013}
}
@article{Hermans2013,
abstract = {Time series often have a temporal hierarchy, with information that is spread out over multiple time scales. Common recurrent neural networks, however, do not explicitly accommodate such a hierarchy, and most research on them has been focusing on training algorithms rather than on their basic architecture. In this pa- per we study the effect of a hierarchy of recurrent neural networks on processing time series. Here, each layer is a recurrent network which receives the hidden state of the previous layer as input. This architecture allows us to perform hi- erarchical processing on difficult temporal tasks, and more naturally capture the structure of time series. We show that they reach state-of-the-art performance for recurrent networks in character-level language modeling when trained with sim- ple stochastic gradient descent. We also offer an analysis of the different emergent time scales.},
author = {Hermans, Michiel and Schrauwen, Benjamin},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hermans, Schrauwen - 2013 - Training and analysing deep recurrent neural networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {Recurrent Neural Networks},
pages = {190--198},
title = {{Training and analysing deep recurrent neural networks}},
year = {2013}
}
@article{Hedjam2013,
author = {Hedjam, Rachid and Cheriet, Mohamed},
xxurl = {10.1109/ICDAR.2013.45},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hedjam, Cheriet - 2013 - Ground-Truth Estimation in Multispectral Representation Space Application to Degraded Document Image Binarizati.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
keywords = {-ground-truth estimation,document image analy-,document image binarization,historical document images,multispectral document imaging,sis},
month = {aug},
pages = {190--194},
publisher = {Ieee},
title = {{Ground-Truth Estimation in Multispectral Representation Space: Application to Degraded Document Image Binarization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628610},
year = {2013}
}
@article{Rusinol2013a,
author = {Rusi{\~{n}}ol, Mar{\c{c}}al and {Poulain D'Andecy}, Vincent and Karatzas, Dimosthenis and Llad{\'{o}}s, Josep},
xxurl = {10.1007/978-3-642-36824-0_5},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusi{\~{n}}ol et al. - 2013 - Classification of administrative document images by logo identification.pdf:pdf},
isbn = {9783642368233},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Administrative Document Classification,Logo Recognition,Logo Spotting},
pages = {49--58},
title = {{Classification of administrative document images by logo identification}},
volume = {7423 LNCS},
year = {2013}
}
@article{Nicolaou2009,
author = {Nicolaou, Anguelos and Gatos, Basilis},
xxurl = {10.1109/ICDAR.2009.243},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nicolaou, Gatos - 2009 - Handwritten Text Line Segmentation by Shredding Text into its Lines.pdf:pdf},
isbn = {978-1-4244-4500-4},
journal = {2009 10th International Conference on Document Analysis and Recognition},
pages = {626--630},
publisher = {Ieee},
title = {{Handwritten Text Line Segmentation by Shredding Text into its Lines}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277573},
year = {2009}
}
@article{Zhu2016,
abstract = {We present a novel framework for hallucinating faces of unconstrained poses and with very low resolution (face size as small as 5pxIOD). In contrast to existing studies that mostly ignore or assume pre-aligned face spatial configuration (e.g. facial landmarks localization or dense correspondence field), we alternatingly optimize two complementary tasks, namely face hallucination and dense correspondence field estimation, in a unified framework. In addition, we propose a new gated deep bi-network that contains two functionality-specialized branches to recover different levels of texture details. Extensive experiments demonstrate that such formulation allows exceptional hallucination quality on in-the-wild low-res faces with significant pose and illumination variations.},
archivePrefix = {arXiv},
arxivId = {1607.05046},
author = {Zhu, Shizhan and Liu, Sifei and Loy, Chen Change and Tang, Xiaoou},
xxurl = {10.1007/978-3-319-46454-1_37},
eprint = {1607.05046},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2016 - Deep cascaded Bi-network for face hallucination.pdf:pdf},
isbn = {9783319464534},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {614--630},
pmid = {10463930},
title = {{Deep cascaded Bi-network for face hallucination}},
volume = {9909 LNCS},
year = {2016}
}
@article{Triggs2004,
abstract = {Local feature approaches to vision geometry and object recognition are based on selecting and matching sparse sets of visually salient image points, known as keypoints or points of interest. Their performance depends critically on the accuracy and reliability with which corresponding keypoints can be found in subsequent images. Among the many existing keypoint selection criteria, the popular F{\"{o}}rstner-Harris approach explicitly targets geometric stability, defining keypoints to be points that have locally maximal self-matching precision under translational least squares template matching. However, many applications require stability in orientation and scale as well as in position. Detecting translational keypoints and verifying orientation/scale behaviour post hoc is suboptimal, and can be misleading when different motion variables interact. We give a more principled formulation, based on extending the F{\"{o}}rstner-Harris approach to general motion models and robust template matching. We also incorporate a simple local appearance model to ensure good resistance to the most common illumination variations. We illustrate the resulting methods and quantify their performance on test images.},
author = {Triggs, Bill},
xxurl = {10.1007/978-3-540-24673-2_9},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Triggs - 2004 - Detecting Keypoints with Stable Position, Orientation and Scale under Illumination Changes.pdf:pdf},
isbn = {9783540246732},
issn = {03029743},
journal = {Framework},
keywords = {corner detection,feature based vision,keypoint,point interest},
pages = {100--113},
title = {{Detecting Keypoints with Stable Position, Orientation and Scale under Illumination Changes}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?xxurl=10.1.1.230.138{\&}rep=rep1{\&}type=pdf{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/summary?xxurl=10.1.1.230.138{\%}5Cnhttp://www.springerlink.com/index/H1KXW1PJT86PEYAV.pdf},
year = {2004}
}
@article{Mondal2009,
author = {Mondal, Tanmoy and Ragot, Nicolas and Ramel, Jean-yves and Pal, Umapada and Rabelais, Universit{\'{e}} Fran{\c{c}}ois and Informatique, Laboratoire},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal et al. - 2009 - A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing  A fast word retrieval approach.pdf:pdf},
number = {2007},
pages = {4700},
title = {{A Fast Word Retrieval Technique Based on Kernelized Locality Sensitive Hashing  A fast word retrieval approach based on KLSH , which defines hash functions using arbitrary kernel , which are locality sensitive , thereby permitting sub linear time approxi}},
volume = {139},
year = {2009}
}
@article{Cerri2006,
abstract = {We propose a new, effective system for content-based retrieval of figurative images, which is based on size functions, a geometrical-topological tool for shape description and matching. Three different classes of shape descriptors are introduced and integrated, for a total amount of 25 measuring functions. The evaluation of our fully automatic retrieval system has been performed on a benchmark database of 10,745 real trademark images, supplied by the United Kingdom Patent Office. Comparative results show that our method actually outperforms other existing whole-image matching techniques, comprising features incorporated in the MPEG-7 standard. ?? 2006 Elsevier Inc. All rights reserved.},
author = {Cerri, A. and Ferri, M. and Giorgi, D.},
xxurl = {10.1016/j.gmod.2006.07.001},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cerri, Ferri, Giorgi - 2006 - Retrieval of trademark images by means of size functions.pdf:pdf},
isbn = {1524-0703},
issn = {15240703},
journal = {Graphical Models},
keywords = {Content-based image retrieval,Shape comparison,Size functions,Trademark retrieval},
number = {5-6},
pages = {451--471},
title = {{Retrieval of trademark images by means of size functions}},
volume = {68},
year = {2006}
}
@article{Roy2008,
abstract = {In this paper, we present a scheme towards recognition of English character in multi-scale and multi-oriented environments. Graphical document such as map consists of text lines which appear in different orientation. Sometimes, characters in a single word may follow a curvilinear way to annotate the graphical curve lines. For recognition of such multi-scale and multi-oriented characters a Support Vector Machine (SVM) based scheme is presented in this paper. The feature used here is invariant to character orientation. Circular ring and convex hull have been used along with angular information of the contour pixels of the character to make the feature rotation invariant. We tested our proposed scheme on two different datasets. Combining circular and convex hull feature we have obtained 96.73{\%} and 99.56{\%} accuracy in these two datasets.},
author = {Roy, P.P. and Pal, U. and Llados, J. and Kimura, F.},
xxurl = {10.1109/ICPR.2008.4761447},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy et al. - 2008 - Convex hull based approach for multi-oriented character recognition from graphical documents.pdf:pdf},
isbn = {978-1-4244-2174-9},
issn = {1051-4651},
journal = {2008 19th International Conference on Pattern Recognition},
pages = {6--9},
title = {{Convex hull based approach for multi-oriented character recognition from graphical documents}},
year = {2008}
}
@inproceedings{SIGIR2006,
author = {Lewis, D and Agam, G and Argamon, S and Frieder, O and Grossman, D and J.Heard},
booktitle = {Proc. 29th Annual Int. ACM SIGIR Conference},
pages = {665--666},
title = {{Building a Test Collection for Complex Document Information Processing}},
year = {2006}
}
@article{Keogh2001,
author = {Keogh, Eamonn and Chakrabarti, Kaushik and Pazzani, Michael and Mehrotra, Sharad},
xxurl = {10.1007/PL00011669},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
month = {aug},
number = {3},
pages = {263--286},
title = {{Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases}},
url = {http://link.springer.com/10.1007/PL00011669},
volume = {3},
year = {2001}
}
@article{Mian2008,
author = {Mian, Ajmal S. and Bennamoun, Mohammed and Owens, Robyn},
xxurl = {10.1007/s11263-007-0085-5},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mian, Bennamoun, Owens - 2008 - Keypoint Detection and Local Feature Matching for Textured 3D Face Recognition.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = {aug},
number = {1},
pages = {1--12},
publisher = {Springer US},
title = {{Keypoint Detection and Local Feature Matching for Textured 3D Face Recognition}},
url = {http://link.springer.com/10.1007/s11263-007-0085-5},
volume = {79},
year = {2008}
}
@article{Zuo2015,
abstract = {In existing convolutional neural networks (CNNs), both convolution and pooling are locally performed for image regions separately, no contextual dependencies between different image regions have been taken into consideration. Such dependencies represent useful spatial structure information in images. Whereas recurrent neural networks (RNNs) are designed for learning contextual dependencies among sequential data by using the recurrent (feedback) connections. In this work, we propose the convolutional recurrent neural network (C-RNN), which learns the spatial dependencies between image regions to enhance the discriminative power of image representation. The C-RNN is trained in an end-to-end manner from raw pixel images. CNN layers are firstly processed to generate middle level features. RNN layer is then learned to encode spatial dependencies. The C-RNN can learn better image representation, especially for images with obvious spatial contextual dependencies. Our method achieves competitive performance on ILSVRC 2012, SUN 397, and MIT indoor.},
author = {Zuo, Zhen and Shuai, Bing and Wang, Gang and Liu, Xiao and Wang, Xingxing and Wang, Bing and Chen, Yushi},
xxurl = {10.1109/CVPRW.2015.7301268},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zuo et al. - 2015 - Convolutional Recurrent Neural Networks Learning Spatial Dependencies for Image Representation.pdf:pdf},
isbn = {9781467367592},
issn = {21607516},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
pages = {18--26},
title = {{Convolutional Recurrent Neural Networks: Learning Spatial Dependencies for Image Representation}},
year = {2015}
}
@article{Silva2018,
abstract = {—Most algorithms for music data mining and retrieval analyze the similarity between feature sets extracted from the raw audio. A conventional approach to assess similarities within or between recordings is to create similarity matrices. However, this method requires quadratic space for each comparison and typically requires a costly post-processing of the matrix. We have recently proposed SiMPle, a powerful representation based on subsequence similarity join, which is applicable in several music analysis tasks. In this paper, we propose SiMPle-Fast a highly efficient method for exact computation of SiMPle that is up to one order of magnitude faster than SiMPle. Furthermore, we demonstrate the utility of SiMPle-Fast in cover music recognition and thumbnailing tasks and show our method is significantly faster and more accurate than the state-of-the-art.},
author = {Silva, Diego Furtado and Yeh, Chin Chia Michael and Zhu, Yan and Batista, Gustavo and Keogh, Eamonn},
xxurl = {10.1109/TMM.2018.2849563},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva et al. - 2018 - Fast Similarity Matrix Profile for Music Analysis and Exploration.pdf:pdf},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Data analysis,distance measurement,music information retrieval},
number = {8},
pages = {1--10},
title = {{Fast Similarity Matrix Profile for Music Analysis and Exploration}},
volume = {14},
year = {2018}
}
@article{Radford2015b,
abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
archivePrefix = {arXiv},
arxivId = {1511.06434},
author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
eprint = {1511.06434},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radford, Metz, Chintala - 2015 - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.pdf:pdf},
month = {nov},
title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
year = {2015}
}
@article{Gharghabi2017,
abstract = {Unsupervised semantic segmentation in the time series domain is a much-studied problem due to its potential to detect unexpected regularities and regimes in poorly understood data. However, the current techniques have several shortcomings, which have limited the adoption of time series semantic segmentation beyond academic settings for three primary reasons. First, most methods require setting/learning many parameters and thus may have problems generalizing to novel situations. Second, most methods implicitly assume that all the data is segmentable, and have difficulty when that assumption is unwarranted. Finally, most research efforts have been confined to the batch case, but online segmentation is clearly more useful and actionable. To address these issues, we present an algorithm which is domain agnostic, has only one easily determined parameter, and can handle data streaming at a high rate. In this context, we test our algorithm on the largest and most diverse collection of time series datasets ever considered, and demonstrate our algorithm's superiority over current solutions. Furthermore, we are the first to show that semantic segmentation may be possible at superhuman performance levels.},
author = {Gharghabi, Shaghayegh and Ding, Yifei and Yeh, Chin Chia Michael and Kamgar, Kaveh and Ulanova, Liudmila and Keogh, Eamonn},
xxurl = {10.1109/ICDM.2017.21},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gharghabi et al. - 2017 - Matrix profile VIII Domain agnostic online semantic segmentation at superhuman performance levels.pdf:pdf},
isbn = {9781538638347},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Online Algorithms,Semantic Segmentation,Time Series},
pages = {117--126},
title = {{Matrix profile VIII: Domain agnostic online semantic segmentation at superhuman performance levels}},
volume = {2017-Novem},
year = {2017}
}
@inproceedings{Thies2016,
abstract = {We present a novel approach for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The source sequence is also a monocular video stream, captured live with a commodity webcam. Our goal is to animate the facial expressions of the target video by a source actor and re-render the manipulated output video in a photo-realistic fashion. To this end, we first address the under-constrained problem of facial identity recovery from monocular video by non-rigid model-based bundling. At run time, we track facial expressions of both source and target video using a dense photometric consistency measure. Reenactment is then achieved by fast and efficient deformation transfer between source and target. The mouth interior that best matches the re-targeted expression is retrieved from the target sequence and warped to produce an accurate fit. Finally, we convincingly re-render the synthesized target face on top of the corresponding video stream such that it seamlessly blends with the real-world illumination. We demonstrate our method in a live setup, where Youtube videos are reenacted in real time.},
author = {Thies, Justus and Zollhofer, Michael and Stamminger, Marc and Theobalt, Christian and Niebner, Matthias},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
xxurl = {10.1109/CVPR.2016.262},
isbn = {9781467388504},
issn = {10636919},
title = {{Face2Face: Real-Time Face Capture and Reenactment of RGB Videos}},
year = {2016}
}
@article{Karras2018,
abstract = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 10242. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.},
archivePrefix = {arXiv},
arxivId = {1710.10196},
author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
eprint = {1710.10196},
file = {:home/mondal/Downloads/1710.10196.pdf:pdf},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
pages = {1--26},
title = {{Progressive growing of GANs for improved quality, stability, and variation}},
year = {2018}
}
@inproceedings{Chen2011,
author = {Chen, Huizhong},
booktitle = {Image Processing (ICIP), 18th IEEE International Conference on IEEE},
title = {{Robust Text Detection In Natural Images With Edge-Enhanced Maximally Stable Extremal Regions}},
year = {2011}
}
@article{Salimans2016,
abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3{\%}. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
archivePrefix = {arXiv},
arxivId = {1606.03498},
author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
xxurl = {arXiv:1504.01391},
eprint = {1606.03498},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf:pdf},
isbn = {0924-6495},
issn = {09246495},
pages = {1--10},
pmid = {23259955},
title = {{Improved Techniques for Training GANs}},
url = {http://arxiv.org/abs/1606.03498},
year = {2016}
}
@article{Yi2000,
abstract = {Fast indexing in time sequence databases for similarity searching has attracted a lot of research recently. Most of the proposals, however, typically centered around the Euclidean distance and its derivatives. We examine the problem of multimodal similarity search in which users can choose the best one from multiple similarity models for their needs.},
author = {Krawinkel, Michael B.},
xxurl = {10.1016/j.cppeds.2011.05.001},
isbn = {1-55860-715-3},
issn = {15385442},
journal = {Current Problems in Pediatric and Adolescent Health Care},
month = {oct},
number = {9},
pages = {233},
pmid = {24752072},
title = {{Introduction}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1538544211001064},
volume = {41},
year = {2011}
}
@article{Giotis2014,
author = {Giotis, Angelos P. and Gerogiannis, Demetrios P. and Nikou, Christophoros},
xxurl = {10.1109/ICFHR.2014.73},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giotis, Gerogiannis, Nikou - 2014 - Word Spotting in Handwritten Text Using Contour-Based Models.pdf:pdf},
isbn = {978-1-4799-4334-0},
journal = {2014 14th International Conference on Frontiers in Handwriting Recognition},
keywords = {Word spotting, handwritten text, local contour fea,a representative shape of,a word-class,detection system in real,extracted from segmented word,images,images in order to,in images of handwritten,local contour features are,obtain,relying on an object,text,thus,word spotting},
pages = {399--404},
title = {{Word Spotting in Handwritten Text Using Contour-Based Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6981052},
year = {2014}
}
@misc{Philadelphia:LinguisticDataConsortium1993bIMIT,
author = {Garofolo, John and Lamel, Lori and Fisher, William and Fiscus, Jonathan and Pallett, David and Dahlgren, Nancy and Zue, Victor},
booktitle = {Philadelphia: Linguistic Data Consortium},
title = {{TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT )}},
url = {http://www.lt-world.org/kb/resources-and-tools/language-data/ltw{\_}x3alanguage{\_}x5fdata{\_}.2010-09-22.6113077662},
urldate = {2015-08-28},
year = {1993}
}
@article{Sudholt2017a,
abstract = {In recent years, deep convolutional neural networks have achieved state of the art performance in various computer vision task such as classification, detection or segmentation. Due to their outstanding performance, CNNs are more and more used in the field of document image analysis as well. In this work, we present a CNN architecture that is trained with the recently proposed PHOC representation. We show empirically that our CNN architecture is able to outperform state of the art results for various word spotting benchmarks while exhibiting short training and test times.},
archivePrefix = {arXiv},
arxivId = {1604.00187},
author = {Sudholt, Sebastian and Fink, Gernot A.},
xxurl = {10.1109/ICFHR.2016.0060},
eprint = {1604.00187},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sudholt, Fink - 2017 - PHOCNet A deep convolutional neural network for word spotting in handwritten documents.pdf:pdf},
isbn = {9781509009817},
issn = {21676453},
journal = {Proceedings of International Conference on Frontiers in Handwriting Recognition, ICFHR},
keywords = {Attribute representations,Convolutional neural networks,Deep learning,Handwritten documents,Historical documents,Word spotting},
pages = {277--282},
title = {{PHOCNet: A deep convolutional neural network for word spotting in handwritten documents}},
year = {2017}
}
@article{Bilane2008,
author = {Bilane, P and Bres, S and Emptoz, H},
xxurl = {10.1109/CBMI.2008.4564992},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bilane, Bres, Emptoz - 2008 - Robust directional features for wordspotting in degraded Syriac manuscripts.pdf:pdf},
isbn = {978-1-4244-2043-8},
journal = {2008 International Workshop on Content-Based Multimedia Indexing},
pages = {526--533},
publisher = {Ieee},
title = {{Robust directional features for wordspotting in degraded Syriac manuscripts}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4564992},
year = {2008}
}
@article{Saabni2013,
author = {Saabni, Raid},
xxurl = {10.1109/ICDAR.2013.70},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saabni - 2013 - Efficient Word Image Retrieval Using Earth Movers Distance Embedded to Wavelets Coefficients Domain.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {314--318},
publisher = {Ieee},
title = {{Efficient Word Image Retrieval Using Earth Movers Distance Embedded to Wavelets Coefficients Domain}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628635},
year = {2013}
}
@article{M.2017,
author = {M., Ibrahim and Hamdy, Salma and G., Mostafa},
xxurl = {10.5120/ijca2017915589},
file = {:home/mondal/Downloads/amer-2017-ijca-915589.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {d-cnn,deep,deep convolutional neural network,dla,document layout analysis,font family recognition,font size recognition,learning,ocr,optical charac-,ter recognition},
number = {4},
pages = {1--6},
title = {{Deep Arabic Font Family and Font Size Recognition}},
volume = {176},
year = {2017}
}
@article{Lin2003,
address = {New York, New York, USA},
author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill},
xxurl = {10.1145/882085.882086},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2003 - A symbolic representation of time series, with implications for streaming algorithms.pdf:pdf},
journal = {Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery - DMKD '03},
keywords = {data mining,data streams,discretize,symbolic,time series},
pages = {2},
publisher = {ACM Press},
title = {{A symbolic representation of time series, with implications for streaming algorithms}},
url = {http://portal.acm.org/citation.cfm?xxurld=882082.882086},
year = {2003}
}
@article{LeCun2017,
author = {LeCun, Yann and Bronstein, Michael M. and Szlam, Arthur and Vandergheynst, Pierre and Bruna, Joan},
xxurl = {10.1109/msp.2017.2693418},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
number = {4},
pages = {18--42},
title = {{Geometric Deep Learning: Going beyond Euclidean data}},
volume = {34},
year = {2017}
}
@article{Perdoch2011,
author = {Perd'och, M},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perd'och - 2011 - Maximally Stable Extremal Regions and Local Geometry for Visual Correspondences.pdf:pdf},
pages = {20--26},
title = {{Maximally Stable Extremal Regions and Local Geometry for Visual Correspondences}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Maximally+Stable+Extremal+Regions+and+Local+Geometry+for+Visual+Correspondences{\#}0},
year = {2011}
}
@inproceedings{Riba2015,
author = {Riba, Pau and Llad, Josep},
booktitle = {ICDAR},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riba, Llad - 2015 - Handwritten Word Spotting by Inexact Matching of Grapheme Graphs.pdf:pdf},
isbn = {9781479918058},
keywords = {a robust representation,able to cope with,efficient way,far away of being,first,has to deal with,in general,large databases in an,matching for word spotting,spotting,the use of graph,these approaches are still,two factors},
pages = {781--785},
title = {{Handwritten Word Spotting by Inexact Matching of Grapheme Graphs}},
year = {2015}
}
@article{Schmidt2007,
abstract = {The matching of planar shapes can be cast as a problem of finding the shortest path through a graph spanned by the two shapes, where the nodes of the graph encode the local similarity of respective points on each contour. While this problem can be solved using dynamic time warping, the complete search over the initial correspondence leads to cubic runtime in the number of sample points. In this paper, we cast the shape matching problem as one of finding the shortest circular path on a torus. We propose an algorithm to determine this shortest cycle which has provably sub-cubic runtime. Numerical experiments demonstrate that the proposed algorithm provides faster shape matching than previous methods. As an application, we show that it allows to efficiently compute a clustering of a shape data base.},
author = {Schmidt, Frank R. and Farin, Dirk and Cremers, Daniel},
xxurl = {10.1109/ICCV.2007.4409018},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidt, Farin, Cremers - 2007 - Fast matching of planar shapes in sub-cubic runtime.pdf:pdf},
isbn = {1550-5499},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
title = {{Fast matching of planar shapes in sub-cubic runtime}},
year = {2007}
}
@article{Mueen2010,
abstract = {We consider the problem of computing all-pair correlations in a warehouse containing a large number (e.g., tens of thousands) of time-series (or, signals). The problem arises in automatic discovery of patterns and anomalies in data intensive applications such as data center management, environmental monitoring, and scientific experiments. However, with existing techniques, solving the problem for a large stream warehouse is extremely expensive, due to the problem's inherent quadratic I/O and CPU complexities. We propose novel algorithms, based on Discrete Fourier Transformation (DFT) and graph partitioning, to reduce the end-to-end response time of an all-pair correlation query. To minimize I/O cost, we partition a massive set of input signals into smaller batches such that caching the signals one batch at a time maximizes data reuse and minimizes disk I/O. To reduce CPU cost, we propose two approximation algorithms. Our first algorithm efficiently computes approximate correlation coefficients of similar signal pairs within a given error bound. The second algorithm efficiently identifies, without any false positives or negatives, all signal pairs with correlations above a given threshold. For many real applications, our approximate solutions are as useful as corresponding exact solutions, due to our strict error guarantees. However, compared to the state-of-the-art exact algorithms, our algorithms are up to 17x faster for several real datasets. {\textcopyright} 2010 ACM.},
author = {Mueen, Abdullah and Nath, Suman and Liu, Jie},
xxurl = {10.1145/1807167.1807188},
file = {:home/mondal/Downloads/sigmod2010.pdf:pdf},
isbn = {9781450300322},
issn = {07308078},
journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
keywords = {correlation matrix,discrete fourier transform},
pages = {171--182},
title = {{Fast approximate correlation for massive time-series data}},
volume = {1},
year = {2010}
}
@article{Masalovitch2007,
author = {Masalovitch, Anton and Mestetskiy, Leonid},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Masalovitch, Mestetskiy - 2007 - Usage of continuous skeletal image representation for document images de-warping.pdf:pdf},
journal = {{\ldots} Int. Workshop on Camera-Based Document {\ldots}},
pages = {45--52},
title = {{Usage of continuous skeletal image representation for document images de-warping}},
url = {http://imlab.jp/cbdar2007/proceedings/papers/O3-2.pdf},
year = {2007}
}
@article{Radford2015a,
abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
archivePrefix = {arXiv},
arxivId = {1511.06434},
author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
eprint = {1511.06434},
month = {nov},
title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
year = {2015}
}
@article{Albrecht2009,
author = {Albrecht, Thomas},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Albrecht - 2009 - Dynamic Time Warping (DTW).pdf:pdf},
isbn = {978-0-387-73002-8},
pages = {69--85},
title = {{Dynamic Time Warping (DTW)}},
year = {2009}
}
@article{Walha2013,
author = {Walha, Rim and Drira, Fadoua and Lebourgeois, Franck and Garcia, Christophe and Alimi, Adel M.},
xxurl = {10.1109/ICDAR.2013.103},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walha et al. - 2013 - Multiple Learned Dictionaries Based Clustered Sparse Coding for the Super-Resolution of Single Text Image.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
pages = {484--488},
publisher = {Ieee},
title = {{Multiple Learned Dictionaries Based Clustered Sparse Coding for the Super-Resolution of Single Text Image}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628668},
year = {2013}
}
@article{Pham2014,
abstract = {In this paper, we present a new approach for junction detection and characterization in line-drawing images. We formulate this problem as searching for optimal meeting points of median lines. In this context, the main contribution of the proposed approach is three-fold. First, a new algorithm for the determination of the support region is presented using the linear least squares technique, making it robust to digitization effects. Second, an efficient algorithm is proposed to detect and conceptually remove all distorted zones, retaining reliable line segments only. These line segments are then locally characterized to form a local structure representation of each crossing zone. Finally, a novel optimization algorithm is presented to reconstruct the junctions. Junction characterization is then simply derived. The proposed approach is very highly robust to common geometry transformations and can resist a satisfactory level of noise/degradation. Furthermore, it works very efficiently in terms of time complexity and requires no prior knowledge of the document content. Extensive evaluations have been performed to validate the proposed approach using other baseline methods. An application of symbol spotting is also provided, demonstrating quite good results. ?? 2013 Elsevier Ltd. All rights reserved.},
author = {Pham, The Anh and Delalandre, Mathieu and Barrat, Sabine and Ramel, Jean Yves},
xxurl = {10.1016/j.patcog.2013.06.027},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pham et al. - 2014 - Accurate junction detection and characterization in line-drawing images.pdf:pdf},
isbn = {9784990644116},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Dominant point detection,Graphical documents,Junction characterization,Junction detection,Line-drawings},
number = {1},
pages = {282--295},
publisher = {Elsevier},
title = {{Accurate junction detection and characterization in line-drawing images}},
url = {http://dx.xxurl.org/10.1016/j.patcog.2013.06.027},
volume = {47},
year = {2014}
}
@article{Gatos2009c,
author = {Gatos, Basilis and Pratikakis, Ioannis},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatos, Pratikakis - 2009 - Segmentation-free Word Spotting in Historical Printed Documents.pdf:pdf},
journal = {ICDAR},
pages = {271--275},
publisher = {Ieee},
title = {{Segmentation-free Word Spotting in Historical Printed Documents}},
year = {2009}
}
@article{Dinges2013,
author = {Dinges, Laslo and Al-Hamadi, Ayoub and Elzobi, Moftah},
xxurl = {10.1109/ICDAR.2013.164},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinges, Al-Hamadi, Elzobi - 2013 - A Locale Group Based Line Segmentation Approach for Non Uniform Skewed and Curved Arabic Handwritings.pdf:pdf},
isbn = {978-0-7695-4999-6},
journal = {2013 12th International Conference on Document Analysis and Recognition},
month = {aug},
number = {Cc},
pages = {803--806},
publisher = {Ieee},
title = {{A Locale Group Based Line Segmentation Approach for Non Uniform Skewed and Curved Arabic Handwritings}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6628729},
year = {2013}
}
@article{Kovalchuk2014,
author = {Kovalchuk, Alon and Wolf, Lior and Dershowitz, Nachum},
xxurl = {10.1109/ICFHR.2014.9},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kovalchuk, Wolf, Dershowitz - 2014 - A Simple and Fast Word Spotting Method.pdf:pdf},
isbn = {978-1-4799-4334-0},
title = {{A Simple and Fast Word Spotting Method}},
year = {2014}
}
@article{Ding2008,
abstract = {The last decade has witnessed a tremendous growths of interests in applications that deal with querying and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures geared towards time series have been introduced. Each individual work introducing a particular method has made specific claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive set of time series experiments re-implementing 8 different representation methods and 9 similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this paper, we give an overview of these different techniques and present our comparative experimental findings regarding their effectiveness. Our experiments have provided both a unified validation of some of the existing achievements, and in some cases, suggested that certain claims in the literature may be unduly optimistic. 1.},
archivePrefix = {arXiv},
arxivId = {1012.2789v1},
author = {Ding, Hui and Trajcevski, Goce and Scheuermann, Peter and Wang, Xiaoyue and Keogh, Eamonn},
xxurl = {10.1145/1454159.1454226},
eprint = {1012.2789v1},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2008 - Querying and Mining of Time Series Data Experimental Comparison of Representations and Distance Measures.pdf:pdf},
isbn = {0000000000000},
issn = {2150-8097},
journal = {Proceedings of the VLDB Endowment},
pages = {1542--1552},
title = {{Querying and mining of time series data: experimental comparison of representations and distance measures}},
url = {http://dl.acm.org/citation.cfm?id=1454226},
volume = {1},
year = {2008}
}
@article{Fan2007,
author = {Fan, Jian},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan - 2007 - Enhancement of camera-captured document images with watershed segmentation.pdf:pdf},
journal = {Cbdar07},
pages = {87--93},
title = {{Enhancement of camera-captured document images with watershed segmentation}},
url = {http://imlab.jp/cbdar2007/proceedings/papers/P4.pdf},
year = {2007}
}
@article{Silva2016,
abstract = {Most algorithms for music information retrieval are based on the analysis of the similarity between feature sets ex-tracted from the raw audio. A common approach to as-sessing similarities within or between recordings is by creating similarity matrices. However, this approach re-quires quadratic space for each comparison and typically requires a costly post-processing of the matrix. In this work, we propose a simple and efficient representation based on a subsequence similarity join, which may be used in several music information retrieval tasks. We ap-ply our method to the cover song recognition problem and demonstrate that it is superior to state-of-the-art algo-rithms. In addition, we demonstrate how the proposed representation can be exploited for multiple applications in music processing.},
author = {Silva, D. and Yeh, C. and Batista, G. and Keogh, E.},
xxurl = {10.1007/s00276-011-0805-y},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva et al. - 2016 - SiMPle Assessing Music Similarity using Subsequences Joins.pdf:pdf},
issn = {1279-8517},
journal = {International Conference on Music Information Retrieval (ISMIR)},
pages = {23--30},
pmid = {21424726},
title = {{SiMPle: Assessing Music Similarity using Subsequences Joins}},
year = {2016}
}
@article{Biswas2014,
abstract = {{\textless}p{\textgreater}Text segmentation from land map images is a non-trivial task as map components are interleaved and overlapped in a complex spatial form. The characters in a word in most of the Indic languages, including Bangla (the 6th most spoken language in the world), are connected through a headline (”matra” or ”shirorekha”) which makes the corresponding word a single component. It has been observed that the Delaunay triangulation (DT) forms a number of small triangles on the text regions compared to other regions of the map - a property very much discernible for Bangla (and some other Indic scripts) texts. This property is primarily exploited here to segment text from the complex background of the land map images. The proposed text segmentation approach is tested and compared with an existing method on a collected dataset of paper map images( containing Bangla, an Indian regional language texts) and the results are encouraging.{\textless}/p{\textgreater}},
author = {Biswas, Samit and {Kumar Das}, Amit and Chanda, Bhabatosh},
xxurl = {10.1515/ipc-2015-0003},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biswas, Kumar Das, Chanda - 2014 - Text Segmentation from Bangla Land Map Images.pdf:pdf},
issn = {2300-8709},
journal = {Image Processing {\&} Communications},
number = {1},
pages = {21--34},
title = {{Text Segmentation from Bangla Land Map Images}},
url = {http://content.sciendo.com/view/journals/ipc/19/1/article-p21.xml},
volume = {19},
year = {2014}
}
@article{Lebanon2005,
abstract = {Abstract Stream and lake ecosystems in agricultural watersheds are exposed to fungicide inputs that can threaten the structure and functioning of aquatic microbial communities. This research analyzes the impact of the triazole fungicide tebuconazole (TBZ) on natural biofilm and plankton microbial communities from sites presenting different degrees of agricultural contamination. Biofilm and plankton communities from less-polluted (LP) and polluted (P) sites were exposed to nominal concentrations of 0 (control), 2 and 20 $\mu$g {\{}TBZ{\}} L− 1 in 3-week microcosm experiments. Descriptors of microbial community structure (bacterial density and chlorophyll-a concentration) and function (bacterial respiration and production and photosynthesis) were analyzed to chart the effects of {\{}TBZ{\}} and the kinetics of {\{}TBZ{\}} attenuation in water during the experiments. The results showed TBZ-induced effects on biofilm function (inhibition of substrate-induced respiration and photosynthetic activity), especially in LP-site communities, whereas plankton communities experienced a transitory stimulation of bacterial densities in communities from both {\{}LP{\}} and P sites. {\{}TBZ{\}} attenuation was stronger in biofilm (60–75{\%}) than plankton (15–18{\%}) experiments, probably due to greater adsorption on biofilms. The differences between biofilm and plankton responses to {\{}TBZ{\}} were likely explained by differences in community structure (presence of extracellular polymeric substances (EPS) matrix) and microbial composition. Biofilm communities also exhibited different sensitivity levels according to their in-field pre-exposure to fungicide, with P-site communities demonstrating adaptation capacities to TBZ. This study indicates that {\{}TBZ{\}} toxicity to non-targeted aquatic microbial communities essentially composed by microalgae and bacteria was moderate, and that its effects varied between stream and lake microbial communities. },
author = {Lebanon, Guy},
xxurl = {http://dx.xxurl.org/10.1016/j.scitotenv.2013.08.074},
isbn = {0-496-93472-4},
issn = {0048-9697},
journal = {PhD Thesis},
pages = {1--132},
title = {{Riemannian Geometry and Statistical Machine Learning}},
year = {2005}
}
@article{Noise2007,
author = {Noise, Fixed Pattern},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noise - 2007 - Topic 5 Noise in Images.pdf:pdf},
number = {August},
title = {{Topic 5 : Noise in Images}},
year = {2007}
}
@article{KumarBoyat2015,
abstract = {Noise is always presents in digital images during image acquisition, coding, transmission, and processing steps. Noise is very difficult to remove it from the digital images without the prior knowledge of noise model. That is why, review of noise models are essential in the study of image denoising techniques. In this paper, we express a brief overview of various noise models. These noise models can be selected by analysis of their origin. In this way, we present a complete and quantitative analysis of noise models available in digital images.},
author = {{Kumar Boyat}, Ajay and Joshi, Brijendra Kumar},
xxurl = {10.5121/sipij.2015.6206},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar Boyat, Joshi - 2015 - A Review Paper Noise Models in Digital Image Processing.pdf:pdf},
issn = {22293922},
journal = {An International Journal (SIPIJ)},
keywords = {Digital images,Noise model,Power spectral density (PDF),Probability density function},
number = {2},
pages = {63--75},
title = {{A Review Paper: Noise Models in Digital Image Processing}},
volume = {6},
year = {2015}
}
@article{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
arxivId = {1701.07875},
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'{e}}on},
eprint = {1701.07875},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arjovsky, Chintala, Bottou - 2017 - Wasserstein GAN.pdf:pdf},
month = {jan},
title = {{Wasserstein GAN}},
url = {http://arxiv.org/abs/1701.07875},
year = {2017}
}
@article{Kingma2013a,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Welling - 2013 - Auto-Encoding Variational Bayes(2).pdf:pdf},
month = {dec},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2013}
}
@article{Salimans,
abstract = {Recent advances in stochastic gradient vari-ational inference have made it possible to perform variational Bayesian inference with posterior approximations containing auxil-iary random variables. This enables us to explore a new synthesis of variational infer-ence and Monte Carlo methods where we in-corporate one or more steps of MCMC into our variational approximation. By xxurlng so we obtain a rich class of inference algorithms bridging the gap between variational meth-ods and MCMC, and offering the best of both worlds: fast posterior approximation through the maximization of an explicit ob-jective, with the option of trading off addi-tional computation for additional accuracy. We describe the theoretical foundations that make this possible and show some promising first results.},
author = {Salimans, Tim and Diederik, Algoritmica and Kingma, P and Welling, Max},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salimans et al. - Unknown - Markov Chain Monte Carlo and Variational Inference Bridging the Gap.pdf:pdf},
title = {{Markov Chain Monte Carlo and Variational Inference: Bridging the Gap}},
url = {https://arxiv.org/pdf/1410.6460.pdf}
}
@article{Rezende2014,
abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.},
archivePrefix = {arXiv},
arxivId = {1401.4082},
author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
eprint = {1401.4082},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rezende, Mohamed, Wierstra - 2014 - Stochastic Backpropagation and Approximate Inference in Deep Generative Models.pdf:pdf},
month = {jan},
title = {{Stochastic Backpropagation and Approximate Inference in Deep Generative Models}},
url = {http://arxiv.org/abs/1401.4082},
year = {2014}
}
@article{Rifai2011,
abstract = {We present in this paper a novel approach for training deterministic auto-encoders. We show that by adding a well chosen penalty term to the classical reconstruction cost func-tion, we can achieve results that equal or sur-pass those attained by other regularized auto-encoders as well as denoising auto-encoders on a range of datasets. This penalty term corresponds to the Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input. We show that this penalty term results in a localized space contraction which in turn yields robust fea-tures on the activation layer. Furthermore, we show how this penalty term is related to both regularized auto-encoders and denoising auto-encoders and how it can be seen as a link between deterministic and non-deterministic auto-encoders. We find empirically that this penalty helps to carve a representation that better captures the local directions of varia-tion dictated by the data, corresponding to a lower-dimensional non-linear manifold, while being more invariant to the vast majority of directions orthogonal to the manifold. Fi-nally, we show that by using the learned fea-tures to initialize a MLP, we achieve state of the art classification error on a range of datasets, surpassing other methods of pre-training.},
author = {Rifai, Salah and Vincent, Pascal and Muller, Xavier and Glorot, Xavier and Bengio, Yoshua},
file = {:home/mondal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifai, Muller - 2011 - Contractive Auto-Encoders Explicit Invariance During Feature Extraction.pdf:pdf},
title = {{Contractive Auto-Encoders: Explicit Invariance During Feature Extraction}},
url = {http://www.icml-2011.org/papers/455{\_}icmlpaper.pdf},
year = {2011}
}
@article{Radford2015a,
abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
archivePrefix = {arXiv},
arxivId = {1511.06434},
author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
eprint = {1511.06434},
month = {nov},
title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1511.06434},
year = {2015}
}
